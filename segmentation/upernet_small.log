2023-12-28 06:00:05,744 - mmseg - INFO - Multi-processing start method is `None`
2023-12-28 06:00:05,745 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2023-12-28 06:00:05,745 - mmseg - INFO - OMP num threads is 1
2023-12-28 06:00:05,780 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.2.0
MMCV: 1.5.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.23.0+922e771
------------------------------------------------------------

2023-12-28 06:00:05,780 - mmseg - INFO - Distributed training: True
2023-12-28 06:00:06,239 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='debi_small',
        resume='/data/Next-ViT/nextvit_cls_exp/1208_115909/checkpoint_best.pth'
    ),
    decode_head=dict(
        type='UPerHead',
        in_channels=[64, 128, 256, 512],
        in_index=[0, 1, 2, 3],
        pool_scales=(1, 2, 3, 6),
        channels=512,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=256,
        in_index=2,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = '/data/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='AlignResize', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='AlignResize', keep_ratio=True, size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='AlignResize', keep_ratio=True, size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = False
gpu_multiples = 6e-05
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            rpe_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(type='Fp16OptimizerHook', loss_scale=512.0)
fp16 = dict()
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=3000,
    warmup_ratio=2e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/upernet_512_debi_small_160k'
gpu_ids = range(0, 8)
auto_resume = False

2023-12-28 06:00:13,610 - mmseg - INFO - Set random seed to 16450149, deterministic: False
2023-12-28 06:00:15,642 - mmseg - INFO - initialize UPerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2023-12-28 06:00:15,839 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.downsample_layers.0.0.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.0.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.3.weight - torch.Size([64, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed1.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed2.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.lepe.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.lepe.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.qkv.qkv.weight - torch.Size([192, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.qkv.qkv.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.wo.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.wo.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.rpe_table - torch.Size([2, 111, 111]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.lepe1.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.lepe1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.qkv_conv.qkv.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.qkv_conv.qkv.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_q.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_q.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_k.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_k.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_v.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_out.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_out.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.unifyheads1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.unifyheads1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 9, 9]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed1.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed2.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.lepe.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.lepe.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.qkv.qkv.weight - torch.Size([192, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.qkv.qkv.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.wo.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.wo.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.rpe_table - torch.Size([2, 111, 111]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.lepe1.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.lepe1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.qkv_conv.qkv.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.qkv_conv.qkv.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_q.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_q.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_k.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_k.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_v.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_out.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_out.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.unifyheads1.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.unifyheads1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 9, 9]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm3.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm3.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm4.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm4.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear1.0.weight - torch.Size([192, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear2.0.weight - torch.Size([64, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear2.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.dwc.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.dwc.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed1.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed2.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.lepe.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.lepe.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.qkv.qkv.weight - torch.Size([384, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.qkv.qkv.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.wo.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.wo.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.rpe_table - torch.Size([4, 55, 55]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.lepe1.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.lepe1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.qkv_conv.qkv.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.qkv_conv.qkv.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_q.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_q.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_k.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_k.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_v.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_out.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_out.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.unifyheads1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.unifyheads1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm3.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed1.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed2.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.lepe.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.lepe.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.qkv.qkv.weight - torch.Size([384, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.qkv.qkv.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.wo.weight - torch.Size([128, 128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.wo.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.rpe_table - torch.Size([4, 55, 55]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.lepe1.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.lepe1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.qkv_conv.qkv.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.qkv_conv.qkv.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_q.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_q.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_k.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_k.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_v.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_out.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_out.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.unifyheads1.weight - torch.Size([128, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.unifyheads1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm3.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm3.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm4.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm4.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear1.0.weight - torch.Size([384, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear1.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear2.0.weight - torch.Size([128, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear2.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.dwc.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.dwc.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed1.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed2.weight - torch.Size([256, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.lepe.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.lepe.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.qkv.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.qkv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.wo.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.wo.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.rpe_table - torch.Size([8, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.lepe1.weight - torch.Size([256, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.lepe1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.qkv_conv.qkv.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.qkv_conv.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_q.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_k.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_v.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_out.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.unifyheads1.weight - torch.Size([256, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.unifyheads1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear1.0.weight - torch.Size([768, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear1.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear2.0.weight - torch.Size([256, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.dwc.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.dwc.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed1.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed2.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed1.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed2.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pos_embed1.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pos_embed1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pos_embed2.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pos_embed2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn1.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.rpe_table - torch.Size([16, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.lepe1.weight - torch.Size([512, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.lepe1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.qkv_conv.qkv.weight - torch.Size([1536, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.qkv_conv.qkv.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_q.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_q.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_k.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_k.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_v.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_out.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.proj_out.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.unifyheads1.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.unifyheads1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.conv_offset_q.0.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.conv_offset_q.1.norm.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.conv_offset_q.1.norm.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.conv_offset_q.3.weight - torch.Size([1, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.linear1.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.linear1.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.linear2.0.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.dwc.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.attn2.mlp.dwc.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp1.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.linear1.0.weight - torch.Size([1024, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.linear1.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.linear2.0.weight - torch.Size([512, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.linear2.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.dwc.weight - torch.Size([1024, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.mlp2.dwc.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.0.ln.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.0.ln.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.1.ln.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.1.ln.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.2.ln.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.2.ln.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.3.ln.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.3.ln.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 512, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([512, 2560, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.conv.weight - torch.Size([512, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.conv.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.conv.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.conv.weight - torch.Size([512, 2048, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.fpn_bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-12-28 06:00:15,856 - mmseg - INFO - EncoderDecoder(
  (backbone): debi_small(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU()
        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pos_embed2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=64, out_features=192, bias=True)
            )
            (wo): Linear(in_features=64, out_features=64, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(64, 64, kernel_size=(5, 5), stride=(8, 8), padding=(2, 2), groups=64)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(9, 9), stride=(8, 8), padding=(4, 4), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
            )
          )
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          )
          (drop_path1): Identity()
          (drop_path2): Identity()
          (norm3): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (pos_embed2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=64, out_features=192, bias=True)
            )
            (wo): Linear(in_features=64, out_features=64, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(64, 64, kernel_size=(5, 5), stride=(8, 8), padding=(2, 2), groups=64)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(9, 9), stride=(8, 8), padding=(4, 4), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
            )
          )
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          )
        )
      )
      (1): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pos_embed2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=128, out_features=384, bias=True)
            )
            (wo): Linear(in_features=128, out_features=128, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(128, 128, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), groups=128)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
            )
          )
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (pos_embed2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=128, out_features=384, bias=True)
            )
            (wo): Linear(in_features=128, out_features=128, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(128, 128, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), groups=128)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
            )
          )
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          )
        )
      )
      (2): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (2): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (3): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (4): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (5): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (6): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (7): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
        (8): Block(
          (pos_embed1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (pos_embed2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=256, out_features=768, bias=True)
            )
            (wo): Linear(in_features=256, out_features=256, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
            )
          )
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          )
        )
      )
      (3): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pos_embed2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn1): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pos_embed2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn1): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
        )
        (2): Block(
          (pos_embed1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (pos_embed2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn1): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=512)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
          )
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
        )
      )
    )
    (pre_logits): Identity()
    (extra_norms): ModuleList(
      (0): LayerNorm2d(
        (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (1): LayerNorm2d(
        (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (2): LayerNorm2d(
        (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (3): LayerNorm2d(
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decode_head): UPerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (0): Sequential(
        (0): AdaptiveAvgPool2d(output_size=1)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): AdaptiveAvgPool2d(output_size=2)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): AdaptiveAvgPool2d(output_size=3)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (3): Sequential(
        (0): AdaptiveAvgPool2d(output_size=6)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-12-28 06:00:16,416 - mmseg - INFO - Loaded 20210 images
2023-12-28 06:00:17,926 - mmseg - INFO - Loaded 2000 images
2023-12-28 06:00:17,927 - mmseg - INFO - Start running, host: cuda11py3.9@1082ba884f56, work_dir: /data/Next-ViT/segmentation/work_dirs/upernet_512_debi_small_160k
2023-12-28 06:00:17,927 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-12-28 06:00:17,927 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-12-28 06:00:17,935 - mmseg - INFO - Checkpoints will be saved to /data/Next-ViT/segmentation/work_dirs/upernet_512_debi_small_160k by HardDiskBackend.
2023-12-28 06:01:17,396 - mmseg - INFO - Iter [50/160000]	lr: 9.798e-07, eta: 1 day, 23:06:33, time: 1.060, data_time: 0.014, memory: 15708, decode.loss_ce: 4.0633, decode.acc_seg: 0.7027, aux.loss_ce: 1.6236, aux.acc_seg: 0.8489, loss: 5.6869
2023-12-28 06:01:59,444 - mmseg - INFO - Iter [100/160000]	lr: 1.979e-06, eta: 1 day, 18:13:31, time: 0.841, data_time: 0.013, memory: 15708, decode.loss_ce: 3.9795, decode.acc_seg: 1.6412, aux.loss_ce: 1.5985, aux.acc_seg: 1.0787, loss: 5.5780
2023-12-28 06:02:40,864 - mmseg - INFO - Iter [150/160000]	lr: 2.977e-06, eta: 1 day, 16:25:01, time: 0.829, data_time: 0.012, memory: 15708, decode.loss_ce: 3.9986, decode.acc_seg: 9.9730, aux.loss_ce: 1.6291, aux.acc_seg: 1.7140, loss: 5.6277
2023-12-28 06:03:20,686 - mmseg - INFO - Iter [200/160000]	lr: 3.975e-06, eta: 1 day, 15:08:35, time: 0.797, data_time: 0.012, memory: 15708, decode.loss_ce: 3.8096, decode.acc_seg: 27.2114, aux.loss_ce: 1.5920, aux.acc_seg: 3.4421, loss: 5.4016
2023-12-28 06:04:02,186 - mmseg - INFO - Iter [250/160000]	lr: 4.972e-06, eta: 1 day, 14:40:06, time: 0.830, data_time: 0.012, memory: 15708, decode.loss_ce: 3.6104, decode.acc_seg: 40.3023, aux.loss_ce: 1.5741, aux.acc_seg: 9.3281, loss: 5.1844
2023-12-28 06:04:41,283 - mmseg - INFO - Iter [300/160000]	lr: 5.969e-06, eta: 1 day, 13:59:21, time: 0.781, data_time: 0.011, memory: 15708, decode.loss_ce: 3.3588, decode.acc_seg: 46.5460, aux.loss_ce: 1.5698, aux.acc_seg: 23.4410, loss: 4.9286
2023-12-28 06:05:22,027 - mmseg - INFO - Iter [350/160000]	lr: 6.965e-06, eta: 1 day, 13:42:46, time: 0.815, data_time: 0.011, memory: 15708, decode.loss_ce: 2.9977, decode.acc_seg: 47.2524, aux.loss_ce: 1.4911, aux.acc_seg: 36.2263, loss: 4.4888
2023-12-28 06:06:02,946 - mmseg - INFO - Iter [400/160000]	lr: 7.960e-06, eta: 1 day, 13:31:45, time: 0.819, data_time: 0.012, memory: 15708, decode.loss_ce: 2.9328, decode.acc_seg: 48.2314, aux.loss_ce: 1.4985, aux.acc_seg: 42.4020, loss: 4.4312
2023-12-28 06:06:41,839 - mmseg - INFO - Iter [450/160000]	lr: 8.955e-06, eta: 1 day, 13:10:25, time: 0.777, data_time: 0.012, memory: 15708, decode.loss_ce: 2.7580, decode.acc_seg: 50.7592, aux.loss_ce: 1.4490, aux.acc_seg: 45.2645, loss: 4.2070
2023-12-28 06:07:22,593 - mmseg - INFO - Iter [500/160000]	lr: 9.949e-06, eta: 1 day, 13:03:46, time: 0.816, data_time: 0.013, memory: 15708, decode.loss_ce: 2.5855, decode.acc_seg: 51.0522, aux.loss_ce: 1.3808, aux.acc_seg: 46.3991, loss: 3.9663
2023-12-28 06:08:00,851 - mmseg - INFO - Iter [550/160000]	lr: 1.094e-05, eta: 1 day, 12:45:46, time: 0.765, data_time: 0.012, memory: 15708, decode.loss_ce: 2.4639, decode.acc_seg: 54.4523, aux.loss_ce: 1.3560, aux.acc_seg: 48.1037, loss: 3.8199
2023-12-28 06:08:41,004 - mmseg - INFO - Iter [600/160000]	lr: 1.194e-05, eta: 1 day, 12:38:57, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 2.3074, decode.acc_seg: 55.1228, aux.loss_ce: 1.2882, aux.acc_seg: 48.9728, loss: 3.5956
2023-12-28 06:09:21,981 - mmseg - INFO - Iter [650/160000]	lr: 1.293e-05, eta: 1 day, 12:36:35, time: 0.820, data_time: 0.012, memory: 15708, decode.loss_ce: 2.2509, decode.acc_seg: 56.4051, aux.loss_ce: 1.2672, aux.acc_seg: 50.3597, loss: 3.5181
2023-12-28 06:10:03,137 - mmseg - INFO - Iter [700/160000]	lr: 1.392e-05, eta: 1 day, 12:35:19, time: 0.824, data_time: 0.013, memory: 15708, decode.loss_ce: 2.1696, decode.acc_seg: 57.6169, aux.loss_ce: 1.2303, aux.acc_seg: 51.8497, loss: 3.3999
2023-12-28 06:10:43,417 - mmseg - INFO - Iter [750/160000]	lr: 1.491e-05, eta: 1 day, 12:30:42, time: 0.805, data_time: 0.011, memory: 15708, decode.loss_ce: 2.0479, decode.acc_seg: 57.5556, aux.loss_ce: 1.1680, aux.acc_seg: 51.1071, loss: 3.2159
2023-12-28 06:11:24,001 - mmseg - INFO - Iter [800/160000]	lr: 1.590e-05, eta: 1 day, 12:27:53, time: 0.813, data_time: 0.012, memory: 15708, decode.loss_ce: 1.9445, decode.acc_seg: 57.8365, aux.loss_ce: 1.1165, aux.acc_seg: 50.9793, loss: 3.0610
2023-12-28 06:12:04,127 - mmseg - INFO - Iter [850/160000]	lr: 1.689e-05, eta: 1 day, 12:23:42, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 1.8867, decode.acc_seg: 59.7533, aux.loss_ce: 1.0989, aux.acc_seg: 53.0855, loss: 2.9855
2023-12-28 06:12:44,215 - mmseg - INFO - Iter [900/160000]	lr: 1.788e-05, eta: 1 day, 12:19:52, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 1.9014, decode.acc_seg: 58.1293, aux.loss_ce: 1.0901, aux.acc_seg: 51.4201, loss: 2.9915
2023-12-28 06:13:23,137 - mmseg - INFO - Iter [950/160000]	lr: 1.887e-05, eta: 1 day, 12:12:56, time: 0.777, data_time: 0.012, memory: 15708, decode.loss_ce: 1.7881, decode.acc_seg: 60.2007, aux.loss_ce: 1.0407, aux.acc_seg: 53.4740, loss: 2.8288
2023-12-28 06:14:03,258 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 06:14:03,258 - mmseg - INFO - Iter [1000/160000]	lr: 1.986e-05, eta: 1 day, 12:10:06, time: 0.804, data_time: 0.013, memory: 15708, decode.loss_ce: 1.7639, decode.acc_seg: 59.6952, aux.loss_ce: 1.0024, aux.acc_seg: 52.5269, loss: 2.7663
2023-12-28 06:14:42,458 - mmseg - INFO - Iter [1050/160000]	lr: 2.084e-05, eta: 1 day, 12:05:00, time: 0.784, data_time: 0.012, memory: 15708, decode.loss_ce: 1.6259, decode.acc_seg: 61.5215, aux.loss_ce: 0.9588, aux.acc_seg: 54.0821, loss: 2.5847
2023-12-28 06:15:22,056 - mmseg - INFO - Iter [1100/160000]	lr: 2.183e-05, eta: 1 day, 12:01:09, time: 0.791, data_time: 0.011, memory: 15708, decode.loss_ce: 1.5706, decode.acc_seg: 62.0340, aux.loss_ce: 0.9184, aux.acc_seg: 53.7713, loss: 2.4890
2023-12-28 06:16:02,961 - mmseg - INFO - Iter [1150/160000]	lr: 2.282e-05, eta: 1 day, 12:00:51, time: 0.819, data_time: 0.013, memory: 15708, decode.loss_ce: 1.6240, decode.acc_seg: 60.1146, aux.loss_ce: 0.9309, aux.acc_seg: 52.5997, loss: 2.5549
2023-12-28 06:16:42,669 - mmseg - INFO - Iter [1200/160000]	lr: 2.380e-05, eta: 1 day, 11:57:42, time: 0.794, data_time: 0.011, memory: 15708, decode.loss_ce: 1.5861, decode.acc_seg: 60.6409, aux.loss_ce: 0.8982, aux.acc_seg: 51.7884, loss: 2.4843
2023-12-28 06:17:22,885 - mmseg - INFO - Iter [1250/160000]	lr: 2.479e-05, eta: 1 day, 11:55:48, time: 0.804, data_time: 0.011, memory: 15708, decode.loss_ce: 1.4723, decode.acc_seg: 62.4752, aux.loss_ce: 0.8466, aux.acc_seg: 54.9016, loss: 2.3189
2023-12-28 06:18:04,939 - mmseg - INFO - Iter [1300/160000]	lr: 2.577e-05, eta: 1 day, 11:57:46, time: 0.841, data_time: 0.053, memory: 15708, decode.loss_ce: 1.4679, decode.acc_seg: 62.1151, aux.loss_ce: 0.8390, aux.acc_seg: 53.2873, loss: 2.3069
2023-12-28 06:18:44,996 - mmseg - INFO - Iter [1350/160000]	lr: 2.675e-05, eta: 1 day, 11:55:46, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 1.4033, decode.acc_seg: 63.8185, aux.loss_ce: 0.7989, aux.acc_seg: 55.5456, loss: 2.2023
2023-12-28 06:19:22,908 - mmseg - INFO - Iter [1400/160000]	lr: 2.774e-05, eta: 1 day, 11:49:43, time: 0.758, data_time: 0.011, memory: 15708, decode.loss_ce: 1.4054, decode.acc_seg: 63.1444, aux.loss_ce: 0.7915, aux.acc_seg: 55.5157, loss: 2.1970
2023-12-28 06:20:03,151 - mmseg - INFO - Iter [1450/160000]	lr: 2.872e-05, eta: 1 day, 11:48:11, time: 0.804, data_time: 0.010, memory: 15708, decode.loss_ce: 1.3494, decode.acc_seg: 64.1807, aux.loss_ce: 0.7542, aux.acc_seg: 57.8436, loss: 2.1036
2023-12-28 06:20:43,167 - mmseg - INFO - Iter [1500/160000]	lr: 2.970e-05, eta: 1 day, 11:46:29, time: 0.801, data_time: 0.012, memory: 15708, decode.loss_ce: 1.3974, decode.acc_seg: 62.9495, aux.loss_ce: 0.7585, aux.acc_seg: 56.6884, loss: 2.1559
2023-12-28 06:21:22,455 - mmseg - INFO - Iter [1550/160000]	lr: 3.068e-05, eta: 1 day, 11:43:30, time: 0.785, data_time: 0.011, memory: 15708, decode.loss_ce: 1.3549, decode.acc_seg: 63.8680, aux.loss_ce: 0.7485, aux.acc_seg: 56.5685, loss: 2.1034
2023-12-28 06:22:01,584 - mmseg - INFO - Iter [1600/160000]	lr: 3.166e-05, eta: 1 day, 11:40:20, time: 0.782, data_time: 0.011, memory: 15708, decode.loss_ce: 1.3028, decode.acc_seg: 64.0779, aux.loss_ce: 0.7150, aux.acc_seg: 57.6314, loss: 2.0178
2023-12-28 06:22:43,243 - mmseg - INFO - Iter [1650/160000]	lr: 3.264e-05, eta: 1 day, 11:41:27, time: 0.833, data_time: 0.011, memory: 15708, decode.loss_ce: 1.3352, decode.acc_seg: 64.2934, aux.loss_ce: 0.7162, aux.acc_seg: 57.3087, loss: 2.0514
2023-12-28 06:23:24,307 - mmseg - INFO - Iter [1700/160000]	lr: 3.362e-05, eta: 1 day, 11:41:33, time: 0.821, data_time: 0.012, memory: 15708, decode.loss_ce: 1.3237, decode.acc_seg: 64.0780, aux.loss_ce: 0.7076, aux.acc_seg: 58.1372, loss: 2.0313
2023-12-28 06:24:04,365 - mmseg - INFO - Iter [1750/160000]	lr: 3.460e-05, eta: 1 day, 11:40:03, time: 0.801, data_time: 0.013, memory: 15708, decode.loss_ce: 1.2926, decode.acc_seg: 64.2289, aux.loss_ce: 0.6834, aux.acc_seg: 57.3966, loss: 1.9760
2023-12-28 06:24:43,953 - mmseg - INFO - Iter [1800/160000]	lr: 3.558e-05, eta: 1 day, 11:37:57, time: 0.792, data_time: 0.012, memory: 15708, decode.loss_ce: 1.2475, decode.acc_seg: 65.0110, aux.loss_ce: 0.6659, aux.acc_seg: 58.1483, loss: 1.9134
2023-12-28 06:25:24,415 - mmseg - INFO - Iter [1850/160000]	lr: 3.655e-05, eta: 1 day, 11:37:10, time: 0.809, data_time: 0.012, memory: 15708, decode.loss_ce: 1.3047, decode.acc_seg: 64.2653, aux.loss_ce: 0.6797, aux.acc_seg: 57.5743, loss: 1.9844
2023-12-28 06:26:04,491 - mmseg - INFO - Iter [1900/160000]	lr: 3.753e-05, eta: 1 day, 11:35:51, time: 0.801, data_time: 0.012, memory: 15708, decode.loss_ce: 1.2071, decode.acc_seg: 65.5678, aux.loss_ce: 0.6390, aux.acc_seg: 59.5809, loss: 1.8461
2023-12-28 06:26:45,360 - mmseg - INFO - Iter [1950/160000]	lr: 3.851e-05, eta: 1 day, 11:35:38, time: 0.818, data_time: 0.011, memory: 15708, decode.loss_ce: 1.2021, decode.acc_seg: 65.5895, aux.loss_ce: 0.6219, aux.acc_seg: 60.2926, loss: 1.8240
2023-12-28 06:27:24,070 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 06:27:24,071 - mmseg - INFO - Iter [2000/160000]	lr: 3.948e-05, eta: 1 day, 11:32:38, time: 0.775, data_time: 0.012, memory: 15708, decode.loss_ce: 1.1774, decode.acc_seg: 66.0864, aux.loss_ce: 0.6101, aux.acc_seg: 60.0857, loss: 1.7875
2023-12-28 06:28:04,042 - mmseg - INFO - Iter [2050/160000]	lr: 4.046e-05, eta: 1 day, 11:31:12, time: 0.798, data_time: 0.012, memory: 15708, decode.loss_ce: 1.1604, decode.acc_seg: 66.8892, aux.loss_ce: 0.6039, aux.acc_seg: 60.9736, loss: 1.7643
2023-12-28 06:28:44,732 - mmseg - INFO - Iter [2100/160000]	lr: 4.143e-05, eta: 1 day, 11:30:47, time: 0.814, data_time: 0.011, memory: 15708, decode.loss_ce: 1.1534, decode.acc_seg: 66.5141, aux.loss_ce: 0.5989, aux.acc_seg: 61.0135, loss: 1.7523
2023-12-28 06:29:25,789 - mmseg - INFO - Iter [2150/160000]	lr: 4.240e-05, eta: 1 day, 11:30:49, time: 0.821, data_time: 0.012, memory: 15708, decode.loss_ce: 1.1546, decode.acc_seg: 66.9956, aux.loss_ce: 0.5984, aux.acc_seg: 61.2790, loss: 1.7530
2023-12-28 06:30:05,907 - mmseg - INFO - Iter [2200/160000]	lr: 4.338e-05, eta: 1 day, 11:29:42, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 1.1154, decode.acc_seg: 66.8293, aux.loss_ce: 0.5666, aux.acc_seg: 62.9366, loss: 1.6820
2023-12-28 06:30:46,859 - mmseg - INFO - Iter [2250/160000]	lr: 4.435e-05, eta: 1 day, 11:29:33, time: 0.819, data_time: 0.011, memory: 15708, decode.loss_ce: 1.1246, decode.acc_seg: 67.5230, aux.loss_ce: 0.5702, aux.acc_seg: 62.9316, loss: 1.6948
2023-12-28 06:31:25,206 - mmseg - INFO - Iter [2300/160000]	lr: 4.532e-05, eta: 1 day, 11:26:29, time: 0.768, data_time: 0.012, memory: 15708, decode.loss_ce: 1.0871, decode.acc_seg: 67.7577, aux.loss_ce: 0.5655, aux.acc_seg: 62.9176, loss: 1.6526
2023-12-28 06:32:06,176 - mmseg - INFO - Iter [2350/160000]	lr: 4.629e-05, eta: 1 day, 11:26:20, time: 0.818, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0689, decode.acc_seg: 67.9633, aux.loss_ce: 0.5383, aux.acc_seg: 63.9079, loss: 1.6071
2023-12-28 06:32:45,447 - mmseg - INFO - Iter [2400/160000]	lr: 4.726e-05, eta: 1 day, 11:24:24, time: 0.786, data_time: 0.012, memory: 15708, decode.loss_ce: 1.0937, decode.acc_seg: 66.6889, aux.loss_ce: 0.5450, aux.acc_seg: 62.9452, loss: 1.6387
2023-12-28 06:33:23,428 - mmseg - INFO - Iter [2450/160000]	lr: 4.823e-05, eta: 1 day, 11:21:02, time: 0.758, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0849, decode.acc_seg: 67.1323, aux.loss_ce: 0.5485, aux.acc_seg: 62.6453, loss: 1.6334
2023-12-28 06:34:02,991 - mmseg - INFO - Iter [2500/160000]	lr: 4.920e-05, eta: 1 day, 11:19:33, time: 0.792, data_time: 0.012, memory: 15708, decode.loss_ce: 1.1138, decode.acc_seg: 67.0124, aux.loss_ce: 0.5595, aux.acc_seg: 63.2282, loss: 1.6733
2023-12-28 06:34:42,721 - mmseg - INFO - Iter [2550/160000]	lr: 5.017e-05, eta: 1 day, 11:18:14, time: 0.795, data_time: 0.053, memory: 15708, decode.loss_ce: 1.0488, decode.acc_seg: 67.6120, aux.loss_ce: 0.5344, aux.acc_seg: 63.8367, loss: 1.5833
2023-12-28 06:35:21,920 - mmseg - INFO - Iter [2600/160000]	lr: 5.114e-05, eta: 1 day, 11:16:23, time: 0.784, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0049, decode.acc_seg: 68.9471, aux.loss_ce: 0.5165, aux.acc_seg: 64.2794, loss: 1.5214
2023-12-28 06:36:01,010 - mmseg - INFO - Iter [2650/160000]	lr: 5.210e-05, eta: 1 day, 11:14:28, time: 0.782, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0598, decode.acc_seg: 67.5223, aux.loss_ce: 0.5364, aux.acc_seg: 63.5409, loss: 1.5962
2023-12-28 06:36:40,447 - mmseg - INFO - Iter [2700/160000]	lr: 5.307e-05, eta: 1 day, 11:12:56, time: 0.789, data_time: 0.012, memory: 15708, decode.loss_ce: 0.9510, decode.acc_seg: 70.8042, aux.loss_ce: 0.4856, aux.acc_seg: 66.5043, loss: 1.4367
2023-12-28 06:37:19,088 - mmseg - INFO - Iter [2750/160000]	lr: 5.404e-05, eta: 1 day, 11:10:41, time: 0.773, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0330, decode.acc_seg: 67.7227, aux.loss_ce: 0.5247, aux.acc_seg: 62.6980, loss: 1.5577
2023-12-28 06:37:57,612 - mmseg - INFO - Iter [2800/160000]	lr: 5.500e-05, eta: 1 day, 11:08:21, time: 0.770, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0136, decode.acc_seg: 67.9943, aux.loss_ce: 0.5014, aux.acc_seg: 64.1615, loss: 1.5151
2023-12-28 06:38:37,077 - mmseg - INFO - Iter [2850/160000]	lr: 5.597e-05, eta: 1 day, 11:07:01, time: 0.790, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9203, decode.acc_seg: 70.4095, aux.loss_ce: 0.4647, aux.acc_seg: 65.7912, loss: 1.3850
2023-12-28 06:39:14,953 - mmseg - INFO - Iter [2900/160000]	lr: 5.693e-05, eta: 1 day, 11:04:13, time: 0.757, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0257, decode.acc_seg: 67.9728, aux.loss_ce: 0.5016, aux.acc_seg: 64.3818, loss: 1.5273
2023-12-28 06:39:52,586 - mmseg - INFO - Iter [2950/160000]	lr: 5.789e-05, eta: 1 day, 11:01:17, time: 0.752, data_time: 0.010, memory: 15708, decode.loss_ce: 0.9525, decode.acc_seg: 69.5139, aux.loss_ce: 0.4755, aux.acc_seg: 65.9105, loss: 1.4279
2023-12-28 06:40:33,352 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 06:40:33,352 - mmseg - INFO - Iter [3000/160000]	lr: 5.886e-05, eta: 1 day, 11:01:10, time: 0.816, data_time: 0.012, memory: 15708, decode.loss_ce: 0.9332, decode.acc_seg: 68.9930, aux.loss_ce: 0.4665, aux.acc_seg: 65.4676, loss: 1.3997
2023-12-28 06:41:12,211 - mmseg - INFO - Iter [3050/160000]	lr: 5.886e-05, eta: 1 day, 10:59:20, time: 0.776, data_time: 0.010, memory: 15708, decode.loss_ce: 1.0154, decode.acc_seg: 68.9436, aux.loss_ce: 0.5139, aux.acc_seg: 64.8687, loss: 1.5294
2023-12-28 06:41:51,419 - mmseg - INFO - Iter [3100/160000]	lr: 5.884e-05, eta: 1 day, 10:57:56, time: 0.785, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9747, decode.acc_seg: 69.6587, aux.loss_ce: 0.4780, aux.acc_seg: 66.1960, loss: 1.4527
2023-12-28 06:42:31,412 - mmseg - INFO - Iter [3150/160000]	lr: 5.882e-05, eta: 1 day, 10:57:08, time: 0.799, data_time: 0.011, memory: 15708, decode.loss_ce: 1.0112, decode.acc_seg: 67.0180, aux.loss_ce: 0.4974, aux.acc_seg: 63.2095, loss: 1.5087
2023-12-28 06:43:11,521 - mmseg - INFO - Iter [3200/160000]	lr: 5.880e-05, eta: 1 day, 10:56:28, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9387, decode.acc_seg: 69.5020, aux.loss_ce: 0.4681, aux.acc_seg: 66.3628, loss: 1.4069
2023-12-28 06:43:49,461 - mmseg - INFO - Iter [3250/160000]	lr: 5.878e-05, eta: 1 day, 10:54:03, time: 0.759, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9357, decode.acc_seg: 70.3354, aux.loss_ce: 0.4592, aux.acc_seg: 67.2089, loss: 1.3949
2023-12-28 06:44:28,234 - mmseg - INFO - Iter [3300/160000]	lr: 5.876e-05, eta: 1 day, 10:52:20, time: 0.775, data_time: 0.012, memory: 15708, decode.loss_ce: 0.9391, decode.acc_seg: 69.8646, aux.loss_ce: 0.4643, aux.acc_seg: 66.9922, loss: 1.4035
2023-12-28 06:45:08,767 - mmseg - INFO - Iter [3350/160000]	lr: 5.874e-05, eta: 1 day, 10:52:03, time: 0.811, data_time: 0.012, memory: 15708, decode.loss_ce: 0.9273, decode.acc_seg: 70.3592, aux.loss_ce: 0.4535, aux.acc_seg: 66.6734, loss: 1.3808
2023-12-28 06:45:49,401 - mmseg - INFO - Iter [3400/160000]	lr: 5.873e-05, eta: 1 day, 10:51:49, time: 0.813, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9403, decode.acc_seg: 69.3424, aux.loss_ce: 0.4624, aux.acc_seg: 65.7570, loss: 1.4027
2023-12-28 06:46:29,400 - mmseg - INFO - Iter [3450/160000]	lr: 5.871e-05, eta: 1 day, 10:51:06, time: 0.800, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9154, decode.acc_seg: 69.7250, aux.loss_ce: 0.4459, aux.acc_seg: 66.1758, loss: 1.3613
2023-12-28 06:47:09,388 - mmseg - INFO - Iter [3500/160000]	lr: 5.869e-05, eta: 1 day, 10:50:22, time: 0.800, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8828, decode.acc_seg: 70.6141, aux.loss_ce: 0.4368, aux.acc_seg: 67.5343, loss: 1.3196
2023-12-28 06:47:47,476 - mmseg - INFO - Iter [3550/160000]	lr: 5.867e-05, eta: 1 day, 10:48:16, time: 0.762, data_time: 0.011, memory: 15708, decode.loss_ce: 0.9479, decode.acc_seg: 69.4052, aux.loss_ce: 0.4704, aux.acc_seg: 65.7085, loss: 1.4183
2023-12-28 06:48:27,615 - mmseg - INFO - Iter [3600/160000]	lr: 5.865e-05, eta: 1 day, 10:47:38, time: 0.802, data_time: 0.010, memory: 15708, decode.loss_ce: 0.8875, decode.acc_seg: 71.2105, aux.loss_ce: 0.4372, aux.acc_seg: 67.2067, loss: 1.3247
2023-12-28 06:49:07,757 - mmseg - INFO - Iter [3650/160000]	lr: 5.863e-05, eta: 1 day, 10:47:02, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8863, decode.acc_seg: 70.8674, aux.loss_ce: 0.4335, aux.acc_seg: 67.3387, loss: 1.3198
2023-12-28 06:49:48,333 - mmseg - INFO - Iter [3700/160000]	lr: 5.861e-05, eta: 1 day, 10:46:45, time: 0.812, data_time: 0.012, memory: 15708, decode.loss_ce: 0.9186, decode.acc_seg: 69.6926, aux.loss_ce: 0.4495, aux.acc_seg: 66.2618, loss: 1.3681
2023-12-28 06:50:28,018 - mmseg - INFO - Iter [3750/160000]	lr: 5.859e-05, eta: 1 day, 10:45:52, time: 0.795, data_time: 0.013, memory: 15708, decode.loss_ce: 0.9083, decode.acc_seg: 70.6557, aux.loss_ce: 0.4446, aux.acc_seg: 67.3997, loss: 1.3529
2023-12-28 06:51:09,378 - mmseg - INFO - Iter [3800/160000]	lr: 5.858e-05, eta: 1 day, 10:46:03, time: 0.826, data_time: 0.053, memory: 15708, decode.loss_ce: 0.8618, decode.acc_seg: 71.2739, aux.loss_ce: 0.4230, aux.acc_seg: 67.9455, loss: 1.2848
2023-12-28 06:51:49,503 - mmseg - INFO - Iter [3850/160000]	lr: 5.856e-05, eta: 1 day, 10:45:26, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8366, decode.acc_seg: 72.1255, aux.loss_ce: 0.4140, aux.acc_seg: 68.4130, loss: 1.2507
2023-12-28 06:52:29,619 - mmseg - INFO - Iter [3900/160000]	lr: 5.854e-05, eta: 1 day, 10:44:50, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8286, decode.acc_seg: 71.4639, aux.loss_ce: 0.4093, aux.acc_seg: 68.2966, loss: 1.2379
2023-12-28 06:53:09,009 - mmseg - INFO - Iter [3950/160000]	lr: 5.852e-05, eta: 1 day, 10:43:41, time: 0.787, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8352, decode.acc_seg: 71.9588, aux.loss_ce: 0.4129, aux.acc_seg: 68.3125, loss: 1.2481
2023-12-28 06:53:48,045 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 06:53:48,046 - mmseg - INFO - Iter [4000/160000]	lr: 5.850e-05, eta: 1 day, 10:42:23, time: 0.782, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8674, decode.acc_seg: 71.3538, aux.loss_ce: 0.4268, aux.acc_seg: 68.0152, loss: 1.2942
2023-12-28 06:54:25,832 - mmseg - INFO - Iter [4050/160000]	lr: 5.848e-05, eta: 1 day, 10:40:14, time: 0.755, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8408, decode.acc_seg: 71.9260, aux.loss_ce: 0.4108, aux.acc_seg: 68.4609, loss: 1.2517
2023-12-28 06:55:04,797 - mmseg - INFO - Iter [4100/160000]	lr: 5.846e-05, eta: 1 day, 10:38:56, time: 0.780, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8082, decode.acc_seg: 73.0104, aux.loss_ce: 0.3962, aux.acc_seg: 69.8701, loss: 1.2044
2023-12-28 06:55:44,192 - mmseg - INFO - Iter [4150/160000]	lr: 5.844e-05, eta: 1 day, 10:37:52, time: 0.788, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8554, decode.acc_seg: 71.1223, aux.loss_ce: 0.4226, aux.acc_seg: 67.3392, loss: 1.2780
2023-12-28 06:56:23,363 - mmseg - INFO - Iter [4200/160000]	lr: 5.843e-05, eta: 1 day, 10:36:41, time: 0.783, data_time: 0.010, memory: 15708, decode.loss_ce: 0.8116, decode.acc_seg: 72.7783, aux.loss_ce: 0.3989, aux.acc_seg: 69.4204, loss: 1.2105
2023-12-28 06:57:00,992 - mmseg - INFO - Iter [4250/160000]	lr: 5.841e-05, eta: 1 day, 10:34:36, time: 0.753, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8355, decode.acc_seg: 71.9444, aux.loss_ce: 0.4158, aux.acc_seg: 67.6216, loss: 1.2514
2023-12-28 06:57:39,124 - mmseg - INFO - Iter [4300/160000]	lr: 5.839e-05, eta: 1 day, 10:32:48, time: 0.762, data_time: 0.010, memory: 15708, decode.loss_ce: 0.7738, decode.acc_seg: 73.2104, aux.loss_ce: 0.3826, aux.acc_seg: 69.7688, loss: 1.1564
2023-12-28 06:58:19,213 - mmseg - INFO - Iter [4350/160000]	lr: 5.837e-05, eta: 1 day, 10:32:12, time: 0.801, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8080, decode.acc_seg: 72.3191, aux.loss_ce: 0.3914, aux.acc_seg: 68.6895, loss: 1.1994
2023-12-28 06:58:59,823 - mmseg - INFO - Iter [4400/160000]	lr: 5.835e-05, eta: 1 day, 10:31:59, time: 0.814, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8219, decode.acc_seg: 72.5185, aux.loss_ce: 0.3983, aux.acc_seg: 69.0016, loss: 1.2202
2023-12-28 06:59:38,210 - mmseg - INFO - Iter [4450/160000]	lr: 5.833e-05, eta: 1 day, 10:30:23, time: 0.767, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7733, decode.acc_seg: 73.3870, aux.loss_ce: 0.3860, aux.acc_seg: 70.0572, loss: 1.1594
2023-12-28 07:00:18,560 - mmseg - INFO - Iter [4500/160000]	lr: 5.831e-05, eta: 1 day, 10:29:57, time: 0.807, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7856, decode.acc_seg: 73.6591, aux.loss_ce: 0.3780, aux.acc_seg: 70.9414, loss: 1.1635
2023-12-28 07:00:59,672 - mmseg - INFO - Iter [4550/160000]	lr: 5.829e-05, eta: 1 day, 10:29:59, time: 0.823, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8319, decode.acc_seg: 72.4225, aux.loss_ce: 0.4073, aux.acc_seg: 69.2242, loss: 1.2391
2023-12-28 07:01:39,551 - mmseg - INFO - Iter [4600/160000]	lr: 5.828e-05, eta: 1 day, 10:29:15, time: 0.797, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8114, decode.acc_seg: 72.0915, aux.loss_ce: 0.3884, aux.acc_seg: 69.0226, loss: 1.1998
2023-12-28 07:02:20,598 - mmseg - INFO - Iter [4650/160000]	lr: 5.826e-05, eta: 1 day, 10:29:11, time: 0.821, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7103, decode.acc_seg: 75.8806, aux.loss_ce: 0.3468, aux.acc_seg: 72.6974, loss: 1.0571
2023-12-28 07:03:01,894 - mmseg - INFO - Iter [4700/160000]	lr: 5.824e-05, eta: 1 day, 10:29:16, time: 0.826, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8551, decode.acc_seg: 71.3950, aux.loss_ce: 0.4119, aux.acc_seg: 68.3002, loss: 1.2670
2023-12-28 07:03:41,862 - mmseg - INFO - Iter [4750/160000]	lr: 5.822e-05, eta: 1 day, 10:28:37, time: 0.801, data_time: 0.013, memory: 15708, decode.loss_ce: 0.8634, decode.acc_seg: 70.5373, aux.loss_ce: 0.4183, aux.acc_seg: 66.8206, loss: 1.2817
2023-12-28 07:04:21,729 - mmseg - INFO - Iter [4800/160000]	lr: 5.820e-05, eta: 1 day, 10:27:52, time: 0.796, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7721, decode.acc_seg: 73.2267, aux.loss_ce: 0.3757, aux.acc_seg: 69.3171, loss: 1.1478
2023-12-28 07:05:01,374 - mmseg - INFO - Iter [4850/160000]	lr: 5.818e-05, eta: 1 day, 10:27:03, time: 0.794, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7780, decode.acc_seg: 73.4612, aux.loss_ce: 0.3838, aux.acc_seg: 69.7915, loss: 1.1617
2023-12-28 07:05:42,228 - mmseg - INFO - Iter [4900/160000]	lr: 5.816e-05, eta: 1 day, 10:26:50, time: 0.816, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7810, decode.acc_seg: 73.0482, aux.loss_ce: 0.3765, aux.acc_seg: 69.6586, loss: 1.1574
2023-12-28 07:06:22,408 - mmseg - INFO - Iter [4950/160000]	lr: 5.814e-05, eta: 1 day, 10:26:16, time: 0.804, data_time: 0.011, memory: 15708, decode.loss_ce: 0.8107, decode.acc_seg: 72.0907, aux.loss_ce: 0.3893, aux.acc_seg: 68.6080, loss: 1.2000
2023-12-28 07:07:01,712 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 07:07:01,713 - mmseg - INFO - Iter [5000/160000]	lr: 5.813e-05, eta: 1 day, 10:25:15, time: 0.786, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7873, decode.acc_seg: 72.8093, aux.loss_ce: 0.3731, aux.acc_seg: 70.0758, loss: 1.1604
2023-12-28 07:07:42,176 - mmseg - INFO - Iter [5050/160000]	lr: 5.811e-05, eta: 1 day, 10:24:52, time: 0.811, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7529, decode.acc_seg: 73.3541, aux.loss_ce: 0.3608, aux.acc_seg: 69.9958, loss: 1.1137
2023-12-28 07:08:22,657 - mmseg - INFO - Iter [5100/160000]	lr: 5.809e-05, eta: 1 day, 10:24:25, time: 0.809, data_time: 0.052, memory: 15708, decode.loss_ce: 0.7901, decode.acc_seg: 73.0915, aux.loss_ce: 0.3797, aux.acc_seg: 70.1858, loss: 1.1698
2023-12-28 07:09:02,016 - mmseg - INFO - Iter [5150/160000]	lr: 5.807e-05, eta: 1 day, 10:23:27, time: 0.787, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7468, decode.acc_seg: 74.0069, aux.loss_ce: 0.3680, aux.acc_seg: 70.3231, loss: 1.1148
2023-12-28 07:09:44,401 - mmseg - INFO - Iter [5200/160000]	lr: 5.805e-05, eta: 1 day, 10:23:59, time: 0.848, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7255, decode.acc_seg: 74.5049, aux.loss_ce: 0.3551, aux.acc_seg: 71.1008, loss: 1.0806
2023-12-28 07:10:27,366 - mmseg - INFO - Iter [5250/160000]	lr: 5.803e-05, eta: 1 day, 10:24:46, time: 0.859, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7328, decode.acc_seg: 74.1163, aux.loss_ce: 0.3507, aux.acc_seg: 71.1236, loss: 1.0834
2023-12-28 07:11:06,033 - mmseg - INFO - Iter [5300/160000]	lr: 5.801e-05, eta: 1 day, 10:23:26, time: 0.774, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7358, decode.acc_seg: 74.3983, aux.loss_ce: 0.3644, aux.acc_seg: 70.8592, loss: 1.1002
2023-12-28 07:11:44,490 - mmseg - INFO - Iter [5350/160000]	lr: 5.799e-05, eta: 1 day, 10:22:02, time: 0.770, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7660, decode.acc_seg: 73.5496, aux.loss_ce: 0.3676, aux.acc_seg: 70.8929, loss: 1.1336
2023-12-28 07:12:25,617 - mmseg - INFO - Iter [5400/160000]	lr: 5.798e-05, eta: 1 day, 10:21:53, time: 0.821, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7542, decode.acc_seg: 73.9741, aux.loss_ce: 0.3650, aux.acc_seg: 70.3855, loss: 1.1192
2023-12-28 07:13:04,987 - mmseg - INFO - Iter [5450/160000]	lr: 5.796e-05, eta: 1 day, 10:20:55, time: 0.788, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7905, decode.acc_seg: 71.7094, aux.loss_ce: 0.3749, aux.acc_seg: 68.8567, loss: 1.1654
2023-12-28 07:13:42,934 - mmseg - INFO - Iter [5500/160000]	lr: 5.794e-05, eta: 1 day, 10:19:19, time: 0.760, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7288, decode.acc_seg: 74.4494, aux.loss_ce: 0.3501, aux.acc_seg: 71.1204, loss: 1.0789
2023-12-28 07:14:23,956 - mmseg - INFO - Iter [5550/160000]	lr: 5.792e-05, eta: 1 day, 10:19:08, time: 0.821, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7355, decode.acc_seg: 74.2798, aux.loss_ce: 0.3532, aux.acc_seg: 71.0166, loss: 1.0887
2023-12-28 07:15:04,364 - mmseg - INFO - Iter [5600/160000]	lr: 5.790e-05, eta: 1 day, 10:18:39, time: 0.808, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7431, decode.acc_seg: 73.4884, aux.loss_ce: 0.3547, aux.acc_seg: 70.3294, loss: 1.0978
2023-12-28 07:15:45,008 - mmseg - INFO - Iter [5650/160000]	lr: 5.788e-05, eta: 1 day, 10:18:17, time: 0.813, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7598, decode.acc_seg: 72.0905, aux.loss_ce: 0.3622, aux.acc_seg: 69.6217, loss: 1.1220
2023-12-28 07:16:23,291 - mmseg - INFO - Iter [5700/160000]	lr: 5.786e-05, eta: 1 day, 10:16:50, time: 0.765, data_time: 0.012, memory: 15708, decode.loss_ce: 0.8072, decode.acc_seg: 72.0686, aux.loss_ce: 0.3751, aux.acc_seg: 69.4370, loss: 1.1823
2023-12-28 07:17:03,344 - mmseg - INFO - Iter [5750/160000]	lr: 5.784e-05, eta: 1 day, 10:16:10, time: 0.800, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7493, decode.acc_seg: 74.1876, aux.loss_ce: 0.3548, aux.acc_seg: 71.3406, loss: 1.1042
2023-12-28 07:17:44,481 - mmseg - INFO - Iter [5800/160000]	lr: 5.783e-05, eta: 1 day, 10:16:00, time: 0.823, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7593, decode.acc_seg: 74.0390, aux.loss_ce: 0.3558, aux.acc_seg: 70.6616, loss: 1.1152
2023-12-28 07:18:25,645 - mmseg - INFO - Iter [5850/160000]	lr: 5.781e-05, eta: 1 day, 10:15:51, time: 0.823, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7656, decode.acc_seg: 73.3298, aux.loss_ce: 0.3625, aux.acc_seg: 70.7659, loss: 1.1281
2023-12-28 07:19:06,388 - mmseg - INFO - Iter [5900/160000]	lr: 5.779e-05, eta: 1 day, 10:15:31, time: 0.815, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7180, decode.acc_seg: 74.3399, aux.loss_ce: 0.3404, aux.acc_seg: 71.9127, loss: 1.0583
2023-12-28 07:19:45,282 - mmseg - INFO - Iter [5950/160000]	lr: 5.777e-05, eta: 1 day, 10:14:23, time: 0.779, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7423, decode.acc_seg: 73.9457, aux.loss_ce: 0.3537, aux.acc_seg: 70.7401, loss: 1.0959
2023-12-28 07:20:25,562 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 07:20:25,562 - mmseg - INFO - Iter [6000/160000]	lr: 5.775e-05, eta: 1 day, 10:13:50, time: 0.806, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7092, decode.acc_seg: 75.4116, aux.loss_ce: 0.3302, aux.acc_seg: 73.0017, loss: 1.0395
2023-12-28 07:21:06,914 - mmseg - INFO - Iter [6050/160000]	lr: 5.773e-05, eta: 1 day, 10:13:42, time: 0.826, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7289, decode.acc_seg: 74.5494, aux.loss_ce: 0.3402, aux.acc_seg: 71.5253, loss: 1.0691
2023-12-28 07:21:48,112 - mmseg - INFO - Iter [6100/160000]	lr: 5.771e-05, eta: 1 day, 10:13:32, time: 0.824, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7335, decode.acc_seg: 74.4557, aux.loss_ce: 0.3530, aux.acc_seg: 71.1010, loss: 1.0866
2023-12-28 07:22:28,610 - mmseg - INFO - Iter [6150/160000]	lr: 5.769e-05, eta: 1 day, 10:13:04, time: 0.810, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7114, decode.acc_seg: 74.6945, aux.loss_ce: 0.3347, aux.acc_seg: 71.9169, loss: 1.0461
2023-12-28 07:23:09,575 - mmseg - INFO - Iter [6200/160000]	lr: 5.768e-05, eta: 1 day, 10:12:47, time: 0.819, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7000, decode.acc_seg: 74.9885, aux.loss_ce: 0.3317, aux.acc_seg: 71.6547, loss: 1.0317
2023-12-28 07:23:49,352 - mmseg - INFO - Iter [6250/160000]	lr: 5.766e-05, eta: 1 day, 10:12:02, time: 0.797, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7574, decode.acc_seg: 73.4370, aux.loss_ce: 0.3568, aux.acc_seg: 71.0801, loss: 1.1142
2023-12-28 07:24:27,169 - mmseg - INFO - Iter [6300/160000]	lr: 5.764e-05, eta: 1 day, 10:10:27, time: 0.756, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7185, decode.acc_seg: 74.2390, aux.loss_ce: 0.3371, aux.acc_seg: 72.0297, loss: 1.0556
2023-12-28 07:25:08,677 - mmseg - INFO - Iter [6350/160000]	lr: 5.762e-05, eta: 1 day, 10:10:23, time: 0.830, data_time: 0.053, memory: 15708, decode.loss_ce: 0.7154, decode.acc_seg: 74.7820, aux.loss_ce: 0.3378, aux.acc_seg: 72.1867, loss: 1.0532
2023-12-28 07:25:50,927 - mmseg - INFO - Iter [6400/160000]	lr: 5.760e-05, eta: 1 day, 10:10:36, time: 0.845, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7109, decode.acc_seg: 73.8732, aux.loss_ce: 0.3346, aux.acc_seg: 71.3923, loss: 1.0455
2023-12-28 07:26:32,899 - mmseg - INFO - Iter [6450/160000]	lr: 5.758e-05, eta: 1 day, 10:10:42, time: 0.839, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7334, decode.acc_seg: 74.2856, aux.loss_ce: 0.3502, aux.acc_seg: 71.3205, loss: 1.0836
2023-12-28 07:27:14,311 - mmseg - INFO - Iter [6500/160000]	lr: 5.756e-05, eta: 1 day, 10:10:34, time: 0.828, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6938, decode.acc_seg: 74.9481, aux.loss_ce: 0.3288, aux.acc_seg: 72.0412, loss: 1.0226
2023-12-28 07:27:53,483 - mmseg - INFO - Iter [6550/160000]	lr: 5.754e-05, eta: 1 day, 10:09:31, time: 0.782, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7191, decode.acc_seg: 75.0360, aux.loss_ce: 0.3415, aux.acc_seg: 71.3042, loss: 1.0606
2023-12-28 07:28:33,593 - mmseg - INFO - Iter [6600/160000]	lr: 5.753e-05, eta: 1 day, 10:08:52, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7159, decode.acc_seg: 75.8149, aux.loss_ce: 0.3364, aux.acc_seg: 72.7890, loss: 1.0523
2023-12-28 07:29:13,538 - mmseg - INFO - Iter [6650/160000]	lr: 5.751e-05, eta: 1 day, 10:08:09, time: 0.799, data_time: 0.011, memory: 15708, decode.loss_ce: 0.7018, decode.acc_seg: 75.4960, aux.loss_ce: 0.3289, aux.acc_seg: 72.8415, loss: 1.0307
2023-12-28 07:29:53,483 - mmseg - INFO - Iter [6700/160000]	lr: 5.749e-05, eta: 1 day, 10:07:27, time: 0.799, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6734, decode.acc_seg: 75.9355, aux.loss_ce: 0.3175, aux.acc_seg: 73.4254, loss: 0.9910
2023-12-28 07:30:32,765 - mmseg - INFO - Iter [6750/160000]	lr: 5.747e-05, eta: 1 day, 10:06:28, time: 0.785, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6991, decode.acc_seg: 74.6623, aux.loss_ce: 0.3266, aux.acc_seg: 72.4700, loss: 1.0257
2023-12-28 07:31:12,174 - mmseg - INFO - Iter [6800/160000]	lr: 5.745e-05, eta: 1 day, 10:05:35, time: 0.789, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7090, decode.acc_seg: 74.3992, aux.loss_ce: 0.3360, aux.acc_seg: 71.7400, loss: 1.0450
2023-12-28 07:31:53,132 - mmseg - INFO - Iter [6850/160000]	lr: 5.743e-05, eta: 1 day, 10:05:15, time: 0.819, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6283, decode.acc_seg: 77.1888, aux.loss_ce: 0.2974, aux.acc_seg: 74.4457, loss: 0.9257
2023-12-28 07:32:31,235 - mmseg - INFO - Iter [6900/160000]	lr: 5.741e-05, eta: 1 day, 10:03:51, time: 0.762, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6859, decode.acc_seg: 75.8208, aux.loss_ce: 0.3282, aux.acc_seg: 72.5083, loss: 1.0141
2023-12-28 07:33:10,517 - mmseg - INFO - Iter [6950/160000]	lr: 5.739e-05, eta: 1 day, 10:02:53, time: 0.785, data_time: 0.010, memory: 15708, decode.loss_ce: 0.6759, decode.acc_seg: 76.0434, aux.loss_ce: 0.3205, aux.acc_seg: 73.1143, loss: 0.9963
2023-12-28 07:33:48,183 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 07:33:48,183 - mmseg - INFO - Iter [7000/160000]	lr: 5.738e-05, eta: 1 day, 10:01:22, time: 0.754, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6533, decode.acc_seg: 75.8211, aux.loss_ce: 0.3021, aux.acc_seg: 73.4706, loss: 0.9554
2023-12-28 07:34:28,128 - mmseg - INFO - Iter [7050/160000]	lr: 5.736e-05, eta: 1 day, 10:00:39, time: 0.798, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6946, decode.acc_seg: 74.9446, aux.loss_ce: 0.3235, aux.acc_seg: 72.6065, loss: 1.0181
2023-12-28 07:35:08,730 - mmseg - INFO - Iter [7100/160000]	lr: 5.734e-05, eta: 1 day, 10:00:12, time: 0.812, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6818, decode.acc_seg: 75.8136, aux.loss_ce: 0.3256, aux.acc_seg: 73.0512, loss: 1.0074
2023-12-28 07:35:49,001 - mmseg - INFO - Iter [7150/160000]	lr: 5.732e-05, eta: 1 day, 9:59:37, time: 0.806, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7034, decode.acc_seg: 75.4934, aux.loss_ce: 0.3258, aux.acc_seg: 73.1080, loss: 1.0292
2023-12-28 07:36:28,981 - mmseg - INFO - Iter [7200/160000]	lr: 5.730e-05, eta: 1 day, 9:58:56, time: 0.800, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6559, decode.acc_seg: 75.8258, aux.loss_ce: 0.3059, aux.acc_seg: 73.5271, loss: 0.9618
2023-12-28 07:37:09,247 - mmseg - INFO - Iter [7250/160000]	lr: 5.728e-05, eta: 1 day, 9:58:20, time: 0.805, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6661, decode.acc_seg: 75.6796, aux.loss_ce: 0.3089, aux.acc_seg: 73.3495, loss: 0.9749
2023-12-28 07:37:49,567 - mmseg - INFO - Iter [7300/160000]	lr: 5.726e-05, eta: 1 day, 9:57:46, time: 0.806, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7154, decode.acc_seg: 74.6152, aux.loss_ce: 0.3317, aux.acc_seg: 71.9728, loss: 1.0471
2023-12-28 07:38:29,795 - mmseg - INFO - Iter [7350/160000]	lr: 5.724e-05, eta: 1 day, 9:57:11, time: 0.805, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6715, decode.acc_seg: 75.1980, aux.loss_ce: 0.3085, aux.acc_seg: 72.9638, loss: 0.9800
2023-12-28 07:39:10,224 - mmseg - INFO - Iter [7400/160000]	lr: 5.723e-05, eta: 1 day, 9:56:38, time: 0.808, data_time: 0.012, memory: 15708, decode.loss_ce: 0.7041, decode.acc_seg: 75.1705, aux.loss_ce: 0.3276, aux.acc_seg: 72.5012, loss: 1.0317
2023-12-28 07:39:50,594 - mmseg - INFO - Iter [7450/160000]	lr: 5.721e-05, eta: 1 day, 9:56:05, time: 0.807, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6722, decode.acc_seg: 76.2229, aux.loss_ce: 0.3117, aux.acc_seg: 73.9373, loss: 0.9839
2023-12-28 07:40:29,560 - mmseg - INFO - Iter [7500/160000]	lr: 5.719e-05, eta: 1 day, 9:55:04, time: 0.780, data_time: 0.013, memory: 15708, decode.loss_ce: 0.7001, decode.acc_seg: 74.9676, aux.loss_ce: 0.3202, aux.acc_seg: 72.9184, loss: 1.0203
2023-12-28 07:41:08,197 - mmseg - INFO - Iter [7550/160000]	lr: 5.717e-05, eta: 1 day, 9:53:56, time: 0.773, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6937, decode.acc_seg: 75.3846, aux.loss_ce: 0.3195, aux.acc_seg: 72.7228, loss: 1.0132
2023-12-28 07:41:48,113 - mmseg - INFO - Iter [7600/160000]	lr: 5.715e-05, eta: 1 day, 9:53:14, time: 0.798, data_time: 0.053, memory: 15708, decode.loss_ce: 0.6825, decode.acc_seg: 75.1458, aux.loss_ce: 0.3157, aux.acc_seg: 73.0142, loss: 0.9983
2023-12-28 07:42:27,329 - mmseg - INFO - Iter [7650/160000]	lr: 5.713e-05, eta: 1 day, 9:52:17, time: 0.783, data_time: 0.010, memory: 15708, decode.loss_ce: 0.6494, decode.acc_seg: 75.6321, aux.loss_ce: 0.3043, aux.acc_seg: 73.0327, loss: 0.9537
2023-12-28 07:43:07,801 - mmseg - INFO - Iter [7700/160000]	lr: 5.711e-05, eta: 1 day, 9:51:47, time: 0.811, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6563, decode.acc_seg: 76.0185, aux.loss_ce: 0.3047, aux.acc_seg: 73.6930, loss: 0.9611
2023-12-28 07:43:47,711 - mmseg - INFO - Iter [7750/160000]	lr: 5.709e-05, eta: 1 day, 9:51:04, time: 0.797, data_time: 0.010, memory: 15708, decode.loss_ce: 0.6614, decode.acc_seg: 76.3233, aux.loss_ce: 0.3087, aux.acc_seg: 73.7175, loss: 0.9701
2023-12-28 07:44:27,886 - mmseg - INFO - Iter [7800/160000]	lr: 5.708e-05, eta: 1 day, 9:50:27, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6449, decode.acc_seg: 76.4414, aux.loss_ce: 0.3057, aux.acc_seg: 73.4739, loss: 0.9506
2023-12-28 07:45:08,389 - mmseg - INFO - Iter [7850/160000]	lr: 5.706e-05, eta: 1 day, 9:49:56, time: 0.810, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6425, decode.acc_seg: 76.7613, aux.loss_ce: 0.2976, aux.acc_seg: 74.1308, loss: 0.9402
2023-12-28 07:45:47,697 - mmseg - INFO - Iter [7900/160000]	lr: 5.704e-05, eta: 1 day, 9:49:03, time: 0.787, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6712, decode.acc_seg: 75.6295, aux.loss_ce: 0.3068, aux.acc_seg: 73.8896, loss: 0.9780
2023-12-28 07:46:25,595 - mmseg - INFO - Iter [7950/160000]	lr: 5.702e-05, eta: 1 day, 9:47:42, time: 0.758, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6459, decode.acc_seg: 76.1040, aux.loss_ce: 0.2954, aux.acc_seg: 74.4386, loss: 0.9413
2023-12-28 07:47:04,159 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 07:47:04,160 - mmseg - INFO - Iter [8000/160000]	lr: 5.700e-05, eta: 1 day, 9:46:35, time: 0.771, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6695, decode.acc_seg: 75.7475, aux.loss_ce: 0.3068, aux.acc_seg: 73.9896, loss: 0.9762
2023-12-28 07:47:44,470 - mmseg - INFO - Iter [8050/160000]	lr: 5.698e-05, eta: 1 day, 9:46:01, time: 0.806, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6522, decode.acc_seg: 76.2337, aux.loss_ce: 0.3045, aux.acc_seg: 73.4970, loss: 0.9567
2023-12-28 07:48:24,689 - mmseg - INFO - Iter [8100/160000]	lr: 5.696e-05, eta: 1 day, 9:45:25, time: 0.804, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6718, decode.acc_seg: 76.0610, aux.loss_ce: 0.3192, aux.acc_seg: 72.9751, loss: 0.9910
2023-12-28 07:49:02,265 - mmseg - INFO - Iter [8150/160000]	lr: 5.694e-05, eta: 1 day, 9:44:00, time: 0.751, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6917, decode.acc_seg: 75.0722, aux.loss_ce: 0.3141, aux.acc_seg: 73.0280, loss: 1.0058
2023-12-28 07:49:40,593 - mmseg - INFO - Iter [8200/160000]	lr: 5.693e-05, eta: 1 day, 9:42:49, time: 0.767, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6562, decode.acc_seg: 76.1302, aux.loss_ce: 0.2967, aux.acc_seg: 74.2459, loss: 0.9529
2023-12-28 07:50:20,742 - mmseg - INFO - Iter [8250/160000]	lr: 5.691e-05, eta: 1 day, 9:42:12, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6446, decode.acc_seg: 76.5180, aux.loss_ce: 0.2996, aux.acc_seg: 74.4904, loss: 0.9442
2023-12-28 07:51:01,184 - mmseg - INFO - Iter [8300/160000]	lr: 5.689e-05, eta: 1 day, 9:41:41, time: 0.809, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6490, decode.acc_seg: 76.0414, aux.loss_ce: 0.2978, aux.acc_seg: 74.1005, loss: 0.9468
2023-12-28 07:51:41,442 - mmseg - INFO - Iter [8350/160000]	lr: 5.687e-05, eta: 1 day, 9:41:06, time: 0.805, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6905, decode.acc_seg: 75.1563, aux.loss_ce: 0.3172, aux.acc_seg: 72.6897, loss: 1.0077
2023-12-28 07:52:21,661 - mmseg - INFO - Iter [8400/160000]	lr: 5.685e-05, eta: 1 day, 9:40:30, time: 0.804, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6789, decode.acc_seg: 75.4467, aux.loss_ce: 0.3110, aux.acc_seg: 73.2688, loss: 0.9899
2023-12-28 07:53:01,731 - mmseg - INFO - Iter [8450/160000]	lr: 5.683e-05, eta: 1 day, 9:39:52, time: 0.801, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6319, decode.acc_seg: 76.9945, aux.loss_ce: 0.2857, aux.acc_seg: 74.9458, loss: 0.9176
2023-12-28 07:53:41,748 - mmseg - INFO - Iter [8500/160000]	lr: 5.681e-05, eta: 1 day, 9:39:12, time: 0.800, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6415, decode.acc_seg: 77.0090, aux.loss_ce: 0.2980, aux.acc_seg: 74.8038, loss: 0.9395
2023-12-28 07:54:21,076 - mmseg - INFO - Iter [8550/160000]	lr: 5.679e-05, eta: 1 day, 9:38:19, time: 0.785, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6493, decode.acc_seg: 76.3853, aux.loss_ce: 0.3045, aux.acc_seg: 73.5812, loss: 0.9538
2023-12-28 07:55:00,351 - mmseg - INFO - Iter [8600/160000]	lr: 5.678e-05, eta: 1 day, 9:37:27, time: 0.786, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6536, decode.acc_seg: 76.4210, aux.loss_ce: 0.3003, aux.acc_seg: 74.0655, loss: 0.9539
2023-12-28 07:55:40,618 - mmseg - INFO - Iter [8650/160000]	lr: 5.676e-05, eta: 1 day, 9:36:53, time: 0.806, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6296, decode.acc_seg: 76.8479, aux.loss_ce: 0.2864, aux.acc_seg: 74.9599, loss: 0.9160
2023-12-28 07:56:19,469 - mmseg - INFO - Iter [8700/160000]	lr: 5.674e-05, eta: 1 day, 9:35:53, time: 0.776, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6583, decode.acc_seg: 75.9457, aux.loss_ce: 0.2994, aux.acc_seg: 73.9283, loss: 0.9577
2023-12-28 07:56:59,008 - mmseg - INFO - Iter [8750/160000]	lr: 5.672e-05, eta: 1 day, 9:35:06, time: 0.792, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6222, decode.acc_seg: 76.5931, aux.loss_ce: 0.2866, aux.acc_seg: 74.4210, loss: 0.9089
2023-12-28 07:57:36,872 - mmseg - INFO - Iter [8800/160000]	lr: 5.670e-05, eta: 1 day, 9:33:50, time: 0.757, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6480, decode.acc_seg: 76.1193, aux.loss_ce: 0.2995, aux.acc_seg: 73.7728, loss: 0.9475
2023-12-28 07:58:17,440 - mmseg - INFO - Iter [8850/160000]	lr: 5.668e-05, eta: 1 day, 9:33:20, time: 0.811, data_time: 0.052, memory: 15708, decode.loss_ce: 0.6743, decode.acc_seg: 76.1087, aux.loss_ce: 0.3049, aux.acc_seg: 74.5614, loss: 0.9792
2023-12-28 07:58:56,214 - mmseg - INFO - Iter [8900/160000]	lr: 5.666e-05, eta: 1 day, 9:32:19, time: 0.775, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6387, decode.acc_seg: 76.7605, aux.loss_ce: 0.2938, aux.acc_seg: 74.6092, loss: 0.9324
2023-12-28 07:59:34,937 - mmseg - INFO - Iter [8950/160000]	lr: 5.664e-05, eta: 1 day, 9:31:20, time: 0.775, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6104, decode.acc_seg: 77.5669, aux.loss_ce: 0.2835, aux.acc_seg: 75.3574, loss: 0.8939
2023-12-28 08:00:15,184 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 08:00:15,185 - mmseg - INFO - Iter [9000/160000]	lr: 5.663e-05, eta: 1 day, 9:30:45, time: 0.805, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6148, decode.acc_seg: 77.2260, aux.loss_ce: 0.2836, aux.acc_seg: 74.6445, loss: 0.8984
2023-12-28 08:00:55,310 - mmseg - INFO - Iter [9050/160000]	lr: 5.661e-05, eta: 1 day, 9:30:08, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6079, decode.acc_seg: 77.3157, aux.loss_ce: 0.2818, aux.acc_seg: 75.2641, loss: 0.8897
2023-12-28 08:01:35,528 - mmseg - INFO - Iter [9100/160000]	lr: 5.659e-05, eta: 1 day, 9:29:32, time: 0.804, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6357, decode.acc_seg: 76.6114, aux.loss_ce: 0.2956, aux.acc_seg: 74.2217, loss: 0.9312
2023-12-28 08:02:15,615 - mmseg - INFO - Iter [9150/160000]	lr: 5.657e-05, eta: 1 day, 9:28:54, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6385, decode.acc_seg: 76.9272, aux.loss_ce: 0.2900, aux.acc_seg: 75.1426, loss: 0.9286
2023-12-28 08:02:55,619 - mmseg - INFO - Iter [9200/160000]	lr: 5.655e-05, eta: 1 day, 9:28:15, time: 0.800, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6389, decode.acc_seg: 76.8767, aux.loss_ce: 0.2946, aux.acc_seg: 74.5852, loss: 0.9335
2023-12-28 08:03:35,593 - mmseg - INFO - Iter [9250/160000]	lr: 5.653e-05, eta: 1 day, 9:27:35, time: 0.798, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5955, decode.acc_seg: 77.8476, aux.loss_ce: 0.2709, aux.acc_seg: 75.9546, loss: 0.8664
2023-12-28 08:04:16,253 - mmseg - INFO - Iter [9300/160000]	lr: 5.651e-05, eta: 1 day, 9:27:07, time: 0.814, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6123, decode.acc_seg: 77.5778, aux.loss_ce: 0.2825, aux.acc_seg: 75.4679, loss: 0.8948
2023-12-28 08:04:55,039 - mmseg - INFO - Iter [9350/160000]	lr: 5.649e-05, eta: 1 day, 9:26:08, time: 0.775, data_time: 0.010, memory: 15708, decode.loss_ce: 0.6191, decode.acc_seg: 77.5255, aux.loss_ce: 0.2825, aux.acc_seg: 75.4157, loss: 0.9015
2023-12-28 08:05:33,246 - mmseg - INFO - Iter [9400/160000]	lr: 5.648e-05, eta: 1 day, 9:25:00, time: 0.765, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6296, decode.acc_seg: 76.4595, aux.loss_ce: 0.2887, aux.acc_seg: 74.6383, loss: 0.9183
2023-12-28 08:06:13,404 - mmseg - INFO - Iter [9450/160000]	lr: 5.646e-05, eta: 1 day, 9:24:24, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5956, decode.acc_seg: 77.3447, aux.loss_ce: 0.2744, aux.acc_seg: 75.2335, loss: 0.8700
2023-12-28 08:06:52,229 - mmseg - INFO - Iter [9500/160000]	lr: 5.644e-05, eta: 1 day, 9:23:26, time: 0.775, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6241, decode.acc_seg: 76.8743, aux.loss_ce: 0.2874, aux.acc_seg: 74.4751, loss: 0.9115
2023-12-28 08:07:30,635 - mmseg - INFO - Iter [9550/160000]	lr: 5.642e-05, eta: 1 day, 9:22:22, time: 0.769, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6284, decode.acc_seg: 77.0895, aux.loss_ce: 0.2885, aux.acc_seg: 74.9742, loss: 0.9170
2023-12-28 08:08:11,489 - mmseg - INFO - Iter [9600/160000]	lr: 5.640e-05, eta: 1 day, 9:21:57, time: 0.818, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6562, decode.acc_seg: 76.2655, aux.loss_ce: 0.2982, aux.acc_seg: 74.0884, loss: 0.9544
2023-12-28 08:08:50,494 - mmseg - INFO - Iter [9650/160000]	lr: 5.638e-05, eta: 1 day, 9:21:03, time: 0.780, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6058, decode.acc_seg: 77.3162, aux.loss_ce: 0.2810, aux.acc_seg: 75.3441, loss: 0.8868
2023-12-28 08:09:28,785 - mmseg - INFO - Iter [9700/160000]	lr: 5.636e-05, eta: 1 day, 9:19:57, time: 0.765, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6040, decode.acc_seg: 77.8399, aux.loss_ce: 0.2749, aux.acc_seg: 75.9976, loss: 0.8789
2023-12-28 08:10:08,787 - mmseg - INFO - Iter [9750/160000]	lr: 5.634e-05, eta: 1 day, 9:19:19, time: 0.801, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6318, decode.acc_seg: 76.3887, aux.loss_ce: 0.2849, aux.acc_seg: 74.6400, loss: 0.9167
2023-12-28 08:10:49,103 - mmseg - INFO - Iter [9800/160000]	lr: 5.633e-05, eta: 1 day, 9:18:45, time: 0.806, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6138, decode.acc_seg: 77.6609, aux.loss_ce: 0.2798, aux.acc_seg: 75.6701, loss: 0.8935
2023-12-28 08:11:29,069 - mmseg - INFO - Iter [9850/160000]	lr: 5.631e-05, eta: 1 day, 9:18:05, time: 0.798, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6642, decode.acc_seg: 75.9991, aux.loss_ce: 0.2989, aux.acc_seg: 74.2388, loss: 0.9631
2023-12-28 08:12:08,809 - mmseg - INFO - Iter [9900/160000]	lr: 5.629e-05, eta: 1 day, 9:17:23, time: 0.796, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6297, decode.acc_seg: 77.3913, aux.loss_ce: 0.2854, aux.acc_seg: 75.2862, loss: 0.9151
2023-12-28 08:12:48,962 - mmseg - INFO - Iter [9950/160000]	lr: 5.627e-05, eta: 1 day, 9:16:46, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6126, decode.acc_seg: 77.3771, aux.loss_ce: 0.2818, aux.acc_seg: 75.0951, loss: 0.8944
2023-12-28 08:13:29,090 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 08:13:29,091 - mmseg - INFO - Iter [10000/160000]	lr: 5.625e-05, eta: 1 day, 9:16:09, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6285, decode.acc_seg: 76.1243, aux.loss_ce: 0.2843, aux.acc_seg: 74.3300, loss: 0.9128
2023-12-28 08:14:08,895 - mmseg - INFO - Iter [10050/160000]	lr: 5.623e-05, eta: 1 day, 9:15:27, time: 0.796, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6284, decode.acc_seg: 77.0508, aux.loss_ce: 0.2859, aux.acc_seg: 74.8873, loss: 0.9142
2023-12-28 08:14:49,006 - mmseg - INFO - Iter [10100/160000]	lr: 5.621e-05, eta: 1 day, 9:14:50, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6323, decode.acc_seg: 76.9964, aux.loss_ce: 0.2929, aux.acc_seg: 74.6917, loss: 0.9251
2023-12-28 08:15:30,446 - mmseg - INFO - Iter [10150/160000]	lr: 5.619e-05, eta: 1 day, 9:14:33, time: 0.829, data_time: 0.054, memory: 15708, decode.loss_ce: 0.6375, decode.acc_seg: 76.2950, aux.loss_ce: 0.2864, aux.acc_seg: 74.7798, loss: 0.9239
2023-12-28 08:16:08,935 - mmseg - INFO - Iter [10200/160000]	lr: 5.618e-05, eta: 1 day, 9:13:31, time: 0.769, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5642, decode.acc_seg: 78.2461, aux.loss_ce: 0.2651, aux.acc_seg: 75.9781, loss: 0.8293
2023-12-28 08:16:48,443 - mmseg - INFO - Iter [10250/160000]	lr: 5.616e-05, eta: 1 day, 9:12:45, time: 0.790, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6067, decode.acc_seg: 77.6378, aux.loss_ce: 0.2765, aux.acc_seg: 75.4070, loss: 0.8832
2023-12-28 08:17:28,093 - mmseg - INFO - Iter [10300/160000]	lr: 5.614e-05, eta: 1 day, 9:12:02, time: 0.794, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5735, decode.acc_seg: 79.0153, aux.loss_ce: 0.2687, aux.acc_seg: 76.5533, loss: 0.8422
2023-12-28 08:18:08,556 - mmseg - INFO - Iter [10350/160000]	lr: 5.612e-05, eta: 1 day, 9:11:30, time: 0.809, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6209, decode.acc_seg: 76.6960, aux.loss_ce: 0.2818, aux.acc_seg: 74.9183, loss: 0.9027
2023-12-28 08:18:48,759 - mmseg - INFO - Iter [10400/160000]	lr: 5.610e-05, eta: 1 day, 9:10:53, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5715, decode.acc_seg: 78.7103, aux.loss_ce: 0.2592, aux.acc_seg: 76.3013, loss: 0.8307
2023-12-28 08:19:27,279 - mmseg - INFO - Iter [10450/160000]	lr: 5.608e-05, eta: 1 day, 9:09:53, time: 0.770, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6224, decode.acc_seg: 77.6772, aux.loss_ce: 0.2864, aux.acc_seg: 75.3303, loss: 0.9089
2023-12-28 08:20:07,666 - mmseg - INFO - Iter [10500/160000]	lr: 5.606e-05, eta: 1 day, 9:09:20, time: 0.808, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5908, decode.acc_seg: 77.9336, aux.loss_ce: 0.2701, aux.acc_seg: 75.5888, loss: 0.8610
2023-12-28 08:20:47,241 - mmseg - INFO - Iter [10550/160000]	lr: 5.604e-05, eta: 1 day, 9:08:36, time: 0.792, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6007, decode.acc_seg: 77.9152, aux.loss_ce: 0.2732, aux.acc_seg: 75.9926, loss: 0.8739
2023-12-28 08:21:25,480 - mmseg - INFO - Iter [10600/160000]	lr: 5.603e-05, eta: 1 day, 9:07:32, time: 0.764, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5813, decode.acc_seg: 77.5976, aux.loss_ce: 0.2654, aux.acc_seg: 76.3670, loss: 0.8467
2023-12-28 08:22:03,781 - mmseg - INFO - Iter [10650/160000]	lr: 5.601e-05, eta: 1 day, 9:06:30, time: 0.767, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6313, decode.acc_seg: 77.1420, aux.loss_ce: 0.2805, aux.acc_seg: 75.5373, loss: 0.9118
2023-12-28 08:22:42,523 - mmseg - INFO - Iter [10700/160000]	lr: 5.599e-05, eta: 1 day, 9:05:33, time: 0.774, data_time: 0.010, memory: 15708, decode.loss_ce: 0.6329, decode.acc_seg: 76.3729, aux.loss_ce: 0.2859, aux.acc_seg: 74.5317, loss: 0.9188
2023-12-28 08:23:22,515 - mmseg - INFO - Iter [10750/160000]	lr: 5.597e-05, eta: 1 day, 9:04:55, time: 0.800, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6316, decode.acc_seg: 77.2404, aux.loss_ce: 0.2852, aux.acc_seg: 75.4820, loss: 0.9168
2023-12-28 08:24:01,683 - mmseg - INFO - Iter [10800/160000]	lr: 5.595e-05, eta: 1 day, 9:04:05, time: 0.783, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6215, decode.acc_seg: 76.8452, aux.loss_ce: 0.2781, aux.acc_seg: 74.9849, loss: 0.8996
2023-12-28 08:24:41,972 - mmseg - INFO - Iter [10850/160000]	lr: 5.593e-05, eta: 1 day, 9:03:31, time: 0.807, data_time: 0.013, memory: 15708, decode.loss_ce: 0.6484, decode.acc_seg: 76.5430, aux.loss_ce: 0.2918, aux.acc_seg: 74.5949, loss: 0.9402
2023-12-28 08:25:22,470 - mmseg - INFO - Iter [10900/160000]	lr: 5.591e-05, eta: 1 day, 9:02:59, time: 0.810, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5943, decode.acc_seg: 77.9939, aux.loss_ce: 0.2705, aux.acc_seg: 76.2939, loss: 0.8647
2023-12-28 08:26:01,942 - mmseg - INFO - Iter [10950/160000]	lr: 5.589e-05, eta: 1 day, 9:02:13, time: 0.789, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5855, decode.acc_seg: 78.4978, aux.loss_ce: 0.2660, aux.acc_seg: 76.3602, loss: 0.8515
2023-12-28 08:26:41,556 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 08:26:41,556 - mmseg - INFO - Iter [11000/160000]	lr: 5.588e-05, eta: 1 day, 9:01:29, time: 0.792, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5685, decode.acc_seg: 78.7897, aux.loss_ce: 0.2635, aux.acc_seg: 75.9809, loss: 0.8320
2023-12-28 08:27:21,493 - mmseg - INFO - Iter [11050/160000]	lr: 5.586e-05, eta: 1 day, 9:00:50, time: 0.798, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5884, decode.acc_seg: 77.8366, aux.loss_ce: 0.2698, aux.acc_seg: 75.7145, loss: 0.8582
2023-12-28 08:28:01,300 - mmseg - INFO - Iter [11100/160000]	lr: 5.584e-05, eta: 1 day, 9:00:09, time: 0.796, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5928, decode.acc_seg: 77.4768, aux.loss_ce: 0.2687, aux.acc_seg: 75.6626, loss: 0.8614
2023-12-28 08:28:40,181 - mmseg - INFO - Iter [11150/160000]	lr: 5.582e-05, eta: 1 day, 8:59:16, time: 0.778, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6122, decode.acc_seg: 77.2929, aux.loss_ce: 0.2746, aux.acc_seg: 75.5257, loss: 0.8868
2023-12-28 08:29:18,057 - mmseg - INFO - Iter [11200/160000]	lr: 5.580e-05, eta: 1 day, 8:58:09, time: 0.757, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6033, decode.acc_seg: 77.2851, aux.loss_ce: 0.2730, aux.acc_seg: 75.2657, loss: 0.8763
2023-12-28 08:29:57,248 - mmseg - INFO - Iter [11250/160000]	lr: 5.578e-05, eta: 1 day, 8:57:20, time: 0.785, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6292, decode.acc_seg: 76.4906, aux.loss_ce: 0.2839, aux.acc_seg: 74.3070, loss: 0.9130
2023-12-28 08:30:36,725 - mmseg - INFO - Iter [11300/160000]	lr: 5.576e-05, eta: 1 day, 8:56:35, time: 0.789, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6014, decode.acc_seg: 78.1246, aux.loss_ce: 0.2754, aux.acc_seg: 75.9219, loss: 0.8768
2023-12-28 08:31:13,464 - mmseg - INFO - Iter [11350/160000]	lr: 5.574e-05, eta: 1 day, 8:55:14, time: 0.735, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5926, decode.acc_seg: 78.4555, aux.loss_ce: 0.2724, aux.acc_seg: 76.2041, loss: 0.8650
2023-12-28 08:31:54,783 - mmseg - INFO - Iter [11400/160000]	lr: 5.573e-05, eta: 1 day, 8:54:52, time: 0.826, data_time: 0.053, memory: 15708, decode.loss_ce: 0.5731, decode.acc_seg: 78.4067, aux.loss_ce: 0.2665, aux.acc_seg: 76.2059, loss: 0.8395
2023-12-28 08:32:31,409 - mmseg - INFO - Iter [11450/160000]	lr: 5.571e-05, eta: 1 day, 8:53:31, time: 0.733, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5816, decode.acc_seg: 77.7975, aux.loss_ce: 0.2640, aux.acc_seg: 75.8859, loss: 0.8456
2023-12-28 08:33:10,663 - mmseg - INFO - Iter [11500/160000]	lr: 5.569e-05, eta: 1 day, 8:52:43, time: 0.785, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5668, decode.acc_seg: 78.9272, aux.loss_ce: 0.2557, aux.acc_seg: 77.1520, loss: 0.8225
2023-12-28 08:33:50,854 - mmseg - INFO - Iter [11550/160000]	lr: 5.567e-05, eta: 1 day, 8:52:07, time: 0.804, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5652, decode.acc_seg: 78.7599, aux.loss_ce: 0.2613, aux.acc_seg: 76.5694, loss: 0.8264
2023-12-28 08:34:28,905 - mmseg - INFO - Iter [11600/160000]	lr: 5.565e-05, eta: 1 day, 8:51:05, time: 0.762, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5513, decode.acc_seg: 79.0840, aux.loss_ce: 0.2565, aux.acc_seg: 77.1055, loss: 0.8077
2023-12-28 08:35:08,904 - mmseg - INFO - Iter [11650/160000]	lr: 5.563e-05, eta: 1 day, 8:50:26, time: 0.799, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5808, decode.acc_seg: 78.4783, aux.loss_ce: 0.2618, aux.acc_seg: 76.3638, loss: 0.8427
2023-12-28 08:35:47,021 - mmseg - INFO - Iter [11700/160000]	lr: 5.561e-05, eta: 1 day, 8:49:25, time: 0.763, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5776, decode.acc_seg: 77.8107, aux.loss_ce: 0.2675, aux.acc_seg: 75.6512, loss: 0.8451
2023-12-28 08:36:26,889 - mmseg - INFO - Iter [11750/160000]	lr: 5.559e-05, eta: 1 day, 8:48:45, time: 0.797, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5475, decode.acc_seg: 79.2754, aux.loss_ce: 0.2541, aux.acc_seg: 77.0065, loss: 0.8016
2023-12-28 08:37:06,983 - mmseg - INFO - Iter [11800/160000]	lr: 5.558e-05, eta: 1 day, 8:48:08, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6007, decode.acc_seg: 77.8255, aux.loss_ce: 0.2737, aux.acc_seg: 75.2761, loss: 0.8744
2023-12-28 08:37:45,881 - mmseg - INFO - Iter [11850/160000]	lr: 5.556e-05, eta: 1 day, 8:47:17, time: 0.778, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5512, decode.acc_seg: 79.0099, aux.loss_ce: 0.2519, aux.acc_seg: 77.0039, loss: 0.8031
2023-12-28 08:38:25,425 - mmseg - INFO - Iter [11900/160000]	lr: 5.554e-05, eta: 1 day, 8:46:33, time: 0.791, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5712, decode.acc_seg: 79.0105, aux.loss_ce: 0.2551, aux.acc_seg: 77.3128, loss: 0.8263
2023-12-28 08:39:04,130 - mmseg - INFO - Iter [11950/160000]	lr: 5.552e-05, eta: 1 day, 8:45:39, time: 0.774, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5826, decode.acc_seg: 78.3755, aux.loss_ce: 0.2665, aux.acc_seg: 76.1473, loss: 0.8491
2023-12-28 08:39:43,622 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 08:39:43,622 - mmseg - INFO - Iter [12000/160000]	lr: 5.550e-05, eta: 1 day, 8:44:56, time: 0.791, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5783, decode.acc_seg: 77.8705, aux.loss_ce: 0.2587, aux.acc_seg: 76.5358, loss: 0.8370
2023-12-28 08:40:21,867 - mmseg - INFO - Iter [12050/160000]	lr: 5.548e-05, eta: 1 day, 8:43:57, time: 0.765, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5872, decode.acc_seg: 79.4447, aux.loss_ce: 0.2658, aux.acc_seg: 77.5312, loss: 0.8530
2023-12-28 08:41:02,035 - mmseg - INFO - Iter [12100/160000]	lr: 5.546e-05, eta: 1 day, 8:43:21, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6220, decode.acc_seg: 76.8276, aux.loss_ce: 0.2733, aux.acc_seg: 75.6426, loss: 0.8953
2023-12-28 08:41:41,097 - mmseg - INFO - Iter [12150/160000]	lr: 5.544e-05, eta: 1 day, 8:42:32, time: 0.781, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5748, decode.acc_seg: 78.6895, aux.loss_ce: 0.2567, aux.acc_seg: 76.8138, loss: 0.8315
2023-12-28 08:42:21,056 - mmseg - INFO - Iter [12200/160000]	lr: 5.543e-05, eta: 1 day, 8:41:53, time: 0.798, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5670, decode.acc_seg: 78.7517, aux.loss_ce: 0.2544, aux.acc_seg: 77.4371, loss: 0.8214
2023-12-28 08:43:00,336 - mmseg - INFO - Iter [12250/160000]	lr: 5.541e-05, eta: 1 day, 8:41:07, time: 0.785, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5942, decode.acc_seg: 78.4742, aux.loss_ce: 0.2694, aux.acc_seg: 76.3772, loss: 0.8636
2023-12-28 08:43:40,419 - mmseg - INFO - Iter [12300/160000]	lr: 5.539e-05, eta: 1 day, 8:40:31, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.6121, decode.acc_seg: 77.3014, aux.loss_ce: 0.2717, aux.acc_seg: 75.3712, loss: 0.8838
2023-12-28 08:44:20,744 - mmseg - INFO - Iter [12350/160000]	lr: 5.537e-05, eta: 1 day, 8:39:57, time: 0.806, data_time: 0.011, memory: 15708, decode.loss_ce: 0.6010, decode.acc_seg: 77.8326, aux.loss_ce: 0.2745, aux.acc_seg: 75.7042, loss: 0.8755
2023-12-28 08:45:00,695 - mmseg - INFO - Iter [12400/160000]	lr: 5.535e-05, eta: 1 day, 8:39:18, time: 0.799, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5659, decode.acc_seg: 78.1939, aux.loss_ce: 0.2584, aux.acc_seg: 76.4979, loss: 0.8243
2023-12-28 08:45:42,203 - mmseg - INFO - Iter [12450/160000]	lr: 5.533e-05, eta: 1 day, 8:38:58, time: 0.830, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5679, decode.acc_seg: 78.6044, aux.loss_ce: 0.2569, aux.acc_seg: 76.7796, loss: 0.8248
2023-12-28 08:46:22,425 - mmseg - INFO - Iter [12500/160000]	lr: 5.531e-05, eta: 1 day, 8:38:23, time: 0.805, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5790, decode.acc_seg: 78.6679, aux.loss_ce: 0.2644, aux.acc_seg: 76.8946, loss: 0.8434
2023-12-28 08:47:01,246 - mmseg - INFO - Iter [12550/160000]	lr: 5.529e-05, eta: 1 day, 8:37:31, time: 0.776, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5878, decode.acc_seg: 78.0266, aux.loss_ce: 0.2679, aux.acc_seg: 75.9775, loss: 0.8558
2023-12-28 08:47:41,007 - mmseg - INFO - Iter [12600/160000]	lr: 5.528e-05, eta: 1 day, 8:36:51, time: 0.795, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5643, decode.acc_seg: 78.9138, aux.loss_ce: 0.2559, aux.acc_seg: 76.5349, loss: 0.8201
2023-12-28 08:48:20,504 - mmseg - INFO - Iter [12650/160000]	lr: 5.526e-05, eta: 1 day, 8:36:08, time: 0.791, data_time: 0.054, memory: 15708, decode.loss_ce: 0.5718, decode.acc_seg: 78.4606, aux.loss_ce: 0.2589, aux.acc_seg: 76.8344, loss: 0.8307
2023-12-28 08:48:59,563 - mmseg - INFO - Iter [12700/160000]	lr: 5.524e-05, eta: 1 day, 8:35:18, time: 0.780, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5680, decode.acc_seg: 78.7088, aux.loss_ce: 0.2656, aux.acc_seg: 76.3239, loss: 0.8336
2023-12-28 08:49:39,872 - mmseg - INFO - Iter [12750/160000]	lr: 5.522e-05, eta: 1 day, 8:34:45, time: 0.807, data_time: 0.014, memory: 15708, decode.loss_ce: 0.5698, decode.acc_seg: 78.3292, aux.loss_ce: 0.2666, aux.acc_seg: 76.1083, loss: 0.8364
2023-12-28 08:50:19,563 - mmseg - INFO - Iter [12800/160000]	lr: 5.520e-05, eta: 1 day, 8:34:03, time: 0.794, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5338, decode.acc_seg: 79.8422, aux.loss_ce: 0.2464, aux.acc_seg: 77.5525, loss: 0.7802
2023-12-28 08:51:00,870 - mmseg - INFO - Iter [12850/160000]	lr: 5.518e-05, eta: 1 day, 8:33:41, time: 0.826, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5591, decode.acc_seg: 79.4958, aux.loss_ce: 0.2556, aux.acc_seg: 77.1288, loss: 0.8147
2023-12-28 08:51:42,845 - mmseg - INFO - Iter [12900/160000]	lr: 5.516e-05, eta: 1 day, 8:33:25, time: 0.840, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5598, decode.acc_seg: 79.2292, aux.loss_ce: 0.2549, aux.acc_seg: 77.0921, loss: 0.8147
2023-12-28 08:52:24,580 - mmseg - INFO - Iter [12950/160000]	lr: 5.514e-05, eta: 1 day, 8:33:06, time: 0.833, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5759, decode.acc_seg: 78.9323, aux.loss_ce: 0.2580, aux.acc_seg: 77.2532, loss: 0.8339
2023-12-28 08:53:02,906 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 08:53:02,907 - mmseg - INFO - Iter [13000/160000]	lr: 5.513e-05, eta: 1 day, 8:32:10, time: 0.767, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5699, decode.acc_seg: 78.4132, aux.loss_ce: 0.2637, aux.acc_seg: 76.4301, loss: 0.8337
2023-12-28 08:53:42,450 - mmseg - INFO - Iter [13050/160000]	lr: 5.511e-05, eta: 1 day, 8:31:26, time: 0.790, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5618, decode.acc_seg: 79.2020, aux.loss_ce: 0.2522, aux.acc_seg: 77.5918, loss: 0.8140
2023-12-28 08:54:22,454 - mmseg - INFO - Iter [13100/160000]	lr: 5.509e-05, eta: 1 day, 8:30:49, time: 0.801, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5577, decode.acc_seg: 79.4612, aux.loss_ce: 0.2507, aux.acc_seg: 77.6009, loss: 0.8084
2023-12-28 08:55:02,721 - mmseg - INFO - Iter [13150/160000]	lr: 5.507e-05, eta: 1 day, 8:30:14, time: 0.805, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5648, decode.acc_seg: 79.0725, aux.loss_ce: 0.2605, aux.acc_seg: 76.6889, loss: 0.8253
2023-12-28 08:55:42,799 - mmseg - INFO - Iter [13200/160000]	lr: 5.505e-05, eta: 1 day, 8:29:36, time: 0.802, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5428, decode.acc_seg: 79.5956, aux.loss_ce: 0.2443, aux.acc_seg: 77.6375, loss: 0.7871
2023-12-28 08:56:22,433 - mmseg - INFO - Iter [13250/160000]	lr: 5.503e-05, eta: 1 day, 8:28:54, time: 0.792, data_time: 0.013, memory: 15708, decode.loss_ce: 0.5469, decode.acc_seg: 79.8194, aux.loss_ce: 0.2505, aux.acc_seg: 77.6772, loss: 0.7974
2023-12-28 08:57:01,380 - mmseg - INFO - Iter [13300/160000]	lr: 5.501e-05, eta: 1 day, 8:28:04, time: 0.779, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5764, decode.acc_seg: 78.8083, aux.loss_ce: 0.2654, aux.acc_seg: 76.6853, loss: 0.8418
2023-12-28 08:57:40,233 - mmseg - INFO - Iter [13350/160000]	lr: 5.499e-05, eta: 1 day, 8:27:14, time: 0.777, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5420, decode.acc_seg: 79.0867, aux.loss_ce: 0.2437, aux.acc_seg: 77.6842, loss: 0.7858
2023-12-28 08:58:18,542 - mmseg - INFO - Iter [13400/160000]	lr: 5.498e-05, eta: 1 day, 8:26:17, time: 0.766, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5800, decode.acc_seg: 77.9772, aux.loss_ce: 0.2626, aux.acc_seg: 76.2660, loss: 0.8427
2023-12-28 08:58:57,729 - mmseg - INFO - Iter [13450/160000]	lr: 5.496e-05, eta: 1 day, 8:25:30, time: 0.784, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5646, decode.acc_seg: 78.7985, aux.loss_ce: 0.2579, aux.acc_seg: 76.8401, loss: 0.8225
2023-12-28 08:59:37,886 - mmseg - INFO - Iter [13500/160000]	lr: 5.494e-05, eta: 1 day, 8:24:54, time: 0.803, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5583, decode.acc_seg: 79.2672, aux.loss_ce: 0.2574, aux.acc_seg: 77.1173, loss: 0.8157
2023-12-28 09:00:18,233 - mmseg - INFO - Iter [13550/160000]	lr: 5.492e-05, eta: 1 day, 8:24:20, time: 0.807, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5440, decode.acc_seg: 79.3938, aux.loss_ce: 0.2487, aux.acc_seg: 77.4389, loss: 0.7928
2023-12-28 09:00:57,767 - mmseg - INFO - Iter [13600/160000]	lr: 5.490e-05, eta: 1 day, 8:23:37, time: 0.791, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5697, decode.acc_seg: 79.0744, aux.loss_ce: 0.2558, aux.acc_seg: 77.4115, loss: 0.8255
2023-12-28 09:01:36,767 - mmseg - INFO - Iter [13650/160000]	lr: 5.488e-05, eta: 1 day, 8:22:48, time: 0.780, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5573, decode.acc_seg: 79.1959, aux.loss_ce: 0.2526, aux.acc_seg: 77.2881, loss: 0.8100
2023-12-28 09:02:13,945 - mmseg - INFO - Iter [13700/160000]	lr: 5.486e-05, eta: 1 day, 8:21:40, time: 0.744, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5456, decode.acc_seg: 79.6689, aux.loss_ce: 0.2477, aux.acc_seg: 77.9848, loss: 0.7933
2023-12-28 09:02:52,054 - mmseg - INFO - Iter [13750/160000]	lr: 5.484e-05, eta: 1 day, 8:20:42, time: 0.761, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5551, decode.acc_seg: 78.5232, aux.loss_ce: 0.2508, aux.acc_seg: 76.4393, loss: 0.8059
2023-12-28 09:03:32,084 - mmseg - INFO - Iter [13800/160000]	lr: 5.483e-05, eta: 1 day, 8:20:04, time: 0.800, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5438, decode.acc_seg: 79.7837, aux.loss_ce: 0.2531, aux.acc_seg: 77.1644, loss: 0.7969
2023-12-28 09:04:10,897 - mmseg - INFO - Iter [13850/160000]	lr: 5.481e-05, eta: 1 day, 8:19:14, time: 0.776, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5325, decode.acc_seg: 79.8848, aux.loss_ce: 0.2444, aux.acc_seg: 78.1231, loss: 0.7768
2023-12-28 09:04:50,786 - mmseg - INFO - Iter [13900/160000]	lr: 5.479e-05, eta: 1 day, 8:18:35, time: 0.799, data_time: 0.053, memory: 15708, decode.loss_ce: 0.5344, decode.acc_seg: 79.5461, aux.loss_ce: 0.2447, aux.acc_seg: 77.8367, loss: 0.7791
2023-12-28 09:05:30,547 - mmseg - INFO - Iter [13950/160000]	lr: 5.477e-05, eta: 1 day, 8:17:54, time: 0.794, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5397, decode.acc_seg: 79.3048, aux.loss_ce: 0.2530, aux.acc_seg: 76.8563, loss: 0.7927
2023-12-28 09:06:10,760 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 09:06:10,761 - mmseg - INFO - Iter [14000/160000]	lr: 5.475e-05, eta: 1 day, 8:17:19, time: 0.805, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5177, decode.acc_seg: 79.8527, aux.loss_ce: 0.2400, aux.acc_seg: 77.8227, loss: 0.7577
2023-12-28 09:06:51,102 - mmseg - INFO - Iter [14050/160000]	lr: 5.473e-05, eta: 1 day, 8:16:45, time: 0.808, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5209, decode.acc_seg: 80.2019, aux.loss_ce: 0.2400, aux.acc_seg: 77.9709, loss: 0.7610
2023-12-28 09:07:30,263 - mmseg - INFO - Iter [14100/160000]	lr: 5.471e-05, eta: 1 day, 8:15:58, time: 0.782, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5284, decode.acc_seg: 80.1870, aux.loss_ce: 0.2438, aux.acc_seg: 77.7839, loss: 0.7721
2023-12-28 09:08:09,173 - mmseg - INFO - Iter [14150/160000]	lr: 5.469e-05, eta: 1 day, 8:15:09, time: 0.778, data_time: 0.013, memory: 15708, decode.loss_ce: 0.5166, decode.acc_seg: 79.7741, aux.loss_ce: 0.2356, aux.acc_seg: 78.0139, loss: 0.7522
2023-12-28 09:08:48,923 - mmseg - INFO - Iter [14200/160000]	lr: 5.468e-05, eta: 1 day, 8:14:29, time: 0.796, data_time: 0.013, memory: 15708, decode.loss_ce: 0.5586, decode.acc_seg: 78.7275, aux.loss_ce: 0.2556, aux.acc_seg: 76.3625, loss: 0.8141
2023-12-28 09:09:27,585 - mmseg - INFO - Iter [14250/160000]	lr: 5.466e-05, eta: 1 day, 8:13:38, time: 0.773, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5103, decode.acc_seg: 80.4962, aux.loss_ce: 0.2328, aux.acc_seg: 78.9017, loss: 0.7431
2023-12-28 09:10:06,544 - mmseg - INFO - Iter [14300/160000]	lr: 5.464e-05, eta: 1 day, 8:12:49, time: 0.779, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5506, decode.acc_seg: 78.7913, aux.loss_ce: 0.2478, aux.acc_seg: 77.1984, loss: 0.7985
2023-12-28 09:10:47,391 - mmseg - INFO - Iter [14350/160000]	lr: 5.462e-05, eta: 1 day, 8:12:20, time: 0.816, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5464, decode.acc_seg: 79.4228, aux.loss_ce: 0.2489, aux.acc_seg: 77.5101, loss: 0.7954
2023-12-28 09:11:25,620 - mmseg - INFO - Iter [14400/160000]	lr: 5.460e-05, eta: 1 day, 8:11:24, time: 0.765, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5421, decode.acc_seg: 79.1825, aux.loss_ce: 0.2459, aux.acc_seg: 77.2180, loss: 0.7881
2023-12-28 09:12:05,549 - mmseg - INFO - Iter [14450/160000]	lr: 5.458e-05, eta: 1 day, 8:10:46, time: 0.799, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5309, decode.acc_seg: 80.2540, aux.loss_ce: 0.2385, aux.acc_seg: 78.8084, loss: 0.7694
2023-12-28 09:12:44,273 - mmseg - INFO - Iter [14500/160000]	lr: 5.456e-05, eta: 1 day, 8:09:56, time: 0.776, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5563, decode.acc_seg: 78.9332, aux.loss_ce: 0.2521, aux.acc_seg: 76.6994, loss: 0.8084
2023-12-28 09:13:24,664 - mmseg - INFO - Iter [14550/160000]	lr: 5.454e-05, eta: 1 day, 8:09:21, time: 0.807, data_time: 0.010, memory: 15708, decode.loss_ce: 0.5736, decode.acc_seg: 78.5848, aux.loss_ce: 0.2583, aux.acc_seg: 76.3722, loss: 0.8319
2023-12-28 09:14:04,076 - mmseg - INFO - Iter [14600/160000]	lr: 5.453e-05, eta: 1 day, 8:08:38, time: 0.789, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5305, decode.acc_seg: 79.5275, aux.loss_ce: 0.2370, aux.acc_seg: 78.1723, loss: 0.7675
2023-12-28 09:14:42,899 - mmseg - INFO - Iter [14650/160000]	lr: 5.451e-05, eta: 1 day, 8:07:49, time: 0.776, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5442, decode.acc_seg: 79.5875, aux.loss_ce: 0.2476, aux.acc_seg: 77.3450, loss: 0.7918
2023-12-28 09:15:21,598 - mmseg - INFO - Iter [14700/160000]	lr: 5.449e-05, eta: 1 day, 8:06:58, time: 0.774, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5480, decode.acc_seg: 79.4884, aux.loss_ce: 0.2525, aux.acc_seg: 77.3400, loss: 0.8005
2023-12-28 09:16:00,020 - mmseg - INFO - Iter [14750/160000]	lr: 5.447e-05, eta: 1 day, 8:06:05, time: 0.768, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5635, decode.acc_seg: 79.2295, aux.loss_ce: 0.2560, aux.acc_seg: 76.9883, loss: 0.8195
2023-12-28 09:16:37,511 - mmseg - INFO - Iter [14800/160000]	lr: 5.445e-05, eta: 1 day, 8:05:03, time: 0.750, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5502, decode.acc_seg: 79.3811, aux.loss_ce: 0.2486, aux.acc_seg: 77.2161, loss: 0.7988
2023-12-28 09:17:16,669 - mmseg - INFO - Iter [14850/160000]	lr: 5.443e-05, eta: 1 day, 8:04:16, time: 0.782, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5651, decode.acc_seg: 79.3429, aux.loss_ce: 0.2563, aux.acc_seg: 77.3452, loss: 0.8214
2023-12-28 09:17:56,835 - mmseg - INFO - Iter [14900/160000]	lr: 5.441e-05, eta: 1 day, 8:03:40, time: 0.803, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5323, decode.acc_seg: 79.5530, aux.loss_ce: 0.2404, aux.acc_seg: 77.9831, loss: 0.7727
2023-12-28 09:18:37,799 - mmseg - INFO - Iter [14950/160000]	lr: 5.439e-05, eta: 1 day, 8:03:12, time: 0.819, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5489, decode.acc_seg: 78.7767, aux.loss_ce: 0.2469, aux.acc_seg: 77.1731, loss: 0.7958
2023-12-28 09:19:18,004 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 09:19:18,005 - mmseg - INFO - Iter [15000/160000]	lr: 5.438e-05, eta: 1 day, 8:02:37, time: 0.805, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5381, decode.acc_seg: 79.7321, aux.loss_ce: 0.2394, aux.acc_seg: 78.5331, loss: 0.7776
2023-12-28 09:19:58,580 - mmseg - INFO - Iter [15050/160000]	lr: 5.436e-05, eta: 1 day, 8:02:05, time: 0.812, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5489, decode.acc_seg: 79.3542, aux.loss_ce: 0.2478, aux.acc_seg: 77.4680, loss: 0.7968
2023-12-28 09:20:39,055 - mmseg - INFO - Iter [15100/160000]	lr: 5.434e-05, eta: 1 day, 8:01:31, time: 0.808, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5499, decode.acc_seg: 79.0245, aux.loss_ce: 0.2482, aux.acc_seg: 77.4398, loss: 0.7981
2023-12-28 09:21:18,174 - mmseg - INFO - Iter [15150/160000]	lr: 5.432e-05, eta: 1 day, 8:00:46, time: 0.783, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5536, decode.acc_seg: 78.8393, aux.loss_ce: 0.2519, aux.acc_seg: 76.4082, loss: 0.8055
2023-12-28 09:22:00,268 - mmseg - INFO - Iter [15200/160000]	lr: 5.430e-05, eta: 1 day, 8:00:27, time: 0.841, data_time: 0.052, memory: 15708, decode.loss_ce: 0.5052, decode.acc_seg: 80.7617, aux.loss_ce: 0.2361, aux.acc_seg: 78.6988, loss: 0.7413
2023-12-28 09:22:40,380 - mmseg - INFO - Iter [15250/160000]	lr: 5.428e-05, eta: 1 day, 7:59:51, time: 0.802, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5475, decode.acc_seg: 79.0935, aux.loss_ce: 0.2576, aux.acc_seg: 76.5270, loss: 0.8051
2023-12-28 09:23:20,586 - mmseg - INFO - Iter [15300/160000]	lr: 5.426e-05, eta: 1 day, 7:59:15, time: 0.805, data_time: 0.013, memory: 15708, decode.loss_ce: 0.5120, decode.acc_seg: 80.2729, aux.loss_ce: 0.2327, aux.acc_seg: 78.4103, loss: 0.7446
2023-12-28 09:24:00,298 - mmseg - INFO - Iter [15350/160000]	lr: 5.424e-05, eta: 1 day, 7:58:34, time: 0.793, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5086, decode.acc_seg: 80.2739, aux.loss_ce: 0.2331, aux.acc_seg: 78.6033, loss: 0.7417
2023-12-28 09:24:38,322 - mmseg - INFO - Iter [15400/160000]	lr: 5.423e-05, eta: 1 day, 7:57:38, time: 0.761, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5176, decode.acc_seg: 80.0518, aux.loss_ce: 0.2402, aux.acc_seg: 77.5894, loss: 0.7578
2023-12-28 09:25:18,449 - mmseg - INFO - Iter [15450/160000]	lr: 5.421e-05, eta: 1 day, 7:57:01, time: 0.801, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5153, decode.acc_seg: 79.7847, aux.loss_ce: 0.2384, aux.acc_seg: 78.2120, loss: 0.7537
2023-12-28 09:25:58,791 - mmseg - INFO - Iter [15500/160000]	lr: 5.419e-05, eta: 1 day, 7:56:27, time: 0.807, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5236, decode.acc_seg: 80.3907, aux.loss_ce: 0.2361, aux.acc_seg: 78.8699, loss: 0.7597
2023-12-28 09:26:39,039 - mmseg - INFO - Iter [15550/160000]	lr: 5.417e-05, eta: 1 day, 7:55:51, time: 0.805, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5343, decode.acc_seg: 79.6580, aux.loss_ce: 0.2500, aux.acc_seg: 77.3939, loss: 0.7843
2023-12-28 09:27:18,477 - mmseg - INFO - Iter [15600/160000]	lr: 5.415e-05, eta: 1 day, 7:55:09, time: 0.789, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5397, decode.acc_seg: 79.6731, aux.loss_ce: 0.2477, aux.acc_seg: 77.6489, loss: 0.7874
2023-12-28 09:27:57,048 - mmseg - INFO - Iter [15650/160000]	lr: 5.413e-05, eta: 1 day, 7:54:18, time: 0.772, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5263, decode.acc_seg: 80.2732, aux.loss_ce: 0.2373, aux.acc_seg: 78.4496, loss: 0.7636
2023-12-28 09:28:37,484 - mmseg - INFO - Iter [15700/160000]	lr: 5.411e-05, eta: 1 day, 7:53:43, time: 0.808, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5360, decode.acc_seg: 79.8984, aux.loss_ce: 0.2402, aux.acc_seg: 78.0025, loss: 0.7761
2023-12-28 09:29:19,601 - mmseg - INFO - Iter [15750/160000]	lr: 5.409e-05, eta: 1 day, 7:53:25, time: 0.842, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5635, decode.acc_seg: 78.5482, aux.loss_ce: 0.2567, aux.acc_seg: 76.5082, loss: 0.8202
2023-12-28 09:29:59,793 - mmseg - INFO - Iter [15800/160000]	lr: 5.408e-05, eta: 1 day, 7:52:49, time: 0.805, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5571, decode.acc_seg: 79.0516, aux.loss_ce: 0.2506, aux.acc_seg: 77.7879, loss: 0.8077
2023-12-28 09:30:39,156 - mmseg - INFO - Iter [15850/160000]	lr: 5.406e-05, eta: 1 day, 7:52:06, time: 0.788, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5364, decode.acc_seg: 79.6562, aux.loss_ce: 0.2448, aux.acc_seg: 77.3367, loss: 0.7812
2023-12-28 09:31:16,464 - mmseg - INFO - Iter [15900/160000]	lr: 5.404e-05, eta: 1 day, 7:51:03, time: 0.746, data_time: 0.011, memory: 15708, decode.loss_ce: 0.5317, decode.acc_seg: 79.7224, aux.loss_ce: 0.2420, aux.acc_seg: 77.8275, loss: 0.7737
2023-12-28 09:31:56,470 - mmseg - INFO - Iter [15950/160000]	lr: 5.402e-05, eta: 1 day, 7:50:25, time: 0.800, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5351, decode.acc_seg: 79.5907, aux.loss_ce: 0.2425, aux.acc_seg: 77.9981, loss: 0.7776
2023-12-28 09:32:36,511 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-12-28 09:32:39,883 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 09:32:39,883 - mmseg - INFO - Iter [16000/160000]	lr: 5.400e-05, eta: 1 day, 7:50:18, time: 0.868, data_time: 0.012, memory: 15708, decode.loss_ce: 0.5369, decode.acc_seg: 79.8638, aux.loss_ce: 0.2453, aux.acc_seg: 77.8343, loss: 0.7822
2023-12-28 09:35:54,708 - mmseg - INFO - per class results:
2023-12-28 09:35:54,722 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 72.76 | 84.65 |
|       building      | 80.01 | 87.58 |
|         sky         | 93.84 | 96.74 |
|        floor        | 79.26 |  88.9 |
|         tree        |  72.4 | 89.68 |
|       ceiling       | 80.82 | 88.92 |
|         road        | 80.41 | 86.57 |
|         bed         | 81.55 | 94.74 |
|      windowpane     |  57.5 | 75.41 |
|        grass        | 66.55 | 82.41 |
|       cabinet       | 52.28 | 62.65 |
|       sidewalk      | 61.67 | 81.05 |
|        person       | 77.31 | 88.32 |
|        earth        | 33.97 | 47.32 |
|         door        | 40.47 | 59.43 |
|        table        | 48.61 | 62.44 |
|       mountain      |  55.3 | 71.46 |
|        plant        | 47.37 | 54.48 |
|       curtain       | 71.23 | 85.43 |
|        chair        | 47.17 | 61.84 |
|         car         | 82.96 | 90.99 |
|        water        | 43.71 | 52.35 |
|       painting      | 64.11 | 82.85 |
|         sofa        | 55.81 | 73.78 |
|        shelf        | 42.25 | 65.54 |
|        house        | 48.01 | 84.55 |
|         sea         | 57.11 | 83.46 |
|        mirror       | 55.11 | 65.31 |
|         rug         | 64.25 | 73.85 |
|        field        | 26.77 | 44.82 |
|       armchair      | 28.07 | 46.21 |
|         seat        | 51.96 | 75.81 |
|        fence        | 37.83 | 45.78 |
|         desk        | 35.58 | 60.59 |
|         rock        | 43.73 | 72.57 |
|       wardrobe      |  40.4 | 66.88 |
|         lamp        | 52.71 | 71.48 |
|       bathtub       |  60.5 | 77.92 |
|       railing       | 32.08 | 49.13 |
|       cushion       | 49.13 | 63.11 |
|         base        | 27.47 | 41.15 |
|         box         |  17.1 | 21.53 |
|        column       | 41.45 | 58.47 |
|      signboard      | 32.71 | 48.05 |
|   chest of drawers  | 41.46 |  52.1 |
|       counter       |  20.9 |  25.3 |
|         sand        | 29.98 | 52.73 |
|         sink        | 55.27 | 72.55 |
|      skyscraper     | 50.36 | 65.67 |
|      fireplace      | 55.23 | 81.64 |
|     refrigerator    |  57.1 |  77.8 |
|      grandstand     | 28.77 | 68.16 |
|         path        | 24.17 | 33.92 |
|        stairs       |  29.0 | 35.04 |
|        runway       | 62.31 | 97.28 |
|         case        | 63.03 | 69.98 |
|      pool table     | 91.05 | 96.79 |
|        pillow       |  38.3 | 42.71 |
|     screen door     | 67.44 | 80.43 |
|       stairway      | 29.46 | 36.84 |
|        river        | 19.92 |  61.9 |
|        bridge       | 67.63 | 84.91 |
|       bookcase      | 27.48 | 37.97 |
|        blind        | 28.54 | 33.44 |
|     coffee table    | 44.69 | 76.71 |
|        toilet       | 70.44 | 85.43 |
|        flower       | 29.08 | 33.75 |
|         book        | 41.67 | 68.67 |
|         hill        |  3.35 |  4.65 |
|        bench        | 39.36 |  53.1 |
|      countertop     | 55.12 | 67.15 |
|        stove        | 52.84 | 66.16 |
|         palm        | 44.05 | 58.84 |
|    kitchen island   |  27.7 | 78.57 |
|       computer      | 58.96 | 83.17 |
|     swivel chair    | 33.47 |  72.1 |
|         boat        | 59.34 | 83.67 |
|         bar         | 46.44 | 53.01 |
|    arcade machine   | 46.33 | 93.59 |
|        hovel        | 53.45 | 60.66 |
|         bus         | 61.84 | 89.72 |
|        towel        | 45.58 | 58.56 |
|        light        | 40.55 | 45.95 |
|        truck        | 21.19 |  41.3 |
|        tower        | 20.49 | 33.33 |
|      chandelier     | 55.72 | 74.78 |
|        awning       | 16.84 | 19.12 |
|     streetlight     | 15.77 | 20.16 |
|        booth        | 17.65 | 19.94 |
| television receiver | 50.93 | 72.63 |
|       airplane      | 48.21 | 64.25 |
|      dirt track     |  2.51 |  18.2 |
|       apparel       | 25.54 | 32.05 |
|         pole        | 12.41 | 15.41 |
|         land        |  0.19 |  0.43 |
|      bannister      |  6.46 |  8.44 |
|      escalator      | 25.83 | 27.24 |
|       ottoman       | 32.19 | 34.83 |
|        bottle       | 18.26 | 23.28 |
|        buffet       | 42.85 | 64.16 |
|        poster       | 14.88 | 17.31 |
|        stage        |  7.58 | 17.34 |
|         van         | 31.56 | 35.37 |
|         ship        | 44.96 | 65.39 |
|       fountain      | 21.08 | 21.78 |
|    conveyer belt    | 55.21 | 93.91 |
|        canopy       | 21.38 | 27.69 |
|        washer       | 58.84 | 76.51 |
|      plaything      | 19.52 | 30.08 |
|    swimming pool    | 60.87 | 79.66 |
|        stool        | 19.25 | 23.32 |
|        barrel       | 17.17 | 65.01 |
|        basket       | 27.93 | 30.53 |
|      waterfall      | 66.37 | 92.28 |
|         tent        | 80.52 | 99.52 |
|         bag         |  0.14 |  0.14 |
|       minibike      | 62.08 | 80.05 |
|        cradle       | 54.95 | 83.81 |
|         oven        | 20.34 | 24.49 |
|         ball        |  43.7 | 58.74 |
|         food        | 55.73 | 68.68 |
|         step        |  0.0  |  0.0  |
|         tank        | 46.53 | 56.39 |
|      trade name     | 15.81 | 17.37 |
|      microwave      | 63.13 | 90.01 |
|         pot         | 33.11 |  40.5 |
|        animal       | 57.72 | 59.63 |
|       bicycle       | 54.66 |  78.4 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 31.21 | 72.09 |
|        screen       | 58.66 | 91.33 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      | 47.24 | 55.76 |
|         hood        | 34.37 | 42.39 |
|        sconce       | 11.37 | 12.38 |
|         vase        | 27.58 | 42.92 |
|    traffic light    | 14.98 | 27.78 |
|         tray        |  0.12 |  0.12 |
|        ashcan       | 28.55 | 37.46 |
|         fan         | 41.65 | 53.25 |
|         pier        | 61.78 | 77.72 |
|      crt screen     |  8.62 | 14.51 |
|        plate        | 44.56 | 67.16 |
|       monitor       | 37.74 | 84.04 |
|    bulletin board   | 34.25 | 37.39 |
|        shower       |  0.0  |  0.0  |
|       radiator      |  42.7 | 45.42 |
|        glass        |  4.08 |  4.18 |
|        clock        | 25.59 | 28.32 |
|         flag        | 35.69 | 37.58 |
+---------------------+-------+-------+
2023-12-28 09:35:54,722 - mmseg - INFO - Summary:
2023-12-28 09:35:54,723 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 79.77 | 41.28 | 55.61 |
+-------+-------+-------+
2023-12-28 09:35:54,747 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 09:35:54,748 - mmseg - INFO - Iter(val) [250]	aAcc: 0.7977, mIoU: 0.4128, mAcc: 0.5561, IoU.wall: 0.7276, IoU.building: 0.8001, IoU.sky: 0.9384, IoU.floor: 0.7926, IoU.tree: 0.7240, IoU.ceiling: 0.8082, IoU.road: 0.8041, IoU.bed : 0.8155, IoU.windowpane: 0.5750, IoU.grass: 0.6655, IoU.cabinet: 0.5228, IoU.sidewalk: 0.6167, IoU.person: 0.7731, IoU.earth: 0.3397, IoU.door: 0.4047, IoU.table: 0.4861, IoU.mountain: 0.5530, IoU.plant: 0.4737, IoU.curtain: 0.7123, IoU.chair: 0.4717, IoU.car: 0.8296, IoU.water: 0.4371, IoU.painting: 0.6411, IoU.sofa: 0.5581, IoU.shelf: 0.4225, IoU.house: 0.4801, IoU.sea: 0.5711, IoU.mirror: 0.5511, IoU.rug: 0.6425, IoU.field: 0.2677, IoU.armchair: 0.2807, IoU.seat: 0.5196, IoU.fence: 0.3783, IoU.desk: 0.3558, IoU.rock: 0.4373, IoU.wardrobe: 0.4040, IoU.lamp: 0.5271, IoU.bathtub: 0.6050, IoU.railing: 0.3208, IoU.cushion: 0.4913, IoU.base: 0.2747, IoU.box: 0.1710, IoU.column: 0.4145, IoU.signboard: 0.3271, IoU.chest of drawers: 0.4146, IoU.counter: 0.2090, IoU.sand: 0.2998, IoU.sink: 0.5527, IoU.skyscraper: 0.5036, IoU.fireplace: 0.5523, IoU.refrigerator: 0.5710, IoU.grandstand: 0.2877, IoU.path: 0.2417, IoU.stairs: 0.2900, IoU.runway: 0.6231, IoU.case: 0.6303, IoU.pool table: 0.9105, IoU.pillow: 0.3830, IoU.screen door: 0.6744, IoU.stairway: 0.2946, IoU.river: 0.1992, IoU.bridge: 0.6763, IoU.bookcase: 0.2748, IoU.blind: 0.2854, IoU.coffee table: 0.4469, IoU.toilet: 0.7044, IoU.flower: 0.2908, IoU.book: 0.4167, IoU.hill: 0.0335, IoU.bench: 0.3936, IoU.countertop: 0.5512, IoU.stove: 0.5284, IoU.palm: 0.4405, IoU.kitchen island: 0.2770, IoU.computer: 0.5896, IoU.swivel chair: 0.3347, IoU.boat: 0.5934, IoU.bar: 0.4644, IoU.arcade machine: 0.4633, IoU.hovel: 0.5345, IoU.bus: 0.6184, IoU.towel: 0.4558, IoU.light: 0.4055, IoU.truck: 0.2119, IoU.tower: 0.2049, IoU.chandelier: 0.5572, IoU.awning: 0.1684, IoU.streetlight: 0.1577, IoU.booth: 0.1765, IoU.television receiver: 0.5093, IoU.airplane: 0.4821, IoU.dirt track: 0.0251, IoU.apparel: 0.2554, IoU.pole: 0.1241, IoU.land: 0.0019, IoU.bannister: 0.0646, IoU.escalator: 0.2583, IoU.ottoman: 0.3219, IoU.bottle: 0.1826, IoU.buffet: 0.4285, IoU.poster: 0.1488, IoU.stage: 0.0758, IoU.van: 0.3156, IoU.ship: 0.4496, IoU.fountain: 0.2108, IoU.conveyer belt: 0.5521, IoU.canopy: 0.2138, IoU.washer: 0.5884, IoU.plaything: 0.1952, IoU.swimming pool: 0.6087, IoU.stool: 0.1925, IoU.barrel: 0.1717, IoU.basket: 0.2793, IoU.waterfall: 0.6637, IoU.tent: 0.8052, IoU.bag: 0.0014, IoU.minibike: 0.6208, IoU.cradle: 0.5495, IoU.oven: 0.2034, IoU.ball: 0.4370, IoU.food: 0.5573, IoU.step: 0.0000, IoU.tank: 0.4653, IoU.trade name: 0.1581, IoU.microwave: 0.6313, IoU.pot: 0.3311, IoU.animal: 0.5772, IoU.bicycle: 0.5466, IoU.lake: 0.0000, IoU.dishwasher: 0.3121, IoU.screen: 0.5866, IoU.blanket: 0.0000, IoU.sculpture: 0.4724, IoU.hood: 0.3437, IoU.sconce: 0.1137, IoU.vase: 0.2758, IoU.traffic light: 0.1498, IoU.tray: 0.0012, IoU.ashcan: 0.2855, IoU.fan: 0.4165, IoU.pier: 0.6178, IoU.crt screen: 0.0862, IoU.plate: 0.4456, IoU.monitor: 0.3774, IoU.bulletin board: 0.3425, IoU.shower: 0.0000, IoU.radiator: 0.4270, IoU.glass: 0.0408, IoU.clock: 0.2559, IoU.flag: 0.3569, Acc.wall: 0.8465, Acc.building: 0.8758, Acc.sky: 0.9674, Acc.floor: 0.8890, Acc.tree: 0.8968, Acc.ceiling: 0.8892, Acc.road: 0.8657, Acc.bed : 0.9474, Acc.windowpane: 0.7541, Acc.grass: 0.8241, Acc.cabinet: 0.6265, Acc.sidewalk: 0.8105, Acc.person: 0.8832, Acc.earth: 0.4732, Acc.door: 0.5943, Acc.table: 0.6244, Acc.mountain: 0.7146, Acc.plant: 0.5448, Acc.curtain: 0.8543, Acc.chair: 0.6184, Acc.car: 0.9099, Acc.water: 0.5235, Acc.painting: 0.8285, Acc.sofa: 0.7378, Acc.shelf: 0.6554, Acc.house: 0.8455, Acc.sea: 0.8346, Acc.mirror: 0.6531, Acc.rug: 0.7385, Acc.field: 0.4482, Acc.armchair: 0.4621, Acc.seat: 0.7581, Acc.fence: 0.4578, Acc.desk: 0.6059, Acc.rock: 0.7257, Acc.wardrobe: 0.6688, Acc.lamp: 0.7148, Acc.bathtub: 0.7792, Acc.railing: 0.4913, Acc.cushion: 0.6311, Acc.base: 0.4115, Acc.box: 0.2153, Acc.column: 0.5847, Acc.signboard: 0.4805, Acc.chest of drawers: 0.5210, Acc.counter: 0.2530, Acc.sand: 0.5273, Acc.sink: 0.7255, Acc.skyscraper: 0.6567, Acc.fireplace: 0.8164, Acc.refrigerator: 0.7780, Acc.grandstand: 0.6816, Acc.path: 0.3392, Acc.stairs: 0.3504, Acc.runway: 0.9728, Acc.case: 0.6998, Acc.pool table: 0.9679, Acc.pillow: 0.4271, Acc.screen door: 0.8043, Acc.stairway: 0.3684, Acc.river: 0.6190, Acc.bridge: 0.8491, Acc.bookcase: 0.3797, Acc.blind: 0.3344, Acc.coffee table: 0.7671, Acc.toilet: 0.8543, Acc.flower: 0.3375, Acc.book: 0.6867, Acc.hill: 0.0465, Acc.bench: 0.5310, Acc.countertop: 0.6715, Acc.stove: 0.6616, Acc.palm: 0.5884, Acc.kitchen island: 0.7857, Acc.computer: 0.8317, Acc.swivel chair: 0.7210, Acc.boat: 0.8367, Acc.bar: 0.5301, Acc.arcade machine: 0.9359, Acc.hovel: 0.6066, Acc.bus: 0.8972, Acc.towel: 0.5856, Acc.light: 0.4595, Acc.truck: 0.4130, Acc.tower: 0.3333, Acc.chandelier: 0.7478, Acc.awning: 0.1912, Acc.streetlight: 0.2016, Acc.booth: 0.1994, Acc.television receiver: 0.7263, Acc.airplane: 0.6425, Acc.dirt track: 0.1820, Acc.apparel: 0.3205, Acc.pole: 0.1541, Acc.land: 0.0043, Acc.bannister: 0.0844, Acc.escalator: 0.2724, Acc.ottoman: 0.3483, Acc.bottle: 0.2328, Acc.buffet: 0.6416, Acc.poster: 0.1731, Acc.stage: 0.1734, Acc.van: 0.3537, Acc.ship: 0.6539, Acc.fountain: 0.2178, Acc.conveyer belt: 0.9391, Acc.canopy: 0.2769, Acc.washer: 0.7651, Acc.plaything: 0.3008, Acc.swimming pool: 0.7966, Acc.stool: 0.2332, Acc.barrel: 0.6501, Acc.basket: 0.3053, Acc.waterfall: 0.9228, Acc.tent: 0.9952, Acc.bag: 0.0014, Acc.minibike: 0.8005, Acc.cradle: 0.8381, Acc.oven: 0.2449, Acc.ball: 0.5874, Acc.food: 0.6868, Acc.step: 0.0000, Acc.tank: 0.5639, Acc.trade name: 0.1737, Acc.microwave: 0.9001, Acc.pot: 0.4050, Acc.animal: 0.5963, Acc.bicycle: 0.7840, Acc.lake: 0.0000, Acc.dishwasher: 0.7209, Acc.screen: 0.9133, Acc.blanket: 0.0000, Acc.sculpture: 0.5576, Acc.hood: 0.4239, Acc.sconce: 0.1238, Acc.vase: 0.4292, Acc.traffic light: 0.2778, Acc.tray: 0.0012, Acc.ashcan: 0.3746, Acc.fan: 0.5325, Acc.pier: 0.7772, Acc.crt screen: 0.1451, Acc.plate: 0.6716, Acc.monitor: 0.8404, Acc.bulletin board: 0.3739, Acc.shower: 0.0000, Acc.radiator: 0.4542, Acc.glass: 0.0418, Acc.clock: 0.2832, Acc.flag: 0.3758
2023-12-28 09:36:34,672 - mmseg - INFO - Iter [16050/160000]	lr: 5.398e-05, eta: 1 day, 8:18:47, time: 4.695, data_time: 3.907, memory: 18256, decode.loss_ce: 0.4992, decode.acc_seg: 80.9214, aux.loss_ce: 0.2223, aux.acc_seg: 79.3071, loss: 0.7215
2023-12-28 09:37:14,377 - mmseg - INFO - Iter [16100/160000]	lr: 5.396e-05, eta: 1 day, 8:18:00, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5558, decode.acc_seg: 79.3914, aux.loss_ce: 0.2550, aux.acc_seg: 77.4424, loss: 0.8107
2023-12-28 09:37:53,881 - mmseg - INFO - Iter [16150/160000]	lr: 5.394e-05, eta: 1 day, 8:17:12, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5402, decode.acc_seg: 80.0683, aux.loss_ce: 0.2455, aux.acc_seg: 78.0459, loss: 0.7857
2023-12-28 09:38:33,412 - mmseg - INFO - Iter [16200/160000]	lr: 5.393e-05, eta: 1 day, 8:16:24, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5095, decode.acc_seg: 80.3929, aux.loss_ce: 0.2316, aux.acc_seg: 78.5650, loss: 0.7412
2023-12-28 09:39:13,200 - mmseg - INFO - Iter [16250/160000]	lr: 5.391e-05, eta: 1 day, 8:15:38, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5149, decode.acc_seg: 80.5470, aux.loss_ce: 0.2339, aux.acc_seg: 78.8568, loss: 0.7489
2023-12-28 09:39:52,503 - mmseg - INFO - Iter [16300/160000]	lr: 5.389e-05, eta: 1 day, 8:14:48, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5347, decode.acc_seg: 79.6090, aux.loss_ce: 0.2428, aux.acc_seg: 77.9583, loss: 0.7774
2023-12-28 09:40:33,187 - mmseg - INFO - Iter [16350/160000]	lr: 5.387e-05, eta: 1 day, 8:14:10, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4986, decode.acc_seg: 81.0077, aux.loss_ce: 0.2289, aux.acc_seg: 79.1190, loss: 0.7276
2023-12-28 09:41:13,396 - mmseg - INFO - Iter [16400/160000]	lr: 5.385e-05, eta: 1 day, 8:13:28, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5383, decode.acc_seg: 79.7838, aux.loss_ce: 0.2441, aux.acc_seg: 77.9563, loss: 0.7824
2023-12-28 09:41:54,469 - mmseg - INFO - Iter [16450/160000]	lr: 5.383e-05, eta: 1 day, 8:12:54, time: 0.823, data_time: 0.054, memory: 18256, decode.loss_ce: 0.5221, decode.acc_seg: 79.7991, aux.loss_ce: 0.2369, aux.acc_seg: 77.9752, loss: 0.7590
2023-12-28 09:42:34,638 - mmseg - INFO - Iter [16500/160000]	lr: 5.381e-05, eta: 1 day, 8:12:11, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4889, decode.acc_seg: 81.4996, aux.loss_ce: 0.2257, aux.acc_seg: 79.2988, loss: 0.7147
2023-12-28 09:43:13,409 - mmseg - INFO - Iter [16550/160000]	lr: 5.379e-05, eta: 1 day, 8:11:17, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4823, decode.acc_seg: 81.2920, aux.loss_ce: 0.2246, aux.acc_seg: 79.1312, loss: 0.7069
2023-12-28 09:43:51,995 - mmseg - INFO - Iter [16600/160000]	lr: 5.378e-05, eta: 1 day, 8:10:21, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5152, decode.acc_seg: 80.2500, aux.loss_ce: 0.2359, aux.acc_seg: 78.3104, loss: 0.7511
2023-12-28 09:44:31,538 - mmseg - INFO - Iter [16650/160000]	lr: 5.376e-05, eta: 1 day, 8:09:33, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5241, decode.acc_seg: 80.3508, aux.loss_ce: 0.2397, aux.acc_seg: 78.2997, loss: 0.7638
2023-12-28 09:45:09,303 - mmseg - INFO - Iter [16700/160000]	lr: 5.374e-05, eta: 1 day, 8:08:31, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5161, decode.acc_seg: 80.8985, aux.loss_ce: 0.2394, aux.acc_seg: 78.7414, loss: 0.7555
2023-12-28 09:45:49,087 - mmseg - INFO - Iter [16750/160000]	lr: 5.372e-05, eta: 1 day, 8:07:45, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5260, decode.acc_seg: 80.6243, aux.loss_ce: 0.2386, aux.acc_seg: 78.6819, loss: 0.7646
2023-12-28 09:46:26,459 - mmseg - INFO - Iter [16800/160000]	lr: 5.370e-05, eta: 1 day, 8:06:39, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4998, decode.acc_seg: 80.6046, aux.loss_ce: 0.2263, aux.acc_seg: 79.1744, loss: 0.7261
2023-12-28 09:47:04,552 - mmseg - INFO - Iter [16850/160000]	lr: 5.368e-05, eta: 1 day, 8:05:39, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5190, decode.acc_seg: 80.9418, aux.loss_ce: 0.2379, aux.acc_seg: 78.7985, loss: 0.7569
2023-12-28 09:47:45,038 - mmseg - INFO - Iter [16900/160000]	lr: 5.366e-05, eta: 1 day, 8:05:00, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4858, decode.acc_seg: 81.6497, aux.loss_ce: 0.2254, aux.acc_seg: 79.5003, loss: 0.7112
2023-12-28 09:48:24,272 - mmseg - INFO - Iter [16950/160000]	lr: 5.364e-05, eta: 1 day, 8:04:10, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4891, decode.acc_seg: 81.2967, aux.loss_ce: 0.2247, aux.acc_seg: 79.4292, loss: 0.7139
2023-12-28 09:49:03,010 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 09:49:03,010 - mmseg - INFO - Iter [17000/160000]	lr: 5.363e-05, eta: 1 day, 8:03:17, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5112, decode.acc_seg: 80.7952, aux.loss_ce: 0.2338, aux.acc_seg: 79.1957, loss: 0.7450
2023-12-28 09:49:43,289 - mmseg - INFO - Iter [17050/160000]	lr: 5.361e-05, eta: 1 day, 8:02:36, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5001, decode.acc_seg: 80.5694, aux.loss_ce: 0.2302, aux.acc_seg: 78.4778, loss: 0.7303
2023-12-28 09:50:23,498 - mmseg - INFO - Iter [17100/160000]	lr: 5.359e-05, eta: 1 day, 8:01:54, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5110, decode.acc_seg: 80.8088, aux.loss_ce: 0.2351, aux.acc_seg: 78.6700, loss: 0.7462
2023-12-28 09:51:02,161 - mmseg - INFO - Iter [17150/160000]	lr: 5.357e-05, eta: 1 day, 8:01:00, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5254, decode.acc_seg: 79.5205, aux.loss_ce: 0.2427, aux.acc_seg: 77.3097, loss: 0.7681
2023-12-28 09:51:39,839 - mmseg - INFO - Iter [17200/160000]	lr: 5.355e-05, eta: 1 day, 7:59:57, time: 0.753, data_time: 0.010, memory: 18256, decode.loss_ce: 0.5309, decode.acc_seg: 79.5889, aux.loss_ce: 0.2394, aux.acc_seg: 77.7722, loss: 0.7703
2023-12-28 09:52:19,659 - mmseg - INFO - Iter [17250/160000]	lr: 5.353e-05, eta: 1 day, 7:59:12, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5366, decode.acc_seg: 79.7214, aux.loss_ce: 0.2422, aux.acc_seg: 77.9851, loss: 0.7788
2023-12-28 09:52:59,621 - mmseg - INFO - Iter [17300/160000]	lr: 5.351e-05, eta: 1 day, 7:58:29, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5097, decode.acc_seg: 80.4721, aux.loss_ce: 0.2330, aux.acc_seg: 78.8420, loss: 0.7427
2023-12-28 09:53:39,942 - mmseg - INFO - Iter [17350/160000]	lr: 5.349e-05, eta: 1 day, 7:57:48, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5180, decode.acc_seg: 80.0967, aux.loss_ce: 0.2349, aux.acc_seg: 78.1715, loss: 0.7529
2023-12-28 09:54:18,741 - mmseg - INFO - Iter [17400/160000]	lr: 5.348e-05, eta: 1 day, 7:56:55, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5421, decode.acc_seg: 80.0923, aux.loss_ce: 0.2458, aux.acc_seg: 78.1521, loss: 0.7880
2023-12-28 09:54:59,007 - mmseg - INFO - Iter [17450/160000]	lr: 5.346e-05, eta: 1 day, 7:56:14, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5392, decode.acc_seg: 79.6127, aux.loss_ce: 0.2438, aux.acc_seg: 78.0324, loss: 0.7830
2023-12-28 09:55:39,596 - mmseg - INFO - Iter [17500/160000]	lr: 5.344e-05, eta: 1 day, 7:55:36, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5180, decode.acc_seg: 79.4584, aux.loss_ce: 0.2363, aux.acc_seg: 77.6984, loss: 0.7543
2023-12-28 09:56:20,104 - mmseg - INFO - Iter [17550/160000]	lr: 5.342e-05, eta: 1 day, 7:54:57, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5165, decode.acc_seg: 80.4590, aux.loss_ce: 0.2327, aux.acc_seg: 78.8727, loss: 0.7492
2023-12-28 09:57:00,097 - mmseg - INFO - Iter [17600/160000]	lr: 5.340e-05, eta: 1 day, 7:54:14, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5004, decode.acc_seg: 81.0073, aux.loss_ce: 0.2274, aux.acc_seg: 78.9496, loss: 0.7277
2023-12-28 09:57:40,098 - mmseg - INFO - Iter [17650/160000]	lr: 5.338e-05, eta: 1 day, 7:53:31, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5233, decode.acc_seg: 80.0744, aux.loss_ce: 0.2368, aux.acc_seg: 78.2778, loss: 0.7601
2023-12-28 09:58:19,997 - mmseg - INFO - Iter [17700/160000]	lr: 5.336e-05, eta: 1 day, 7:52:48, time: 0.799, data_time: 0.054, memory: 18256, decode.loss_ce: 0.5035, decode.acc_seg: 80.8259, aux.loss_ce: 0.2340, aux.acc_seg: 78.6706, loss: 0.7375
2023-12-28 09:58:59,031 - mmseg - INFO - Iter [17750/160000]	lr: 5.334e-05, eta: 1 day, 7:51:57, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5076, decode.acc_seg: 80.5191, aux.loss_ce: 0.2323, aux.acc_seg: 78.5874, loss: 0.7399
2023-12-28 09:59:39,228 - mmseg - INFO - Iter [17800/160000]	lr: 5.333e-05, eta: 1 day, 7:51:16, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5113, decode.acc_seg: 79.8158, aux.loss_ce: 0.2344, aux.acc_seg: 77.9020, loss: 0.7458
2023-12-28 10:00:18,142 - mmseg - INFO - Iter [17850/160000]	lr: 5.331e-05, eta: 1 day, 7:50:25, time: 0.778, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4854, decode.acc_seg: 81.9222, aux.loss_ce: 0.2278, aux.acc_seg: 79.8478, loss: 0.7132
2023-12-28 10:00:57,634 - mmseg - INFO - Iter [17900/160000]	lr: 5.329e-05, eta: 1 day, 7:49:38, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4892, decode.acc_seg: 81.4330, aux.loss_ce: 0.2274, aux.acc_seg: 79.1541, loss: 0.7166
2023-12-28 10:01:37,713 - mmseg - INFO - Iter [17950/160000]	lr: 5.327e-05, eta: 1 day, 7:48:55, time: 0.800, data_time: 0.010, memory: 18256, decode.loss_ce: 0.5050, decode.acc_seg: 80.8346, aux.loss_ce: 0.2302, aux.acc_seg: 79.1554, loss: 0.7352
2023-12-28 10:02:17,761 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 10:02:17,762 - mmseg - INFO - Iter [18000/160000]	lr: 5.325e-05, eta: 1 day, 7:48:13, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5067, decode.acc_seg: 80.8342, aux.loss_ce: 0.2335, aux.acc_seg: 79.0296, loss: 0.7402
2023-12-28 10:02:57,806 - mmseg - INFO - Iter [18050/160000]	lr: 5.323e-05, eta: 1 day, 7:47:30, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5000, decode.acc_seg: 80.6515, aux.loss_ce: 0.2302, aux.acc_seg: 78.6303, loss: 0.7302
2023-12-28 10:03:36,401 - mmseg - INFO - Iter [18100/160000]	lr: 5.321e-05, eta: 1 day, 7:46:37, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4913, decode.acc_seg: 81.0005, aux.loss_ce: 0.2245, aux.acc_seg: 79.0298, loss: 0.7158
2023-12-28 10:04:15,639 - mmseg - INFO - Iter [18150/160000]	lr: 5.319e-05, eta: 1 day, 7:45:48, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4878, decode.acc_seg: 81.2492, aux.loss_ce: 0.2210, aux.acc_seg: 79.7754, loss: 0.7088
2023-12-28 10:04:53,925 - mmseg - INFO - Iter [18200/160000]	lr: 5.318e-05, eta: 1 day, 7:44:52, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4886, decode.acc_seg: 81.1768, aux.loss_ce: 0.2265, aux.acc_seg: 79.3944, loss: 0.7151
2023-12-28 10:05:33,555 - mmseg - INFO - Iter [18250/160000]	lr: 5.316e-05, eta: 1 day, 7:44:06, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4969, decode.acc_seg: 81.2677, aux.loss_ce: 0.2284, aux.acc_seg: 79.4293, loss: 0.7253
2023-12-28 10:06:12,683 - mmseg - INFO - Iter [18300/160000]	lr: 5.314e-05, eta: 1 day, 7:43:17, time: 0.782, data_time: 0.010, memory: 18256, decode.loss_ce: 0.5275, decode.acc_seg: 80.5419, aux.loss_ce: 0.2381, aux.acc_seg: 78.7404, loss: 0.7657
2023-12-28 10:06:49,939 - mmseg - INFO - Iter [18350/160000]	lr: 5.312e-05, eta: 1 day, 7:42:13, time: 0.746, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5149, decode.acc_seg: 80.2741, aux.loss_ce: 0.2355, aux.acc_seg: 77.9858, loss: 0.7504
2023-12-28 10:07:29,346 - mmseg - INFO - Iter [18400/160000]	lr: 5.310e-05, eta: 1 day, 7:41:26, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5039, decode.acc_seg: 81.2369, aux.loss_ce: 0.2340, aux.acc_seg: 78.8236, loss: 0.7379
2023-12-28 10:08:09,503 - mmseg - INFO - Iter [18450/160000]	lr: 5.308e-05, eta: 1 day, 7:40:45, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4954, decode.acc_seg: 80.4575, aux.loss_ce: 0.2310, aux.acc_seg: 78.0989, loss: 0.7263
2023-12-28 10:08:48,834 - mmseg - INFO - Iter [18500/160000]	lr: 5.306e-05, eta: 1 day, 7:39:57, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5076, decode.acc_seg: 80.3353, aux.loss_ce: 0.2349, aux.acc_seg: 78.6322, loss: 0.7426
2023-12-28 10:09:26,556 - mmseg - INFO - Iter [18550/160000]	lr: 5.304e-05, eta: 1 day, 7:38:58, time: 0.754, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4683, decode.acc_seg: 81.7639, aux.loss_ce: 0.2136, aux.acc_seg: 80.1354, loss: 0.6819
2023-12-28 10:10:07,239 - mmseg - INFO - Iter [18600/160000]	lr: 5.303e-05, eta: 1 day, 7:38:20, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5077, decode.acc_seg: 80.7216, aux.loss_ce: 0.2312, aux.acc_seg: 78.6973, loss: 0.7389
2023-12-28 10:10:47,728 - mmseg - INFO - Iter [18650/160000]	lr: 5.301e-05, eta: 1 day, 7:37:41, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5088, decode.acc_seg: 80.3105, aux.loss_ce: 0.2293, aux.acc_seg: 78.7177, loss: 0.7381
2023-12-28 10:11:25,437 - mmseg - INFO - Iter [18700/160000]	lr: 5.299e-05, eta: 1 day, 7:36:42, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4967, decode.acc_seg: 81.2469, aux.loss_ce: 0.2255, aux.acc_seg: 79.3352, loss: 0.7222
2023-12-28 10:12:05,137 - mmseg - INFO - Iter [18750/160000]	lr: 5.297e-05, eta: 1 day, 7:35:57, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5259, decode.acc_seg: 79.3986, aux.loss_ce: 0.2387, aux.acc_seg: 77.6248, loss: 0.7646
2023-12-28 10:12:45,181 - mmseg - INFO - Iter [18800/160000]	lr: 5.295e-05, eta: 1 day, 7:35:15, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5325, decode.acc_seg: 79.7731, aux.loss_ce: 0.2396, aux.acc_seg: 78.1138, loss: 0.7721
2023-12-28 10:13:25,255 - mmseg - INFO - Iter [18850/160000]	lr: 5.293e-05, eta: 1 day, 7:34:34, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4825, decode.acc_seg: 81.7679, aux.loss_ce: 0.2199, aux.acc_seg: 79.7472, loss: 0.7023
2023-12-28 10:14:05,229 - mmseg - INFO - Iter [18900/160000]	lr: 5.291e-05, eta: 1 day, 7:33:51, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5055, decode.acc_seg: 80.5468, aux.loss_ce: 0.2332, aux.acc_seg: 78.1424, loss: 0.7387
2023-12-28 10:14:47,414 - mmseg - INFO - Iter [18950/160000]	lr: 5.289e-05, eta: 1 day, 7:33:25, time: 0.845, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4837, decode.acc_seg: 81.3183, aux.loss_ce: 0.2201, aux.acc_seg: 79.7035, loss: 0.7038
2023-12-28 10:15:27,360 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 10:15:27,361 - mmseg - INFO - Iter [19000/160000]	lr: 5.288e-05, eta: 1 day, 7:32:42, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4823, decode.acc_seg: 81.1887, aux.loss_ce: 0.2232, aux.acc_seg: 79.2655, loss: 0.7055
2023-12-28 10:16:05,339 - mmseg - INFO - Iter [19050/160000]	lr: 5.286e-05, eta: 1 day, 7:31:46, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5018, decode.acc_seg: 81.2324, aux.loss_ce: 0.2261, aux.acc_seg: 79.5511, loss: 0.7279
2023-12-28 10:16:44,800 - mmseg - INFO - Iter [19100/160000]	lr: 5.284e-05, eta: 1 day, 7:30:59, time: 0.788, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4687, decode.acc_seg: 81.6722, aux.loss_ce: 0.2211, aux.acc_seg: 79.7016, loss: 0.6897
2023-12-28 10:17:22,749 - mmseg - INFO - Iter [19150/160000]	lr: 5.282e-05, eta: 1 day, 7:30:02, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4535, decode.acc_seg: 82.3183, aux.loss_ce: 0.2149, aux.acc_seg: 79.9647, loss: 0.6684
2023-12-28 10:18:02,630 - mmseg - INFO - Iter [19200/160000]	lr: 5.280e-05, eta: 1 day, 7:29:19, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4792, decode.acc_seg: 81.6535, aux.loss_ce: 0.2210, aux.acc_seg: 79.7892, loss: 0.7002
2023-12-28 10:18:40,112 - mmseg - INFO - Iter [19250/160000]	lr: 5.278e-05, eta: 1 day, 7:28:18, time: 0.750, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4825, decode.acc_seg: 81.5134, aux.loss_ce: 0.2236, aux.acc_seg: 79.4275, loss: 0.7062
2023-12-28 10:19:19,523 - mmseg - INFO - Iter [19300/160000]	lr: 5.276e-05, eta: 1 day, 7:27:32, time: 0.787, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4608, decode.acc_seg: 82.3735, aux.loss_ce: 0.2092, aux.acc_seg: 80.5950, loss: 0.6700
2023-12-28 10:19:59,528 - mmseg - INFO - Iter [19350/160000]	lr: 5.274e-05, eta: 1 day, 7:26:50, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4888, decode.acc_seg: 81.4368, aux.loss_ce: 0.2243, aux.acc_seg: 79.3792, loss: 0.7131
2023-12-28 10:20:39,327 - mmseg - INFO - Iter [19400/160000]	lr: 5.273e-05, eta: 1 day, 7:26:06, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5077, decode.acc_seg: 80.2166, aux.loss_ce: 0.2358, aux.acc_seg: 78.3779, loss: 0.7435
2023-12-28 10:21:19,055 - mmseg - INFO - Iter [19450/160000]	lr: 5.271e-05, eta: 1 day, 7:25:22, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4956, decode.acc_seg: 81.4703, aux.loss_ce: 0.2257, aux.acc_seg: 79.4834, loss: 0.7213
2023-12-28 10:21:58,475 - mmseg - INFO - Iter [19500/160000]	lr: 5.269e-05, eta: 1 day, 7:24:36, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4757, decode.acc_seg: 81.4817, aux.loss_ce: 0.2204, aux.acc_seg: 79.5224, loss: 0.6961
2023-12-28 10:22:38,221 - mmseg - INFO - Iter [19550/160000]	lr: 5.267e-05, eta: 1 day, 7:23:52, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5198, decode.acc_seg: 80.0075, aux.loss_ce: 0.2351, aux.acc_seg: 78.3291, loss: 0.7549
2023-12-28 10:23:18,387 - mmseg - INFO - Iter [19600/160000]	lr: 5.265e-05, eta: 1 day, 7:23:12, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4730, decode.acc_seg: 81.4085, aux.loss_ce: 0.2204, aux.acc_seg: 79.6865, loss: 0.6935
2023-12-28 10:23:58,016 - mmseg - INFO - Iter [19650/160000]	lr: 5.263e-05, eta: 1 day, 7:22:27, time: 0.792, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4811, decode.acc_seg: 81.2951, aux.loss_ce: 0.2188, aux.acc_seg: 79.1511, loss: 0.6998
2023-12-28 10:24:38,264 - mmseg - INFO - Iter [19700/160000]	lr: 5.261e-05, eta: 1 day, 7:21:47, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4722, decode.acc_seg: 82.0767, aux.loss_ce: 0.2149, aux.acc_seg: 80.0951, loss: 0.6871
2023-12-28 10:25:18,244 - mmseg - INFO - Iter [19750/160000]	lr: 5.259e-05, eta: 1 day, 7:21:05, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5004, decode.acc_seg: 80.8679, aux.loss_ce: 0.2301, aux.acc_seg: 78.6433, loss: 0.7305
2023-12-28 10:25:56,192 - mmseg - INFO - Iter [19800/160000]	lr: 5.258e-05, eta: 1 day, 7:20:09, time: 0.759, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4332, decode.acc_seg: 82.7459, aux.loss_ce: 0.2017, aux.acc_seg: 80.7692, loss: 0.6349
2023-12-28 10:26:33,320 - mmseg - INFO - Iter [19850/160000]	lr: 5.256e-05, eta: 1 day, 7:19:06, time: 0.742, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4910, decode.acc_seg: 80.8735, aux.loss_ce: 0.2239, aux.acc_seg: 79.0858, loss: 0.7149
2023-12-28 10:27:09,764 - mmseg - INFO - Iter [19900/160000]	lr: 5.254e-05, eta: 1 day, 7:18:00, time: 0.729, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4927, decode.acc_seg: 81.1153, aux.loss_ce: 0.2254, aux.acc_seg: 79.5915, loss: 0.7181
2023-12-28 10:27:48,440 - mmseg - INFO - Iter [19950/160000]	lr: 5.252e-05, eta: 1 day, 7:17:08, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5075, decode.acc_seg: 80.7053, aux.loss_ce: 0.2306, aux.acc_seg: 78.8267, loss: 0.7381
2023-12-28 10:28:29,321 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 10:28:29,322 - mmseg - INFO - Iter [20000/160000]	lr: 5.250e-05, eta: 1 day, 7:16:33, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4962, decode.acc_seg: 81.3390, aux.loss_ce: 0.2280, aux.acc_seg: 79.3628, loss: 0.7243
2023-12-28 10:29:10,859 - mmseg - INFO - Iter [20050/160000]	lr: 5.248e-05, eta: 1 day, 7:16:02, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4904, decode.acc_seg: 80.7225, aux.loss_ce: 0.2229, aux.acc_seg: 78.7836, loss: 0.7133
2023-12-28 10:29:50,433 - mmseg - INFO - Iter [20100/160000]	lr: 5.246e-05, eta: 1 day, 7:15:17, time: 0.791, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4690, decode.acc_seg: 82.0675, aux.loss_ce: 0.2102, aux.acc_seg: 80.7445, loss: 0.6792
2023-12-28 10:30:30,284 - mmseg - INFO - Iter [20150/160000]	lr: 5.244e-05, eta: 1 day, 7:14:34, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5222, decode.acc_seg: 80.1697, aux.loss_ce: 0.2385, aux.acc_seg: 78.3016, loss: 0.7607
2023-12-28 10:31:10,238 - mmseg - INFO - Iter [20200/160000]	lr: 5.243e-05, eta: 1 day, 7:13:53, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5148, decode.acc_seg: 80.5682, aux.loss_ce: 0.2413, aux.acc_seg: 77.9615, loss: 0.7561
2023-12-28 10:31:50,113 - mmseg - INFO - Iter [20250/160000]	lr: 5.241e-05, eta: 1 day, 7:13:10, time: 0.796, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4476, decode.acc_seg: 82.7228, aux.loss_ce: 0.2125, aux.acc_seg: 80.5180, loss: 0.6601
2023-12-28 10:32:28,220 - mmseg - INFO - Iter [20300/160000]	lr: 5.239e-05, eta: 1 day, 7:12:15, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4711, decode.acc_seg: 81.8874, aux.loss_ce: 0.2177, aux.acc_seg: 79.9894, loss: 0.6888
2023-12-28 10:33:06,886 - mmseg - INFO - Iter [20350/160000]	lr: 5.237e-05, eta: 1 day, 7:11:25, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4791, decode.acc_seg: 81.3602, aux.loss_ce: 0.2197, aux.acc_seg: 79.7288, loss: 0.6988
2023-12-28 10:33:46,678 - mmseg - INFO - Iter [20400/160000]	lr: 5.235e-05, eta: 1 day, 7:10:41, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4832, decode.acc_seg: 81.6187, aux.loss_ce: 0.2201, aux.acc_seg: 79.4273, loss: 0.7033
2023-12-28 10:34:25,313 - mmseg - INFO - Iter [20450/160000]	lr: 5.233e-05, eta: 1 day, 7:09:51, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4766, decode.acc_seg: 81.4653, aux.loss_ce: 0.2228, aux.acc_seg: 79.3233, loss: 0.6994
2023-12-28 10:35:05,009 - mmseg - INFO - Iter [20500/160000]	lr: 5.231e-05, eta: 1 day, 7:09:07, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4603, decode.acc_seg: 82.2475, aux.loss_ce: 0.2183, aux.acc_seg: 79.5763, loss: 0.6786
2023-12-28 10:35:43,795 - mmseg - INFO - Iter [20550/160000]	lr: 5.229e-05, eta: 1 day, 7:08:17, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4278, decode.acc_seg: 82.9219, aux.loss_ce: 0.1989, aux.acc_seg: 80.9632, loss: 0.6266
2023-12-28 10:36:23,732 - mmseg - INFO - Iter [20600/160000]	lr: 5.228e-05, eta: 1 day, 7:07:35, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4597, decode.acc_seg: 82.5493, aux.loss_ce: 0.2142, aux.acc_seg: 79.8782, loss: 0.6738
2023-12-28 10:37:03,057 - mmseg - INFO - Iter [20650/160000]	lr: 5.226e-05, eta: 1 day, 7:06:49, time: 0.786, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4911, decode.acc_seg: 80.8147, aux.loss_ce: 0.2253, aux.acc_seg: 79.0531, loss: 0.7164
2023-12-28 10:37:42,738 - mmseg - INFO - Iter [20700/160000]	lr: 5.224e-05, eta: 1 day, 7:06:05, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4699, decode.acc_seg: 82.5699, aux.loss_ce: 0.2161, aux.acc_seg: 80.4232, loss: 0.6861
2023-12-28 10:38:22,903 - mmseg - INFO - Iter [20750/160000]	lr: 5.222e-05, eta: 1 day, 7:05:25, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4875, decode.acc_seg: 81.4207, aux.loss_ce: 0.2268, aux.acc_seg: 79.1744, loss: 0.7143
2023-12-28 10:39:02,889 - mmseg - INFO - Iter [20800/160000]	lr: 5.220e-05, eta: 1 day, 7:04:44, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4846, decode.acc_seg: 81.6620, aux.loss_ce: 0.2220, aux.acc_seg: 79.9043, loss: 0.7066
2023-12-28 10:39:43,226 - mmseg - INFO - Iter [20850/160000]	lr: 5.218e-05, eta: 1 day, 7:04:04, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4666, decode.acc_seg: 81.9518, aux.loss_ce: 0.2157, aux.acc_seg: 79.8490, loss: 0.6824
2023-12-28 10:40:22,651 - mmseg - INFO - Iter [20900/160000]	lr: 5.216e-05, eta: 1 day, 7:03:19, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4617, decode.acc_seg: 82.2324, aux.loss_ce: 0.2177, aux.acc_seg: 80.2800, loss: 0.6794
2023-12-28 10:41:02,014 - mmseg - INFO - Iter [20950/160000]	lr: 5.214e-05, eta: 1 day, 7:02:34, time: 0.787, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4946, decode.acc_seg: 80.9051, aux.loss_ce: 0.2246, aux.acc_seg: 79.2288, loss: 0.7192
2023-12-28 10:41:41,760 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 10:41:41,760 - mmseg - INFO - Iter [21000/160000]	lr: 5.213e-05, eta: 1 day, 7:01:50, time: 0.794, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4687, decode.acc_seg: 81.9071, aux.loss_ce: 0.2177, aux.acc_seg: 79.8264, loss: 0.6864
2023-12-28 10:42:21,352 - mmseg - INFO - Iter [21050/160000]	lr: 5.211e-05, eta: 1 day, 7:01:07, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4470, decode.acc_seg: 82.5523, aux.loss_ce: 0.2080, aux.acc_seg: 80.4880, loss: 0.6550
2023-12-28 10:42:59,312 - mmseg - INFO - Iter [21100/160000]	lr: 5.209e-05, eta: 1 day, 7:00:12, time: 0.759, data_time: 0.010, memory: 18256, decode.loss_ce: 0.5024, decode.acc_seg: 81.4212, aux.loss_ce: 0.2294, aux.acc_seg: 79.1215, loss: 0.7318
2023-12-28 10:43:38,624 - mmseg - INFO - Iter [21150/160000]	lr: 5.207e-05, eta: 1 day, 6:59:26, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4734, decode.acc_seg: 82.3617, aux.loss_ce: 0.2178, aux.acc_seg: 80.0938, loss: 0.6912
2023-12-28 10:44:18,360 - mmseg - INFO - Iter [21200/160000]	lr: 5.205e-05, eta: 1 day, 6:58:43, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4890, decode.acc_seg: 80.5885, aux.loss_ce: 0.2251, aux.acc_seg: 78.7329, loss: 0.7141
2023-12-28 10:44:58,444 - mmseg - INFO - Iter [21250/160000]	lr: 5.203e-05, eta: 1 day, 6:58:02, time: 0.802, data_time: 0.010, memory: 18256, decode.loss_ce: 0.5068, decode.acc_seg: 80.8789, aux.loss_ce: 0.2283, aux.acc_seg: 79.3011, loss: 0.7351
2023-12-28 10:45:37,284 - mmseg - INFO - Iter [21300/160000]	lr: 5.201e-05, eta: 1 day, 6:57:13, time: 0.776, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4425, decode.acc_seg: 83.4080, aux.loss_ce: 0.2058, aux.acc_seg: 81.1030, loss: 0.6483
2023-12-28 10:46:15,610 - mmseg - INFO - Iter [21350/160000]	lr: 5.199e-05, eta: 1 day, 6:56:21, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5126, decode.acc_seg: 80.1078, aux.loss_ce: 0.2290, aux.acc_seg: 78.7428, loss: 0.7416
2023-12-28 10:46:55,699 - mmseg - INFO - Iter [21400/160000]	lr: 5.198e-05, eta: 1 day, 6:55:40, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.5002, decode.acc_seg: 80.9363, aux.loss_ce: 0.2312, aux.acc_seg: 78.8472, loss: 0.7315
2023-12-28 10:47:35,909 - mmseg - INFO - Iter [21450/160000]	lr: 5.196e-05, eta: 1 day, 6:55:00, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4793, decode.acc_seg: 81.1708, aux.loss_ce: 0.2164, aux.acc_seg: 79.7907, loss: 0.6957
2023-12-28 10:48:16,983 - mmseg - INFO - Iter [21500/160000]	lr: 5.194e-05, eta: 1 day, 6:54:26, time: 0.822, data_time: 0.052, memory: 18256, decode.loss_ce: 0.4700, decode.acc_seg: 82.0857, aux.loss_ce: 0.2169, aux.acc_seg: 80.1372, loss: 0.6869
2023-12-28 10:48:57,127 - mmseg - INFO - Iter [21550/160000]	lr: 5.192e-05, eta: 1 day, 6:53:45, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4732, decode.acc_seg: 82.1373, aux.loss_ce: 0.2193, aux.acc_seg: 80.2461, loss: 0.6925
2023-12-28 10:49:37,176 - mmseg - INFO - Iter [21600/160000]	lr: 5.190e-05, eta: 1 day, 6:53:05, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4538, decode.acc_seg: 82.0174, aux.loss_ce: 0.2108, aux.acc_seg: 79.8804, loss: 0.6646
2023-12-28 10:50:16,895 - mmseg - INFO - Iter [21650/160000]	lr: 5.188e-05, eta: 1 day, 6:52:22, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.5049, decode.acc_seg: 80.8322, aux.loss_ce: 0.2307, aux.acc_seg: 78.9931, loss: 0.7357
2023-12-28 10:50:55,953 - mmseg - INFO - Iter [21700/160000]	lr: 5.186e-05, eta: 1 day, 6:51:34, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4560, decode.acc_seg: 82.0302, aux.loss_ce: 0.2139, aux.acc_seg: 79.8163, loss: 0.6699
2023-12-28 10:51:36,144 - mmseg - INFO - Iter [21750/160000]	lr: 5.184e-05, eta: 1 day, 6:50:54, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4648, decode.acc_seg: 82.1865, aux.loss_ce: 0.2157, aux.acc_seg: 80.0448, loss: 0.6805
2023-12-28 10:52:16,208 - mmseg - INFO - Iter [21800/160000]	lr: 5.183e-05, eta: 1 day, 6:50:14, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4308, decode.acc_seg: 82.5631, aux.loss_ce: 0.1994, aux.acc_seg: 80.6770, loss: 0.6303
2023-12-28 10:52:55,975 - mmseg - INFO - Iter [21850/160000]	lr: 5.181e-05, eta: 1 day, 6:49:31, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4598, decode.acc_seg: 82.0739, aux.loss_ce: 0.2113, aux.acc_seg: 80.3671, loss: 0.6712
2023-12-28 10:53:35,955 - mmseg - INFO - Iter [21900/160000]	lr: 5.179e-05, eta: 1 day, 6:48:50, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4554, decode.acc_seg: 82.5393, aux.loss_ce: 0.2144, aux.acc_seg: 80.3890, loss: 0.6698
2023-12-28 10:54:14,886 - mmseg - INFO - Iter [21950/160000]	lr: 5.177e-05, eta: 1 day, 6:48:02, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4355, decode.acc_seg: 82.9884, aux.loss_ce: 0.2026, aux.acc_seg: 81.0097, loss: 0.6381
2023-12-28 10:54:54,767 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 10:54:54,767 - mmseg - INFO - Iter [22000/160000]	lr: 5.175e-05, eta: 1 day, 6:47:20, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4431, decode.acc_seg: 82.2741, aux.loss_ce: 0.2046, aux.acc_seg: 80.5580, loss: 0.6477
2023-12-28 10:55:34,821 - mmseg - INFO - Iter [22050/160000]	lr: 5.173e-05, eta: 1 day, 6:46:39, time: 0.800, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4312, decode.acc_seg: 83.3225, aux.loss_ce: 0.2042, aux.acc_seg: 80.9511, loss: 0.6355
2023-12-28 10:56:13,721 - mmseg - INFO - Iter [22100/160000]	lr: 5.171e-05, eta: 1 day, 6:45:51, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4692, decode.acc_seg: 81.9039, aux.loss_ce: 0.2185, aux.acc_seg: 79.6256, loss: 0.6877
2023-12-28 10:56:53,816 - mmseg - INFO - Iter [22150/160000]	lr: 5.169e-05, eta: 1 day, 6:45:11, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4778, decode.acc_seg: 81.4268, aux.loss_ce: 0.2183, aux.acc_seg: 79.4438, loss: 0.6961
2023-12-28 10:57:31,853 - mmseg - INFO - Iter [22200/160000]	lr: 5.168e-05, eta: 1 day, 6:44:17, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4705, decode.acc_seg: 81.7139, aux.loss_ce: 0.2159, aux.acc_seg: 79.9299, loss: 0.6864
2023-12-28 10:58:11,965 - mmseg - INFO - Iter [22250/160000]	lr: 5.166e-05, eta: 1 day, 6:43:37, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4693, decode.acc_seg: 82.1386, aux.loss_ce: 0.2162, aux.acc_seg: 80.6387, loss: 0.6855
2023-12-28 10:58:49,156 - mmseg - INFO - Iter [22300/160000]	lr: 5.164e-05, eta: 1 day, 6:42:38, time: 0.743, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4697, decode.acc_seg: 82.1249, aux.loss_ce: 0.2191, aux.acc_seg: 79.8234, loss: 0.6888
2023-12-28 10:59:28,231 - mmseg - INFO - Iter [22350/160000]	lr: 5.162e-05, eta: 1 day, 6:41:51, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4532, decode.acc_seg: 81.9894, aux.loss_ce: 0.2107, aux.acc_seg: 79.9607, loss: 0.6639
2023-12-28 11:00:06,799 - mmseg - INFO - Iter [22400/160000]	lr: 5.160e-05, eta: 1 day, 6:41:02, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4624, decode.acc_seg: 82.9667, aux.loss_ce: 0.2189, aux.acc_seg: 80.5406, loss: 0.6814
2023-12-28 11:00:46,420 - mmseg - INFO - Iter [22450/160000]	lr: 5.158e-05, eta: 1 day, 6:40:18, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4455, decode.acc_seg: 82.9927, aux.loss_ce: 0.2103, aux.acc_seg: 80.5641, loss: 0.6558
2023-12-28 11:01:25,458 - mmseg - INFO - Iter [22500/160000]	lr: 5.156e-05, eta: 1 day, 6:39:32, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4534, decode.acc_seg: 82.5975, aux.loss_ce: 0.2119, aux.acc_seg: 80.3783, loss: 0.6653
2023-12-28 11:02:02,680 - mmseg - INFO - Iter [22550/160000]	lr: 5.154e-05, eta: 1 day, 6:38:34, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4971, decode.acc_seg: 80.8496, aux.loss_ce: 0.2277, aux.acc_seg: 79.3377, loss: 0.7248
2023-12-28 11:02:41,700 - mmseg - INFO - Iter [22600/160000]	lr: 5.153e-05, eta: 1 day, 6:37:47, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4743, decode.acc_seg: 81.7968, aux.loss_ce: 0.2160, aux.acc_seg: 79.3963, loss: 0.6903
2023-12-28 11:03:20,782 - mmseg - INFO - Iter [22650/160000]	lr: 5.151e-05, eta: 1 day, 6:37:00, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4626, decode.acc_seg: 82.5115, aux.loss_ce: 0.2133, aux.acc_seg: 80.8410, loss: 0.6759
2023-12-28 11:03:58,708 - mmseg - INFO - Iter [22700/160000]	lr: 5.149e-05, eta: 1 day, 6:36:07, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4796, decode.acc_seg: 81.6632, aux.loss_ce: 0.2209, aux.acc_seg: 79.7625, loss: 0.7005
2023-12-28 11:04:39,898 - mmseg - INFO - Iter [22750/160000]	lr: 5.147e-05, eta: 1 day, 6:35:34, time: 0.825, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4722, decode.acc_seg: 82.1229, aux.loss_ce: 0.2153, aux.acc_seg: 80.2777, loss: 0.6875
2023-12-28 11:05:17,892 - mmseg - INFO - Iter [22800/160000]	lr: 5.145e-05, eta: 1 day, 6:34:41, time: 0.760, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4663, decode.acc_seg: 81.9602, aux.loss_ce: 0.2184, aux.acc_seg: 79.5725, loss: 0.6847
2023-12-28 11:05:58,401 - mmseg - INFO - Iter [22850/160000]	lr: 5.143e-05, eta: 1 day, 6:34:03, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4498, decode.acc_seg: 82.1678, aux.loss_ce: 0.2060, aux.acc_seg: 80.3366, loss: 0.6557
2023-12-28 11:06:35,476 - mmseg - INFO - Iter [22900/160000]	lr: 5.141e-05, eta: 1 day, 6:33:04, time: 0.741, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4570, decode.acc_seg: 81.8964, aux.loss_ce: 0.2122, aux.acc_seg: 80.0984, loss: 0.6693
2023-12-28 11:07:12,168 - mmseg - INFO - Iter [22950/160000]	lr: 5.139e-05, eta: 1 day, 6:32:04, time: 0.734, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4404, decode.acc_seg: 83.3373, aux.loss_ce: 0.2084, aux.acc_seg: 81.4367, loss: 0.6488
2023-12-28 11:07:51,342 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 11:07:51,342 - mmseg - INFO - Iter [23000/160000]	lr: 5.138e-05, eta: 1 day, 6:31:18, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4697, decode.acc_seg: 82.0110, aux.loss_ce: 0.2171, aux.acc_seg: 79.6074, loss: 0.6868
2023-12-28 11:08:31,468 - mmseg - INFO - Iter [23050/160000]	lr: 5.136e-05, eta: 1 day, 6:30:38, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4691, decode.acc_seg: 81.6308, aux.loss_ce: 0.2176, aux.acc_seg: 79.8484, loss: 0.6868
2023-12-28 11:09:11,617 - mmseg - INFO - Iter [23100/160000]	lr: 5.134e-05, eta: 1 day, 6:29:58, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4828, decode.acc_seg: 82.2127, aux.loss_ce: 0.2212, aux.acc_seg: 80.3055, loss: 0.7040
2023-12-28 11:09:49,433 - mmseg - INFO - Iter [23150/160000]	lr: 5.132e-05, eta: 1 day, 6:29:05, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4510, decode.acc_seg: 82.3947, aux.loss_ce: 0.2095, aux.acc_seg: 80.2025, loss: 0.6605
2023-12-28 11:10:29,858 - mmseg - INFO - Iter [23200/160000]	lr: 5.130e-05, eta: 1 day, 6:28:26, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4615, decode.acc_seg: 82.1115, aux.loss_ce: 0.2179, aux.acc_seg: 79.9151, loss: 0.6794
2023-12-28 11:11:10,074 - mmseg - INFO - Iter [23250/160000]	lr: 5.128e-05, eta: 1 day, 6:27:47, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4330, decode.acc_seg: 82.9377, aux.loss_ce: 0.2043, aux.acc_seg: 80.9036, loss: 0.6373
2023-12-28 11:11:49,666 - mmseg - INFO - Iter [23300/160000]	lr: 5.126e-05, eta: 1 day, 6:27:04, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4643, decode.acc_seg: 82.0770, aux.loss_ce: 0.2153, aux.acc_seg: 79.9974, loss: 0.6795
2023-12-28 11:12:28,631 - mmseg - INFO - Iter [23350/160000]	lr: 5.124e-05, eta: 1 day, 6:26:17, time: 0.778, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4827, decode.acc_seg: 81.4033, aux.loss_ce: 0.2213, aux.acc_seg: 79.1609, loss: 0.7040
2023-12-28 11:13:08,168 - mmseg - INFO - Iter [23400/160000]	lr: 5.123e-05, eta: 1 day, 6:25:34, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4728, decode.acc_seg: 81.9140, aux.loss_ce: 0.2200, aux.acc_seg: 79.5244, loss: 0.6928
2023-12-28 11:13:48,362 - mmseg - INFO - Iter [23450/160000]	lr: 5.121e-05, eta: 1 day, 6:24:55, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4832, decode.acc_seg: 80.9050, aux.loss_ce: 0.2234, aux.acc_seg: 78.7571, loss: 0.7066
2023-12-28 11:14:28,832 - mmseg - INFO - Iter [23500/160000]	lr: 5.119e-05, eta: 1 day, 6:24:17, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4597, decode.acc_seg: 81.8665, aux.loss_ce: 0.2117, aux.acc_seg: 80.0167, loss: 0.6714
2023-12-28 11:15:09,059 - mmseg - INFO - Iter [23550/160000]	lr: 5.117e-05, eta: 1 day, 6:23:37, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4500, decode.acc_seg: 82.6495, aux.loss_ce: 0.2069, aux.acc_seg: 80.6346, loss: 0.6568
2023-12-28 11:15:48,242 - mmseg - INFO - Iter [23600/160000]	lr: 5.115e-05, eta: 1 day, 6:22:52, time: 0.783, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4451, decode.acc_seg: 82.8200, aux.loss_ce: 0.2053, aux.acc_seg: 81.0745, loss: 0.6504
2023-12-28 11:16:26,688 - mmseg - INFO - Iter [23650/160000]	lr: 5.113e-05, eta: 1 day, 6:22:02, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4458, decode.acc_seg: 82.3693, aux.loss_ce: 0.2053, aux.acc_seg: 80.5427, loss: 0.6511
2023-12-28 11:17:06,891 - mmseg - INFO - Iter [23700/160000]	lr: 5.111e-05, eta: 1 day, 6:21:23, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4496, decode.acc_seg: 82.3309, aux.loss_ce: 0.2088, aux.acc_seg: 80.4139, loss: 0.6585
2023-12-28 11:17:46,788 - mmseg - INFO - Iter [23750/160000]	lr: 5.109e-05, eta: 1 day, 6:20:41, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4533, decode.acc_seg: 82.2899, aux.loss_ce: 0.2124, aux.acc_seg: 79.9692, loss: 0.6658
2023-12-28 11:18:26,488 - mmseg - INFO - Iter [23800/160000]	lr: 5.108e-05, eta: 1 day, 6:19:59, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4900, decode.acc_seg: 81.6742, aux.loss_ce: 0.2227, aux.acc_seg: 79.5926, loss: 0.7127
2023-12-28 11:19:06,472 - mmseg - INFO - Iter [23850/160000]	lr: 5.106e-05, eta: 1 day, 6:19:19, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4662, decode.acc_seg: 81.3611, aux.loss_ce: 0.2194, aux.acc_seg: 79.1531, loss: 0.6856
2023-12-28 11:19:46,288 - mmseg - INFO - Iter [23900/160000]	lr: 5.104e-05, eta: 1 day, 6:18:37, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4429, decode.acc_seg: 82.6832, aux.loss_ce: 0.2097, aux.acc_seg: 80.3885, loss: 0.6525
2023-12-28 11:20:26,348 - mmseg - INFO - Iter [23950/160000]	lr: 5.102e-05, eta: 1 day, 6:17:57, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4476, decode.acc_seg: 82.6736, aux.loss_ce: 0.2047, aux.acc_seg: 80.6602, loss: 0.6523
2023-12-28 11:21:06,098 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 11:21:06,099 - mmseg - INFO - Iter [24000/160000]	lr: 5.100e-05, eta: 1 day, 6:17:15, time: 0.795, data_time: 0.054, memory: 18256, decode.loss_ce: 0.4531, decode.acc_seg: 82.5110, aux.loss_ce: 0.2084, aux.acc_seg: 80.4514, loss: 0.6616
2023-12-28 11:21:46,295 - mmseg - INFO - Iter [24050/160000]	lr: 5.098e-05, eta: 1 day, 6:16:35, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4504, decode.acc_seg: 82.5221, aux.loss_ce: 0.2090, aux.acc_seg: 80.4645, loss: 0.6594
2023-12-28 11:22:26,345 - mmseg - INFO - Iter [24100/160000]	lr: 5.096e-05, eta: 1 day, 6:15:55, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4636, decode.acc_seg: 82.5653, aux.loss_ce: 0.2132, aux.acc_seg: 80.3316, loss: 0.6768
2023-12-28 11:23:06,341 - mmseg - INFO - Iter [24150/160000]	lr: 5.094e-05, eta: 1 day, 6:15:15, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4605, decode.acc_seg: 82.6353, aux.loss_ce: 0.2100, aux.acc_seg: 80.9259, loss: 0.6705
2023-12-28 11:23:46,253 - mmseg - INFO - Iter [24200/160000]	lr: 5.093e-05, eta: 1 day, 6:14:33, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4748, decode.acc_seg: 81.8678, aux.loss_ce: 0.2211, aux.acc_seg: 79.9369, loss: 0.6959
2023-12-28 11:24:28,629 - mmseg - INFO - Iter [24250/160000]	lr: 5.091e-05, eta: 1 day, 6:14:06, time: 0.847, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4325, decode.acc_seg: 83.0090, aux.loss_ce: 0.2018, aux.acc_seg: 81.1363, loss: 0.6343
2023-12-28 11:25:06,066 - mmseg - INFO - Iter [24300/160000]	lr: 5.089e-05, eta: 1 day, 6:13:11, time: 0.750, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4353, decode.acc_seg: 83.6476, aux.loss_ce: 0.2032, aux.acc_seg: 81.3105, loss: 0.6385
2023-12-28 11:25:45,925 - mmseg - INFO - Iter [24350/160000]	lr: 5.087e-05, eta: 1 day, 6:12:30, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4452, decode.acc_seg: 83.1186, aux.loss_ce: 0.2093, aux.acc_seg: 80.7503, loss: 0.6545
2023-12-28 11:26:22,753 - mmseg - INFO - Iter [24400/160000]	lr: 5.085e-05, eta: 1 day, 6:11:32, time: 0.737, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4435, decode.acc_seg: 82.6293, aux.loss_ce: 0.2107, aux.acc_seg: 80.5027, loss: 0.6542
2023-12-28 11:27:02,573 - mmseg - INFO - Iter [24450/160000]	lr: 5.083e-05, eta: 1 day, 6:10:50, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4421, decode.acc_seg: 82.5686, aux.loss_ce: 0.2088, aux.acc_seg: 80.1583, loss: 0.6509
2023-12-28 11:27:42,605 - mmseg - INFO - Iter [24500/160000]	lr: 5.081e-05, eta: 1 day, 6:10:10, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4559, decode.acc_seg: 82.4521, aux.loss_ce: 0.2136, aux.acc_seg: 79.8346, loss: 0.6695
2023-12-28 11:28:22,534 - mmseg - INFO - Iter [24550/160000]	lr: 5.079e-05, eta: 1 day, 6:09:29, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4397, decode.acc_seg: 83.2601, aux.loss_ce: 0.2056, aux.acc_seg: 80.8723, loss: 0.6452
2023-12-28 11:29:02,279 - mmseg - INFO - Iter [24600/160000]	lr: 5.078e-05, eta: 1 day, 6:08:47, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4449, decode.acc_seg: 83.1822, aux.loss_ce: 0.2079, aux.acc_seg: 81.1994, loss: 0.6528
2023-12-28 11:29:41,393 - mmseg - INFO - Iter [24650/160000]	lr: 5.076e-05, eta: 1 day, 6:08:02, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4338, decode.acc_seg: 82.9196, aux.loss_ce: 0.2004, aux.acc_seg: 81.2129, loss: 0.6341
2023-12-28 11:30:18,311 - mmseg - INFO - Iter [24700/160000]	lr: 5.074e-05, eta: 1 day, 6:07:04, time: 0.738, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4337, decode.acc_seg: 82.8172, aux.loss_ce: 0.1963, aux.acc_seg: 81.2759, loss: 0.6300
2023-12-28 11:30:57,769 - mmseg - INFO - Iter [24750/160000]	lr: 5.072e-05, eta: 1 day, 6:06:21, time: 0.788, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4491, decode.acc_seg: 82.6045, aux.loss_ce: 0.2131, aux.acc_seg: 79.8754, loss: 0.6621
2023-12-28 11:31:37,421 - mmseg - INFO - Iter [24800/160000]	lr: 5.070e-05, eta: 1 day, 6:05:38, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4631, decode.acc_seg: 81.9182, aux.loss_ce: 0.2140, aux.acc_seg: 80.0555, loss: 0.6771
2023-12-28 11:32:17,645 - mmseg - INFO - Iter [24850/160000]	lr: 5.068e-05, eta: 1 day, 6:04:59, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4257, decode.acc_seg: 83.6635, aux.loss_ce: 0.1965, aux.acc_seg: 82.0322, loss: 0.6222
2023-12-28 11:32:57,283 - mmseg - INFO - Iter [24900/160000]	lr: 5.066e-05, eta: 1 day, 6:04:17, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4666, decode.acc_seg: 81.7201, aux.loss_ce: 0.2206, aux.acc_seg: 79.2325, loss: 0.6872
2023-12-28 11:33:34,800 - mmseg - INFO - Iter [24950/160000]	lr: 5.064e-05, eta: 1 day, 6:03:23, time: 0.750, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4302, decode.acc_seg: 83.1434, aux.loss_ce: 0.1962, aux.acc_seg: 81.8464, loss: 0.6264
2023-12-28 11:34:12,979 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 11:34:12,979 - mmseg - INFO - Iter [25000/160000]	lr: 5.063e-05, eta: 1 day, 6:02:33, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4384, decode.acc_seg: 82.9090, aux.loss_ce: 0.2044, aux.acc_seg: 80.8896, loss: 0.6428
2023-12-28 11:34:52,971 - mmseg - INFO - Iter [25050/160000]	lr: 5.061e-05, eta: 1 day, 6:01:53, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4287, decode.acc_seg: 82.8976, aux.loss_ce: 0.1950, aux.acc_seg: 81.4055, loss: 0.6237
2023-12-28 11:35:33,398 - mmseg - INFO - Iter [25100/160000]	lr: 5.059e-05, eta: 1 day, 6:01:14, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4458, decode.acc_seg: 82.9128, aux.loss_ce: 0.2038, aux.acc_seg: 81.3288, loss: 0.6497
2023-12-28 11:36:12,773 - mmseg - INFO - Iter [25150/160000]	lr: 5.057e-05, eta: 1 day, 6:00:31, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4551, decode.acc_seg: 82.0019, aux.loss_ce: 0.2086, aux.acc_seg: 80.2021, loss: 0.6637
2023-12-28 11:36:52,083 - mmseg - INFO - Iter [25200/160000]	lr: 5.055e-05, eta: 1 day, 5:59:47, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4470, decode.acc_seg: 82.2363, aux.loss_ce: 0.2057, aux.acc_seg: 80.2023, loss: 0.6527
2023-12-28 11:37:31,579 - mmseg - INFO - Iter [25250/160000]	lr: 5.053e-05, eta: 1 day, 5:59:03, time: 0.789, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4623, decode.acc_seg: 82.6296, aux.loss_ce: 0.2094, aux.acc_seg: 81.2819, loss: 0.6717
2023-12-28 11:38:14,129 - mmseg - INFO - Iter [25300/160000]	lr: 5.051e-05, eta: 1 day, 5:58:37, time: 0.851, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3969, decode.acc_seg: 84.5488, aux.loss_ce: 0.1932, aux.acc_seg: 81.6071, loss: 0.5901
2023-12-28 11:38:54,614 - mmseg - INFO - Iter [25350/160000]	lr: 5.049e-05, eta: 1 day, 5:57:59, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4248, decode.acc_seg: 83.4950, aux.loss_ce: 0.2021, aux.acc_seg: 81.2100, loss: 0.6270
2023-12-28 11:39:34,660 - mmseg - INFO - Iter [25400/160000]	lr: 5.048e-05, eta: 1 day, 5:57:19, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4339, decode.acc_seg: 83.4150, aux.loss_ce: 0.2075, aux.acc_seg: 80.8604, loss: 0.6414
2023-12-28 11:40:14,841 - mmseg - INFO - Iter [25450/160000]	lr: 5.046e-05, eta: 1 day, 5:56:39, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4105, decode.acc_seg: 83.8612, aux.loss_ce: 0.1934, aux.acc_seg: 81.7400, loss: 0.6040
2023-12-28 11:40:55,260 - mmseg - INFO - Iter [25500/160000]	lr: 5.044e-05, eta: 1 day, 5:56:01, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4413, decode.acc_seg: 83.0088, aux.loss_ce: 0.2068, aux.acc_seg: 81.2520, loss: 0.6482
2023-12-28 11:41:34,727 - mmseg - INFO - Iter [25550/160000]	lr: 5.042e-05, eta: 1 day, 5:55:18, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4291, decode.acc_seg: 83.6106, aux.loss_ce: 0.2019, aux.acc_seg: 81.5344, loss: 0.6310
2023-12-28 11:42:14,495 - mmseg - INFO - Iter [25600/160000]	lr: 5.040e-05, eta: 1 day, 5:54:36, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4453, decode.acc_seg: 82.8658, aux.loss_ce: 0.2033, aux.acc_seg: 80.9460, loss: 0.6486
2023-12-28 11:42:54,139 - mmseg - INFO - Iter [25650/160000]	lr: 5.038e-05, eta: 1 day, 5:53:54, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4447, decode.acc_seg: 82.8624, aux.loss_ce: 0.2045, aux.acc_seg: 80.7672, loss: 0.6492
2023-12-28 11:43:33,317 - mmseg - INFO - Iter [25700/160000]	lr: 5.036e-05, eta: 1 day, 5:53:10, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4604, decode.acc_seg: 82.0968, aux.loss_ce: 0.2126, aux.acc_seg: 79.9115, loss: 0.6730
2023-12-28 11:44:12,730 - mmseg - INFO - Iter [25750/160000]	lr: 5.034e-05, eta: 1 day, 5:52:26, time: 0.787, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4370, decode.acc_seg: 83.2202, aux.loss_ce: 0.2068, aux.acc_seg: 80.7233, loss: 0.6439
2023-12-28 11:44:52,229 - mmseg - INFO - Iter [25800/160000]	lr: 5.033e-05, eta: 1 day, 5:51:43, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4299, decode.acc_seg: 83.1824, aux.loss_ce: 0.2014, aux.acc_seg: 80.8279, loss: 0.6313
2023-12-28 11:45:32,024 - mmseg - INFO - Iter [25850/160000]	lr: 5.031e-05, eta: 1 day, 5:51:02, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4526, decode.acc_seg: 83.2050, aux.loss_ce: 0.2142, aux.acc_seg: 80.4371, loss: 0.6668
2023-12-28 11:46:10,980 - mmseg - INFO - Iter [25900/160000]	lr: 5.029e-05, eta: 1 day, 5:50:16, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4401, decode.acc_seg: 82.6435, aux.loss_ce: 0.2076, aux.acc_seg: 80.3395, loss: 0.6477
2023-12-28 11:46:50,039 - mmseg - INFO - Iter [25950/160000]	lr: 5.027e-05, eta: 1 day, 5:49:31, time: 0.781, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4409, decode.acc_seg: 82.7858, aux.loss_ce: 0.2090, aux.acc_seg: 80.2165, loss: 0.6499
2023-12-28 11:47:28,341 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 11:47:28,341 - mmseg - INFO - Iter [26000/160000]	lr: 5.025e-05, eta: 1 day, 5:48:42, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4393, decode.acc_seg: 83.1221, aux.loss_ce: 0.2017, aux.acc_seg: 81.2438, loss: 0.6410
2023-12-28 11:48:06,775 - mmseg - INFO - Iter [26050/160000]	lr: 5.023e-05, eta: 1 day, 5:47:54, time: 0.768, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4661, decode.acc_seg: 81.8438, aux.loss_ce: 0.2163, aux.acc_seg: 79.6726, loss: 0.6825
2023-12-28 11:48:45,896 - mmseg - INFO - Iter [26100/160000]	lr: 5.021e-05, eta: 1 day, 5:47:09, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4212, decode.acc_seg: 83.7030, aux.loss_ce: 0.1925, aux.acc_seg: 82.0046, loss: 0.6138
2023-12-28 11:49:25,779 - mmseg - INFO - Iter [26150/160000]	lr: 5.019e-05, eta: 1 day, 5:46:28, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4228, decode.acc_seg: 83.4678, aux.loss_ce: 0.2008, aux.acc_seg: 81.4424, loss: 0.6236
2023-12-28 11:50:04,323 - mmseg - INFO - Iter [26200/160000]	lr: 5.018e-05, eta: 1 day, 5:45:40, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4127, decode.acc_seg: 83.8418, aux.loss_ce: 0.1983, aux.acc_seg: 81.4264, loss: 0.6111
2023-12-28 11:50:43,779 - mmseg - INFO - Iter [26250/160000]	lr: 5.016e-05, eta: 1 day, 5:44:57, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4311, decode.acc_seg: 83.5210, aux.loss_ce: 0.2054, aux.acc_seg: 81.1083, loss: 0.6365
2023-12-28 11:51:22,299 - mmseg - INFO - Iter [26300/160000]	lr: 5.014e-05, eta: 1 day, 5:44:09, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4512, decode.acc_seg: 82.3103, aux.loss_ce: 0.2078, aux.acc_seg: 80.6192, loss: 0.6590
2023-12-28 11:52:00,544 - mmseg - INFO - Iter [26350/160000]	lr: 5.012e-05, eta: 1 day, 5:43:21, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4602, decode.acc_seg: 82.5154, aux.loss_ce: 0.2140, aux.acc_seg: 80.3535, loss: 0.6741
2023-12-28 11:52:39,324 - mmseg - INFO - Iter [26400/160000]	lr: 5.010e-05, eta: 1 day, 5:42:34, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4277, decode.acc_seg: 83.0353, aux.loss_ce: 0.1966, aux.acc_seg: 81.3106, loss: 0.6243
2023-12-28 11:53:18,836 - mmseg - INFO - Iter [26450/160000]	lr: 5.008e-05, eta: 1 day, 5:41:51, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4464, decode.acc_seg: 82.9784, aux.loss_ce: 0.2107, aux.acc_seg: 80.7445, loss: 0.6572
2023-12-28 11:54:00,295 - mmseg - INFO - Iter [26500/160000]	lr: 5.006e-05, eta: 1 day, 5:41:18, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4385, decode.acc_seg: 82.7036, aux.loss_ce: 0.2036, aux.acc_seg: 80.7488, loss: 0.6421
2023-12-28 11:54:42,665 - mmseg - INFO - Iter [26550/160000]	lr: 5.004e-05, eta: 1 day, 5:40:50, time: 0.848, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4400, decode.acc_seg: 83.0080, aux.loss_ce: 0.2052, aux.acc_seg: 80.6819, loss: 0.6452
2023-12-28 11:55:23,072 - mmseg - INFO - Iter [26600/160000]	lr: 5.003e-05, eta: 1 day, 5:40:12, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4320, decode.acc_seg: 83.3387, aux.loss_ce: 0.2064, aux.acc_seg: 81.1353, loss: 0.6384
2023-12-28 11:56:03,211 - mmseg - INFO - Iter [26650/160000]	lr: 5.001e-05, eta: 1 day, 5:39:33, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4551, decode.acc_seg: 82.6809, aux.loss_ce: 0.2151, aux.acc_seg: 80.1037, loss: 0.6701
2023-12-28 11:56:43,122 - mmseg - INFO - Iter [26700/160000]	lr: 4.999e-05, eta: 1 day, 5:38:52, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4226, decode.acc_seg: 83.6889, aux.loss_ce: 0.1940, aux.acc_seg: 82.0769, loss: 0.6166
2023-12-28 11:57:22,994 - mmseg - INFO - Iter [26750/160000]	lr: 4.997e-05, eta: 1 day, 5:38:11, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4445, decode.acc_seg: 82.8657, aux.loss_ce: 0.2092, aux.acc_seg: 80.7188, loss: 0.6538
2023-12-28 11:58:02,975 - mmseg - INFO - Iter [26800/160000]	lr: 4.995e-05, eta: 1 day, 5:37:31, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4305, decode.acc_seg: 83.6785, aux.loss_ce: 0.2036, aux.acc_seg: 81.2207, loss: 0.6341
2023-12-28 11:58:43,000 - mmseg - INFO - Iter [26850/160000]	lr: 4.993e-05, eta: 1 day, 5:36:51, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4292, decode.acc_seg: 82.6793, aux.loss_ce: 0.2018, aux.acc_seg: 80.3786, loss: 0.6310
2023-12-28 11:59:23,174 - mmseg - INFO - Iter [26900/160000]	lr: 4.991e-05, eta: 1 day, 5:36:11, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4448, decode.acc_seg: 82.9767, aux.loss_ce: 0.2058, aux.acc_seg: 81.0757, loss: 0.6506
2023-12-28 12:00:02,973 - mmseg - INFO - Iter [26950/160000]	lr: 4.989e-05, eta: 1 day, 5:35:30, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4176, decode.acc_seg: 83.6943, aux.loss_ce: 0.1940, aux.acc_seg: 81.6689, loss: 0.6116
2023-12-28 12:00:42,117 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 12:00:42,117 - mmseg - INFO - Iter [27000/160000]	lr: 4.988e-05, eta: 1 day, 5:34:46, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4286, decode.acc_seg: 83.2111, aux.loss_ce: 0.2020, aux.acc_seg: 81.1448, loss: 0.6306
2023-12-28 12:01:23,001 - mmseg - INFO - Iter [27050/160000]	lr: 4.986e-05, eta: 1 day, 5:34:10, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4121, decode.acc_seg: 83.7809, aux.loss_ce: 0.1909, aux.acc_seg: 82.1089, loss: 0.6030
2023-12-28 12:02:00,519 - mmseg - INFO - Iter [27100/160000]	lr: 4.984e-05, eta: 1 day, 5:33:18, time: 0.751, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4358, decode.acc_seg: 83.2520, aux.loss_ce: 0.2070, aux.acc_seg: 80.9252, loss: 0.6429
2023-12-28 12:02:40,110 - mmseg - INFO - Iter [27150/160000]	lr: 4.982e-05, eta: 1 day, 5:32:35, time: 0.791, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4117, decode.acc_seg: 83.6577, aux.loss_ce: 0.1919, aux.acc_seg: 81.7320, loss: 0.6036
2023-12-28 12:03:20,362 - mmseg - INFO - Iter [27200/160000]	lr: 4.980e-05, eta: 1 day, 5:31:56, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4271, decode.acc_seg: 83.2759, aux.loss_ce: 0.1966, aux.acc_seg: 81.3938, loss: 0.6237
2023-12-28 12:03:59,714 - mmseg - INFO - Iter [27250/160000]	lr: 4.978e-05, eta: 1 day, 5:31:13, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4305, decode.acc_seg: 83.0317, aux.loss_ce: 0.2013, aux.acc_seg: 81.0433, loss: 0.6318
2023-12-28 12:04:40,448 - mmseg - INFO - Iter [27300/160000]	lr: 4.976e-05, eta: 1 day, 5:30:36, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4103, decode.acc_seg: 83.9618, aux.loss_ce: 0.1924, aux.acc_seg: 81.7792, loss: 0.6027
2023-12-28 12:05:20,277 - mmseg - INFO - Iter [27350/160000]	lr: 4.974e-05, eta: 1 day, 5:29:55, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4408, decode.acc_seg: 83.6938, aux.loss_ce: 0.2052, aux.acc_seg: 81.8437, loss: 0.6459
2023-12-28 12:06:01,110 - mmseg - INFO - Iter [27400/160000]	lr: 4.973e-05, eta: 1 day, 5:29:19, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4221, decode.acc_seg: 83.4609, aux.loss_ce: 0.1968, aux.acc_seg: 81.3267, loss: 0.6190
2023-12-28 12:06:42,352 - mmseg - INFO - Iter [27450/160000]	lr: 4.971e-05, eta: 1 day, 5:28:45, time: 0.825, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4392, decode.acc_seg: 83.3185, aux.loss_ce: 0.2047, aux.acc_seg: 81.1531, loss: 0.6439
2023-12-28 12:07:23,546 - mmseg - INFO - Iter [27500/160000]	lr: 4.969e-05, eta: 1 day, 5:28:11, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4490, decode.acc_seg: 82.6975, aux.loss_ce: 0.2053, aux.acc_seg: 80.7025, loss: 0.6543
2023-12-28 12:08:03,448 - mmseg - INFO - Iter [27550/160000]	lr: 4.967e-05, eta: 1 day, 5:27:30, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4320, decode.acc_seg: 83.0674, aux.loss_ce: 0.1988, aux.acc_seg: 81.2476, loss: 0.6308
2023-12-28 12:08:42,257 - mmseg - INFO - Iter [27600/160000]	lr: 4.965e-05, eta: 1 day, 5:26:44, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4249, decode.acc_seg: 83.4900, aux.loss_ce: 0.2003, aux.acc_seg: 81.1581, loss: 0.6253
2023-12-28 12:09:22,790 - mmseg - INFO - Iter [27650/160000]	lr: 4.963e-05, eta: 1 day, 5:26:06, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4372, decode.acc_seg: 83.3323, aux.loss_ce: 0.2066, aux.acc_seg: 80.8372, loss: 0.6439
2023-12-28 12:10:03,476 - mmseg - INFO - Iter [27700/160000]	lr: 4.961e-05, eta: 1 day, 5:25:29, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4283, decode.acc_seg: 83.2111, aux.loss_ce: 0.2034, aux.acc_seg: 81.1173, loss: 0.6317
2023-12-28 12:10:44,119 - mmseg - INFO - Iter [27750/160000]	lr: 4.959e-05, eta: 1 day, 5:24:53, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4204, decode.acc_seg: 83.3087, aux.loss_ce: 0.1948, aux.acc_seg: 81.5550, loss: 0.6152
2023-12-28 12:11:25,765 - mmseg - INFO - Iter [27800/160000]	lr: 4.958e-05, eta: 1 day, 5:24:20, time: 0.832, data_time: 0.054, memory: 18256, decode.loss_ce: 0.4083, decode.acc_seg: 84.1779, aux.loss_ce: 0.1906, aux.acc_seg: 82.1901, loss: 0.5989
2023-12-28 12:12:05,639 - mmseg - INFO - Iter [27850/160000]	lr: 4.956e-05, eta: 1 day, 5:23:39, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4190, decode.acc_seg: 84.3346, aux.loss_ce: 0.1952, aux.acc_seg: 82.1276, loss: 0.6142
2023-12-28 12:12:45,743 - mmseg - INFO - Iter [27900/160000]	lr: 4.954e-05, eta: 1 day, 5:23:00, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3991, decode.acc_seg: 83.8711, aux.loss_ce: 0.1885, aux.acc_seg: 81.8868, loss: 0.5876
2023-12-28 12:13:25,163 - mmseg - INFO - Iter [27950/160000]	lr: 4.952e-05, eta: 1 day, 5:22:16, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4064, decode.acc_seg: 84.0291, aux.loss_ce: 0.1911, aux.acc_seg: 81.9570, loss: 0.5974
2023-12-28 12:14:06,398 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 12:14:06,399 - mmseg - INFO - Iter [28000/160000]	lr: 4.950e-05, eta: 1 day, 5:21:42, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3884, decode.acc_seg: 84.4802, aux.loss_ce: 0.1849, aux.acc_seg: 82.1808, loss: 0.5733
2023-12-28 12:14:47,741 - mmseg - INFO - Iter [28050/160000]	lr: 4.948e-05, eta: 1 day, 5:21:08, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4015, decode.acc_seg: 84.0992, aux.loss_ce: 0.1898, aux.acc_seg: 82.1245, loss: 0.5913
2023-12-28 12:15:27,054 - mmseg - INFO - Iter [28100/160000]	lr: 4.946e-05, eta: 1 day, 5:20:25, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4324, decode.acc_seg: 83.3688, aux.loss_ce: 0.2025, aux.acc_seg: 81.2377, loss: 0.6349
2023-12-28 12:16:06,952 - mmseg - INFO - Iter [28150/160000]	lr: 4.944e-05, eta: 1 day, 5:19:44, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4170, decode.acc_seg: 83.5012, aux.loss_ce: 0.1983, aux.acc_seg: 80.8898, loss: 0.6153
2023-12-28 12:16:46,154 - mmseg - INFO - Iter [28200/160000]	lr: 4.943e-05, eta: 1 day, 5:19:00, time: 0.783, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4150, decode.acc_seg: 83.5872, aux.loss_ce: 0.1962, aux.acc_seg: 81.3551, loss: 0.6113
2023-12-28 12:17:25,574 - mmseg - INFO - Iter [28250/160000]	lr: 4.941e-05, eta: 1 day, 5:18:17, time: 0.789, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4147, decode.acc_seg: 83.8645, aux.loss_ce: 0.1938, aux.acc_seg: 81.7512, loss: 0.6085
2023-12-28 12:18:05,505 - mmseg - INFO - Iter [28300/160000]	lr: 4.939e-05, eta: 1 day, 5:17:37, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4057, decode.acc_seg: 83.9601, aux.loss_ce: 0.1876, aux.acc_seg: 82.3603, loss: 0.5933
2023-12-28 12:18:46,014 - mmseg - INFO - Iter [28350/160000]	lr: 4.937e-05, eta: 1 day, 5:16:59, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4307, decode.acc_seg: 83.3419, aux.loss_ce: 0.1998, aux.acc_seg: 81.3818, loss: 0.6305
2023-12-28 12:19:26,111 - mmseg - INFO - Iter [28400/160000]	lr: 4.935e-05, eta: 1 day, 5:16:19, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4337, decode.acc_seg: 83.0047, aux.loss_ce: 0.2020, aux.acc_seg: 80.6804, loss: 0.6357
2023-12-28 12:20:05,722 - mmseg - INFO - Iter [28450/160000]	lr: 4.933e-05, eta: 1 day, 5:15:37, time: 0.791, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4167, decode.acc_seg: 83.5584, aux.loss_ce: 0.1963, aux.acc_seg: 81.2345, loss: 0.6131
2023-12-28 12:20:45,937 - mmseg - INFO - Iter [28500/160000]	lr: 4.931e-05, eta: 1 day, 5:14:58, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4239, decode.acc_seg: 83.6637, aux.loss_ce: 0.1945, aux.acc_seg: 81.9787, loss: 0.6183
2023-12-28 12:21:24,771 - mmseg - INFO - Iter [28550/160000]	lr: 4.929e-05, eta: 1 day, 5:14:12, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4264, decode.acc_seg: 83.9138, aux.loss_ce: 0.2008, aux.acc_seg: 81.8340, loss: 0.6272
2023-12-28 12:22:03,049 - mmseg - INFO - Iter [28600/160000]	lr: 4.928e-05, eta: 1 day, 5:13:24, time: 0.766, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4308, decode.acc_seg: 83.6026, aux.loss_ce: 0.2021, aux.acc_seg: 81.4675, loss: 0.6328
2023-12-28 12:22:43,137 - mmseg - INFO - Iter [28650/160000]	lr: 4.926e-05, eta: 1 day, 5:12:44, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4247, decode.acc_seg: 83.2966, aux.loss_ce: 0.1949, aux.acc_seg: 81.6206, loss: 0.6196
2023-12-28 12:23:21,428 - mmseg - INFO - Iter [28700/160000]	lr: 4.924e-05, eta: 1 day, 5:11:56, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4497, decode.acc_seg: 82.8008, aux.loss_ce: 0.2109, aux.acc_seg: 80.7129, loss: 0.6606
2023-12-28 12:24:00,188 - mmseg - INFO - Iter [28750/160000]	lr: 4.922e-05, eta: 1 day, 5:11:11, time: 0.775, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4024, decode.acc_seg: 84.2390, aux.loss_ce: 0.1872, aux.acc_seg: 82.1292, loss: 0.5896
2023-12-28 12:24:39,656 - mmseg - INFO - Iter [28800/160000]	lr: 4.920e-05, eta: 1 day, 5:10:28, time: 0.788, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4214, decode.acc_seg: 83.6835, aux.loss_ce: 0.1985, aux.acc_seg: 81.1300, loss: 0.6199
2023-12-28 12:25:20,604 - mmseg - INFO - Iter [28850/160000]	lr: 4.918e-05, eta: 1 day, 5:09:52, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4003, decode.acc_seg: 84.2879, aux.loss_ce: 0.1876, aux.acc_seg: 82.1847, loss: 0.5880
2023-12-28 12:25:59,707 - mmseg - INFO - Iter [28900/160000]	lr: 4.916e-05, eta: 1 day, 5:09:08, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4214, decode.acc_seg: 83.6713, aux.loss_ce: 0.1950, aux.acc_seg: 81.6721, loss: 0.6165
2023-12-28 12:26:38,326 - mmseg - INFO - Iter [28950/160000]	lr: 4.914e-05, eta: 1 day, 5:08:21, time: 0.771, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4131, decode.acc_seg: 83.9921, aux.loss_ce: 0.1951, aux.acc_seg: 81.7974, loss: 0.6082
2023-12-28 12:27:17,790 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 12:27:17,790 - mmseg - INFO - Iter [29000/160000]	lr: 4.913e-05, eta: 1 day, 5:07:39, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4175, decode.acc_seg: 83.5919, aux.loss_ce: 0.1942, aux.acc_seg: 81.6653, loss: 0.6118
2023-12-28 12:27:59,336 - mmseg - INFO - Iter [29050/160000]	lr: 4.911e-05, eta: 1 day, 5:07:06, time: 0.831, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4053, decode.acc_seg: 84.1167, aux.loss_ce: 0.1919, aux.acc_seg: 81.9344, loss: 0.5973
2023-12-28 12:28:37,936 - mmseg - INFO - Iter [29100/160000]	lr: 4.909e-05, eta: 1 day, 5:06:19, time: 0.771, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4026, decode.acc_seg: 84.2038, aux.loss_ce: 0.1897, aux.acc_seg: 81.9080, loss: 0.5924
2023-12-28 12:29:17,893 - mmseg - INFO - Iter [29150/160000]	lr: 4.907e-05, eta: 1 day, 5:05:39, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4013, decode.acc_seg: 84.2305, aux.loss_ce: 0.1936, aux.acc_seg: 81.6734, loss: 0.5949
2023-12-28 12:29:56,793 - mmseg - INFO - Iter [29200/160000]	lr: 4.905e-05, eta: 1 day, 5:04:54, time: 0.779, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4022, decode.acc_seg: 84.2109, aux.loss_ce: 0.1867, aux.acc_seg: 82.5236, loss: 0.5889
2023-12-28 12:30:36,912 - mmseg - INFO - Iter [29250/160000]	lr: 4.903e-05, eta: 1 day, 5:04:14, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4060, decode.acc_seg: 84.2750, aux.loss_ce: 0.1921, aux.acc_seg: 82.2125, loss: 0.5980
2023-12-28 12:31:16,914 - mmseg - INFO - Iter [29300/160000]	lr: 4.901e-05, eta: 1 day, 5:03:34, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4099, decode.acc_seg: 84.0908, aux.loss_ce: 0.1915, aux.acc_seg: 82.1178, loss: 0.6014
2023-12-28 12:31:57,218 - mmseg - INFO - Iter [29350/160000]	lr: 4.899e-05, eta: 1 day, 5:02:55, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4121, decode.acc_seg: 83.8055, aux.loss_ce: 0.1936, aux.acc_seg: 81.9111, loss: 0.6057
2023-12-28 12:32:36,184 - mmseg - INFO - Iter [29400/160000]	lr: 4.898e-05, eta: 1 day, 5:02:11, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4263, decode.acc_seg: 83.6772, aux.loss_ce: 0.1962, aux.acc_seg: 81.6369, loss: 0.6224
2023-12-28 12:33:16,350 - mmseg - INFO - Iter [29450/160000]	lr: 4.896e-05, eta: 1 day, 5:01:31, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4198, decode.acc_seg: 83.5327, aux.loss_ce: 0.1975, aux.acc_seg: 81.6455, loss: 0.6173
2023-12-28 12:33:56,604 - mmseg - INFO - Iter [29500/160000]	lr: 4.894e-05, eta: 1 day, 5:00:52, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3921, decode.acc_seg: 84.4617, aux.loss_ce: 0.1845, aux.acc_seg: 82.4700, loss: 0.5766
2023-12-28 12:34:36,999 - mmseg - INFO - Iter [29550/160000]	lr: 4.892e-05, eta: 1 day, 5:00:14, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4211, decode.acc_seg: 83.5535, aux.loss_ce: 0.2021, aux.acc_seg: 81.1888, loss: 0.6233
2023-12-28 12:35:15,137 - mmseg - INFO - Iter [29600/160000]	lr: 4.890e-05, eta: 1 day, 4:59:26, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4132, decode.acc_seg: 83.8127, aux.loss_ce: 0.1942, aux.acc_seg: 81.7904, loss: 0.6074
2023-12-28 12:35:54,357 - mmseg - INFO - Iter [29650/160000]	lr: 4.888e-05, eta: 1 day, 4:58:42, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3951, decode.acc_seg: 84.3727, aux.loss_ce: 0.1854, aux.acc_seg: 82.6492, loss: 0.5805
2023-12-28 12:36:32,356 - mmseg - INFO - Iter [29700/160000]	lr: 4.886e-05, eta: 1 day, 4:57:53, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4005, decode.acc_seg: 84.3764, aux.loss_ce: 0.1884, aux.acc_seg: 82.4218, loss: 0.5889
2023-12-28 12:37:11,334 - mmseg - INFO - Iter [29750/160000]	lr: 4.884e-05, eta: 1 day, 4:57:09, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4010, decode.acc_seg: 84.1682, aux.loss_ce: 0.1907, aux.acc_seg: 82.1289, loss: 0.5918
2023-12-28 12:37:50,942 - mmseg - INFO - Iter [29800/160000]	lr: 4.883e-05, eta: 1 day, 4:56:27, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4143, decode.acc_seg: 83.8740, aux.loss_ce: 0.1976, aux.acc_seg: 81.3206, loss: 0.6119
2023-12-28 12:38:29,657 - mmseg - INFO - Iter [29850/160000]	lr: 4.881e-05, eta: 1 day, 4:55:42, time: 0.774, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4070, decode.acc_seg: 84.1914, aux.loss_ce: 0.1929, aux.acc_seg: 81.9527, loss: 0.5999
2023-12-28 12:39:09,768 - mmseg - INFO - Iter [29900/160000]	lr: 4.879e-05, eta: 1 day, 4:55:02, time: 0.801, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4109, decode.acc_seg: 83.7622, aux.loss_ce: 0.1915, aux.acc_seg: 82.1730, loss: 0.6025
2023-12-28 12:39:50,248 - mmseg - INFO - Iter [29950/160000]	lr: 4.877e-05, eta: 1 day, 4:54:24, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4150, decode.acc_seg: 83.5772, aux.loss_ce: 0.1937, aux.acc_seg: 81.6814, loss: 0.6088
2023-12-28 12:40:30,794 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 12:40:30,794 - mmseg - INFO - Iter [30000/160000]	lr: 4.875e-05, eta: 1 day, 4:53:46, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4186, decode.acc_seg: 83.8869, aux.loss_ce: 0.1959, aux.acc_seg: 81.8767, loss: 0.6146
2023-12-28 12:41:10,104 - mmseg - INFO - Iter [30050/160000]	lr: 4.873e-05, eta: 1 day, 4:53:03, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4179, decode.acc_seg: 83.6448, aux.loss_ce: 0.1946, aux.acc_seg: 81.5138, loss: 0.6126
2023-12-28 12:41:49,237 - mmseg - INFO - Iter [30100/160000]	lr: 4.871e-05, eta: 1 day, 4:52:19, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4357, decode.acc_seg: 83.6513, aux.loss_ce: 0.1986, aux.acc_seg: 81.5191, loss: 0.6342
2023-12-28 12:42:28,879 - mmseg - INFO - Iter [30150/160000]	lr: 4.869e-05, eta: 1 day, 4:51:38, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4181, decode.acc_seg: 83.7967, aux.loss_ce: 0.1954, aux.acc_seg: 81.9392, loss: 0.6135
2023-12-28 12:43:05,342 - mmseg - INFO - Iter [30200/160000]	lr: 4.868e-05, eta: 1 day, 4:50:43, time: 0.730, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4274, decode.acc_seg: 83.3214, aux.loss_ce: 0.1991, aux.acc_seg: 81.2702, loss: 0.6265
2023-12-28 12:43:44,903 - mmseg - INFO - Iter [30250/160000]	lr: 4.866e-05, eta: 1 day, 4:50:01, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4247, decode.acc_seg: 82.7559, aux.loss_ce: 0.1971, aux.acc_seg: 80.8191, loss: 0.6218
2023-12-28 12:44:25,298 - mmseg - INFO - Iter [30300/160000]	lr: 4.864e-05, eta: 1 day, 4:49:22, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4086, decode.acc_seg: 83.8428, aux.loss_ce: 0.1917, aux.acc_seg: 82.1613, loss: 0.6004
2023-12-28 12:45:07,794 - mmseg - INFO - Iter [30350/160000]	lr: 4.862e-05, eta: 1 day, 4:48:53, time: 0.849, data_time: 0.052, memory: 18256, decode.loss_ce: 0.4087, decode.acc_seg: 83.6344, aux.loss_ce: 0.1907, aux.acc_seg: 81.8063, loss: 0.5994
2023-12-28 12:45:46,110 - mmseg - INFO - Iter [30400/160000]	lr: 4.860e-05, eta: 1 day, 4:48:06, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4062, decode.acc_seg: 83.7595, aux.loss_ce: 0.1913, aux.acc_seg: 81.4348, loss: 0.5975
2023-12-28 12:46:25,001 - mmseg - INFO - Iter [30450/160000]	lr: 4.858e-05, eta: 1 day, 4:47:21, time: 0.778, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4011, decode.acc_seg: 84.0933, aux.loss_ce: 0.1913, aux.acc_seg: 81.9048, loss: 0.5924
2023-12-28 12:47:04,715 - mmseg - INFO - Iter [30500/160000]	lr: 4.856e-05, eta: 1 day, 4:46:40, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4019, decode.acc_seg: 84.6584, aux.loss_ce: 0.1932, aux.acc_seg: 82.2158, loss: 0.5951
2023-12-28 12:47:43,613 - mmseg - INFO - Iter [30550/160000]	lr: 4.854e-05, eta: 1 day, 4:45:55, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3781, decode.acc_seg: 85.2972, aux.loss_ce: 0.1789, aux.acc_seg: 83.5803, loss: 0.5570
2023-12-28 12:48:22,163 - mmseg - INFO - Iter [30600/160000]	lr: 4.853e-05, eta: 1 day, 4:45:09, time: 0.771, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3865, decode.acc_seg: 84.5705, aux.loss_ce: 0.1850, aux.acc_seg: 82.5151, loss: 0.5715
2023-12-28 12:49:01,163 - mmseg - INFO - Iter [30650/160000]	lr: 4.851e-05, eta: 1 day, 4:44:25, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4010, decode.acc_seg: 84.0713, aux.loss_ce: 0.1883, aux.acc_seg: 81.9058, loss: 0.5893
2023-12-28 12:49:41,446 - mmseg - INFO - Iter [30700/160000]	lr: 4.849e-05, eta: 1 day, 4:43:46, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4044, decode.acc_seg: 84.4833, aux.loss_ce: 0.1917, aux.acc_seg: 82.2611, loss: 0.5961
2023-12-28 12:50:19,616 - mmseg - INFO - Iter [30750/160000]	lr: 4.847e-05, eta: 1 day, 4:42:58, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4028, decode.acc_seg: 83.9757, aux.loss_ce: 0.1928, aux.acc_seg: 81.6682, loss: 0.5957
2023-12-28 12:50:58,678 - mmseg - INFO - Iter [30800/160000]	lr: 4.845e-05, eta: 1 day, 4:42:15, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4186, decode.acc_seg: 83.8134, aux.loss_ce: 0.1966, aux.acc_seg: 81.7278, loss: 0.6152
2023-12-28 12:51:36,910 - mmseg - INFO - Iter [30850/160000]	lr: 4.843e-05, eta: 1 day, 4:41:27, time: 0.764, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4162, decode.acc_seg: 83.5962, aux.loss_ce: 0.1982, aux.acc_seg: 81.2087, loss: 0.6144
2023-12-28 12:52:15,407 - mmseg - INFO - Iter [30900/160000]	lr: 4.841e-05, eta: 1 day, 4:40:41, time: 0.770, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4205, decode.acc_seg: 83.3421, aux.loss_ce: 0.1976, aux.acc_seg: 81.3079, loss: 0.6181
2023-12-28 12:52:54,086 - mmseg - INFO - Iter [30950/160000]	lr: 4.839e-05, eta: 1 day, 4:39:55, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4275, decode.acc_seg: 83.2651, aux.loss_ce: 0.2014, aux.acc_seg: 81.2177, loss: 0.6289
2023-12-28 12:53:34,267 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 12:53:34,268 - mmseg - INFO - Iter [31000/160000]	lr: 4.838e-05, eta: 1 day, 4:39:16, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3960, decode.acc_seg: 84.2297, aux.loss_ce: 0.1923, aux.acc_seg: 81.8432, loss: 0.5883
2023-12-28 12:54:13,035 - mmseg - INFO - Iter [31050/160000]	lr: 4.836e-05, eta: 1 day, 4:38:31, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4083, decode.acc_seg: 83.9706, aux.loss_ce: 0.1900, aux.acc_seg: 81.8043, loss: 0.5983
2023-12-28 12:54:51,682 - mmseg - INFO - Iter [31100/160000]	lr: 4.834e-05, eta: 1 day, 4:37:46, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4224, decode.acc_seg: 83.7060, aux.loss_ce: 0.1946, aux.acc_seg: 81.8403, loss: 0.6170
2023-12-28 12:55:31,006 - mmseg - INFO - Iter [31150/160000]	lr: 4.832e-05, eta: 1 day, 4:37:03, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3933, decode.acc_seg: 84.1011, aux.loss_ce: 0.1834, aux.acc_seg: 82.0295, loss: 0.5766
2023-12-28 12:56:10,487 - mmseg - INFO - Iter [31200/160000]	lr: 4.830e-05, eta: 1 day, 4:36:21, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3957, decode.acc_seg: 84.4772, aux.loss_ce: 0.1870, aux.acc_seg: 82.7390, loss: 0.5827
2023-12-28 12:56:48,965 - mmseg - INFO - Iter [31250/160000]	lr: 4.828e-05, eta: 1 day, 4:35:35, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4220, decode.acc_seg: 83.5784, aux.loss_ce: 0.2029, aux.acc_seg: 80.7980, loss: 0.6249
2023-12-28 12:57:29,318 - mmseg - INFO - Iter [31300/160000]	lr: 4.826e-05, eta: 1 day, 4:34:57, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4008, decode.acc_seg: 83.7023, aux.loss_ce: 0.1899, aux.acc_seg: 81.5311, loss: 0.5907
2023-12-28 12:58:10,251 - mmseg - INFO - Iter [31350/160000]	lr: 4.824e-05, eta: 1 day, 4:34:20, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4258, decode.acc_seg: 83.7567, aux.loss_ce: 0.1979, aux.acc_seg: 81.8865, loss: 0.6237
2023-12-28 12:58:51,664 - mmseg - INFO - Iter [31400/160000]	lr: 4.823e-05, eta: 1 day, 4:33:46, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4171, decode.acc_seg: 83.4465, aux.loss_ce: 0.2004, aux.acc_seg: 81.0797, loss: 0.6174
2023-12-28 12:59:32,412 - mmseg - INFO - Iter [31450/160000]	lr: 4.821e-05, eta: 1 day, 4:33:09, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3913, decode.acc_seg: 84.6507, aux.loss_ce: 0.1837, aux.acc_seg: 82.8253, loss: 0.5750
2023-12-28 13:00:12,466 - mmseg - INFO - Iter [31500/160000]	lr: 4.819e-05, eta: 1 day, 4:32:30, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4038, decode.acc_seg: 83.5881, aux.loss_ce: 0.1877, aux.acc_seg: 81.6421, loss: 0.5915
2023-12-28 13:00:51,021 - mmseg - INFO - Iter [31550/160000]	lr: 4.817e-05, eta: 1 day, 4:31:44, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4026, decode.acc_seg: 84.5436, aux.loss_ce: 0.1898, aux.acc_seg: 82.3630, loss: 0.5924
2023-12-28 13:01:32,022 - mmseg - INFO - Iter [31600/160000]	lr: 4.815e-05, eta: 1 day, 4:31:08, time: 0.820, data_time: 0.053, memory: 18256, decode.loss_ce: 0.4065, decode.acc_seg: 84.1456, aux.loss_ce: 0.1883, aux.acc_seg: 82.1854, loss: 0.5948
2023-12-28 13:02:11,150 - mmseg - INFO - Iter [31650/160000]	lr: 4.813e-05, eta: 1 day, 4:30:25, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3849, decode.acc_seg: 84.9324, aux.loss_ce: 0.1841, aux.acc_seg: 82.4962, loss: 0.5690
2023-12-28 13:02:51,104 - mmseg - INFO - Iter [31700/160000]	lr: 4.811e-05, eta: 1 day, 4:29:45, time: 0.800, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3864, decode.acc_seg: 84.6780, aux.loss_ce: 0.1846, aux.acc_seg: 82.3513, loss: 0.5710
2023-12-28 13:03:31,595 - mmseg - INFO - Iter [31750/160000]	lr: 4.809e-05, eta: 1 day, 4:29:07, time: 0.809, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3924, decode.acc_seg: 85.1552, aux.loss_ce: 0.1895, aux.acc_seg: 82.5985, loss: 0.5819
2023-12-28 13:04:11,582 - mmseg - INFO - Iter [31800/160000]	lr: 4.808e-05, eta: 1 day, 4:28:27, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3737, decode.acc_seg: 84.5847, aux.loss_ce: 0.1776, aux.acc_seg: 82.5881, loss: 0.5513
2023-12-28 13:04:49,441 - mmseg - INFO - Iter [31850/160000]	lr: 4.806e-05, eta: 1 day, 4:27:38, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3645, decode.acc_seg: 85.8300, aux.loss_ce: 0.1732, aux.acc_seg: 83.9305, loss: 0.5377
2023-12-28 13:05:30,188 - mmseg - INFO - Iter [31900/160000]	lr: 4.804e-05, eta: 1 day, 4:27:02, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3691, decode.acc_seg: 85.1621, aux.loss_ce: 0.1765, aux.acc_seg: 82.8906, loss: 0.5455
2023-12-28 13:06:10,630 - mmseg - INFO - Iter [31950/160000]	lr: 4.802e-05, eta: 1 day, 4:26:23, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3795, decode.acc_seg: 84.8295, aux.loss_ce: 0.1811, aux.acc_seg: 82.6610, loss: 0.5606
2023-12-28 13:06:51,169 - mmseg - INFO - Saving checkpoint at 32000 iterations
2023-12-28 13:06:55,394 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 13:06:55,394 - mmseg - INFO - Iter [32000/160000]	lr: 4.800e-05, eta: 1 day, 4:26:03, time: 0.895, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3807, decode.acc_seg: 85.3488, aux.loss_ce: 0.1818, aux.acc_seg: 83.1664, loss: 0.5624
2023-12-28 13:08:28,248 - mmseg - INFO - per class results:
2023-12-28 13:08:28,262 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 74.54 | 86.36 |
|       building      | 81.91 | 90.57 |
|         sky         | 94.08 |  97.8 |
|        floor        | 80.19 | 88.94 |
|         tree        | 73.46 | 86.94 |
|       ceiling       | 81.11 |  91.2 |
|         road        | 82.23 | 88.93 |
|         bed         | 87.51 | 94.69 |
|      windowpane     | 60.53 | 77.28 |
|        grass        | 70.15 | 78.72 |
|       cabinet       | 56.67 | 66.56 |
|       sidewalk      | 63.38 | 75.99 |
|        person       | 79.61 | 90.58 |
|        earth        | 39.33 | 58.98 |
|         door        | 43.63 | 58.18 |
|        table        | 54.02 | 72.75 |
|       mountain      | 58.56 | 82.37 |
|        plant        | 53.56 | 61.96 |
|       curtain       |  71.7 | 85.08 |
|        chair        | 52.19 | 63.74 |
|         car         | 82.47 | 90.86 |
|        water        | 59.11 | 74.34 |
|       painting      | 64.46 | 86.72 |
|         sofa        | 62.84 | 82.17 |
|        shelf        | 40.88 | 58.71 |
|        house        | 48.34 |  77.8 |
|         sea         |  61.8 | 84.54 |
|        mirror       |  59.1 | 69.62 |
|         rug         |  67.5 | 77.48 |
|        field        | 28.61 | 46.14 |
|       armchair      | 41.06 | 61.09 |
|         seat        | 60.17 | 83.83 |
|        fence        | 44.07 | 62.73 |
|         desk        | 46.08 | 71.93 |
|         rock        | 43.81 | 58.69 |
|       wardrobe      | 48.84 | 67.15 |
|         lamp        | 57.43 | 73.45 |
|       bathtub       |  71.6 | 81.64 |
|       railing       | 34.46 | 48.06 |
|       cushion       |  53.4 | 68.45 |
|         base        | 28.15 | 41.01 |
|         box         | 20.62 | 27.62 |
|        column       | 43.43 | 51.48 |
|      signboard      | 32.99 | 43.82 |
|   chest of drawers  | 39.32 | 59.01 |
|       counter       | 16.37 | 18.63 |
|         sand        | 38.93 | 69.86 |
|         sink        | 64.12 |  78.4 |
|      skyscraper     | 41.46 | 46.26 |
|      fireplace      | 64.97 | 79.35 |
|     refrigerator    | 68.82 | 83.07 |
|      grandstand     | 37.99 |  74.4 |
|         path        | 18.85 | 25.48 |
|        stairs       | 21.51 | 26.37 |
|        runway       | 66.27 | 97.05 |
|         case        | 54.95 | 75.57 |
|      pool table     |  91.5 |  96.9 |
|        pillow       | 55.25 | 64.57 |
|     screen door     | 67.24 | 70.23 |
|       stairway      | 33.61 | 47.32 |
|        river        | 20.82 | 30.65 |
|        bridge       |  65.0 | 74.72 |
|       bookcase      | 29.31 | 52.42 |
|        blind        |  42.2 |  50.2 |
|     coffee table    | 48.86 | 80.01 |
|        toilet       | 77.94 | 88.15 |
|        flower       | 35.06 | 49.12 |
|         book        | 42.42 | 59.16 |
|         hill        |  2.21 |  3.69 |
|        bench        | 39.99 | 48.16 |
|      countertop     | 62.03 | 77.22 |
|        stove        | 57.05 | 64.17 |
|         palm        | 42.35 | 72.86 |
|    kitchen island   | 36.12 | 75.65 |
|       computer      | 58.97 | 77.03 |
|     swivel chair    | 40.15 | 71.09 |
|         boat        | 32.69 | 53.12 |
|         bar         | 26.49 | 37.88 |
|    arcade machine   | 79.61 | 95.67 |
|        hovel        | 27.42 | 29.57 |
|         bus         | 84.17 | 95.89 |
|        towel        | 57.75 | 65.28 |
|        light        | 48.08 | 54.89 |
|        truck        | 28.36 | 46.98 |
|        tower        | 33.86 | 56.63 |
|      chandelier     | 63.44 | 76.19 |
|        awning       | 23.63 | 30.53 |
|     streetlight     | 20.03 | 24.33 |
|        booth        | 35.27 | 52.84 |
| television receiver | 62.89 | 74.68 |
|       airplane      | 48.37 | 65.98 |
|      dirt track     |  4.46 | 25.54 |
|       apparel       | 36.97 | 51.16 |
|         pole        | 13.83 |  17.1 |
|         land        |  0.0  |  0.0  |
|      bannister      | 12.46 | 15.77 |
|      escalator      | 45.28 | 63.41 |
|       ottoman       | 38.28 |  49.3 |
|        bottle       | 18.04 | 22.36 |
|        buffet       | 36.88 | 46.73 |
|        poster       | 31.69 | 42.57 |
|        stage        | 13.43 | 19.95 |
|         van         | 41.47 | 49.37 |
|         ship        | 53.09 | 79.66 |
|       fountain      | 21.19 | 21.49 |
|    conveyer belt    | 53.31 | 93.08 |
|        canopy       | 15.91 | 21.12 |
|        washer       | 72.28 |  78.4 |
|      plaything      | 26.33 | 49.43 |
|    swimming pool    | 57.98 | 90.73 |
|        stool        | 25.27 | 33.72 |
|        barrel       |  18.1 | 64.93 |
|        basket       | 25.42 | 41.86 |
|      waterfall      | 71.99 | 85.69 |
|         tent        | 90.47 | 99.17 |
|         bag         |  9.74 |  11.1 |
|       minibike      | 67.48 | 83.34 |
|        cradle       | 68.72 | 97.16 |
|         oven        | 18.25 | 43.01 |
|         ball        |  40.3 | 45.13 |
|         food        | 45.78 | 52.73 |
|         step        |  7.81 |  8.93 |
|         tank        | 50.68 | 53.18 |
|      trade name     | 25.86 | 33.63 |
|      microwave      | 57.73 | 69.58 |
|         pot         | 31.88 | 36.69 |
|        animal       | 53.82 | 55.32 |
|       bicycle       | 54.02 | 68.38 |
|         lake        | 65.04 |  65.5 |
|      dishwasher     | 42.65 | 62.94 |
|        screen       | 61.41 | 90.33 |
|       blanket       |  1.09 |  1.24 |
|      sculpture      |  51.7 | 64.95 |
|         hood        | 52.27 | 62.74 |
|        sconce       | 24.76 | 28.85 |
|         vase        | 32.65 | 42.35 |
|    traffic light    | 17.96 | 25.61 |
|         tray        |  3.64 |  3.75 |
|        ashcan       | 32.35 | 41.41 |
|         fan         | 48.84 | 66.65 |
|         pier        | 56.84 | 85.17 |
|      crt screen     |  9.75 | 11.29 |
|        plate        | 49.07 | 64.66 |
|       monitor       | 38.36 | 63.48 |
|    bulletin board   | 45.08 | 51.29 |
|        shower       |  1.37 |  1.49 |
|       radiator      | 53.43 | 58.26 |
|        glass        |  6.24 |  6.37 |
|        clock        |  24.9 | 26.41 |
|         flag        | 47.14 | 51.85 |
+---------------------+-------+-------+
2023-12-28 13:08:28,262 - mmseg - INFO - Summary:
2023-12-28 13:08:28,262 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 81.73 | 45.57 | 58.88 |
+-------+-------+-------+
2023-12-28 13:08:28,274 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 13:08:28,274 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8173, mIoU: 0.4557, mAcc: 0.5888, IoU.wall: 0.7454, IoU.building: 0.8191, IoU.sky: 0.9408, IoU.floor: 0.8019, IoU.tree: 0.7346, IoU.ceiling: 0.8111, IoU.road: 0.8223, IoU.bed : 0.8751, IoU.windowpane: 0.6053, IoU.grass: 0.7015, IoU.cabinet: 0.5667, IoU.sidewalk: 0.6338, IoU.person: 0.7961, IoU.earth: 0.3933, IoU.door: 0.4363, IoU.table: 0.5402, IoU.mountain: 0.5856, IoU.plant: 0.5356, IoU.curtain: 0.7170, IoU.chair: 0.5219, IoU.car: 0.8247, IoU.water: 0.5911, IoU.painting: 0.6446, IoU.sofa: 0.6284, IoU.shelf: 0.4088, IoU.house: 0.4834, IoU.sea: 0.6180, IoU.mirror: 0.5910, IoU.rug: 0.6750, IoU.field: 0.2861, IoU.armchair: 0.4106, IoU.seat: 0.6017, IoU.fence: 0.4407, IoU.desk: 0.4608, IoU.rock: 0.4381, IoU.wardrobe: 0.4884, IoU.lamp: 0.5743, IoU.bathtub: 0.7160, IoU.railing: 0.3446, IoU.cushion: 0.5340, IoU.base: 0.2815, IoU.box: 0.2062, IoU.column: 0.4343, IoU.signboard: 0.3299, IoU.chest of drawers: 0.3932, IoU.counter: 0.1637, IoU.sand: 0.3893, IoU.sink: 0.6412, IoU.skyscraper: 0.4146, IoU.fireplace: 0.6497, IoU.refrigerator: 0.6882, IoU.grandstand: 0.3799, IoU.path: 0.1885, IoU.stairs: 0.2151, IoU.runway: 0.6627, IoU.case: 0.5495, IoU.pool table: 0.9150, IoU.pillow: 0.5525, IoU.screen door: 0.6724, IoU.stairway: 0.3361, IoU.river: 0.2082, IoU.bridge: 0.6500, IoU.bookcase: 0.2931, IoU.blind: 0.4220, IoU.coffee table: 0.4886, IoU.toilet: 0.7794, IoU.flower: 0.3506, IoU.book: 0.4242, IoU.hill: 0.0221, IoU.bench: 0.3999, IoU.countertop: 0.6203, IoU.stove: 0.5705, IoU.palm: 0.4235, IoU.kitchen island: 0.3612, IoU.computer: 0.5897, IoU.swivel chair: 0.4015, IoU.boat: 0.3269, IoU.bar: 0.2649, IoU.arcade machine: 0.7961, IoU.hovel: 0.2742, IoU.bus: 0.8417, IoU.towel: 0.5775, IoU.light: 0.4808, IoU.truck: 0.2836, IoU.tower: 0.3386, IoU.chandelier: 0.6344, IoU.awning: 0.2363, IoU.streetlight: 0.2003, IoU.booth: 0.3527, IoU.television receiver: 0.6289, IoU.airplane: 0.4837, IoU.dirt track: 0.0446, IoU.apparel: 0.3697, IoU.pole: 0.1383, IoU.land: 0.0000, IoU.bannister: 0.1246, IoU.escalator: 0.4528, IoU.ottoman: 0.3828, IoU.bottle: 0.1804, IoU.buffet: 0.3688, IoU.poster: 0.3169, IoU.stage: 0.1343, IoU.van: 0.4147, IoU.ship: 0.5309, IoU.fountain: 0.2119, IoU.conveyer belt: 0.5331, IoU.canopy: 0.1591, IoU.washer: 0.7228, IoU.plaything: 0.2633, IoU.swimming pool: 0.5798, IoU.stool: 0.2527, IoU.barrel: 0.1810, IoU.basket: 0.2542, IoU.waterfall: 0.7199, IoU.tent: 0.9047, IoU.bag: 0.0974, IoU.minibike: 0.6748, IoU.cradle: 0.6872, IoU.oven: 0.1825, IoU.ball: 0.4030, IoU.food: 0.4578, IoU.step: 0.0781, IoU.tank: 0.5068, IoU.trade name: 0.2586, IoU.microwave: 0.5773, IoU.pot: 0.3188, IoU.animal: 0.5382, IoU.bicycle: 0.5402, IoU.lake: 0.6504, IoU.dishwasher: 0.4265, IoU.screen: 0.6141, IoU.blanket: 0.0109, IoU.sculpture: 0.5170, IoU.hood: 0.5227, IoU.sconce: 0.2476, IoU.vase: 0.3265, IoU.traffic light: 0.1796, IoU.tray: 0.0364, IoU.ashcan: 0.3235, IoU.fan: 0.4884, IoU.pier: 0.5684, IoU.crt screen: 0.0975, IoU.plate: 0.4907, IoU.monitor: 0.3836, IoU.bulletin board: 0.4508, IoU.shower: 0.0137, IoU.radiator: 0.5343, IoU.glass: 0.0624, IoU.clock: 0.2490, IoU.flag: 0.4714, Acc.wall: 0.8636, Acc.building: 0.9057, Acc.sky: 0.9780, Acc.floor: 0.8894, Acc.tree: 0.8694, Acc.ceiling: 0.9120, Acc.road: 0.8893, Acc.bed : 0.9469, Acc.windowpane: 0.7728, Acc.grass: 0.7872, Acc.cabinet: 0.6656, Acc.sidewalk: 0.7599, Acc.person: 0.9058, Acc.earth: 0.5898, Acc.door: 0.5818, Acc.table: 0.7275, Acc.mountain: 0.8237, Acc.plant: 0.6196, Acc.curtain: 0.8508, Acc.chair: 0.6374, Acc.car: 0.9086, Acc.water: 0.7434, Acc.painting: 0.8672, Acc.sofa: 0.8217, Acc.shelf: 0.5871, Acc.house: 0.7780, Acc.sea: 0.8454, Acc.mirror: 0.6962, Acc.rug: 0.7748, Acc.field: 0.4614, Acc.armchair: 0.6109, Acc.seat: 0.8383, Acc.fence: 0.6273, Acc.desk: 0.7193, Acc.rock: 0.5869, Acc.wardrobe: 0.6715, Acc.lamp: 0.7345, Acc.bathtub: 0.8164, Acc.railing: 0.4806, Acc.cushion: 0.6845, Acc.base: 0.4101, Acc.box: 0.2762, Acc.column: 0.5148, Acc.signboard: 0.4382, Acc.chest of drawers: 0.5901, Acc.counter: 0.1863, Acc.sand: 0.6986, Acc.sink: 0.7840, Acc.skyscraper: 0.4626, Acc.fireplace: 0.7935, Acc.refrigerator: 0.8307, Acc.grandstand: 0.7440, Acc.path: 0.2548, Acc.stairs: 0.2637, Acc.runway: 0.9705, Acc.case: 0.7557, Acc.pool table: 0.9690, Acc.pillow: 0.6457, Acc.screen door: 0.7023, Acc.stairway: 0.4732, Acc.river: 0.3065, Acc.bridge: 0.7472, Acc.bookcase: 0.5242, Acc.blind: 0.5020, Acc.coffee table: 0.8001, Acc.toilet: 0.8815, Acc.flower: 0.4912, Acc.book: 0.5916, Acc.hill: 0.0369, Acc.bench: 0.4816, Acc.countertop: 0.7722, Acc.stove: 0.6417, Acc.palm: 0.7286, Acc.kitchen island: 0.7565, Acc.computer: 0.7703, Acc.swivel chair: 0.7109, Acc.boat: 0.5312, Acc.bar: 0.3788, Acc.arcade machine: 0.9567, Acc.hovel: 0.2957, Acc.bus: 0.9589, Acc.towel: 0.6528, Acc.light: 0.5489, Acc.truck: 0.4698, Acc.tower: 0.5663, Acc.chandelier: 0.7619, Acc.awning: 0.3053, Acc.streetlight: 0.2433, Acc.booth: 0.5284, Acc.television receiver: 0.7468, Acc.airplane: 0.6598, Acc.dirt track: 0.2554, Acc.apparel: 0.5116, Acc.pole: 0.1710, Acc.land: 0.0000, Acc.bannister: 0.1577, Acc.escalator: 0.6341, Acc.ottoman: 0.4930, Acc.bottle: 0.2236, Acc.buffet: 0.4673, Acc.poster: 0.4257, Acc.stage: 0.1995, Acc.van: 0.4937, Acc.ship: 0.7966, Acc.fountain: 0.2149, Acc.conveyer belt: 0.9308, Acc.canopy: 0.2112, Acc.washer: 0.7840, Acc.plaything: 0.4943, Acc.swimming pool: 0.9073, Acc.stool: 0.3372, Acc.barrel: 0.6493, Acc.basket: 0.4186, Acc.waterfall: 0.8569, Acc.tent: 0.9917, Acc.bag: 0.1110, Acc.minibike: 0.8334, Acc.cradle: 0.9716, Acc.oven: 0.4301, Acc.ball: 0.4513, Acc.food: 0.5273, Acc.step: 0.0893, Acc.tank: 0.5318, Acc.trade name: 0.3363, Acc.microwave: 0.6958, Acc.pot: 0.3669, Acc.animal: 0.5532, Acc.bicycle: 0.6838, Acc.lake: 0.6550, Acc.dishwasher: 0.6294, Acc.screen: 0.9033, Acc.blanket: 0.0124, Acc.sculpture: 0.6495, Acc.hood: 0.6274, Acc.sconce: 0.2885, Acc.vase: 0.4235, Acc.traffic light: 0.2561, Acc.tray: 0.0375, Acc.ashcan: 0.4141, Acc.fan: 0.6665, Acc.pier: 0.8517, Acc.crt screen: 0.1129, Acc.plate: 0.6466, Acc.monitor: 0.6348, Acc.bulletin board: 0.5129, Acc.shower: 0.0149, Acc.radiator: 0.5826, Acc.glass: 0.0637, Acc.clock: 0.2641, Acc.flag: 0.5185
2023-12-28 13:09:07,306 - mmseg - INFO - Iter [32050/160000]	lr: 4.798e-05, eta: 1 day, 4:31:29, time: 2.637, data_time: 1.868, memory: 18256, decode.loss_ce: 0.3932, decode.acc_seg: 84.4019, aux.loss_ce: 0.1860, aux.acc_seg: 82.2706, loss: 0.5792
2023-12-28 13:09:47,432 - mmseg - INFO - Iter [32100/160000]	lr: 4.796e-05, eta: 1 day, 4:30:49, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3664, decode.acc_seg: 85.3395, aux.loss_ce: 0.1731, aux.acc_seg: 83.3338, loss: 0.5395
2023-12-28 13:10:25,198 - mmseg - INFO - Iter [32150/160000]	lr: 4.794e-05, eta: 1 day, 4:30:00, time: 0.756, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3966, decode.acc_seg: 84.5162, aux.loss_ce: 0.1854, aux.acc_seg: 82.4942, loss: 0.5820
2023-12-28 13:11:05,275 - mmseg - INFO - Iter [32200/160000]	lr: 4.793e-05, eta: 1 day, 4:29:20, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4073, decode.acc_seg: 84.1506, aux.loss_ce: 0.1887, aux.acc_seg: 82.5258, loss: 0.5960
2023-12-28 13:11:42,273 - mmseg - INFO - Iter [32250/160000]	lr: 4.791e-05, eta: 1 day, 4:28:27, time: 0.740, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4132, decode.acc_seg: 84.0240, aux.loss_ce: 0.1941, aux.acc_seg: 81.8658, loss: 0.6073
2023-12-28 13:12:20,294 - mmseg - INFO - Iter [32300/160000]	lr: 4.789e-05, eta: 1 day, 4:27:38, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3827, decode.acc_seg: 85.0003, aux.loss_ce: 0.1849, aux.acc_seg: 82.5485, loss: 0.5675
2023-12-28 13:12:59,611 - mmseg - INFO - Iter [32350/160000]	lr: 4.787e-05, eta: 1 day, 4:26:55, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3880, decode.acc_seg: 84.7173, aux.loss_ce: 0.1831, aux.acc_seg: 82.8009, loss: 0.5711
2023-12-28 13:13:39,125 - mmseg - INFO - Iter [32400/160000]	lr: 4.785e-05, eta: 1 day, 4:26:13, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4061, decode.acc_seg: 84.3757, aux.loss_ce: 0.1868, aux.acc_seg: 82.9058, loss: 0.5928
2023-12-28 13:14:19,010 - mmseg - INFO - Iter [32450/160000]	lr: 4.783e-05, eta: 1 day, 4:25:32, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3923, decode.acc_seg: 84.3423, aux.loss_ce: 0.1881, aux.acc_seg: 81.9304, loss: 0.5804
2023-12-28 13:14:57,758 - mmseg - INFO - Iter [32500/160000]	lr: 4.781e-05, eta: 1 day, 4:24:46, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3908, decode.acc_seg: 85.0471, aux.loss_ce: 0.1857, aux.acc_seg: 82.6801, loss: 0.5765
2023-12-28 13:15:37,570 - mmseg - INFO - Iter [32550/160000]	lr: 4.779e-05, eta: 1 day, 4:24:05, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3849, decode.acc_seg: 84.8051, aux.loss_ce: 0.1818, aux.acc_seg: 82.8829, loss: 0.5667
2023-12-28 13:16:17,139 - mmseg - INFO - Iter [32600/160000]	lr: 4.778e-05, eta: 1 day, 4:23:23, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3884, decode.acc_seg: 84.9626, aux.loss_ce: 0.1845, aux.acc_seg: 82.7670, loss: 0.5729
2023-12-28 13:16:57,290 - mmseg - INFO - Iter [32650/160000]	lr: 4.776e-05, eta: 1 day, 4:22:43, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4086, decode.acc_seg: 83.6232, aux.loss_ce: 0.1932, aux.acc_seg: 81.5420, loss: 0.6018
2023-12-28 13:17:37,333 - mmseg - INFO - Iter [32700/160000]	lr: 4.774e-05, eta: 1 day, 4:22:02, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4084, decode.acc_seg: 83.7906, aux.loss_ce: 0.1916, aux.acc_seg: 81.7974, loss: 0.6000
2023-12-28 13:18:18,613 - mmseg - INFO - Iter [32750/160000]	lr: 4.772e-05, eta: 1 day, 4:21:27, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4086, decode.acc_seg: 83.9236, aux.loss_ce: 0.1898, aux.acc_seg: 82.1505, loss: 0.5984
2023-12-28 13:18:59,799 - mmseg - INFO - Iter [32800/160000]	lr: 4.770e-05, eta: 1 day, 4:20:51, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4385, decode.acc_seg: 82.8833, aux.loss_ce: 0.2038, aux.acc_seg: 81.0035, loss: 0.6423
2023-12-28 13:19:42,164 - mmseg - INFO - Iter [32850/160000]	lr: 4.768e-05, eta: 1 day, 4:20:20, time: 0.849, data_time: 0.054, memory: 18256, decode.loss_ce: 0.4136, decode.acc_seg: 83.7230, aux.loss_ce: 0.1981, aux.acc_seg: 81.3497, loss: 0.6118
2023-12-28 13:20:19,285 - mmseg - INFO - Iter [32900/160000]	lr: 4.766e-05, eta: 1 day, 4:19:28, time: 0.742, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3909, decode.acc_seg: 84.6686, aux.loss_ce: 0.1809, aux.acc_seg: 82.8979, loss: 0.5718
2023-12-28 13:20:56,690 - mmseg - INFO - Iter [32950/160000]	lr: 4.764e-05, eta: 1 day, 4:18:37, time: 0.748, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3896, decode.acc_seg: 85.0300, aux.loss_ce: 0.1906, aux.acc_seg: 82.5242, loss: 0.5802
2023-12-28 13:21:36,980 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 13:21:36,981 - mmseg - INFO - Iter [33000/160000]	lr: 4.763e-05, eta: 1 day, 4:17:58, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3720, decode.acc_seg: 85.6251, aux.loss_ce: 0.1774, aux.acc_seg: 83.2166, loss: 0.5494
2023-12-28 13:22:14,751 - mmseg - INFO - Iter [33050/160000]	lr: 4.761e-05, eta: 1 day, 4:17:09, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3850, decode.acc_seg: 84.6451, aux.loss_ce: 0.1888, aux.acc_seg: 82.0114, loss: 0.5738
2023-12-28 13:22:53,561 - mmseg - INFO - Iter [33100/160000]	lr: 4.759e-05, eta: 1 day, 4:16:24, time: 0.776, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3767, decode.acc_seg: 84.9034, aux.loss_ce: 0.1739, aux.acc_seg: 83.4057, loss: 0.5506
2023-12-28 13:23:31,025 - mmseg - INFO - Iter [33150/160000]	lr: 4.757e-05, eta: 1 day, 4:15:33, time: 0.748, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3910, decode.acc_seg: 84.1421, aux.loss_ce: 0.1858, aux.acc_seg: 82.0483, loss: 0.5769
2023-12-28 13:24:11,468 - mmseg - INFO - Iter [33200/160000]	lr: 4.755e-05, eta: 1 day, 4:14:55, time: 0.809, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3717, decode.acc_seg: 85.4342, aux.loss_ce: 0.1748, aux.acc_seg: 83.5926, loss: 0.5465
2023-12-28 13:24:51,577 - mmseg - INFO - Iter [33250/160000]	lr: 4.753e-05, eta: 1 day, 4:14:14, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4066, decode.acc_seg: 84.0617, aux.loss_ce: 0.1907, aux.acc_seg: 82.0321, loss: 0.5974
2023-12-28 13:25:30,844 - mmseg - INFO - Iter [33300/160000]	lr: 4.751e-05, eta: 1 day, 4:13:31, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3701, decode.acc_seg: 85.5171, aux.loss_ce: 0.1781, aux.acc_seg: 83.3283, loss: 0.5482
2023-12-28 13:26:09,786 - mmseg - INFO - Iter [33350/160000]	lr: 4.749e-05, eta: 1 day, 4:12:47, time: 0.780, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3768, decode.acc_seg: 85.2032, aux.loss_ce: 0.1808, aux.acc_seg: 83.1949, loss: 0.5576
2023-12-28 13:26:49,273 - mmseg - INFO - Iter [33400/160000]	lr: 4.748e-05, eta: 1 day, 4:12:04, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3938, decode.acc_seg: 84.4247, aux.loss_ce: 0.1862, aux.acc_seg: 82.6599, loss: 0.5799
2023-12-28 13:27:28,703 - mmseg - INFO - Iter [33450/160000]	lr: 4.746e-05, eta: 1 day, 4:11:22, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3881, decode.acc_seg: 84.6320, aux.loss_ce: 0.1835, aux.acc_seg: 82.4662, loss: 0.5717
2023-12-28 13:28:06,233 - mmseg - INFO - Iter [33500/160000]	lr: 4.744e-05, eta: 1 day, 4:10:32, time: 0.749, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4197, decode.acc_seg: 83.6425, aux.loss_ce: 0.1979, aux.acc_seg: 81.2580, loss: 0.6176
2023-12-28 13:28:44,929 - mmseg - INFO - Iter [33550/160000]	lr: 4.742e-05, eta: 1 day, 4:09:47, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4029, decode.acc_seg: 83.9326, aux.loss_ce: 0.1857, aux.acc_seg: 82.3292, loss: 0.5887
2023-12-28 13:29:24,515 - mmseg - INFO - Iter [33600/160000]	lr: 4.740e-05, eta: 1 day, 4:09:05, time: 0.791, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3795, decode.acc_seg: 85.3243, aux.loss_ce: 0.1814, aux.acc_seg: 83.3450, loss: 0.5608
2023-12-28 13:30:01,603 - mmseg - INFO - Iter [33650/160000]	lr: 4.738e-05, eta: 1 day, 4:08:13, time: 0.743, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3807, decode.acc_seg: 84.9228, aux.loss_ce: 0.1816, aux.acc_seg: 82.6654, loss: 0.5623
2023-12-28 13:30:40,763 - mmseg - INFO - Iter [33700/160000]	lr: 4.736e-05, eta: 1 day, 4:07:30, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3750, decode.acc_seg: 85.2880, aux.loss_ce: 0.1782, aux.acc_seg: 83.2137, loss: 0.5532
2023-12-28 13:31:19,340 - mmseg - INFO - Iter [33750/160000]	lr: 4.734e-05, eta: 1 day, 4:06:44, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4108, decode.acc_seg: 84.1875, aux.loss_ce: 0.1958, aux.acc_seg: 81.6876, loss: 0.6066
2023-12-28 13:31:56,166 - mmseg - INFO - Iter [33800/160000]	lr: 4.733e-05, eta: 1 day, 4:05:52, time: 0.737, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3904, decode.acc_seg: 83.8717, aux.loss_ce: 0.1874, aux.acc_seg: 81.6754, loss: 0.5778
2023-12-28 13:32:36,225 - mmseg - INFO - Iter [33850/160000]	lr: 4.731e-05, eta: 1 day, 4:05:12, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3899, decode.acc_seg: 84.5208, aux.loss_ce: 0.1872, aux.acc_seg: 82.3629, loss: 0.5771
2023-12-28 13:33:14,503 - mmseg - INFO - Iter [33900/160000]	lr: 4.729e-05, eta: 1 day, 4:04:25, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3797, decode.acc_seg: 85.1243, aux.loss_ce: 0.1842, aux.acc_seg: 82.4555, loss: 0.5639
2023-12-28 13:33:54,190 - mmseg - INFO - Iter [33950/160000]	lr: 4.727e-05, eta: 1 day, 4:03:43, time: 0.793, data_time: 0.010, memory: 18256, decode.loss_ce: 0.4033, decode.acc_seg: 84.2500, aux.loss_ce: 0.1852, aux.acc_seg: 82.4056, loss: 0.5885
2023-12-28 13:34:36,024 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 13:34:36,025 - mmseg - INFO - Iter [34000/160000]	lr: 4.725e-05, eta: 1 day, 4:03:10, time: 0.837, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4094, decode.acc_seg: 84.4405, aux.loss_ce: 0.1910, aux.acc_seg: 82.3494, loss: 0.6004
2023-12-28 13:35:17,641 - mmseg - INFO - Iter [34050/160000]	lr: 4.723e-05, eta: 1 day, 4:02:35, time: 0.832, data_time: 0.011, memory: 18256, decode.loss_ce: 0.4092, decode.acc_seg: 83.7891, aux.loss_ce: 0.1884, aux.acc_seg: 82.3497, loss: 0.5976
2023-12-28 13:35:59,270 - mmseg - INFO - Iter [34100/160000]	lr: 4.721e-05, eta: 1 day, 4:02:01, time: 0.833, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3964, decode.acc_seg: 84.9652, aux.loss_ce: 0.1882, aux.acc_seg: 82.2188, loss: 0.5846
2023-12-28 13:36:41,404 - mmseg - INFO - Iter [34150/160000]	lr: 4.719e-05, eta: 1 day, 4:01:28, time: 0.843, data_time: 0.054, memory: 18256, decode.loss_ce: 0.3632, decode.acc_seg: 85.4808, aux.loss_ce: 0.1777, aux.acc_seg: 83.0462, loss: 0.5409
2023-12-28 13:37:20,998 - mmseg - INFO - Iter [34200/160000]	lr: 4.718e-05, eta: 1 day, 4:00:47, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3730, decode.acc_seg: 85.2775, aux.loss_ce: 0.1765, aux.acc_seg: 83.1492, loss: 0.5495
2023-12-28 13:38:00,098 - mmseg - INFO - Iter [34250/160000]	lr: 4.716e-05, eta: 1 day, 4:00:03, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3813, decode.acc_seg: 84.9791, aux.loss_ce: 0.1799, aux.acc_seg: 82.8879, loss: 0.5612
2023-12-28 13:38:39,206 - mmseg - INFO - Iter [34300/160000]	lr: 4.714e-05, eta: 1 day, 3:59:19, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3647, decode.acc_seg: 85.2871, aux.loss_ce: 0.1751, aux.acc_seg: 83.2309, loss: 0.5399
2023-12-28 13:39:17,601 - mmseg - INFO - Iter [34350/160000]	lr: 4.712e-05, eta: 1 day, 3:58:33, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3556, decode.acc_seg: 86.1135, aux.loss_ce: 0.1748, aux.acc_seg: 83.2878, loss: 0.5304
2023-12-28 13:39:55,934 - mmseg - INFO - Iter [34400/160000]	lr: 4.710e-05, eta: 1 day, 3:57:47, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3819, decode.acc_seg: 85.1602, aux.loss_ce: 0.1785, aux.acc_seg: 83.2494, loss: 0.5603
2023-12-28 13:40:35,603 - mmseg - INFO - Iter [34450/160000]	lr: 4.708e-05, eta: 1 day, 3:57:05, time: 0.792, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3633, decode.acc_seg: 85.5988, aux.loss_ce: 0.1727, aux.acc_seg: 83.6264, loss: 0.5360
2023-12-28 13:41:14,186 - mmseg - INFO - Iter [34500/160000]	lr: 4.706e-05, eta: 1 day, 3:56:20, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4040, decode.acc_seg: 84.1596, aux.loss_ce: 0.1961, aux.acc_seg: 82.2203, loss: 0.6001
2023-12-28 13:41:53,413 - mmseg - INFO - Iter [34550/160000]	lr: 4.704e-05, eta: 1 day, 3:55:37, time: 0.785, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4018, decode.acc_seg: 84.6651, aux.loss_ce: 0.1895, aux.acc_seg: 82.5661, loss: 0.5913
2023-12-28 13:42:33,588 - mmseg - INFO - Iter [34600/160000]	lr: 4.703e-05, eta: 1 day, 3:54:57, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3684, decode.acc_seg: 85.2773, aux.loss_ce: 0.1784, aux.acc_seg: 83.2610, loss: 0.5468
2023-12-28 13:43:12,339 - mmseg - INFO - Iter [34650/160000]	lr: 4.701e-05, eta: 1 day, 3:54:12, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3740, decode.acc_seg: 85.1860, aux.loss_ce: 0.1786, aux.acc_seg: 83.1758, loss: 0.5525
2023-12-28 13:43:49,925 - mmseg - INFO - Iter [34700/160000]	lr: 4.699e-05, eta: 1 day, 3:53:23, time: 0.751, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3915, decode.acc_seg: 84.7037, aux.loss_ce: 0.1878, aux.acc_seg: 82.6737, loss: 0.5794
2023-12-28 13:44:30,108 - mmseg - INFO - Iter [34750/160000]	lr: 4.697e-05, eta: 1 day, 3:52:43, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3949, decode.acc_seg: 84.5720, aux.loss_ce: 0.1868, aux.acc_seg: 82.3025, loss: 0.5817
2023-12-28 13:45:10,942 - mmseg - INFO - Iter [34800/160000]	lr: 4.695e-05, eta: 1 day, 3:52:06, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4068, decode.acc_seg: 84.1428, aux.loss_ce: 0.1880, aux.acc_seg: 82.2054, loss: 0.5947
2023-12-28 13:45:50,442 - mmseg - INFO - Iter [34850/160000]	lr: 4.693e-05, eta: 1 day, 3:51:24, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4197, decode.acc_seg: 83.8170, aux.loss_ce: 0.2012, aux.acc_seg: 81.6850, loss: 0.6210
2023-12-28 13:46:29,762 - mmseg - INFO - Iter [34900/160000]	lr: 4.691e-05, eta: 1 day, 3:50:41, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3774, decode.acc_seg: 84.7307, aux.loss_ce: 0.1764, aux.acc_seg: 82.9696, loss: 0.5538
2023-12-28 13:47:08,378 - mmseg - INFO - Iter [34950/160000]	lr: 4.689e-05, eta: 1 day, 3:49:56, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4121, decode.acc_seg: 83.4372, aux.loss_ce: 0.1937, aux.acc_seg: 81.3674, loss: 0.6058
2023-12-28 13:47:48,385 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 13:47:48,386 - mmseg - INFO - Iter [35000/160000]	lr: 4.688e-05, eta: 1 day, 3:49:16, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4165, decode.acc_seg: 84.2264, aux.loss_ce: 0.1945, aux.acc_seg: 81.9288, loss: 0.6110
2023-12-28 13:48:29,313 - mmseg - INFO - Iter [35050/160000]	lr: 4.686e-05, eta: 1 day, 3:48:39, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3879, decode.acc_seg: 85.0351, aux.loss_ce: 0.1826, aux.acc_seg: 82.9196, loss: 0.5705
2023-12-28 13:49:09,801 - mmseg - INFO - Iter [35100/160000]	lr: 4.684e-05, eta: 1 day, 3:48:00, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3774, decode.acc_seg: 84.9988, aux.loss_ce: 0.1783, aux.acc_seg: 83.0072, loss: 0.5557
2023-12-28 13:49:51,367 - mmseg - INFO - Iter [35150/160000]	lr: 4.682e-05, eta: 1 day, 3:47:25, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3954, decode.acc_seg: 84.6830, aux.loss_ce: 0.1856, aux.acc_seg: 82.8196, loss: 0.5810
2023-12-28 13:50:32,855 - mmseg - INFO - Iter [35200/160000]	lr: 4.680e-05, eta: 1 day, 3:46:50, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3829, decode.acc_seg: 84.8774, aux.loss_ce: 0.1795, aux.acc_seg: 82.8699, loss: 0.5625
2023-12-28 13:51:13,785 - mmseg - INFO - Iter [35250/160000]	lr: 4.678e-05, eta: 1 day, 3:46:13, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3971, decode.acc_seg: 84.8637, aux.loss_ce: 0.1898, aux.acc_seg: 82.6099, loss: 0.5869
2023-12-28 13:51:54,010 - mmseg - INFO - Iter [35300/160000]	lr: 4.676e-05, eta: 1 day, 3:45:34, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3993, decode.acc_seg: 84.0696, aux.loss_ce: 0.1879, aux.acc_seg: 81.9785, loss: 0.5872
2023-12-28 13:52:31,401 - mmseg - INFO - Iter [35350/160000]	lr: 4.674e-05, eta: 1 day, 3:44:44, time: 0.749, data_time: 0.012, memory: 18256, decode.loss_ce: 0.4011, decode.acc_seg: 84.7363, aux.loss_ce: 0.1892, aux.acc_seg: 82.4609, loss: 0.5903
2023-12-28 13:53:11,591 - mmseg - INFO - Iter [35400/160000]	lr: 4.673e-05, eta: 1 day, 3:44:04, time: 0.803, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3750, decode.acc_seg: 84.9283, aux.loss_ce: 0.1773, aux.acc_seg: 82.8407, loss: 0.5523
2023-12-28 13:53:51,712 - mmseg - INFO - Iter [35450/160000]	lr: 4.671e-05, eta: 1 day, 3:43:25, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3928, decode.acc_seg: 84.5407, aux.loss_ce: 0.1849, aux.acc_seg: 82.5672, loss: 0.5777
2023-12-28 13:54:30,343 - mmseg - INFO - Iter [35500/160000]	lr: 4.669e-05, eta: 1 day, 3:42:39, time: 0.771, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3604, decode.acc_seg: 86.0477, aux.loss_ce: 0.1744, aux.acc_seg: 83.5013, loss: 0.5348
2023-12-28 13:55:09,603 - mmseg - INFO - Iter [35550/160000]	lr: 4.667e-05, eta: 1 day, 3:41:57, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3794, decode.acc_seg: 85.0480, aux.loss_ce: 0.1812, aux.acc_seg: 82.8983, loss: 0.5606
2023-12-28 13:55:47,675 - mmseg - INFO - Iter [35600/160000]	lr: 4.665e-05, eta: 1 day, 3:41:10, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3596, decode.acc_seg: 85.6475, aux.loss_ce: 0.1701, aux.acc_seg: 83.3915, loss: 0.5297
2023-12-28 13:56:27,354 - mmseg - INFO - Iter [35650/160000]	lr: 4.663e-05, eta: 1 day, 3:40:28, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3819, decode.acc_seg: 85.0521, aux.loss_ce: 0.1812, aux.acc_seg: 82.7224, loss: 0.5631
2023-12-28 13:57:06,211 - mmseg - INFO - Iter [35700/160000]	lr: 4.661e-05, eta: 1 day, 3:39:44, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3658, decode.acc_seg: 85.6038, aux.loss_ce: 0.1752, aux.acc_seg: 83.6583, loss: 0.5410
2023-12-28 13:57:45,510 - mmseg - INFO - Iter [35750/160000]	lr: 4.659e-05, eta: 1 day, 3:39:01, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3967, decode.acc_seg: 84.8054, aux.loss_ce: 0.1884, aux.acc_seg: 82.0979, loss: 0.5850
2023-12-28 13:58:24,797 - mmseg - INFO - Iter [35800/160000]	lr: 4.658e-05, eta: 1 day, 3:38:19, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3667, decode.acc_seg: 85.0376, aux.loss_ce: 0.1711, aux.acc_seg: 83.4857, loss: 0.5378
2023-12-28 13:59:03,928 - mmseg - INFO - Iter [35850/160000]	lr: 4.656e-05, eta: 1 day, 3:37:35, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3765, decode.acc_seg: 85.0223, aux.loss_ce: 0.1818, aux.acc_seg: 82.7100, loss: 0.5582
2023-12-28 13:59:43,299 - mmseg - INFO - Iter [35900/160000]	lr: 4.654e-05, eta: 1 day, 3:36:53, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3669, decode.acc_seg: 85.5828, aux.loss_ce: 0.1756, aux.acc_seg: 83.4793, loss: 0.5426
2023-12-28 14:00:23,820 - mmseg - INFO - Iter [35950/160000]	lr: 4.652e-05, eta: 1 day, 3:36:15, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3686, decode.acc_seg: 85.8181, aux.loss_ce: 0.1746, aux.acc_seg: 83.4915, loss: 0.5432
2023-12-28 14:01:04,920 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 14:01:04,921 - mmseg - INFO - Iter [36000/160000]	lr: 4.650e-05, eta: 1 day, 3:35:38, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3777, decode.acc_seg: 84.8570, aux.loss_ce: 0.1803, aux.acc_seg: 82.6000, loss: 0.5580
2023-12-28 14:01:44,071 - mmseg - INFO - Iter [36050/160000]	lr: 4.648e-05, eta: 1 day, 3:34:55, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3653, decode.acc_seg: 85.6705, aux.loss_ce: 0.1808, aux.acc_seg: 82.9704, loss: 0.5460
2023-12-28 14:02:24,064 - mmseg - INFO - Iter [36100/160000]	lr: 4.646e-05, eta: 1 day, 3:34:15, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3785, decode.acc_seg: 84.8008, aux.loss_ce: 0.1792, aux.acc_seg: 82.9989, loss: 0.5577
2023-12-28 14:03:02,678 - mmseg - INFO - Iter [36150/160000]	lr: 4.644e-05, eta: 1 day, 3:33:30, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3843, decode.acc_seg: 84.8063, aux.loss_ce: 0.1826, aux.acc_seg: 82.5770, loss: 0.5669
2023-12-28 14:03:41,779 - mmseg - INFO - Iter [36200/160000]	lr: 4.643e-05, eta: 1 day, 3:32:46, time: 0.783, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4003, decode.acc_seg: 84.3568, aux.loss_ce: 0.1881, aux.acc_seg: 82.5906, loss: 0.5884
2023-12-28 14:04:21,668 - mmseg - INFO - Iter [36250/160000]	lr: 4.641e-05, eta: 1 day, 3:32:06, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3949, decode.acc_seg: 84.5677, aux.loss_ce: 0.1834, aux.acc_seg: 82.6885, loss: 0.5783
2023-12-28 14:05:00,525 - mmseg - INFO - Iter [36300/160000]	lr: 4.639e-05, eta: 1 day, 3:31:21, time: 0.776, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3829, decode.acc_seg: 84.9004, aux.loss_ce: 0.1834, aux.acc_seg: 82.5369, loss: 0.5664
2023-12-28 14:05:39,572 - mmseg - INFO - Iter [36350/160000]	lr: 4.637e-05, eta: 1 day, 3:30:38, time: 0.782, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3661, decode.acc_seg: 85.4725, aux.loss_ce: 0.1739, aux.acc_seg: 83.2690, loss: 0.5400
2023-12-28 14:06:19,294 - mmseg - INFO - Iter [36400/160000]	lr: 4.635e-05, eta: 1 day, 3:29:57, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3871, decode.acc_seg: 84.7361, aux.loss_ce: 0.1866, aux.acc_seg: 82.5041, loss: 0.5737
2023-12-28 14:06:58,882 - mmseg - INFO - Iter [36450/160000]	lr: 4.633e-05, eta: 1 day, 3:29:15, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.4029, decode.acc_seg: 84.1902, aux.loss_ce: 0.1922, aux.acc_seg: 81.8266, loss: 0.5952
2023-12-28 14:07:38,839 - mmseg - INFO - Iter [36500/160000]	lr: 4.631e-05, eta: 1 day, 3:28:35, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3935, decode.acc_seg: 84.7383, aux.loss_ce: 0.1836, aux.acc_seg: 82.5324, loss: 0.5771
2023-12-28 14:08:17,758 - mmseg - INFO - Iter [36550/160000]	lr: 4.629e-05, eta: 1 day, 3:27:51, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3740, decode.acc_seg: 85.6196, aux.loss_ce: 0.1794, aux.acc_seg: 83.3013, loss: 0.5534
2023-12-28 14:08:57,743 - mmseg - INFO - Iter [36600/160000]	lr: 4.628e-05, eta: 1 day, 3:27:11, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3836, decode.acc_seg: 84.7711, aux.loss_ce: 0.1820, aux.acc_seg: 82.5993, loss: 0.5656
2023-12-28 14:09:38,123 - mmseg - INFO - Iter [36650/160000]	lr: 4.626e-05, eta: 1 day, 3:26:32, time: 0.807, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3830, decode.acc_seg: 84.9948, aux.loss_ce: 0.1840, aux.acc_seg: 82.8910, loss: 0.5670
2023-12-28 14:10:16,929 - mmseg - INFO - Iter [36700/160000]	lr: 4.624e-05, eta: 1 day, 3:25:48, time: 0.776, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3650, decode.acc_seg: 85.6526, aux.loss_ce: 0.1754, aux.acc_seg: 83.2303, loss: 0.5404
2023-12-28 14:11:00,180 - mmseg - INFO - Iter [36750/160000]	lr: 4.622e-05, eta: 1 day, 3:25:18, time: 0.865, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3661, decode.acc_seg: 85.7241, aux.loss_ce: 0.1788, aux.acc_seg: 83.1017, loss: 0.5449
2023-12-28 14:11:43,089 - mmseg - INFO - Iter [36800/160000]	lr: 4.620e-05, eta: 1 day, 3:24:48, time: 0.858, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3773, decode.acc_seg: 84.3046, aux.loss_ce: 0.1803, aux.acc_seg: 82.2703, loss: 0.5577
2023-12-28 14:12:26,230 - mmseg - INFO - Iter [36850/160000]	lr: 4.618e-05, eta: 1 day, 3:24:18, time: 0.864, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3852, decode.acc_seg: 84.9930, aux.loss_ce: 0.1840, aux.acc_seg: 82.4762, loss: 0.5692
2023-12-28 14:13:05,082 - mmseg - INFO - Iter [36900/160000]	lr: 4.616e-05, eta: 1 day, 3:23:34, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3619, decode.acc_seg: 85.8189, aux.loss_ce: 0.1720, aux.acc_seg: 83.9117, loss: 0.5339
2023-12-28 14:13:43,563 - mmseg - INFO - Iter [36950/160000]	lr: 4.614e-05, eta: 1 day, 3:22:49, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3478, decode.acc_seg: 85.9584, aux.loss_ce: 0.1646, aux.acc_seg: 84.1587, loss: 0.5124
2023-12-28 14:14:22,741 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 14:14:22,741 - mmseg - INFO - Iter [37000/160000]	lr: 4.613e-05, eta: 1 day, 3:22:06, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3641, decode.acc_seg: 85.8843, aux.loss_ce: 0.1793, aux.acc_seg: 83.4460, loss: 0.5434
2023-12-28 14:15:01,362 - mmseg - INFO - Iter [37050/160000]	lr: 4.611e-05, eta: 1 day, 3:21:21, time: 0.771, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3860, decode.acc_seg: 85.2457, aux.loss_ce: 0.1830, aux.acc_seg: 83.0688, loss: 0.5690
2023-12-28 14:15:40,063 - mmseg - INFO - Iter [37100/160000]	lr: 4.609e-05, eta: 1 day, 3:20:37, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3507, decode.acc_seg: 85.5917, aux.loss_ce: 0.1670, aux.acc_seg: 83.5542, loss: 0.5177
2023-12-28 14:16:19,542 - mmseg - INFO - Iter [37150/160000]	lr: 4.607e-05, eta: 1 day, 3:19:55, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3467, decode.acc_seg: 86.1423, aux.loss_ce: 0.1671, aux.acc_seg: 84.0560, loss: 0.5138
2023-12-28 14:16:59,729 - mmseg - INFO - Iter [37200/160000]	lr: 4.605e-05, eta: 1 day, 3:19:15, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3803, decode.acc_seg: 85.2495, aux.loss_ce: 0.1767, aux.acc_seg: 83.7570, loss: 0.5570
2023-12-28 14:17:37,973 - mmseg - INFO - Iter [37250/160000]	lr: 4.603e-05, eta: 1 day, 3:18:29, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3583, decode.acc_seg: 85.5811, aux.loss_ce: 0.1709, aux.acc_seg: 83.6242, loss: 0.5292
2023-12-28 14:18:17,889 - mmseg - INFO - Iter [37300/160000]	lr: 4.601e-05, eta: 1 day, 3:17:49, time: 0.798, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3877, decode.acc_seg: 84.9877, aux.loss_ce: 0.1814, aux.acc_seg: 83.0864, loss: 0.5691
2023-12-28 14:18:57,558 - mmseg - INFO - Iter [37350/160000]	lr: 4.599e-05, eta: 1 day, 3:17:07, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3493, decode.acc_seg: 86.1172, aux.loss_ce: 0.1711, aux.acc_seg: 83.6370, loss: 0.5204
2023-12-28 14:19:39,451 - mmseg - INFO - Iter [37400/160000]	lr: 4.598e-05, eta: 1 day, 3:16:33, time: 0.837, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3635, decode.acc_seg: 85.4091, aux.loss_ce: 0.1731, aux.acc_seg: 83.3777, loss: 0.5366
2023-12-28 14:20:20,763 - mmseg - INFO - Iter [37450/160000]	lr: 4.596e-05, eta: 1 day, 3:15:57, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3580, decode.acc_seg: 86.1245, aux.loss_ce: 0.1696, aux.acc_seg: 84.2153, loss: 0.5276
2023-12-28 14:21:00,047 - mmseg - INFO - Iter [37500/160000]	lr: 4.594e-05, eta: 1 day, 3:15:15, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3808, decode.acc_seg: 85.0820, aux.loss_ce: 0.1755, aux.acc_seg: 83.0847, loss: 0.5563
2023-12-28 14:21:38,744 - mmseg - INFO - Iter [37550/160000]	lr: 4.592e-05, eta: 1 day, 3:14:31, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3553, decode.acc_seg: 85.2382, aux.loss_ce: 0.1705, aux.acc_seg: 83.3066, loss: 0.5258
2023-12-28 14:22:16,061 - mmseg - INFO - Iter [37600/160000]	lr: 4.590e-05, eta: 1 day, 3:13:42, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3953, decode.acc_seg: 84.2714, aux.loss_ce: 0.1927, aux.acc_seg: 81.9242, loss: 0.5880
2023-12-28 14:22:56,394 - mmseg - INFO - Iter [37650/160000]	lr: 4.588e-05, eta: 1 day, 3:13:03, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3837, decode.acc_seg: 85.1185, aux.loss_ce: 0.1808, aux.acc_seg: 82.9474, loss: 0.5645
2023-12-28 14:23:36,709 - mmseg - INFO - Iter [37700/160000]	lr: 4.586e-05, eta: 1 day, 3:12:23, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3868, decode.acc_seg: 84.4977, aux.loss_ce: 0.1848, aux.acc_seg: 82.3868, loss: 0.5716
2023-12-28 14:24:15,092 - mmseg - INFO - Iter [37750/160000]	lr: 4.584e-05, eta: 1 day, 3:11:38, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3750, decode.acc_seg: 85.0358, aux.loss_ce: 0.1776, aux.acc_seg: 83.0198, loss: 0.5526
2023-12-28 14:24:53,946 - mmseg - INFO - Iter [37800/160000]	lr: 4.583e-05, eta: 1 day, 3:10:54, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3804, decode.acc_seg: 84.9842, aux.loss_ce: 0.1788, aux.acc_seg: 82.9337, loss: 0.5591
2023-12-28 14:25:32,422 - mmseg - INFO - Iter [37850/160000]	lr: 4.581e-05, eta: 1 day, 3:10:09, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3768, decode.acc_seg: 85.0840, aux.loss_ce: 0.1771, aux.acc_seg: 83.2297, loss: 0.5539
2023-12-28 14:26:13,751 - mmseg - INFO - Iter [37900/160000]	lr: 4.579e-05, eta: 1 day, 3:09:33, time: 0.826, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3661, decode.acc_seg: 85.9396, aux.loss_ce: 0.1774, aux.acc_seg: 83.5574, loss: 0.5435
2023-12-28 14:26:52,936 - mmseg - INFO - Iter [37950/160000]	lr: 4.577e-05, eta: 1 day, 3:08:50, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3602, decode.acc_seg: 85.9500, aux.loss_ce: 0.1718, aux.acc_seg: 83.8525, loss: 0.5320
2023-12-28 14:27:31,295 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 14:27:31,296 - mmseg - INFO - Iter [38000/160000]	lr: 4.575e-05, eta: 1 day, 3:08:05, time: 0.769, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3612, decode.acc_seg: 85.5480, aux.loss_ce: 0.1743, aux.acc_seg: 83.0088, loss: 0.5355
2023-12-28 14:28:11,234 - mmseg - INFO - Iter [38050/160000]	lr: 4.573e-05, eta: 1 day, 3:07:24, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3571, decode.acc_seg: 86.0867, aux.loss_ce: 0.1758, aux.acc_seg: 83.7059, loss: 0.5328
2023-12-28 14:28:50,755 - mmseg - INFO - Iter [38100/160000]	lr: 4.571e-05, eta: 1 day, 3:06:43, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3641, decode.acc_seg: 85.8324, aux.loss_ce: 0.1710, aux.acc_seg: 83.9305, loss: 0.5350
2023-12-28 14:29:31,523 - mmseg - INFO - Iter [38150/160000]	lr: 4.569e-05, eta: 1 day, 3:06:05, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3661, decode.acc_seg: 85.1004, aux.loss_ce: 0.1732, aux.acc_seg: 83.1638, loss: 0.5393
2023-12-28 14:30:11,723 - mmseg - INFO - Iter [38200/160000]	lr: 4.568e-05, eta: 1 day, 3:05:26, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3565, decode.acc_seg: 85.6614, aux.loss_ce: 0.1692, aux.acc_seg: 83.7154, loss: 0.5256
2023-12-28 14:30:48,763 - mmseg - INFO - Iter [38250/160000]	lr: 4.566e-05, eta: 1 day, 3:04:36, time: 0.742, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3764, decode.acc_seg: 85.0372, aux.loss_ce: 0.1827, aux.acc_seg: 82.5751, loss: 0.5592
2023-12-28 14:31:26,126 - mmseg - INFO - Iter [38300/160000]	lr: 4.564e-05, eta: 1 day, 3:03:48, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3721, decode.acc_seg: 85.4495, aux.loss_ce: 0.1816, aux.acc_seg: 82.9878, loss: 0.5537
2023-12-28 14:32:05,050 - mmseg - INFO - Iter [38350/160000]	lr: 4.562e-05, eta: 1 day, 3:03:04, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3481, decode.acc_seg: 85.7944, aux.loss_ce: 0.1694, aux.acc_seg: 83.5991, loss: 0.5175
2023-12-28 14:32:47,289 - mmseg - INFO - Iter [38400/160000]	lr: 4.560e-05, eta: 1 day, 3:02:31, time: 0.845, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3687, decode.acc_seg: 85.4398, aux.loss_ce: 0.1757, aux.acc_seg: 83.4446, loss: 0.5444
2023-12-28 14:33:28,694 - mmseg - INFO - Iter [38450/160000]	lr: 4.558e-05, eta: 1 day, 3:01:55, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3708, decode.acc_seg: 85.1348, aux.loss_ce: 0.1771, aux.acc_seg: 83.1743, loss: 0.5479
2023-12-28 14:34:06,518 - mmseg - INFO - Iter [38500/160000]	lr: 4.556e-05, eta: 1 day, 3:01:08, time: 0.756, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3635, decode.acc_seg: 85.4018, aux.loss_ce: 0.1755, aux.acc_seg: 83.1566, loss: 0.5390
2023-12-28 14:34:46,787 - mmseg - INFO - Iter [38550/160000]	lr: 4.554e-05, eta: 1 day, 3:00:29, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3605, decode.acc_seg: 85.7065, aux.loss_ce: 0.1705, aux.acc_seg: 83.8776, loss: 0.5310
2023-12-28 14:35:23,500 - mmseg - INFO - Iter [38600/160000]	lr: 4.553e-05, eta: 1 day, 2:59:39, time: 0.734, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3617, decode.acc_seg: 85.5481, aux.loss_ce: 0.1723, aux.acc_seg: 83.7405, loss: 0.5340
2023-12-28 14:36:01,750 - mmseg - INFO - Iter [38650/160000]	lr: 4.551e-05, eta: 1 day, 2:58:53, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3504, decode.acc_seg: 86.4413, aux.loss_ce: 0.1676, aux.acc_seg: 84.6121, loss: 0.5180
2023-12-28 14:36:40,528 - mmseg - INFO - Iter [38700/160000]	lr: 4.549e-05, eta: 1 day, 2:58:09, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3464, decode.acc_seg: 86.2414, aux.loss_ce: 0.1674, aux.acc_seg: 84.0368, loss: 0.5137
2023-12-28 14:37:20,502 - mmseg - INFO - Iter [38750/160000]	lr: 4.547e-05, eta: 1 day, 2:57:29, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3553, decode.acc_seg: 86.1918, aux.loss_ce: 0.1698, aux.acc_seg: 84.1706, loss: 0.5251
2023-12-28 14:38:00,812 - mmseg - INFO - Iter [38800/160000]	lr: 4.545e-05, eta: 1 day, 2:56:50, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3716, decode.acc_seg: 85.2194, aux.loss_ce: 0.1795, aux.acc_seg: 82.8291, loss: 0.5511
2023-12-28 14:38:43,850 - mmseg - INFO - Iter [38850/160000]	lr: 4.543e-05, eta: 1 day, 2:56:19, time: 0.861, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3574, decode.acc_seg: 85.2915, aux.loss_ce: 0.1687, aux.acc_seg: 83.7528, loss: 0.5261
2023-12-28 14:39:24,853 - mmseg - INFO - Iter [38900/160000]	lr: 4.541e-05, eta: 1 day, 2:55:42, time: 0.820, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3692, decode.acc_seg: 85.0640, aux.loss_ce: 0.1757, aux.acc_seg: 83.0078, loss: 0.5449
2023-12-28 14:40:05,262 - mmseg - INFO - Iter [38950/160000]	lr: 4.539e-05, eta: 1 day, 2:55:03, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3483, decode.acc_seg: 86.1570, aux.loss_ce: 0.1663, aux.acc_seg: 84.3395, loss: 0.5146
2023-12-28 14:40:46,724 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 14:40:46,724 - mmseg - INFO - Iter [39000/160000]	lr: 4.538e-05, eta: 1 day, 2:54:28, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3656, decode.acc_seg: 85.5847, aux.loss_ce: 0.1702, aux.acc_seg: 83.9403, loss: 0.5357
2023-12-28 14:41:24,895 - mmseg - INFO - Iter [39050/160000]	lr: 4.536e-05, eta: 1 day, 2:53:42, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3548, decode.acc_seg: 85.6974, aux.loss_ce: 0.1689, aux.acc_seg: 83.3959, loss: 0.5238
2023-12-28 14:42:03,766 - mmseg - INFO - Iter [39100/160000]	lr: 4.534e-05, eta: 1 day, 2:52:58, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3878, decode.acc_seg: 84.8460, aux.loss_ce: 0.1844, aux.acc_seg: 82.9413, loss: 0.5722
2023-12-28 14:42:42,137 - mmseg - INFO - Iter [39150/160000]	lr: 4.532e-05, eta: 1 day, 2:52:13, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3741, decode.acc_seg: 84.7714, aux.loss_ce: 0.1746, aux.acc_seg: 82.9344, loss: 0.5487
2023-12-28 14:43:22,835 - mmseg - INFO - Iter [39200/160000]	lr: 4.530e-05, eta: 1 day, 2:51:35, time: 0.814, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3332, decode.acc_seg: 86.8889, aux.loss_ce: 0.1594, aux.acc_seg: 84.8864, loss: 0.4926
2023-12-28 14:43:59,876 - mmseg - INFO - Iter [39250/160000]	lr: 4.528e-05, eta: 1 day, 2:50:46, time: 0.741, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3495, decode.acc_seg: 86.3544, aux.loss_ce: 0.1705, aux.acc_seg: 83.8867, loss: 0.5199
2023-12-28 14:44:38,435 - mmseg - INFO - Iter [39300/160000]	lr: 4.526e-05, eta: 1 day, 2:50:02, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3605, decode.acc_seg: 85.7801, aux.loss_ce: 0.1685, aux.acc_seg: 83.4783, loss: 0.5290
2023-12-28 14:45:17,342 - mmseg - INFO - Iter [39350/160000]	lr: 4.524e-05, eta: 1 day, 2:49:18, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3833, decode.acc_seg: 84.7489, aux.loss_ce: 0.1800, aux.acc_seg: 82.5793, loss: 0.5633
2023-12-28 14:45:58,238 - mmseg - INFO - Iter [39400/160000]	lr: 4.523e-05, eta: 1 day, 2:48:41, time: 0.818, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3716, decode.acc_seg: 85.0667, aux.loss_ce: 0.1750, aux.acc_seg: 83.3464, loss: 0.5466
2023-12-28 14:46:37,813 - mmseg - INFO - Iter [39450/160000]	lr: 4.521e-05, eta: 1 day, 2:47:59, time: 0.791, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3812, decode.acc_seg: 85.2031, aux.loss_ce: 0.1830, aux.acc_seg: 82.6935, loss: 0.5642
2023-12-28 14:47:18,381 - mmseg - INFO - Iter [39500/160000]	lr: 4.519e-05, eta: 1 day, 2:47:21, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3607, decode.acc_seg: 85.7302, aux.loss_ce: 0.1720, aux.acc_seg: 83.3578, loss: 0.5328
2023-12-28 14:47:59,493 - mmseg - INFO - Iter [39550/160000]	lr: 4.517e-05, eta: 1 day, 2:46:44, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3510, decode.acc_seg: 85.8713, aux.loss_ce: 0.1719, aux.acc_seg: 83.3005, loss: 0.5229
2023-12-28 14:48:39,262 - mmseg - INFO - Iter [39600/160000]	lr: 4.515e-05, eta: 1 day, 2:46:04, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3531, decode.acc_seg: 85.6106, aux.loss_ce: 0.1715, aux.acc_seg: 83.3966, loss: 0.5246
2023-12-28 14:49:18,100 - mmseg - INFO - Iter [39650/160000]	lr: 4.513e-05, eta: 1 day, 2:45:20, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3667, decode.acc_seg: 85.3336, aux.loss_ce: 0.1769, aux.acc_seg: 82.9980, loss: 0.5436
2023-12-28 14:49:55,462 - mmseg - INFO - Iter [39700/160000]	lr: 4.511e-05, eta: 1 day, 2:44:32, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3688, decode.acc_seg: 85.3772, aux.loss_ce: 0.1781, aux.acc_seg: 83.4668, loss: 0.5468
2023-12-28 14:50:35,896 - mmseg - INFO - Iter [39750/160000]	lr: 4.509e-05, eta: 1 day, 2:43:53, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3736, decode.acc_seg: 85.0728, aux.loss_ce: 0.1792, aux.acc_seg: 83.0538, loss: 0.5527
2023-12-28 14:51:14,152 - mmseg - INFO - Iter [39800/160000]	lr: 4.508e-05, eta: 1 day, 2:43:08, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3618, decode.acc_seg: 85.8611, aux.loss_ce: 0.1748, aux.acc_seg: 83.5725, loss: 0.5366
2023-12-28 14:51:53,981 - mmseg - INFO - Iter [39850/160000]	lr: 4.506e-05, eta: 1 day, 2:42:27, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3674, decode.acc_seg: 85.7057, aux.loss_ce: 0.1731, aux.acc_seg: 83.9758, loss: 0.5404
2023-12-28 14:52:34,255 - mmseg - INFO - Iter [39900/160000]	lr: 4.504e-05, eta: 1 day, 2:41:48, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3614, decode.acc_seg: 86.3056, aux.loss_ce: 0.1720, aux.acc_seg: 84.3378, loss: 0.5334
2023-12-28 14:53:14,454 - mmseg - INFO - Iter [39950/160000]	lr: 4.502e-05, eta: 1 day, 2:41:09, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3864, decode.acc_seg: 84.5479, aux.loss_ce: 0.1813, aux.acc_seg: 82.7130, loss: 0.5677
2023-12-28 14:53:54,713 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 14:53:54,714 - mmseg - INFO - Iter [40000/160000]	lr: 4.500e-05, eta: 1 day, 2:40:30, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3609, decode.acc_seg: 85.9496, aux.loss_ce: 0.1768, aux.acc_seg: 83.7395, loss: 0.5377
2023-12-28 14:54:33,592 - mmseg - INFO - Iter [40050/160000]	lr: 4.498e-05, eta: 1 day, 2:39:46, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3739, decode.acc_seg: 85.1370, aux.loss_ce: 0.1765, aux.acc_seg: 83.2021, loss: 0.5504
2023-12-28 14:55:13,515 - mmseg - INFO - Iter [40100/160000]	lr: 4.496e-05, eta: 1 day, 2:39:06, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3560, decode.acc_seg: 85.7607, aux.loss_ce: 0.1725, aux.acc_seg: 83.4390, loss: 0.5285
2023-12-28 14:55:53,370 - mmseg - INFO - Iter [40150/160000]	lr: 4.494e-05, eta: 1 day, 2:38:25, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3583, decode.acc_seg: 85.8173, aux.loss_ce: 0.1735, aux.acc_seg: 83.6010, loss: 0.5318
2023-12-28 14:56:33,480 - mmseg - INFO - Iter [40200/160000]	lr: 4.493e-05, eta: 1 day, 2:37:46, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3713, decode.acc_seg: 85.8186, aux.loss_ce: 0.1793, aux.acc_seg: 83.2896, loss: 0.5506
2023-12-28 14:57:13,426 - mmseg - INFO - Iter [40250/160000]	lr: 4.491e-05, eta: 1 day, 2:37:05, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3615, decode.acc_seg: 85.6757, aux.loss_ce: 0.1744, aux.acc_seg: 83.4955, loss: 0.5359
2023-12-28 14:57:51,523 - mmseg - INFO - Iter [40300/160000]	lr: 4.489e-05, eta: 1 day, 2:36:20, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3702, decode.acc_seg: 84.9695, aux.loss_ce: 0.1762, aux.acc_seg: 82.8102, loss: 0.5463
2023-12-28 14:58:31,630 - mmseg - INFO - Iter [40350/160000]	lr: 4.487e-05, eta: 1 day, 2:35:40, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3998, decode.acc_seg: 84.6045, aux.loss_ce: 0.1891, aux.acc_seg: 82.4918, loss: 0.5888
2023-12-28 14:59:10,352 - mmseg - INFO - Iter [40400/160000]	lr: 4.485e-05, eta: 1 day, 2:34:56, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3845, decode.acc_seg: 85.0844, aux.loss_ce: 0.1839, aux.acc_seg: 82.6877, loss: 0.5685
2023-12-28 14:59:50,750 - mmseg - INFO - Iter [40450/160000]	lr: 4.483e-05, eta: 1 day, 2:34:17, time: 0.809, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3635, decode.acc_seg: 85.5885, aux.loss_ce: 0.1724, aux.acc_seg: 83.6314, loss: 0.5359
2023-12-28 15:00:30,467 - mmseg - INFO - Iter [40500/160000]	lr: 4.481e-05, eta: 1 day, 2:33:36, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3650, decode.acc_seg: 85.9293, aux.loss_ce: 0.1751, aux.acc_seg: 83.5985, loss: 0.5401
2023-12-28 15:01:08,714 - mmseg - INFO - Iter [40550/160000]	lr: 4.479e-05, eta: 1 day, 2:32:51, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3398, decode.acc_seg: 86.3666, aux.loss_ce: 0.1670, aux.acc_seg: 83.8859, loss: 0.5068
2023-12-28 15:01:47,052 - mmseg - INFO - Iter [40600/160000]	lr: 4.478e-05, eta: 1 day, 2:32:06, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3267, decode.acc_seg: 87.3010, aux.loss_ce: 0.1615, aux.acc_seg: 84.7820, loss: 0.4882
2023-12-28 15:02:27,070 - mmseg - INFO - Iter [40650/160000]	lr: 4.476e-05, eta: 1 day, 2:31:26, time: 0.800, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3402, decode.acc_seg: 86.5069, aux.loss_ce: 0.1664, aux.acc_seg: 84.3803, loss: 0.5066
2023-12-28 15:03:07,097 - mmseg - INFO - Iter [40700/160000]	lr: 4.474e-05, eta: 1 day, 2:30:46, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3482, decode.acc_seg: 86.1142, aux.loss_ce: 0.1666, aux.acc_seg: 83.8425, loss: 0.5148
2023-12-28 15:03:43,892 - mmseg - INFO - Iter [40750/160000]	lr: 4.472e-05, eta: 1 day, 2:29:57, time: 0.737, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3353, decode.acc_seg: 86.3007, aux.loss_ce: 0.1636, aux.acc_seg: 83.9590, loss: 0.4989
2023-12-28 15:04:24,085 - mmseg - INFO - Iter [40800/160000]	lr: 4.470e-05, eta: 1 day, 2:29:18, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3645, decode.acc_seg: 85.8122, aux.loss_ce: 0.1762, aux.acc_seg: 83.3920, loss: 0.5407
2023-12-28 15:05:04,186 - mmseg - INFO - Iter [40850/160000]	lr: 4.468e-05, eta: 1 day, 2:28:38, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3561, decode.acc_seg: 86.4604, aux.loss_ce: 0.1700, aux.acc_seg: 84.3235, loss: 0.5260
2023-12-28 15:05:43,211 - mmseg - INFO - Iter [40900/160000]	lr: 4.466e-05, eta: 1 day, 2:27:55, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3513, decode.acc_seg: 85.9364, aux.loss_ce: 0.1669, aux.acc_seg: 84.3311, loss: 0.5183
2023-12-28 15:06:21,380 - mmseg - INFO - Iter [40950/160000]	lr: 4.464e-05, eta: 1 day, 2:27:10, time: 0.764, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3452, decode.acc_seg: 86.0387, aux.loss_ce: 0.1649, aux.acc_seg: 83.7921, loss: 0.5100
2023-12-28 15:07:00,386 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 15:07:00,387 - mmseg - INFO - Iter [41000/160000]	lr: 4.463e-05, eta: 1 day, 2:26:27, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3620, decode.acc_seg: 85.9243, aux.loss_ce: 0.1740, aux.acc_seg: 83.8305, loss: 0.5360
2023-12-28 15:07:40,195 - mmseg - INFO - Iter [41050/160000]	lr: 4.461e-05, eta: 1 day, 2:25:46, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3353, decode.acc_seg: 86.5547, aux.loss_ce: 0.1634, aux.acc_seg: 84.2785, loss: 0.4987
2023-12-28 15:08:19,027 - mmseg - INFO - Iter [41100/160000]	lr: 4.459e-05, eta: 1 day, 2:25:03, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3717, decode.acc_seg: 85.1199, aux.loss_ce: 0.1784, aux.acc_seg: 83.2206, loss: 0.5501
2023-12-28 15:08:59,360 - mmseg - INFO - Iter [41150/160000]	lr: 4.457e-05, eta: 1 day, 2:24:24, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3616, decode.acc_seg: 85.5680, aux.loss_ce: 0.1742, aux.acc_seg: 83.3380, loss: 0.5359
2023-12-28 15:09:38,434 - mmseg - INFO - Iter [41200/160000]	lr: 4.455e-05, eta: 1 day, 2:23:41, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3697, decode.acc_seg: 85.6645, aux.loss_ce: 0.1709, aux.acc_seg: 83.7845, loss: 0.5406
2023-12-28 15:10:16,275 - mmseg - INFO - Iter [41250/160000]	lr: 4.453e-05, eta: 1 day, 2:22:55, time: 0.757, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3456, decode.acc_seg: 86.3736, aux.loss_ce: 0.1671, aux.acc_seg: 84.4731, loss: 0.5127
2023-12-28 15:10:54,395 - mmseg - INFO - Iter [41300/160000]	lr: 4.451e-05, eta: 1 day, 2:22:10, time: 0.762, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3574, decode.acc_seg: 85.6509, aux.loss_ce: 0.1720, aux.acc_seg: 83.1972, loss: 0.5294
2023-12-28 15:11:34,244 - mmseg - INFO - Iter [41350/160000]	lr: 4.449e-05, eta: 1 day, 2:21:29, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3397, decode.acc_seg: 86.3194, aux.loss_ce: 0.1646, aux.acc_seg: 84.2494, loss: 0.5044
2023-12-28 15:12:14,362 - mmseg - INFO - Iter [41400/160000]	lr: 4.448e-05, eta: 1 day, 2:20:50, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3424, decode.acc_seg: 86.2730, aux.loss_ce: 0.1660, aux.acc_seg: 84.2115, loss: 0.5085
2023-12-28 15:12:54,999 - mmseg - INFO - Iter [41450/160000]	lr: 4.446e-05, eta: 1 day, 2:20:12, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3489, decode.acc_seg: 85.7826, aux.loss_ce: 0.1699, aux.acc_seg: 83.4397, loss: 0.5188
2023-12-28 15:13:33,989 - mmseg - INFO - Iter [41500/160000]	lr: 4.444e-05, eta: 1 day, 2:19:29, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3609, decode.acc_seg: 85.8461, aux.loss_ce: 0.1709, aux.acc_seg: 83.6120, loss: 0.5318
2023-12-28 15:14:11,021 - mmseg - INFO - Iter [41550/160000]	lr: 4.442e-05, eta: 1 day, 2:18:40, time: 0.741, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3362, decode.acc_seg: 86.8466, aux.loss_ce: 0.1592, aux.acc_seg: 84.8817, loss: 0.4954
2023-12-28 15:14:48,360 - mmseg - INFO - Iter [41600/160000]	lr: 4.440e-05, eta: 1 day, 2:17:53, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3596, decode.acc_seg: 86.0640, aux.loss_ce: 0.1698, aux.acc_seg: 84.1480, loss: 0.5294
2023-12-28 15:15:28,465 - mmseg - INFO - Iter [41650/160000]	lr: 4.438e-05, eta: 1 day, 2:17:13, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3573, decode.acc_seg: 86.0110, aux.loss_ce: 0.1695, aux.acc_seg: 84.1894, loss: 0.5268
2023-12-28 15:16:09,540 - mmseg - INFO - Iter [41700/160000]	lr: 4.436e-05, eta: 1 day, 2:16:36, time: 0.822, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3486, decode.acc_seg: 86.3853, aux.loss_ce: 0.1682, aux.acc_seg: 84.0993, loss: 0.5168
2023-12-28 15:16:48,283 - mmseg - INFO - Iter [41750/160000]	lr: 4.434e-05, eta: 1 day, 2:15:53, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3426, decode.acc_seg: 86.5135, aux.loss_ce: 0.1679, aux.acc_seg: 84.2261, loss: 0.5105
2023-12-28 15:17:27,816 - mmseg - INFO - Iter [41800/160000]	lr: 4.433e-05, eta: 1 day, 2:15:12, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3484, decode.acc_seg: 86.1735, aux.loss_ce: 0.1654, aux.acc_seg: 84.1765, loss: 0.5138
2023-12-28 15:18:06,134 - mmseg - INFO - Iter [41850/160000]	lr: 4.431e-05, eta: 1 day, 2:14:27, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3493, decode.acc_seg: 85.9910, aux.loss_ce: 0.1710, aux.acc_seg: 83.5735, loss: 0.5203
2023-12-28 15:18:45,201 - mmseg - INFO - Iter [41900/160000]	lr: 4.429e-05, eta: 1 day, 2:13:44, time: 0.782, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3438, decode.acc_seg: 86.4985, aux.loss_ce: 0.1673, aux.acc_seg: 84.3180, loss: 0.5110
2023-12-28 15:19:25,932 - mmseg - INFO - Iter [41950/160000]	lr: 4.427e-05, eta: 1 day, 2:13:07, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3566, decode.acc_seg: 85.7294, aux.loss_ce: 0.1731, aux.acc_seg: 83.4692, loss: 0.5297
2023-12-28 15:20:05,726 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 15:20:05,727 - mmseg - INFO - Iter [42000/160000]	lr: 4.425e-05, eta: 1 day, 2:12:26, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3379, decode.acc_seg: 86.3853, aux.loss_ce: 0.1661, aux.acc_seg: 84.0292, loss: 0.5040
2023-12-28 15:20:42,729 - mmseg - INFO - Iter [42050/160000]	lr: 4.423e-05, eta: 1 day, 2:11:38, time: 0.741, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3625, decode.acc_seg: 86.1224, aux.loss_ce: 0.1678, aux.acc_seg: 84.4007, loss: 0.5304
2023-12-28 15:21:21,591 - mmseg - INFO - Iter [42100/160000]	lr: 4.421e-05, eta: 1 day, 2:10:55, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3325, decode.acc_seg: 86.4390, aux.loss_ce: 0.1597, aux.acc_seg: 84.3977, loss: 0.4921
2023-12-28 15:21:58,206 - mmseg - INFO - Iter [42150/160000]	lr: 4.419e-05, eta: 1 day, 2:10:05, time: 0.732, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3367, decode.acc_seg: 86.1449, aux.loss_ce: 0.1649, aux.acc_seg: 83.9771, loss: 0.5016
2023-12-28 15:22:35,961 - mmseg - INFO - Iter [42200/160000]	lr: 4.418e-05, eta: 1 day, 2:09:19, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3544, decode.acc_seg: 85.8288, aux.loss_ce: 0.1685, aux.acc_seg: 84.0650, loss: 0.5229
2023-12-28 15:23:15,263 - mmseg - INFO - Iter [42250/160000]	lr: 4.416e-05, eta: 1 day, 2:08:37, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3484, decode.acc_seg: 86.2248, aux.loss_ce: 0.1666, aux.acc_seg: 84.3184, loss: 0.5150
2023-12-28 15:23:55,321 - mmseg - INFO - Iter [42300/160000]	lr: 4.414e-05, eta: 1 day, 2:07:58, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3699, decode.acc_seg: 85.7238, aux.loss_ce: 0.1818, aux.acc_seg: 82.9537, loss: 0.5517
2023-12-28 15:24:35,986 - mmseg - INFO - Iter [42350/160000]	lr: 4.412e-05, eta: 1 day, 2:07:20, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3580, decode.acc_seg: 85.5436, aux.loss_ce: 0.1737, aux.acc_seg: 83.3295, loss: 0.5317
2023-12-28 15:25:16,332 - mmseg - INFO - Iter [42400/160000]	lr: 4.410e-05, eta: 1 day, 2:06:41, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3632, decode.acc_seg: 85.8374, aux.loss_ce: 0.1713, aux.acc_seg: 83.8330, loss: 0.5345
2023-12-28 15:25:56,602 - mmseg - INFO - Iter [42450/160000]	lr: 4.408e-05, eta: 1 day, 2:06:01, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3522, decode.acc_seg: 86.1717, aux.loss_ce: 0.1721, aux.acc_seg: 83.9443, loss: 0.5243
2023-12-28 15:26:37,510 - mmseg - INFO - Iter [42500/160000]	lr: 4.406e-05, eta: 1 day, 2:05:24, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3327, decode.acc_seg: 86.9076, aux.loss_ce: 0.1637, aux.acc_seg: 84.5231, loss: 0.4963
2023-12-28 15:27:16,563 - mmseg - INFO - Iter [42550/160000]	lr: 4.404e-05, eta: 1 day, 2:04:42, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3496, decode.acc_seg: 86.2075, aux.loss_ce: 0.1713, aux.acc_seg: 83.9346, loss: 0.5208
2023-12-28 15:27:55,800 - mmseg - INFO - Iter [42600/160000]	lr: 4.403e-05, eta: 1 day, 2:04:00, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3466, decode.acc_seg: 86.0440, aux.loss_ce: 0.1681, aux.acc_seg: 84.0341, loss: 0.5147
2023-12-28 15:28:35,683 - mmseg - INFO - Iter [42650/160000]	lr: 4.401e-05, eta: 1 day, 2:03:19, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3373, decode.acc_seg: 86.4851, aux.loss_ce: 0.1596, aux.acc_seg: 84.5320, loss: 0.4968
2023-12-28 15:29:12,717 - mmseg - INFO - Iter [42700/160000]	lr: 4.399e-05, eta: 1 day, 2:02:32, time: 0.741, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3371, decode.acc_seg: 86.6634, aux.loss_ce: 0.1669, aux.acc_seg: 83.7555, loss: 0.5040
2023-12-28 15:29:50,689 - mmseg - INFO - Iter [42750/160000]	lr: 4.397e-05, eta: 1 day, 2:01:46, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3471, decode.acc_seg: 86.4719, aux.loss_ce: 0.1675, aux.acc_seg: 83.9542, loss: 0.5145
2023-12-28 15:30:30,748 - mmseg - INFO - Iter [42800/160000]	lr: 4.395e-05, eta: 1 day, 2:01:06, time: 0.800, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3499, decode.acc_seg: 85.7889, aux.loss_ce: 0.1699, aux.acc_seg: 83.4056, loss: 0.5198
2023-12-28 15:31:11,988 - mmseg - INFO - Iter [42850/160000]	lr: 4.393e-05, eta: 1 day, 2:00:30, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3538, decode.acc_seg: 85.5400, aux.loss_ce: 0.1706, aux.acc_seg: 83.1806, loss: 0.5245
2023-12-28 15:31:52,321 - mmseg - INFO - Iter [42900/160000]	lr: 4.391e-05, eta: 1 day, 1:59:51, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3956, decode.acc_seg: 84.5503, aux.loss_ce: 0.1835, aux.acc_seg: 82.7951, loss: 0.5791
2023-12-28 15:32:33,571 - mmseg - INFO - Iter [42950/160000]	lr: 4.389e-05, eta: 1 day, 1:59:14, time: 0.824, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3466, decode.acc_seg: 86.2274, aux.loss_ce: 0.1679, aux.acc_seg: 83.9751, loss: 0.5145
2023-12-28 15:33:12,849 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 15:33:12,850 - mmseg - INFO - Iter [43000/160000]	lr: 4.388e-05, eta: 1 day, 1:58:33, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3385, decode.acc_seg: 86.6528, aux.loss_ce: 0.1641, aux.acc_seg: 84.4071, loss: 0.5025
2023-12-28 15:33:53,077 - mmseg - INFO - Iter [43050/160000]	lr: 4.386e-05, eta: 1 day, 1:57:54, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3451, decode.acc_seg: 86.3763, aux.loss_ce: 0.1681, aux.acc_seg: 83.8201, loss: 0.5132
2023-12-28 15:34:33,456 - mmseg - INFO - Iter [43100/160000]	lr: 4.384e-05, eta: 1 day, 1:57:15, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3310, decode.acc_seg: 86.5146, aux.loss_ce: 0.1642, aux.acc_seg: 83.7082, loss: 0.4952
2023-12-28 15:35:13,923 - mmseg - INFO - Iter [43150/160000]	lr: 4.382e-05, eta: 1 day, 1:56:36, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3272, decode.acc_seg: 86.3219, aux.loss_ce: 0.1599, aux.acc_seg: 84.0975, loss: 0.4871
2023-12-28 15:35:54,513 - mmseg - INFO - Iter [43200/160000]	lr: 4.380e-05, eta: 1 day, 1:55:58, time: 0.810, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3232, decode.acc_seg: 86.6533, aux.loss_ce: 0.1552, aux.acc_seg: 84.7471, loss: 0.4784
2023-12-28 15:36:34,709 - mmseg - INFO - Iter [43250/160000]	lr: 4.378e-05, eta: 1 day, 1:55:18, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3576, decode.acc_seg: 85.5748, aux.loss_ce: 0.1723, aux.acc_seg: 83.2736, loss: 0.5299
2023-12-28 15:37:12,306 - mmseg - INFO - Iter [43300/160000]	lr: 4.376e-05, eta: 1 day, 1:54:32, time: 0.752, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3374, decode.acc_seg: 87.0116, aux.loss_ce: 0.1643, aux.acc_seg: 84.4755, loss: 0.5018
2023-12-28 15:37:52,462 - mmseg - INFO - Iter [43350/160000]	lr: 4.374e-05, eta: 1 day, 1:53:53, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3510, decode.acc_seg: 85.7754, aux.loss_ce: 0.1680, aux.acc_seg: 84.0109, loss: 0.5190
2023-12-28 15:38:31,003 - mmseg - INFO - Iter [43400/160000]	lr: 4.373e-05, eta: 1 day, 1:53:09, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3518, decode.acc_seg: 86.5455, aux.loss_ce: 0.1708, aux.acc_seg: 84.0560, loss: 0.5226
2023-12-28 15:39:09,060 - mmseg - INFO - Iter [43450/160000]	lr: 4.371e-05, eta: 1 day, 1:52:24, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3379, decode.acc_seg: 86.4279, aux.loss_ce: 0.1620, aux.acc_seg: 84.3880, loss: 0.4999
2023-12-28 15:39:49,205 - mmseg - INFO - Iter [43500/160000]	lr: 4.369e-05, eta: 1 day, 1:51:44, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3578, decode.acc_seg: 85.7590, aux.loss_ce: 0.1701, aux.acc_seg: 83.5753, loss: 0.5279
2023-12-28 15:40:29,489 - mmseg - INFO - Iter [43550/160000]	lr: 4.367e-05, eta: 1 day, 1:51:05, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3458, decode.acc_seg: 86.2627, aux.loss_ce: 0.1631, aux.acc_seg: 84.4641, loss: 0.5089
2023-12-28 15:41:10,055 - mmseg - INFO - Iter [43600/160000]	lr: 4.365e-05, eta: 1 day, 1:50:27, time: 0.811, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3523, decode.acc_seg: 86.3623, aux.loss_ce: 0.1667, aux.acc_seg: 84.3056, loss: 0.5190
2023-12-28 15:41:49,806 - mmseg - INFO - Iter [43650/160000]	lr: 4.363e-05, eta: 1 day, 1:49:46, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3382, decode.acc_seg: 86.3023, aux.loss_ce: 0.1628, aux.acc_seg: 84.3398, loss: 0.5010
2023-12-28 15:42:29,197 - mmseg - INFO - Iter [43700/160000]	lr: 4.361e-05, eta: 1 day, 1:49:05, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3787, decode.acc_seg: 85.3973, aux.loss_ce: 0.1829, aux.acc_seg: 83.1486, loss: 0.5616
2023-12-28 15:43:09,237 - mmseg - INFO - Iter [43750/160000]	lr: 4.359e-05, eta: 1 day, 1:48:25, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3488, decode.acc_seg: 85.9538, aux.loss_ce: 0.1664, aux.acc_seg: 83.9610, loss: 0.5152
2023-12-28 15:43:47,735 - mmseg - INFO - Iter [43800/160000]	lr: 4.358e-05, eta: 1 day, 1:47:41, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3537, decode.acc_seg: 86.0855, aux.loss_ce: 0.1675, aux.acc_seg: 84.0056, loss: 0.5212
2023-12-28 15:44:28,351 - mmseg - INFO - Iter [43850/160000]	lr: 4.356e-05, eta: 1 day, 1:47:03, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3592, decode.acc_seg: 86.0682, aux.loss_ce: 0.1728, aux.acc_seg: 84.0170, loss: 0.5320
2023-12-28 15:45:06,627 - mmseg - INFO - Iter [43900/160000]	lr: 4.354e-05, eta: 1 day, 1:46:19, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3645, decode.acc_seg: 85.3087, aux.loss_ce: 0.1747, aux.acc_seg: 83.1286, loss: 0.5391
2023-12-28 15:45:44,386 - mmseg - INFO - Iter [43950/160000]	lr: 4.352e-05, eta: 1 day, 1:45:33, time: 0.755, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3466, decode.acc_seg: 86.3860, aux.loss_ce: 0.1703, aux.acc_seg: 83.8555, loss: 0.5168
2023-12-28 15:46:23,995 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 15:46:23,995 - mmseg - INFO - Iter [44000/160000]	lr: 4.350e-05, eta: 1 day, 1:44:52, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3736, decode.acc_seg: 85.2689, aux.loss_ce: 0.1770, aux.acc_seg: 83.1453, loss: 0.5506
2023-12-28 15:47:03,588 - mmseg - INFO - Iter [44050/160000]	lr: 4.348e-05, eta: 1 day, 1:44:11, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3366, decode.acc_seg: 86.6318, aux.loss_ce: 0.1618, aux.acc_seg: 84.4026, loss: 0.4984
2023-12-28 15:47:42,747 - mmseg - INFO - Iter [44100/160000]	lr: 4.346e-05, eta: 1 day, 1:43:29, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3807, decode.acc_seg: 85.3801, aux.loss_ce: 0.1834, aux.acc_seg: 83.0174, loss: 0.5641
2023-12-28 15:48:22,085 - mmseg - INFO - Iter [44150/160000]	lr: 4.344e-05, eta: 1 day, 1:42:48, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3399, decode.acc_seg: 85.9555, aux.loss_ce: 0.1680, aux.acc_seg: 83.3198, loss: 0.5079
2023-12-28 15:49:00,102 - mmseg - INFO - Iter [44200/160000]	lr: 4.343e-05, eta: 1 day, 1:42:03, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3548, decode.acc_seg: 85.9916, aux.loss_ce: 0.1716, aux.acc_seg: 83.9807, loss: 0.5264
2023-12-28 15:49:42,072 - mmseg - INFO - Iter [44250/160000]	lr: 4.341e-05, eta: 1 day, 1:41:28, time: 0.838, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3330, decode.acc_seg: 86.4701, aux.loss_ce: 0.1619, aux.acc_seg: 84.4737, loss: 0.4950
2023-12-28 15:50:21,981 - mmseg - INFO - Iter [44300/160000]	lr: 4.339e-05, eta: 1 day, 1:40:48, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3349, decode.acc_seg: 86.2725, aux.loss_ce: 0.1629, aux.acc_seg: 84.0195, loss: 0.4979
2023-12-28 15:51:00,062 - mmseg - INFO - Iter [44350/160000]	lr: 4.337e-05, eta: 1 day, 1:40:03, time: 0.762, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3519, decode.acc_seg: 85.3318, aux.loss_ce: 0.1738, aux.acc_seg: 82.8574, loss: 0.5257
2023-12-28 15:51:37,549 - mmseg - INFO - Iter [44400/160000]	lr: 4.335e-05, eta: 1 day, 1:39:17, time: 0.750, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3316, decode.acc_seg: 86.8666, aux.loss_ce: 0.1642, aux.acc_seg: 84.6254, loss: 0.4958
2023-12-28 15:52:17,360 - mmseg - INFO - Iter [44450/160000]	lr: 4.333e-05, eta: 1 day, 1:38:36, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3590, decode.acc_seg: 86.3947, aux.loss_ce: 0.1720, aux.acc_seg: 84.1759, loss: 0.5310
2023-12-28 15:52:57,240 - mmseg - INFO - Iter [44500/160000]	lr: 4.331e-05, eta: 1 day, 1:37:56, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3196, decode.acc_seg: 87.3010, aux.loss_ce: 0.1575, aux.acc_seg: 84.8963, loss: 0.4771
2023-12-28 15:53:37,652 - mmseg - INFO - Iter [44550/160000]	lr: 4.329e-05, eta: 1 day, 1:37:17, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3497, decode.acc_seg: 86.2205, aux.loss_ce: 0.1710, aux.acc_seg: 83.8311, loss: 0.5208
2023-12-28 15:54:18,344 - mmseg - INFO - Iter [44600/160000]	lr: 4.328e-05, eta: 1 day, 1:36:39, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3242, decode.acc_seg: 87.3497, aux.loss_ce: 0.1577, aux.acc_seg: 84.8387, loss: 0.4819
2023-12-28 15:54:58,449 - mmseg - INFO - Iter [44650/160000]	lr: 4.326e-05, eta: 1 day, 1:36:00, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3341, decode.acc_seg: 86.9399, aux.loss_ce: 0.1624, aux.acc_seg: 84.9052, loss: 0.4964
2023-12-28 15:55:39,520 - mmseg - INFO - Iter [44700/160000]	lr: 4.324e-05, eta: 1 day, 1:35:23, time: 0.821, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3385, decode.acc_seg: 86.6858, aux.loss_ce: 0.1660, aux.acc_seg: 84.2483, loss: 0.5045
2023-12-28 15:56:17,954 - mmseg - INFO - Iter [44750/160000]	lr: 4.322e-05, eta: 1 day, 1:34:39, time: 0.770, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3374, decode.acc_seg: 86.3671, aux.loss_ce: 0.1634, aux.acc_seg: 84.3826, loss: 0.5008
2023-12-28 15:56:56,525 - mmseg - INFO - Iter [44800/160000]	lr: 4.320e-05, eta: 1 day, 1:33:55, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3508, decode.acc_seg: 86.4567, aux.loss_ce: 0.1666, aux.acc_seg: 84.2826, loss: 0.5173
2023-12-28 15:57:35,507 - mmseg - INFO - Iter [44850/160000]	lr: 4.318e-05, eta: 1 day, 1:33:13, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3429, decode.acc_seg: 86.0095, aux.loss_ce: 0.1643, aux.acc_seg: 84.0205, loss: 0.5072
2023-12-28 15:58:14,580 - mmseg - INFO - Iter [44900/160000]	lr: 4.316e-05, eta: 1 day, 1:32:31, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3358, decode.acc_seg: 86.3843, aux.loss_ce: 0.1580, aux.acc_seg: 84.6027, loss: 0.4939
2023-12-28 15:58:53,564 - mmseg - INFO - Iter [44950/160000]	lr: 4.314e-05, eta: 1 day, 1:31:49, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3486, decode.acc_seg: 86.5281, aux.loss_ce: 0.1663, aux.acc_seg: 84.3308, loss: 0.5149
2023-12-28 15:59:32,277 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 15:59:32,278 - mmseg - INFO - Iter [45000/160000]	lr: 4.313e-05, eta: 1 day, 1:31:05, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3320, decode.acc_seg: 86.3766, aux.loss_ce: 0.1599, aux.acc_seg: 84.2283, loss: 0.4919
2023-12-28 16:00:11,264 - mmseg - INFO - Iter [45050/160000]	lr: 4.311e-05, eta: 1 day, 1:30:23, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3400, decode.acc_seg: 86.9758, aux.loss_ce: 0.1604, aux.acc_seg: 85.2056, loss: 0.5004
2023-12-28 16:00:49,693 - mmseg - INFO - Iter [45100/160000]	lr: 4.309e-05, eta: 1 day, 1:29:39, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3845, decode.acc_seg: 84.7103, aux.loss_ce: 0.1832, aux.acc_seg: 82.3926, loss: 0.5676
2023-12-28 16:01:30,597 - mmseg - INFO - Iter [45150/160000]	lr: 4.307e-05, eta: 1 day, 1:29:02, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3576, decode.acc_seg: 86.1783, aux.loss_ce: 0.1651, aux.acc_seg: 84.6543, loss: 0.5228
2023-12-28 16:02:09,513 - mmseg - INFO - Iter [45200/160000]	lr: 4.305e-05, eta: 1 day, 1:28:19, time: 0.780, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3347, decode.acc_seg: 86.4515, aux.loss_ce: 0.1625, aux.acc_seg: 84.3778, loss: 0.4971
2023-12-28 16:02:49,684 - mmseg - INFO - Iter [45250/160000]	lr: 4.303e-05, eta: 1 day, 1:27:40, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3472, decode.acc_seg: 86.4451, aux.loss_ce: 0.1675, aux.acc_seg: 84.2465, loss: 0.5148
2023-12-28 16:03:29,518 - mmseg - INFO - Iter [45300/160000]	lr: 4.301e-05, eta: 1 day, 1:27:00, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3664, decode.acc_seg: 85.9149, aux.loss_ce: 0.1722, aux.acc_seg: 83.9680, loss: 0.5387
2023-12-28 16:04:07,519 - mmseg - INFO - Iter [45350/160000]	lr: 4.299e-05, eta: 1 day, 1:26:15, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3519, decode.acc_seg: 85.8681, aux.loss_ce: 0.1713, aux.acc_seg: 83.4726, loss: 0.5233
2023-12-28 16:04:47,883 - mmseg - INFO - Iter [45400/160000]	lr: 4.298e-05, eta: 1 day, 1:25:36, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3541, decode.acc_seg: 85.8764, aux.loss_ce: 0.1765, aux.acc_seg: 83.2916, loss: 0.5306
2023-12-28 16:05:25,449 - mmseg - INFO - Iter [45450/160000]	lr: 4.296e-05, eta: 1 day, 1:24:50, time: 0.752, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3427, decode.acc_seg: 86.3136, aux.loss_ce: 0.1667, aux.acc_seg: 83.8802, loss: 0.5094
2023-12-28 16:06:05,973 - mmseg - INFO - Iter [45500/160000]	lr: 4.294e-05, eta: 1 day, 1:24:11, time: 0.810, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3225, decode.acc_seg: 86.8697, aux.loss_ce: 0.1603, aux.acc_seg: 84.3651, loss: 0.4828
2023-12-28 16:06:45,508 - mmseg - INFO - Iter [45550/160000]	lr: 4.292e-05, eta: 1 day, 1:23:31, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3041, decode.acc_seg: 87.6075, aux.loss_ce: 0.1497, aux.acc_seg: 85.6793, loss: 0.4538
2023-12-28 16:07:24,616 - mmseg - INFO - Iter [45600/160000]	lr: 4.290e-05, eta: 1 day, 1:22:48, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3275, decode.acc_seg: 87.0885, aux.loss_ce: 0.1615, aux.acc_seg: 84.2636, loss: 0.4890
2023-12-28 16:08:04,489 - mmseg - INFO - Iter [45650/160000]	lr: 4.288e-05, eta: 1 day, 1:22:08, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3189, decode.acc_seg: 86.9132, aux.loss_ce: 0.1525, aux.acc_seg: 85.2408, loss: 0.4714
2023-12-28 16:08:44,158 - mmseg - INFO - Iter [45700/160000]	lr: 4.286e-05, eta: 1 day, 1:21:28, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3250, decode.acc_seg: 87.0037, aux.loss_ce: 0.1624, aux.acc_seg: 84.5979, loss: 0.4874
2023-12-28 16:09:24,524 - mmseg - INFO - Iter [45750/160000]	lr: 4.284e-05, eta: 1 day, 1:20:49, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3312, decode.acc_seg: 86.7267, aux.loss_ce: 0.1633, aux.acc_seg: 84.1989, loss: 0.4944
2023-12-28 16:10:03,483 - mmseg - INFO - Iter [45800/160000]	lr: 4.283e-05, eta: 1 day, 1:20:07, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3301, decode.acc_seg: 86.9264, aux.loss_ce: 0.1638, aux.acc_seg: 84.4144, loss: 0.4939
2023-12-28 16:10:44,354 - mmseg - INFO - Iter [45850/160000]	lr: 4.281e-05, eta: 1 day, 1:19:29, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3339, decode.acc_seg: 86.6689, aux.loss_ce: 0.1676, aux.acc_seg: 84.0984, loss: 0.5016
2023-12-28 16:11:21,133 - mmseg - INFO - Iter [45900/160000]	lr: 4.279e-05, eta: 1 day, 1:18:41, time: 0.735, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3316, decode.acc_seg: 86.7591, aux.loss_ce: 0.1639, aux.acc_seg: 84.1155, loss: 0.4955
2023-12-28 16:11:58,591 - mmseg - INFO - Iter [45950/160000]	lr: 4.277e-05, eta: 1 day, 1:17:55, time: 0.749, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3447, decode.acc_seg: 86.2291, aux.loss_ce: 0.1644, aux.acc_seg: 84.2707, loss: 0.5091
2023-12-28 16:12:37,762 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 16:12:37,762 - mmseg - INFO - Iter [46000/160000]	lr: 4.275e-05, eta: 1 day, 1:17:13, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3153, decode.acc_seg: 87.2369, aux.loss_ce: 0.1568, aux.acc_seg: 84.8210, loss: 0.4721
2023-12-28 16:13:18,105 - mmseg - INFO - Iter [46050/160000]	lr: 4.273e-05, eta: 1 day, 1:16:34, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3462, decode.acc_seg: 86.2655, aux.loss_ce: 0.1690, aux.acc_seg: 83.9263, loss: 0.5152
2023-12-28 16:13:58,317 - mmseg - INFO - Iter [46100/160000]	lr: 4.271e-05, eta: 1 day, 1:15:55, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3466, decode.acc_seg: 86.3919, aux.loss_ce: 0.1664, aux.acc_seg: 84.1789, loss: 0.5130
2023-12-28 16:14:38,682 - mmseg - INFO - Iter [46150/160000]	lr: 4.269e-05, eta: 1 day, 1:15:17, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3258, decode.acc_seg: 86.5970, aux.loss_ce: 0.1614, aux.acc_seg: 84.4732, loss: 0.4872
2023-12-28 16:15:17,669 - mmseg - INFO - Iter [46200/160000]	lr: 4.268e-05, eta: 1 day, 1:14:34, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3267, decode.acc_seg: 86.8322, aux.loss_ce: 0.1582, aux.acc_seg: 84.4935, loss: 0.4849
2023-12-28 16:15:58,474 - mmseg - INFO - Iter [46250/160000]	lr: 4.266e-05, eta: 1 day, 1:13:56, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3359, decode.acc_seg: 86.5757, aux.loss_ce: 0.1616, aux.acc_seg: 84.2700, loss: 0.4975
2023-12-28 16:16:38,972 - mmseg - INFO - Iter [46300/160000]	lr: 4.264e-05, eta: 1 day, 1:13:18, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3392, decode.acc_seg: 86.6294, aux.loss_ce: 0.1678, aux.acc_seg: 83.8770, loss: 0.5070
2023-12-28 16:17:18,622 - mmseg - INFO - Iter [46350/160000]	lr: 4.262e-05, eta: 1 day, 1:12:37, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3448, decode.acc_seg: 86.1447, aux.loss_ce: 0.1631, aux.acc_seg: 84.0859, loss: 0.5079
2023-12-28 16:17:57,915 - mmseg - INFO - Iter [46400/160000]	lr: 4.260e-05, eta: 1 day, 1:11:56, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3321, decode.acc_seg: 86.6382, aux.loss_ce: 0.1587, aux.acc_seg: 84.8294, loss: 0.4908
2023-12-28 16:18:37,992 - mmseg - INFO - Iter [46450/160000]	lr: 4.258e-05, eta: 1 day, 1:11:16, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3235, decode.acc_seg: 87.0823, aux.loss_ce: 0.1589, aux.acc_seg: 84.9847, loss: 0.4824
2023-12-28 16:19:18,337 - mmseg - INFO - Iter [46500/160000]	lr: 4.256e-05, eta: 1 day, 1:10:37, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3374, decode.acc_seg: 86.6704, aux.loss_ce: 0.1635, aux.acc_seg: 84.3625, loss: 0.5009
2023-12-28 16:19:57,850 - mmseg - INFO - Iter [46550/160000]	lr: 4.254e-05, eta: 1 day, 1:09:56, time: 0.789, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3549, decode.acc_seg: 85.8113, aux.loss_ce: 0.1660, aux.acc_seg: 84.1595, loss: 0.5209
2023-12-28 16:20:37,507 - mmseg - INFO - Iter [46600/160000]	lr: 4.253e-05, eta: 1 day, 1:09:16, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3251, decode.acc_seg: 86.6752, aux.loss_ce: 0.1581, aux.acc_seg: 84.6089, loss: 0.4832
2023-12-28 16:21:17,552 - mmseg - INFO - Iter [46650/160000]	lr: 4.251e-05, eta: 1 day, 1:08:36, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3450, decode.acc_seg: 86.3402, aux.loss_ce: 0.1646, aux.acc_seg: 84.1333, loss: 0.5096
2023-12-28 16:21:55,841 - mmseg - INFO - Iter [46700/160000]	lr: 4.249e-05, eta: 1 day, 1:07:52, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3409, decode.acc_seg: 86.2556, aux.loss_ce: 0.1635, aux.acc_seg: 84.0529, loss: 0.5044
2023-12-28 16:22:36,532 - mmseg - INFO - Iter [46750/160000]	lr: 4.247e-05, eta: 1 day, 1:07:14, time: 0.813, data_time: 0.052, memory: 18256, decode.loss_ce: 0.3208, decode.acc_seg: 87.2529, aux.loss_ce: 0.1577, aux.acc_seg: 84.9361, loss: 0.4785
2023-12-28 16:23:16,394 - mmseg - INFO - Iter [46800/160000]	lr: 4.245e-05, eta: 1 day, 1:06:34, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3465, decode.acc_seg: 86.4205, aux.loss_ce: 0.1688, aux.acc_seg: 84.0666, loss: 0.5154
2023-12-28 16:23:56,280 - mmseg - INFO - Iter [46850/160000]	lr: 4.243e-05, eta: 1 day, 1:05:54, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3388, decode.acc_seg: 86.6279, aux.loss_ce: 0.1640, aux.acc_seg: 84.3549, loss: 0.5028
2023-12-28 16:24:37,987 - mmseg - INFO - Iter [46900/160000]	lr: 4.241e-05, eta: 1 day, 1:05:18, time: 0.833, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3526, decode.acc_seg: 85.7718, aux.loss_ce: 0.1712, aux.acc_seg: 83.5171, loss: 0.5238
2023-12-28 16:25:18,542 - mmseg - INFO - Iter [46950/160000]	lr: 4.239e-05, eta: 1 day, 1:04:40, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3404, decode.acc_seg: 86.3976, aux.loss_ce: 0.1694, aux.acc_seg: 84.0657, loss: 0.5098
2023-12-28 16:25:59,015 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 16:25:59,015 - mmseg - INFO - Iter [47000/160000]	lr: 4.238e-05, eta: 1 day, 1:04:01, time: 0.810, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3548, decode.acc_seg: 85.6467, aux.loss_ce: 0.1743, aux.acc_seg: 83.2273, loss: 0.5291
2023-12-28 16:26:39,420 - mmseg - INFO - Iter [47050/160000]	lr: 4.236e-05, eta: 1 day, 1:03:23, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3285, decode.acc_seg: 86.5082, aux.loss_ce: 0.1604, aux.acc_seg: 84.3705, loss: 0.4890
2023-12-28 16:27:17,244 - mmseg - INFO - Iter [47100/160000]	lr: 4.234e-05, eta: 1 day, 1:02:38, time: 0.756, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3238, decode.acc_seg: 87.1946, aux.loss_ce: 0.1578, aux.acc_seg: 85.0512, loss: 0.4816
2023-12-28 16:27:56,075 - mmseg - INFO - Iter [47150/160000]	lr: 4.232e-05, eta: 1 day, 1:01:55, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3472, decode.acc_seg: 86.0666, aux.loss_ce: 0.1689, aux.acc_seg: 83.7599, loss: 0.5161
2023-12-28 16:28:34,221 - mmseg - INFO - Iter [47200/160000]	lr: 4.230e-05, eta: 1 day, 1:01:11, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3495, decode.acc_seg: 85.9758, aux.loss_ce: 0.1652, aux.acc_seg: 84.2550, loss: 0.5148
2023-12-28 16:29:13,522 - mmseg - INFO - Iter [47250/160000]	lr: 4.228e-05, eta: 1 day, 1:00:30, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3422, decode.acc_seg: 86.3002, aux.loss_ce: 0.1647, aux.acc_seg: 84.1558, loss: 0.5069
2023-12-28 16:29:53,814 - mmseg - INFO - Iter [47300/160000]	lr: 4.226e-05, eta: 1 day, 0:59:50, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3235, decode.acc_seg: 87.2698, aux.loss_ce: 0.1588, aux.acc_seg: 84.7625, loss: 0.4823
2023-12-28 16:30:34,383 - mmseg - INFO - Iter [47350/160000]	lr: 4.224e-05, eta: 1 day, 0:59:12, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3343, decode.acc_seg: 86.7846, aux.loss_ce: 0.1643, aux.acc_seg: 84.4541, loss: 0.4985
2023-12-28 16:31:14,615 - mmseg - INFO - Iter [47400/160000]	lr: 4.223e-05, eta: 1 day, 0:58:33, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3282, decode.acc_seg: 87.4086, aux.loss_ce: 0.1586, aux.acc_seg: 85.1980, loss: 0.4867
2023-12-28 16:31:53,393 - mmseg - INFO - Iter [47450/160000]	lr: 4.221e-05, eta: 1 day, 0:57:50, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3250, decode.acc_seg: 86.8598, aux.loss_ce: 0.1602, aux.acc_seg: 84.5334, loss: 0.4852
2023-12-28 16:32:33,596 - mmseg - INFO - Iter [47500/160000]	lr: 4.219e-05, eta: 1 day, 0:57:11, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3182, decode.acc_seg: 86.9939, aux.loss_ce: 0.1539, aux.acc_seg: 84.9102, loss: 0.4722
2023-12-28 16:33:13,510 - mmseg - INFO - Iter [47550/160000]	lr: 4.217e-05, eta: 1 day, 0:56:31, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3217, decode.acc_seg: 86.8424, aux.loss_ce: 0.1565, aux.acc_seg: 84.8099, loss: 0.4782
2023-12-28 16:33:52,960 - mmseg - INFO - Iter [47600/160000]	lr: 4.215e-05, eta: 1 day, 0:55:50, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3351, decode.acc_seg: 86.0867, aux.loss_ce: 0.1626, aux.acc_seg: 83.9243, loss: 0.4978
2023-12-28 16:34:32,211 - mmseg - INFO - Iter [47650/160000]	lr: 4.213e-05, eta: 1 day, 0:55:08, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3198, decode.acc_seg: 87.3665, aux.loss_ce: 0.1547, aux.acc_seg: 85.1963, loss: 0.4745
2023-12-28 16:35:11,371 - mmseg - INFO - Iter [47700/160000]	lr: 4.211e-05, eta: 1 day, 0:54:27, time: 0.783, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3392, decode.acc_seg: 86.2587, aux.loss_ce: 0.1608, aux.acc_seg: 84.4204, loss: 0.5001
2023-12-28 16:35:50,031 - mmseg - INFO - Iter [47750/160000]	lr: 4.209e-05, eta: 1 day, 0:53:44, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3589, decode.acc_seg: 85.6283, aux.loss_ce: 0.1693, aux.acc_seg: 83.3870, loss: 0.5282
2023-12-28 16:36:29,734 - mmseg - INFO - Iter [47800/160000]	lr: 4.208e-05, eta: 1 day, 0:53:03, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3342, decode.acc_seg: 86.7618, aux.loss_ce: 0.1598, aux.acc_seg: 84.8719, loss: 0.4940
2023-12-28 16:37:07,344 - mmseg - INFO - Iter [47850/160000]	lr: 4.206e-05, eta: 1 day, 0:52:18, time: 0.752, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3297, decode.acc_seg: 86.7986, aux.loss_ce: 0.1590, aux.acc_seg: 84.5829, loss: 0.4887
2023-12-28 16:37:45,186 - mmseg - INFO - Iter [47900/160000]	lr: 4.204e-05, eta: 1 day, 0:51:33, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3310, decode.acc_seg: 86.7301, aux.loss_ce: 0.1624, aux.acc_seg: 84.1475, loss: 0.4935
2023-12-28 16:38:21,554 - mmseg - INFO - Iter [47950/160000]	lr: 4.202e-05, eta: 1 day, 0:50:45, time: 0.727, data_time: 0.010, memory: 18256, decode.loss_ce: 0.3092, decode.acc_seg: 87.3598, aux.loss_ce: 0.1498, aux.acc_seg: 85.3281, loss: 0.4590
2023-12-28 16:39:02,258 - mmseg - INFO - Saving checkpoint at 48000 iterations
2023-12-28 16:39:06,418 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 16:39:06,419 - mmseg - INFO - Iter [48000/160000]	lr: 4.200e-05, eta: 1 day, 0:50:17, time: 0.898, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3307, decode.acc_seg: 86.7710, aux.loss_ce: 0.1560, aux.acc_seg: 84.9482, loss: 0.4867
2023-12-28 16:41:09,378 - mmseg - INFO - per class results:
2023-12-28 16:41:09,392 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 75.36 | 86.83 |
|       building      | 82.22 | 90.53 |
|         sky         | 93.41 | 96.05 |
|        floor        | 80.72 | 89.82 |
|         tree        | 74.17 | 88.79 |
|       ceiling       | 80.04 | 86.16 |
|         road        | 82.56 | 88.24 |
|         bed         | 86.08 | 94.31 |
|      windowpane     | 60.98 | 76.83 |
|        grass        | 68.09 | 88.15 |
|       cabinet       | 55.68 | 68.45 |
|       sidewalk      | 64.77 | 82.09 |
|        person       |  78.9 | 90.63 |
|        earth        | 33.42 | 44.35 |
|         door        |  46.0 | 58.26 |
|        table        | 55.74 | 69.88 |
|       mountain      | 58.09 | 72.78 |
|        plant        | 49.07 | 58.68 |
|       curtain       | 72.45 | 86.88 |
|        chair        | 53.35 | 68.17 |
|         car         | 83.45 | 92.39 |
|        water        | 54.97 | 67.23 |
|       painting      | 62.03 | 89.25 |
|         sofa        | 63.66 |  84.0 |
|        shelf        | 40.73 | 59.11 |
|        house        | 47.11 | 70.23 |
|         sea         | 60.99 | 82.46 |
|        mirror       |  58.2 |  68.6 |
|         rug         | 62.79 |  73.3 |
|        field        | 31.61 | 44.49 |
|       armchair      | 36.33 |  52.4 |
|         seat        | 56.91 | 78.83 |
|        fence        | 30.13 | 40.31 |
|         desk        | 43.59 | 66.23 |
|         rock        | 45.09 | 74.19 |
|       wardrobe      |  44.3 | 78.13 |
|         lamp        | 58.99 | 73.56 |
|       bathtub       | 74.03 | 84.22 |
|       railing       | 35.77 | 46.72 |
|       cushion       | 52.15 |  64.6 |
|         base        | 29.61 |  50.7 |
|         box         | 24.65 | 36.58 |
|        column       | 44.37 | 56.75 |
|      signboard      |  35.5 | 48.07 |
|   chest of drawers  | 38.27 | 57.15 |
|       counter       | 33.07 | 42.89 |
|         sand        | 46.51 | 65.92 |
|         sink        | 63.82 |  76.6 |
|      skyscraper     | 50.98 |  65.9 |
|      fireplace      | 62.51 |  87.6 |
|     refrigerator    | 69.67 | 82.68 |
|      grandstand     | 38.81 | 71.44 |
|         path        | 20.54 |  29.5 |
|        stairs       | 29.27 | 34.74 |
|        runway       | 56.06 | 63.61 |
|         case        |  51.2 | 65.43 |
|      pool table     | 92.26 | 96.55 |
|        pillow       | 55.45 | 65.92 |
|     screen door     |  66.8 | 77.83 |
|       stairway      | 32.08 | 38.93 |
|        river        |  8.69 | 22.02 |
|        bridge       | 70.55 | 86.48 |
|       bookcase      | 31.26 | 50.71 |
|        blind        | 40.34 | 45.62 |
|     coffee table    | 53.94 | 74.78 |
|        toilet       | 79.11 | 90.85 |
|        flower       | 36.71 |  51.5 |
|         book        | 42.34 | 73.11 |
|         hill        |  8.15 | 19.99 |
|        bench        | 35.73 | 46.14 |
|      countertop     | 51.48 | 81.05 |
|        stove        | 60.04 | 62.07 |
|         palm        | 47.35 |  66.3 |
|    kitchen island   |  35.2 | 77.87 |
|       computer      | 71.36 | 91.79 |
|     swivel chair    |  37.8 |  54.5 |
|         boat        | 33.14 | 55.12 |
|         bar         | 26.31 | 34.21 |
|    arcade machine   | 59.76 | 75.44 |
|        hovel        | 38.77 | 79.48 |
|         bus         | 69.57 | 95.52 |
|        towel        | 50.81 | 74.12 |
|        light        | 50.87 | 60.16 |
|        truck        |  14.8 | 22.65 |
|        tower        | 28.06 | 70.56 |
|      chandelier     | 66.66 | 81.44 |
|        awning       | 27.37 | 37.01 |
|     streetlight     | 22.04 | 28.57 |
|        booth        | 39.95 | 68.04 |
| television receiver | 61.11 | 79.23 |
|       airplane      |  54.8 | 64.78 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 23.18 | 39.05 |
|         pole        | 18.57 | 23.84 |
|         land        |  0.11 |  0.13 |
|      bannister      |  5.13 |  5.73 |
|      escalator      | 33.33 | 44.79 |
|       ottoman       | 41.51 |  47.7 |
|        bottle       | 16.25 | 18.79 |
|        buffet       |  41.7 | 50.11 |
|        poster       | 13.14 | 17.81 |
|        stage        | 16.23 | 30.41 |
|         van         | 33.78 | 40.87 |
|         ship        | 52.29 | 96.42 |
|       fountain      | 20.69 | 21.19 |
|    conveyer belt    |  73.3 |  88.7 |
|        canopy       | 22.01 | 44.11 |
|        washer       | 69.32 | 97.33 |
|      plaything      | 19.68 | 40.95 |
|    swimming pool    | 57.74 | 83.86 |
|        stool        | 27.75 | 35.72 |
|        barrel       | 11.13 | 64.94 |
|        basket       | 28.83 | 44.41 |
|      waterfall      | 71.55 | 86.77 |
|         tent        | 87.08 | 97.69 |
|         bag         |  6.85 |  7.87 |
|       minibike      | 64.49 |  87.1 |
|        cradle       | 68.93 | 97.65 |
|         oven        | 29.43 | 37.06 |
|         ball        |  49.1 | 66.78 |
|         food        | 46.86 | 53.79 |
|         step        |  3.44 |  5.47 |
|         tank        | 50.66 | 57.84 |
|      trade name     | 13.49 | 14.61 |
|      microwave      | 80.34 | 93.26 |
|         pot         | 38.32 | 45.47 |
|        animal       | 54.93 | 58.35 |
|       bicycle       | 53.26 |  70.2 |
|         lake        | 64.01 | 79.69 |
|      dishwasher     | 47.61 | 70.27 |
|        screen       | 57.24 | 88.98 |
|       blanket       |  4.42 |  5.24 |
|      sculpture      | 48.72 |  71.4 |
|         hood        |  52.5 | 60.19 |
|        sconce       | 29.01 | 33.88 |
|         vase        |  34.8 |  51.6 |
|    traffic light    | 21.09 | 41.37 |
|         tray        |  1.9  |  4.41 |
|        ashcan       | 34.43 | 43.59 |
|         fan         | 51.04 | 75.54 |
|         pier        | 40.75 | 52.78 |
|      crt screen     |  5.58 |  9.52 |
|        plate        | 52.64 | 68.29 |
|       monitor       | 39.39 | 56.76 |
|    bulletin board   | 36.92 |  43.5 |
|        shower       |  1.66 |  4.21 |
|       radiator      | 52.24 | 57.52 |
|        glass        | 10.52 | 11.14 |
|        clock        | 26.13 | 28.84 |
|         flag        | 42.89 | 48.63 |
+---------------------+-------+-------+
2023-12-28 16:41:09,392 - mmseg - INFO - Summary:
2023-12-28 16:41:09,393 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 81.54 | 45.26 | 59.57 |
+-------+-------+-------+
2023-12-28 16:41:09,408 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 16:41:09,408 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8154, mIoU: 0.4526, mAcc: 0.5957, IoU.wall: 0.7536, IoU.building: 0.8222, IoU.sky: 0.9341, IoU.floor: 0.8072, IoU.tree: 0.7417, IoU.ceiling: 0.8004, IoU.road: 0.8256, IoU.bed : 0.8608, IoU.windowpane: 0.6098, IoU.grass: 0.6809, IoU.cabinet: 0.5568, IoU.sidewalk: 0.6477, IoU.person: 0.7890, IoU.earth: 0.3342, IoU.door: 0.4600, IoU.table: 0.5574, IoU.mountain: 0.5809, IoU.plant: 0.4907, IoU.curtain: 0.7245, IoU.chair: 0.5335, IoU.car: 0.8345, IoU.water: 0.5497, IoU.painting: 0.6203, IoU.sofa: 0.6366, IoU.shelf: 0.4073, IoU.house: 0.4711, IoU.sea: 0.6099, IoU.mirror: 0.5820, IoU.rug: 0.6279, IoU.field: 0.3161, IoU.armchair: 0.3633, IoU.seat: 0.5691, IoU.fence: 0.3013, IoU.desk: 0.4359, IoU.rock: 0.4509, IoU.wardrobe: 0.4430, IoU.lamp: 0.5899, IoU.bathtub: 0.7403, IoU.railing: 0.3577, IoU.cushion: 0.5215, IoU.base: 0.2961, IoU.box: 0.2465, IoU.column: 0.4437, IoU.signboard: 0.3550, IoU.chest of drawers: 0.3827, IoU.counter: 0.3307, IoU.sand: 0.4651, IoU.sink: 0.6382, IoU.skyscraper: 0.5098, IoU.fireplace: 0.6251, IoU.refrigerator: 0.6967, IoU.grandstand: 0.3881, IoU.path: 0.2054, IoU.stairs: 0.2927, IoU.runway: 0.5606, IoU.case: 0.5120, IoU.pool table: 0.9226, IoU.pillow: 0.5545, IoU.screen door: 0.6680, IoU.stairway: 0.3208, IoU.river: 0.0869, IoU.bridge: 0.7055, IoU.bookcase: 0.3126, IoU.blind: 0.4034, IoU.coffee table: 0.5394, IoU.toilet: 0.7911, IoU.flower: 0.3671, IoU.book: 0.4234, IoU.hill: 0.0815, IoU.bench: 0.3573, IoU.countertop: 0.5148, IoU.stove: 0.6004, IoU.palm: 0.4735, IoU.kitchen island: 0.3520, IoU.computer: 0.7136, IoU.swivel chair: 0.3780, IoU.boat: 0.3314, IoU.bar: 0.2631, IoU.arcade machine: 0.5976, IoU.hovel: 0.3877, IoU.bus: 0.6957, IoU.towel: 0.5081, IoU.light: 0.5087, IoU.truck: 0.1480, IoU.tower: 0.2806, IoU.chandelier: 0.6666, IoU.awning: 0.2737, IoU.streetlight: 0.2204, IoU.booth: 0.3995, IoU.television receiver: 0.6111, IoU.airplane: 0.5480, IoU.dirt track: 0.0000, IoU.apparel: 0.2318, IoU.pole: 0.1857, IoU.land: 0.0011, IoU.bannister: 0.0513, IoU.escalator: 0.3333, IoU.ottoman: 0.4151, IoU.bottle: 0.1625, IoU.buffet: 0.4170, IoU.poster: 0.1314, IoU.stage: 0.1623, IoU.van: 0.3378, IoU.ship: 0.5229, IoU.fountain: 0.2069, IoU.conveyer belt: 0.7330, IoU.canopy: 0.2201, IoU.washer: 0.6932, IoU.plaything: 0.1968, IoU.swimming pool: 0.5774, IoU.stool: 0.2775, IoU.barrel: 0.1113, IoU.basket: 0.2883, IoU.waterfall: 0.7155, IoU.tent: 0.8708, IoU.bag: 0.0685, IoU.minibike: 0.6449, IoU.cradle: 0.6893, IoU.oven: 0.2943, IoU.ball: 0.4910, IoU.food: 0.4686, IoU.step: 0.0344, IoU.tank: 0.5066, IoU.trade name: 0.1349, IoU.microwave: 0.8034, IoU.pot: 0.3832, IoU.animal: 0.5493, IoU.bicycle: 0.5326, IoU.lake: 0.6401, IoU.dishwasher: 0.4761, IoU.screen: 0.5724, IoU.blanket: 0.0442, IoU.sculpture: 0.4872, IoU.hood: 0.5250, IoU.sconce: 0.2901, IoU.vase: 0.3480, IoU.traffic light: 0.2109, IoU.tray: 0.0190, IoU.ashcan: 0.3443, IoU.fan: 0.5104, IoU.pier: 0.4075, IoU.crt screen: 0.0558, IoU.plate: 0.5264, IoU.monitor: 0.3939, IoU.bulletin board: 0.3692, IoU.shower: 0.0166, IoU.radiator: 0.5224, IoU.glass: 0.1052, IoU.clock: 0.2613, IoU.flag: 0.4289, Acc.wall: 0.8683, Acc.building: 0.9053, Acc.sky: 0.9605, Acc.floor: 0.8982, Acc.tree: 0.8879, Acc.ceiling: 0.8616, Acc.road: 0.8824, Acc.bed : 0.9431, Acc.windowpane: 0.7683, Acc.grass: 0.8815, Acc.cabinet: 0.6845, Acc.sidewalk: 0.8209, Acc.person: 0.9063, Acc.earth: 0.4435, Acc.door: 0.5826, Acc.table: 0.6988, Acc.mountain: 0.7278, Acc.plant: 0.5868, Acc.curtain: 0.8688, Acc.chair: 0.6817, Acc.car: 0.9239, Acc.water: 0.6723, Acc.painting: 0.8925, Acc.sofa: 0.8400, Acc.shelf: 0.5911, Acc.house: 0.7023, Acc.sea: 0.8246, Acc.mirror: 0.6860, Acc.rug: 0.7330, Acc.field: 0.4449, Acc.armchair: 0.5240, Acc.seat: 0.7883, Acc.fence: 0.4031, Acc.desk: 0.6623, Acc.rock: 0.7419, Acc.wardrobe: 0.7813, Acc.lamp: 0.7356, Acc.bathtub: 0.8422, Acc.railing: 0.4672, Acc.cushion: 0.6460, Acc.base: 0.5070, Acc.box: 0.3658, Acc.column: 0.5675, Acc.signboard: 0.4807, Acc.chest of drawers: 0.5715, Acc.counter: 0.4289, Acc.sand: 0.6592, Acc.sink: 0.7660, Acc.skyscraper: 0.6590, Acc.fireplace: 0.8760, Acc.refrigerator: 0.8268, Acc.grandstand: 0.7144, Acc.path: 0.2950, Acc.stairs: 0.3474, Acc.runway: 0.6361, Acc.case: 0.6543, Acc.pool table: 0.9655, Acc.pillow: 0.6592, Acc.screen door: 0.7783, Acc.stairway: 0.3893, Acc.river: 0.2202, Acc.bridge: 0.8648, Acc.bookcase: 0.5071, Acc.blind: 0.4562, Acc.coffee table: 0.7478, Acc.toilet: 0.9085, Acc.flower: 0.5150, Acc.book: 0.7311, Acc.hill: 0.1999, Acc.bench: 0.4614, Acc.countertop: 0.8105, Acc.stove: 0.6207, Acc.palm: 0.6630, Acc.kitchen island: 0.7787, Acc.computer: 0.9179, Acc.swivel chair: 0.5450, Acc.boat: 0.5512, Acc.bar: 0.3421, Acc.arcade machine: 0.7544, Acc.hovel: 0.7948, Acc.bus: 0.9552, Acc.towel: 0.7412, Acc.light: 0.6016, Acc.truck: 0.2265, Acc.tower: 0.7056, Acc.chandelier: 0.8144, Acc.awning: 0.3701, Acc.streetlight: 0.2857, Acc.booth: 0.6804, Acc.television receiver: 0.7923, Acc.airplane: 0.6478, Acc.dirt track: 0.0000, Acc.apparel: 0.3905, Acc.pole: 0.2384, Acc.land: 0.0013, Acc.bannister: 0.0573, Acc.escalator: 0.4479, Acc.ottoman: 0.4770, Acc.bottle: 0.1879, Acc.buffet: 0.5011, Acc.poster: 0.1781, Acc.stage: 0.3041, Acc.van: 0.4087, Acc.ship: 0.9642, Acc.fountain: 0.2119, Acc.conveyer belt: 0.8870, Acc.canopy: 0.4411, Acc.washer: 0.9733, Acc.plaything: 0.4095, Acc.swimming pool: 0.8386, Acc.stool: 0.3572, Acc.barrel: 0.6494, Acc.basket: 0.4441, Acc.waterfall: 0.8677, Acc.tent: 0.9769, Acc.bag: 0.0787, Acc.minibike: 0.8710, Acc.cradle: 0.9765, Acc.oven: 0.3706, Acc.ball: 0.6678, Acc.food: 0.5379, Acc.step: 0.0547, Acc.tank: 0.5784, Acc.trade name: 0.1461, Acc.microwave: 0.9326, Acc.pot: 0.4547, Acc.animal: 0.5835, Acc.bicycle: 0.7020, Acc.lake: 0.7969, Acc.dishwasher: 0.7027, Acc.screen: 0.8898, Acc.blanket: 0.0524, Acc.sculpture: 0.7140, Acc.hood: 0.6019, Acc.sconce: 0.3388, Acc.vase: 0.5160, Acc.traffic light: 0.4137, Acc.tray: 0.0441, Acc.ashcan: 0.4359, Acc.fan: 0.7554, Acc.pier: 0.5278, Acc.crt screen: 0.0952, Acc.plate: 0.6829, Acc.monitor: 0.5676, Acc.bulletin board: 0.4350, Acc.shower: 0.0421, Acc.radiator: 0.5752, Acc.glass: 0.1114, Acc.clock: 0.2884, Acc.flag: 0.4863
2023-12-28 16:41:47,890 - mmseg - INFO - Iter [48050/160000]	lr: 4.198e-05, eta: 1 day, 0:54:20, time: 3.229, data_time: 2.471, memory: 18256, decode.loss_ce: 0.3234, decode.acc_seg: 86.8446, aux.loss_ce: 0.1553, aux.acc_seg: 84.6731, loss: 0.4787
2023-12-28 16:42:25,791 - mmseg - INFO - Iter [48100/160000]	lr: 4.196e-05, eta: 1 day, 0:53:35, time: 0.757, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3132, decode.acc_seg: 87.4576, aux.loss_ce: 0.1520, aux.acc_seg: 85.4421, loss: 0.4652
2023-12-28 16:43:06,539 - mmseg - INFO - Iter [48150/160000]	lr: 4.194e-05, eta: 1 day, 0:52:56, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3116, decode.acc_seg: 87.1696, aux.loss_ce: 0.1529, aux.acc_seg: 84.6237, loss: 0.4645
2023-12-28 16:43:44,626 - mmseg - INFO - Iter [48200/160000]	lr: 4.193e-05, eta: 1 day, 0:52:12, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3449, decode.acc_seg: 86.2061, aux.loss_ce: 0.1675, aux.acc_seg: 84.1816, loss: 0.5124
2023-12-28 16:44:22,879 - mmseg - INFO - Iter [48250/160000]	lr: 4.191e-05, eta: 1 day, 0:51:28, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3287, decode.acc_seg: 86.3999, aux.loss_ce: 0.1641, aux.acc_seg: 84.1323, loss: 0.4928
2023-12-28 16:45:00,946 - mmseg - INFO - Iter [48300/160000]	lr: 4.189e-05, eta: 1 day, 0:50:43, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3272, decode.acc_seg: 86.9239, aux.loss_ce: 0.1567, aux.acc_seg: 85.0885, loss: 0.4839
2023-12-28 16:45:41,293 - mmseg - INFO - Iter [48350/160000]	lr: 4.187e-05, eta: 1 day, 0:50:04, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3521, decode.acc_seg: 86.3307, aux.loss_ce: 0.1671, aux.acc_seg: 84.4005, loss: 0.5193
2023-12-28 16:46:18,891 - mmseg - INFO - Iter [48400/160000]	lr: 4.185e-05, eta: 1 day, 0:49:18, time: 0.752, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3286, decode.acc_seg: 86.7892, aux.loss_ce: 0.1615, aux.acc_seg: 84.5371, loss: 0.4901
2023-12-28 16:46:58,241 - mmseg - INFO - Iter [48450/160000]	lr: 4.183e-05, eta: 1 day, 0:48:37, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3362, decode.acc_seg: 87.0322, aux.loss_ce: 0.1597, aux.acc_seg: 85.0883, loss: 0.4959
2023-12-28 16:47:38,445 - mmseg - INFO - Iter [48500/160000]	lr: 4.181e-05, eta: 1 day, 0:47:57, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3285, decode.acc_seg: 86.7507, aux.loss_ce: 0.1598, aux.acc_seg: 84.5704, loss: 0.4882
2023-12-28 16:48:18,977 - mmseg - INFO - Iter [48550/160000]	lr: 4.179e-05, eta: 1 day, 0:47:18, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3502, decode.acc_seg: 85.9193, aux.loss_ce: 0.1678, aux.acc_seg: 83.7148, loss: 0.5180
2023-12-28 16:48:59,283 - mmseg - INFO - Iter [48600/160000]	lr: 4.178e-05, eta: 1 day, 0:46:39, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3354, decode.acc_seg: 86.5379, aux.loss_ce: 0.1640, aux.acc_seg: 84.5048, loss: 0.4995
2023-12-28 16:49:39,527 - mmseg - INFO - Iter [48650/160000]	lr: 4.176e-05, eta: 1 day, 0:45:59, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3340, decode.acc_seg: 86.8901, aux.loss_ce: 0.1641, aux.acc_seg: 84.3013, loss: 0.4980
2023-12-28 16:50:16,712 - mmseg - INFO - Iter [48700/160000]	lr: 4.174e-05, eta: 1 day, 0:45:12, time: 0.745, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3150, decode.acc_seg: 87.3598, aux.loss_ce: 0.1535, aux.acc_seg: 84.9069, loss: 0.4684
2023-12-28 16:50:54,516 - mmseg - INFO - Iter [48750/160000]	lr: 4.172e-05, eta: 1 day, 0:44:27, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3449, decode.acc_seg: 86.7249, aux.loss_ce: 0.1688, aux.acc_seg: 84.3492, loss: 0.5137
2023-12-28 16:51:34,397 - mmseg - INFO - Iter [48800/160000]	lr: 4.170e-05, eta: 1 day, 0:43:47, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3187, decode.acc_seg: 86.9490, aux.loss_ce: 0.1582, aux.acc_seg: 84.8405, loss: 0.4769
2023-12-28 16:52:11,603 - mmseg - INFO - Iter [48850/160000]	lr: 4.168e-05, eta: 1 day, 0:43:01, time: 0.744, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3169, decode.acc_seg: 87.3297, aux.loss_ce: 0.1520, aux.acc_seg: 85.2280, loss: 0.4689
2023-12-28 16:52:50,797 - mmseg - INFO - Iter [48900/160000]	lr: 4.166e-05, eta: 1 day, 0:42:19, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3315, decode.acc_seg: 86.7469, aux.loss_ce: 0.1595, aux.acc_seg: 84.8209, loss: 0.4910
2023-12-28 16:53:28,112 - mmseg - INFO - Iter [48950/160000]	lr: 4.164e-05, eta: 1 day, 0:41:32, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3354, decode.acc_seg: 86.5534, aux.loss_ce: 0.1640, aux.acc_seg: 83.9827, loss: 0.4995
2023-12-28 16:54:06,129 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 16:54:06,129 - mmseg - INFO - Iter [49000/160000]	lr: 4.163e-05, eta: 1 day, 0:40:48, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3347, decode.acc_seg: 86.6509, aux.loss_ce: 0.1584, aux.acc_seg: 84.6500, loss: 0.4930
2023-12-28 16:54:44,427 - mmseg - INFO - Iter [49050/160000]	lr: 4.161e-05, eta: 1 day, 0:40:04, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3353, decode.acc_seg: 86.4340, aux.loss_ce: 0.1599, aux.acc_seg: 84.3986, loss: 0.4952
2023-12-28 16:55:23,496 - mmseg - INFO - Iter [49100/160000]	lr: 4.159e-05, eta: 1 day, 0:39:22, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3446, decode.acc_seg: 85.3396, aux.loss_ce: 0.1617, aux.acc_seg: 83.6478, loss: 0.5063
2023-12-28 16:56:03,406 - mmseg - INFO - Iter [49150/160000]	lr: 4.157e-05, eta: 1 day, 0:38:41, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3300, decode.acc_seg: 86.5392, aux.loss_ce: 0.1619, aux.acc_seg: 84.2213, loss: 0.4918
2023-12-28 16:56:44,487 - mmseg - INFO - Iter [49200/160000]	lr: 4.155e-05, eta: 1 day, 0:38:04, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3299, decode.acc_seg: 86.4782, aux.loss_ce: 0.1608, aux.acc_seg: 84.1119, loss: 0.4906
2023-12-28 16:57:23,482 - mmseg - INFO - Iter [49250/160000]	lr: 4.153e-05, eta: 1 day, 0:37:22, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3246, decode.acc_seg: 87.0674, aux.loss_ce: 0.1579, aux.acc_seg: 85.0734, loss: 0.4826
2023-12-28 16:58:03,796 - mmseg - INFO - Iter [49300/160000]	lr: 4.151e-05, eta: 1 day, 0:36:42, time: 0.806, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3185, decode.acc_seg: 86.9189, aux.loss_ce: 0.1552, aux.acc_seg: 84.7223, loss: 0.4738
2023-12-28 16:58:44,077 - mmseg - INFO - Iter [49350/160000]	lr: 4.149e-05, eta: 1 day, 0:36:03, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3314, decode.acc_seg: 87.1277, aux.loss_ce: 0.1593, aux.acc_seg: 84.9147, loss: 0.4907
2023-12-28 16:59:24,398 - mmseg - INFO - Iter [49400/160000]	lr: 4.148e-05, eta: 1 day, 0:35:23, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3424, decode.acc_seg: 86.0626, aux.loss_ce: 0.1653, aux.acc_seg: 84.2836, loss: 0.5078
2023-12-28 17:00:04,728 - mmseg - INFO - Iter [49450/160000]	lr: 4.146e-05, eta: 1 day, 0:34:44, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3124, decode.acc_seg: 87.1949, aux.loss_ce: 0.1523, aux.acc_seg: 85.1143, loss: 0.4647
2023-12-28 17:00:43,632 - mmseg - INFO - Iter [49500/160000]	lr: 4.144e-05, eta: 1 day, 0:34:02, time: 0.778, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2965, decode.acc_seg: 88.4520, aux.loss_ce: 0.1443, aux.acc_seg: 86.2559, loss: 0.4407
2023-12-28 17:01:22,789 - mmseg - INFO - Iter [49550/160000]	lr: 4.142e-05, eta: 1 day, 0:33:20, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3154, decode.acc_seg: 87.4812, aux.loss_ce: 0.1536, aux.acc_seg: 85.3887, loss: 0.4690
2023-12-28 17:02:03,380 - mmseg - INFO - Iter [49600/160000]	lr: 4.140e-05, eta: 1 day, 0:32:41, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3229, decode.acc_seg: 87.3778, aux.loss_ce: 0.1598, aux.acc_seg: 84.8184, loss: 0.4828
2023-12-28 17:02:44,224 - mmseg - INFO - Iter [49650/160000]	lr: 4.138e-05, eta: 1 day, 0:32:03, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3100, decode.acc_seg: 87.7566, aux.loss_ce: 0.1529, aux.acc_seg: 85.4252, loss: 0.4629
2023-12-28 17:03:24,667 - mmseg - INFO - Iter [49700/160000]	lr: 4.136e-05, eta: 1 day, 0:31:24, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3411, decode.acc_seg: 86.2509, aux.loss_ce: 0.1678, aux.acc_seg: 83.9736, loss: 0.5089
2023-12-28 17:04:05,589 - mmseg - INFO - Iter [49750/160000]	lr: 4.134e-05, eta: 1 day, 0:30:45, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3380, decode.acc_seg: 86.1826, aux.loss_ce: 0.1659, aux.acc_seg: 83.7595, loss: 0.5039
2023-12-28 17:04:45,151 - mmseg - INFO - Iter [49800/160000]	lr: 4.133e-05, eta: 1 day, 0:30:05, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3220, decode.acc_seg: 87.2991, aux.loss_ce: 0.1601, aux.acc_seg: 84.7789, loss: 0.4821
2023-12-28 17:05:23,856 - mmseg - INFO - Iter [49850/160000]	lr: 4.131e-05, eta: 1 day, 0:29:22, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3153, decode.acc_seg: 87.2977, aux.loss_ce: 0.1529, aux.acc_seg: 85.0504, loss: 0.4682
2023-12-28 17:06:05,823 - mmseg - INFO - Iter [49900/160000]	lr: 4.129e-05, eta: 1 day, 0:28:46, time: 0.838, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3423, decode.acc_seg: 86.8613, aux.loss_ce: 0.1660, aux.acc_seg: 84.4485, loss: 0.5083
2023-12-28 17:06:44,331 - mmseg - INFO - Iter [49950/160000]	lr: 4.127e-05, eta: 1 day, 0:28:02, time: 0.770, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3075, decode.acc_seg: 87.7610, aux.loss_ce: 0.1515, aux.acc_seg: 85.5978, loss: 0.4590
2023-12-28 17:07:24,917 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 17:07:24,917 - mmseg - INFO - Iter [50000/160000]	lr: 4.125e-05, eta: 1 day, 0:27:24, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3437, decode.acc_seg: 86.5907, aux.loss_ce: 0.1640, aux.acc_seg: 84.3432, loss: 0.5077
2023-12-28 17:08:05,536 - mmseg - INFO - Iter [50050/160000]	lr: 4.123e-05, eta: 1 day, 0:26:45, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3272, decode.acc_seg: 86.9452, aux.loss_ce: 0.1589, aux.acc_seg: 84.7284, loss: 0.4861
2023-12-28 17:08:46,206 - mmseg - INFO - Iter [50100/160000]	lr: 4.121e-05, eta: 1 day, 0:26:06, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3182, decode.acc_seg: 87.1255, aux.loss_ce: 0.1555, aux.acc_seg: 84.8377, loss: 0.4737
2023-12-28 17:09:25,613 - mmseg - INFO - Iter [50150/160000]	lr: 4.119e-05, eta: 1 day, 0:25:25, time: 0.790, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3143, decode.acc_seg: 87.1418, aux.loss_ce: 0.1538, aux.acc_seg: 84.9877, loss: 0.4682
2023-12-28 17:10:06,320 - mmseg - INFO - Iter [50200/160000]	lr: 4.118e-05, eta: 1 day, 0:24:46, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3446, decode.acc_seg: 86.4079, aux.loss_ce: 0.1638, aux.acc_seg: 84.2351, loss: 0.5085
2023-12-28 17:10:45,969 - mmseg - INFO - Iter [50250/160000]	lr: 4.116e-05, eta: 1 day, 0:24:06, time: 0.794, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3125, decode.acc_seg: 87.6019, aux.loss_ce: 0.1502, aux.acc_seg: 85.7813, loss: 0.4627
2023-12-28 17:11:26,772 - mmseg - INFO - Iter [50300/160000]	lr: 4.114e-05, eta: 1 day, 0:23:27, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3153, decode.acc_seg: 87.3957, aux.loss_ce: 0.1540, aux.acc_seg: 85.1137, loss: 0.4693
2023-12-28 17:12:04,707 - mmseg - INFO - Iter [50350/160000]	lr: 4.112e-05, eta: 1 day, 0:22:43, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3150, decode.acc_seg: 87.2724, aux.loss_ce: 0.1530, aux.acc_seg: 85.0093, loss: 0.4680
2023-12-28 17:12:44,967 - mmseg - INFO - Iter [50400/160000]	lr: 4.110e-05, eta: 1 day, 0:22:03, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3303, decode.acc_seg: 86.6551, aux.loss_ce: 0.1616, aux.acc_seg: 84.3056, loss: 0.4919
2023-12-28 17:13:25,713 - mmseg - INFO - Iter [50450/160000]	lr: 4.108e-05, eta: 1 day, 0:21:25, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3216, decode.acc_seg: 87.2875, aux.loss_ce: 0.1549, aux.acc_seg: 85.2404, loss: 0.4765
2023-12-28 17:14:06,418 - mmseg - INFO - Iter [50500/160000]	lr: 4.106e-05, eta: 1 day, 0:20:46, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3275, decode.acc_seg: 86.8992, aux.loss_ce: 0.1605, aux.acc_seg: 84.5289, loss: 0.4880
2023-12-28 17:14:45,659 - mmseg - INFO - Iter [50550/160000]	lr: 4.104e-05, eta: 1 day, 0:20:05, time: 0.786, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2881, decode.acc_seg: 88.3848, aux.loss_ce: 0.1447, aux.acc_seg: 85.8907, loss: 0.4328
2023-12-28 17:15:25,205 - mmseg - INFO - Iter [50600/160000]	lr: 4.103e-05, eta: 1 day, 0:19:24, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3386, decode.acc_seg: 86.2742, aux.loss_ce: 0.1645, aux.acc_seg: 84.0113, loss: 0.5031
2023-12-28 17:16:03,480 - mmseg - INFO - Iter [50650/160000]	lr: 4.101e-05, eta: 1 day, 0:18:40, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3349, decode.acc_seg: 86.5327, aux.loss_ce: 0.1635, aux.acc_seg: 84.4303, loss: 0.4985
2023-12-28 17:16:42,757 - mmseg - INFO - Iter [50700/160000]	lr: 4.099e-05, eta: 1 day, 0:17:58, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3268, decode.acc_seg: 86.9697, aux.loss_ce: 0.1595, aux.acc_seg: 85.0309, loss: 0.4863
2023-12-28 17:17:20,943 - mmseg - INFO - Iter [50750/160000]	lr: 4.097e-05, eta: 1 day, 0:17:14, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3321, decode.acc_seg: 87.0819, aux.loss_ce: 0.1592, aux.acc_seg: 84.9853, loss: 0.4912
2023-12-28 17:18:01,462 - mmseg - INFO - Iter [50800/160000]	lr: 4.095e-05, eta: 1 day, 0:16:35, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3137, decode.acc_seg: 87.3151, aux.loss_ce: 0.1536, aux.acc_seg: 85.1657, loss: 0.4673
2023-12-28 17:18:42,023 - mmseg - INFO - Iter [50850/160000]	lr: 4.093e-05, eta: 1 day, 0:15:56, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3142, decode.acc_seg: 87.5635, aux.loss_ce: 0.1559, aux.acc_seg: 84.9820, loss: 0.4701
2023-12-28 17:19:20,363 - mmseg - INFO - Iter [50900/160000]	lr: 4.091e-05, eta: 1 day, 0:15:13, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3129, decode.acc_seg: 87.1361, aux.loss_ce: 0.1532, aux.acc_seg: 85.0979, loss: 0.4661
2023-12-28 17:20:00,758 - mmseg - INFO - Iter [50950/160000]	lr: 4.089e-05, eta: 1 day, 0:14:34, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3374, decode.acc_seg: 86.5427, aux.loss_ce: 0.1575, aux.acc_seg: 84.9202, loss: 0.4950
2023-12-28 17:20:41,900 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 17:20:41,900 - mmseg - INFO - Iter [51000/160000]	lr: 4.088e-05, eta: 1 day, 0:13:56, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3174, decode.acc_seg: 86.8455, aux.loss_ce: 0.1550, aux.acc_seg: 84.9551, loss: 0.4725
2023-12-28 17:21:21,547 - mmseg - INFO - Iter [51050/160000]	lr: 4.086e-05, eta: 1 day, 0:13:15, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2993, decode.acc_seg: 88.1023, aux.loss_ce: 0.1469, aux.acc_seg: 85.9661, loss: 0.4462
2023-12-28 17:22:00,579 - mmseg - INFO - Iter [51100/160000]	lr: 4.084e-05, eta: 1 day, 0:12:33, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3090, decode.acc_seg: 87.4341, aux.loss_ce: 0.1551, aux.acc_seg: 84.8954, loss: 0.4641
2023-12-28 17:22:39,713 - mmseg - INFO - Iter [51150/160000]	lr: 4.082e-05, eta: 1 day, 0:11:51, time: 0.783, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3272, decode.acc_seg: 86.6408, aux.loss_ce: 0.1584, aux.acc_seg: 84.5482, loss: 0.4856
2023-12-28 17:23:20,514 - mmseg - INFO - Iter [51200/160000]	lr: 4.080e-05, eta: 1 day, 0:11:13, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3020, decode.acc_seg: 87.5695, aux.loss_ce: 0.1483, aux.acc_seg: 85.3498, loss: 0.4503
2023-12-28 17:24:01,084 - mmseg - INFO - Iter [51250/160000]	lr: 4.078e-05, eta: 1 day, 0:10:34, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3141, decode.acc_seg: 87.5016, aux.loss_ce: 0.1573, aux.acc_seg: 84.9768, loss: 0.4715
2023-12-28 17:24:40,359 - mmseg - INFO - Iter [51300/160000]	lr: 4.076e-05, eta: 1 day, 0:09:52, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3257, decode.acc_seg: 86.9765, aux.loss_ce: 0.1595, aux.acc_seg: 84.5524, loss: 0.4851
2023-12-28 17:25:19,200 - mmseg - INFO - Iter [51350/160000]	lr: 4.074e-05, eta: 1 day, 0:09:10, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3227, decode.acc_seg: 87.0497, aux.loss_ce: 0.1522, aux.acc_seg: 85.2268, loss: 0.4749
2023-12-28 17:26:02,562 - mmseg - INFO - Iter [51400/160000]	lr: 4.073e-05, eta: 1 day, 0:08:37, time: 0.867, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3209, decode.acc_seg: 87.0423, aux.loss_ce: 0.1566, aux.acc_seg: 85.0270, loss: 0.4775
2023-12-28 17:26:42,734 - mmseg - INFO - Iter [51450/160000]	lr: 4.071e-05, eta: 1 day, 0:07:57, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3205, decode.acc_seg: 87.0756, aux.loss_ce: 0.1541, aux.acc_seg: 85.0574, loss: 0.4746
2023-12-28 17:27:21,727 - mmseg - INFO - Iter [51500/160000]	lr: 4.069e-05, eta: 1 day, 0:07:15, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3229, decode.acc_seg: 86.9496, aux.loss_ce: 0.1574, aux.acc_seg: 84.8262, loss: 0.4803
2023-12-28 17:28:00,256 - mmseg - INFO - Iter [51550/160000]	lr: 4.067e-05, eta: 1 day, 0:06:32, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3317, decode.acc_seg: 86.5832, aux.loss_ce: 0.1646, aux.acc_seg: 83.8873, loss: 0.4963
2023-12-28 17:28:37,967 - mmseg - INFO - Iter [51600/160000]	lr: 4.065e-05, eta: 1 day, 0:05:47, time: 0.756, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3255, decode.acc_seg: 86.9782, aux.loss_ce: 0.1593, aux.acc_seg: 84.7016, loss: 0.4849
2023-12-28 17:29:16,532 - mmseg - INFO - Iter [51650/160000]	lr: 4.063e-05, eta: 1 day, 0:05:04, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3103, decode.acc_seg: 87.3234, aux.loss_ce: 0.1552, aux.acc_seg: 84.9900, loss: 0.4656
2023-12-28 17:29:56,469 - mmseg - INFO - Iter [51700/160000]	lr: 4.061e-05, eta: 1 day, 0:04:24, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3326, decode.acc_seg: 86.7787, aux.loss_ce: 0.1598, aux.acc_seg: 84.9044, loss: 0.4924
2023-12-28 17:30:37,984 - mmseg - INFO - Iter [51750/160000]	lr: 4.059e-05, eta: 1 day, 0:03:47, time: 0.832, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3251, decode.acc_seg: 86.8919, aux.loss_ce: 0.1567, aux.acc_seg: 84.9892, loss: 0.4819
2023-12-28 17:31:19,704 - mmseg - INFO - Iter [51800/160000]	lr: 4.058e-05, eta: 1 day, 0:03:11, time: 0.834, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3256, decode.acc_seg: 86.9422, aux.loss_ce: 0.1593, aux.acc_seg: 84.9457, loss: 0.4849
2023-12-28 17:32:01,344 - mmseg - INFO - Iter [51850/160000]	lr: 4.056e-05, eta: 1 day, 0:02:34, time: 0.832, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3055, decode.acc_seg: 87.6670, aux.loss_ce: 0.1498, aux.acc_seg: 85.8536, loss: 0.4553
2023-12-28 17:32:43,732 - mmseg - INFO - Iter [51900/160000]	lr: 4.054e-05, eta: 1 day, 0:01:59, time: 0.847, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3093, decode.acc_seg: 87.6933, aux.loss_ce: 0.1512, aux.acc_seg: 85.4089, loss: 0.4605
2023-12-28 17:33:24,327 - mmseg - INFO - Iter [51950/160000]	lr: 4.052e-05, eta: 1 day, 0:01:20, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3053, decode.acc_seg: 87.9287, aux.loss_ce: 0.1501, aux.acc_seg: 85.6808, loss: 0.4554
2023-12-28 17:34:05,034 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 17:34:05,035 - mmseg - INFO - Iter [52000/160000]	lr: 4.050e-05, eta: 1 day, 0:00:41, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3099, decode.acc_seg: 87.3527, aux.loss_ce: 0.1542, aux.acc_seg: 84.8603, loss: 0.4640
2023-12-28 17:34:44,561 - mmseg - INFO - Iter [52050/160000]	lr: 4.048e-05, eta: 1 day, 0:00:00, time: 0.791, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3183, decode.acc_seg: 86.8058, aux.loss_ce: 0.1569, aux.acc_seg: 84.6454, loss: 0.4753
2023-12-28 17:35:25,211 - mmseg - INFO - Iter [52100/160000]	lr: 4.046e-05, eta: 23:59:22, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3148, decode.acc_seg: 87.2122, aux.loss_ce: 0.1527, aux.acc_seg: 85.1503, loss: 0.4675
2023-12-28 17:36:04,057 - mmseg - INFO - Iter [52150/160000]	lr: 4.044e-05, eta: 23:58:39, time: 0.778, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3228, decode.acc_seg: 87.2212, aux.loss_ce: 0.1570, aux.acc_seg: 84.9095, loss: 0.4798
2023-12-28 17:36:42,908 - mmseg - INFO - Iter [52200/160000]	lr: 4.043e-05, eta: 23:57:57, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3111, decode.acc_seg: 87.4106, aux.loss_ce: 0.1520, aux.acc_seg: 85.0364, loss: 0.4630
2023-12-28 17:37:22,962 - mmseg - INFO - Iter [52250/160000]	lr: 4.041e-05, eta: 23:57:17, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3238, decode.acc_seg: 86.9482, aux.loss_ce: 0.1596, aux.acc_seg: 84.6439, loss: 0.4833
2023-12-28 17:38:03,610 - mmseg - INFO - Iter [52300/160000]	lr: 4.039e-05, eta: 23:56:38, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3423, decode.acc_seg: 86.4527, aux.loss_ce: 0.1674, aux.acc_seg: 84.0989, loss: 0.5097
2023-12-28 17:38:43,234 - mmseg - INFO - Iter [52350/160000]	lr: 4.037e-05, eta: 23:55:57, time: 0.792, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3148, decode.acc_seg: 87.5555, aux.loss_ce: 0.1523, aux.acc_seg: 85.5131, loss: 0.4671
2023-12-28 17:39:24,507 - mmseg - INFO - Iter [52400/160000]	lr: 4.035e-05, eta: 23:55:20, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3127, decode.acc_seg: 87.2475, aux.loss_ce: 0.1536, aux.acc_seg: 85.4019, loss: 0.4662
2023-12-28 17:40:04,471 - mmseg - INFO - Iter [52450/160000]	lr: 4.033e-05, eta: 23:54:40, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3358, decode.acc_seg: 86.8851, aux.loss_ce: 0.1611, aux.acc_seg: 84.6259, loss: 0.4969
2023-12-28 17:40:43,888 - mmseg - INFO - Iter [52500/160000]	lr: 4.031e-05, eta: 23:53:58, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3283, decode.acc_seg: 87.3462, aux.loss_ce: 0.1597, aux.acc_seg: 85.0423, loss: 0.4880
2023-12-28 17:41:22,892 - mmseg - INFO - Iter [52550/160000]	lr: 4.029e-05, eta: 23:53:16, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3156, decode.acc_seg: 87.3712, aux.loss_ce: 0.1520, aux.acc_seg: 85.2860, loss: 0.4675
2023-12-28 17:42:03,462 - mmseg - INFO - Iter [52600/160000]	lr: 4.028e-05, eta: 23:52:37, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3005, decode.acc_seg: 87.8800, aux.loss_ce: 0.1459, aux.acc_seg: 85.8392, loss: 0.4465
2023-12-28 17:42:44,186 - mmseg - INFO - Iter [52650/160000]	lr: 4.026e-05, eta: 23:51:59, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3037, decode.acc_seg: 87.7379, aux.loss_ce: 0.1495, aux.acc_seg: 85.5239, loss: 0.4533
2023-12-28 17:43:24,344 - mmseg - INFO - Iter [52700/160000]	lr: 4.024e-05, eta: 23:51:19, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3309, decode.acc_seg: 86.8273, aux.loss_ce: 0.1635, aux.acc_seg: 84.2720, loss: 0.4944
2023-12-28 17:44:05,012 - mmseg - INFO - Iter [52750/160000]	lr: 4.022e-05, eta: 23:50:41, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3291, decode.acc_seg: 86.6199, aux.loss_ce: 0.1577, aux.acc_seg: 84.3761, loss: 0.4868
2023-12-28 17:44:43,843 - mmseg - INFO - Iter [52800/160000]	lr: 4.020e-05, eta: 23:49:58, time: 0.776, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3054, decode.acc_seg: 87.6211, aux.loss_ce: 0.1484, aux.acc_seg: 85.7188, loss: 0.4537
2023-12-28 17:45:22,582 - mmseg - INFO - Iter [52850/160000]	lr: 4.018e-05, eta: 23:49:15, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3152, decode.acc_seg: 86.6502, aux.loss_ce: 0.1513, aux.acc_seg: 84.9892, loss: 0.4665
2023-12-28 17:46:03,772 - mmseg - INFO - Iter [52900/160000]	lr: 4.016e-05, eta: 23:48:38, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3246, decode.acc_seg: 87.1065, aux.loss_ce: 0.1593, aux.acc_seg: 84.9433, loss: 0.4839
2023-12-28 17:46:43,051 - mmseg - INFO - Iter [52950/160000]	lr: 4.014e-05, eta: 23:47:56, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3067, decode.acc_seg: 87.8324, aux.loss_ce: 0.1452, aux.acc_seg: 85.8042, loss: 0.4519
2023-12-28 17:47:22,383 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 17:47:22,384 - mmseg - INFO - Iter [53000/160000]	lr: 4.013e-05, eta: 23:47:15, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3305, decode.acc_seg: 86.6230, aux.loss_ce: 0.1596, aux.acc_seg: 84.7853, loss: 0.4901
2023-12-28 17:48:03,042 - mmseg - INFO - Iter [53050/160000]	lr: 4.011e-05, eta: 23:46:36, time: 0.812, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3288, decode.acc_seg: 86.6964, aux.loss_ce: 0.1626, aux.acc_seg: 84.5179, loss: 0.4914
2023-12-28 17:48:42,919 - mmseg - INFO - Iter [53100/160000]	lr: 4.009e-05, eta: 23:45:56, time: 0.799, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3166, decode.acc_seg: 87.2991, aux.loss_ce: 0.1568, aux.acc_seg: 85.2632, loss: 0.4734
2023-12-28 17:49:24,021 - mmseg - INFO - Iter [53150/160000]	lr: 4.007e-05, eta: 23:45:18, time: 0.821, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3127, decode.acc_seg: 87.6667, aux.loss_ce: 0.1563, aux.acc_seg: 85.3917, loss: 0.4690
2023-12-28 17:50:06,113 - mmseg - INFO - Iter [53200/160000]	lr: 4.005e-05, eta: 23:44:42, time: 0.843, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3237, decode.acc_seg: 86.5364, aux.loss_ce: 0.1592, aux.acc_seg: 84.2702, loss: 0.4829
2023-12-28 17:50:48,532 - mmseg - INFO - Iter [53250/160000]	lr: 4.003e-05, eta: 23:44:07, time: 0.847, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3135, decode.acc_seg: 87.3746, aux.loss_ce: 0.1499, aux.acc_seg: 85.5064, loss: 0.4633
2023-12-28 17:51:30,716 - mmseg - INFO - Iter [53300/160000]	lr: 4.001e-05, eta: 23:43:31, time: 0.844, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3266, decode.acc_seg: 86.8498, aux.loss_ce: 0.1586, aux.acc_seg: 84.8770, loss: 0.4852
2023-12-28 17:52:11,540 - mmseg - INFO - Iter [53350/160000]	lr: 3.999e-05, eta: 23:42:53, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3456, decode.acc_seg: 86.2530, aux.loss_ce: 0.1650, aux.acc_seg: 84.1125, loss: 0.5105
2023-12-28 17:52:50,560 - mmseg - INFO - Iter [53400/160000]	lr: 3.998e-05, eta: 23:42:11, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2909, decode.acc_seg: 88.1336, aux.loss_ce: 0.1422, aux.acc_seg: 85.9962, loss: 0.4330
2023-12-28 17:53:32,464 - mmseg - INFO - Iter [53450/160000]	lr: 3.996e-05, eta: 23:41:35, time: 0.838, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3335, decode.acc_seg: 86.8605, aux.loss_ce: 0.1592, aux.acc_seg: 84.5963, loss: 0.4927
2023-12-28 17:54:11,411 - mmseg - INFO - Iter [53500/160000]	lr: 3.994e-05, eta: 23:40:52, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3120, decode.acc_seg: 87.4011, aux.loss_ce: 0.1534, aux.acc_seg: 85.1309, loss: 0.4654
2023-12-28 17:54:48,391 - mmseg - INFO - Iter [53550/160000]	lr: 3.992e-05, eta: 23:40:06, time: 0.740, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3085, decode.acc_seg: 87.4401, aux.loss_ce: 0.1520, aux.acc_seg: 85.3142, loss: 0.4605
2023-12-28 17:55:29,114 - mmseg - INFO - Iter [53600/160000]	lr: 3.990e-05, eta: 23:39:28, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3019, decode.acc_seg: 87.5998, aux.loss_ce: 0.1481, aux.acc_seg: 85.5299, loss: 0.4500
2023-12-28 17:56:09,850 - mmseg - INFO - Iter [53650/160000]	lr: 3.988e-05, eta: 23:38:49, time: 0.815, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3102, decode.acc_seg: 87.6262, aux.loss_ce: 0.1543, aux.acc_seg: 85.3760, loss: 0.4646
2023-12-28 17:56:50,520 - mmseg - INFO - Iter [53700/160000]	lr: 3.986e-05, eta: 23:38:10, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3275, decode.acc_seg: 86.6439, aux.loss_ce: 0.1617, aux.acc_seg: 83.9737, loss: 0.4892
2023-12-28 17:57:31,177 - mmseg - INFO - Iter [53750/160000]	lr: 3.984e-05, eta: 23:37:31, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3320, decode.acc_seg: 86.9140, aux.loss_ce: 0.1565, aux.acc_seg: 84.8039, loss: 0.4885
2023-12-28 17:58:12,055 - mmseg - INFO - Iter [53800/160000]	lr: 3.983e-05, eta: 23:36:53, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3158, decode.acc_seg: 87.5107, aux.loss_ce: 0.1564, aux.acc_seg: 84.9279, loss: 0.4722
2023-12-28 17:58:49,678 - mmseg - INFO - Iter [53850/160000]	lr: 3.981e-05, eta: 23:36:08, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3133, decode.acc_seg: 87.3441, aux.loss_ce: 0.1520, aux.acc_seg: 85.4220, loss: 0.4653
2023-12-28 17:59:29,012 - mmseg - INFO - Iter [53900/160000]	lr: 3.979e-05, eta: 23:35:27, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3279, decode.acc_seg: 87.2031, aux.loss_ce: 0.1595, aux.acc_seg: 84.8464, loss: 0.4874
2023-12-28 18:00:10,043 - mmseg - INFO - Iter [53950/160000]	lr: 3.977e-05, eta: 23:34:49, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3025, decode.acc_seg: 87.6207, aux.loss_ce: 0.1494, aux.acc_seg: 85.1488, loss: 0.4519
2023-12-28 18:00:50,305 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 18:00:50,305 - mmseg - INFO - Iter [54000/160000]	lr: 3.975e-05, eta: 23:34:09, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3097, decode.acc_seg: 87.7823, aux.loss_ce: 0.1555, aux.acc_seg: 85.1084, loss: 0.4652
2023-12-28 18:01:31,324 - mmseg - INFO - Iter [54050/160000]	lr: 3.973e-05, eta: 23:33:31, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3183, decode.acc_seg: 87.1136, aux.loss_ce: 0.1556, aux.acc_seg: 85.1004, loss: 0.4739
2023-12-28 18:02:11,017 - mmseg - INFO - Iter [54100/160000]	lr: 3.971e-05, eta: 23:32:51, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3117, decode.acc_seg: 87.5724, aux.loss_ce: 0.1502, aux.acc_seg: 85.5803, loss: 0.4619
2023-12-28 18:02:50,486 - mmseg - INFO - Iter [54150/160000]	lr: 3.969e-05, eta: 23:32:10, time: 0.790, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3212, decode.acc_seg: 87.1651, aux.loss_ce: 0.1562, aux.acc_seg: 85.2212, loss: 0.4774
2023-12-28 18:03:30,940 - mmseg - INFO - Iter [54200/160000]	lr: 3.968e-05, eta: 23:31:30, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3248, decode.acc_seg: 87.0147, aux.loss_ce: 0.1577, aux.acc_seg: 84.9169, loss: 0.4825
2023-12-28 18:04:11,470 - mmseg - INFO - Iter [54250/160000]	lr: 3.966e-05, eta: 23:30:51, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3349, decode.acc_seg: 86.5224, aux.loss_ce: 0.1641, aux.acc_seg: 84.5190, loss: 0.4990
2023-12-28 18:04:52,197 - mmseg - INFO - Iter [54300/160000]	lr: 3.964e-05, eta: 23:30:13, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2988, decode.acc_seg: 87.8792, aux.loss_ce: 0.1448, aux.acc_seg: 85.8571, loss: 0.4435
2023-12-28 18:05:33,626 - mmseg - INFO - Iter [54350/160000]	lr: 3.962e-05, eta: 23:29:35, time: 0.830, data_time: 0.055, memory: 18256, decode.loss_ce: 0.3064, decode.acc_seg: 87.8992, aux.loss_ce: 0.1495, aux.acc_seg: 85.7213, loss: 0.4559
2023-12-28 18:06:14,597 - mmseg - INFO - Iter [54400/160000]	lr: 3.960e-05, eta: 23:28:57, time: 0.818, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2944, decode.acc_seg: 88.3962, aux.loss_ce: 0.1467, aux.acc_seg: 85.9196, loss: 0.4411
2023-12-28 18:06:55,539 - mmseg - INFO - Iter [54450/160000]	lr: 3.958e-05, eta: 23:28:19, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2986, decode.acc_seg: 87.7921, aux.loss_ce: 0.1458, aux.acc_seg: 85.7431, loss: 0.4444
2023-12-28 18:07:35,196 - mmseg - INFO - Iter [54500/160000]	lr: 3.956e-05, eta: 23:27:38, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3200, decode.acc_seg: 87.1506, aux.loss_ce: 0.1573, aux.acc_seg: 84.7704, loss: 0.4772
2023-12-28 18:08:14,447 - mmseg - INFO - Iter [54550/160000]	lr: 3.954e-05, eta: 23:26:57, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3051, decode.acc_seg: 87.3092, aux.loss_ce: 0.1510, aux.acc_seg: 85.2771, loss: 0.4561
2023-12-28 18:08:54,720 - mmseg - INFO - Iter [54600/160000]	lr: 3.953e-05, eta: 23:26:17, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3223, decode.acc_seg: 86.9905, aux.loss_ce: 0.1657, aux.acc_seg: 84.1274, loss: 0.4880
2023-12-28 18:09:34,746 - mmseg - INFO - Iter [54650/160000]	lr: 3.951e-05, eta: 23:25:37, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3218, decode.acc_seg: 87.4774, aux.loss_ce: 0.1575, aux.acc_seg: 85.1520, loss: 0.4793
2023-12-28 18:10:15,938 - mmseg - INFO - Iter [54700/160000]	lr: 3.949e-05, eta: 23:24:59, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3011, decode.acc_seg: 87.8548, aux.loss_ce: 0.1498, aux.acc_seg: 85.5998, loss: 0.4510
2023-12-28 18:10:55,015 - mmseg - INFO - Iter [54750/160000]	lr: 3.947e-05, eta: 23:24:17, time: 0.783, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3122, decode.acc_seg: 87.2939, aux.loss_ce: 0.1539, aux.acc_seg: 84.9773, loss: 0.4661
2023-12-28 18:11:35,518 - mmseg - INFO - Iter [54800/160000]	lr: 3.945e-05, eta: 23:23:38, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3242, decode.acc_seg: 86.9546, aux.loss_ce: 0.1564, aux.acc_seg: 84.8486, loss: 0.4806
2023-12-28 18:12:16,271 - mmseg - INFO - Iter [54850/160000]	lr: 3.943e-05, eta: 23:23:00, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3263, decode.acc_seg: 87.1729, aux.loss_ce: 0.1576, aux.acc_seg: 85.1288, loss: 0.4839
2023-12-28 18:12:56,625 - mmseg - INFO - Iter [54900/160000]	lr: 3.941e-05, eta: 23:22:20, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3244, decode.acc_seg: 87.1690, aux.loss_ce: 0.1575, aux.acc_seg: 85.2126, loss: 0.4819
2023-12-28 18:13:37,187 - mmseg - INFO - Iter [54950/160000]	lr: 3.939e-05, eta: 23:21:41, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3160, decode.acc_seg: 87.4260, aux.loss_ce: 0.1565, aux.acc_seg: 84.9262, loss: 0.4725
2023-12-28 18:14:16,200 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 18:14:16,201 - mmseg - INFO - Iter [55000/160000]	lr: 3.938e-05, eta: 23:20:59, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2992, decode.acc_seg: 87.8151, aux.loss_ce: 0.1455, aux.acc_seg: 85.7252, loss: 0.4448
2023-12-28 18:14:57,188 - mmseg - INFO - Iter [55050/160000]	lr: 3.936e-05, eta: 23:20:21, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3162, decode.acc_seg: 87.1827, aux.loss_ce: 0.1522, aux.acc_seg: 84.9180, loss: 0.4684
2023-12-28 18:15:37,488 - mmseg - INFO - Iter [55100/160000]	lr: 3.934e-05, eta: 23:19:42, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3060, decode.acc_seg: 87.7990, aux.loss_ce: 0.1515, aux.acc_seg: 85.4672, loss: 0.4576
2023-12-28 18:16:16,251 - mmseg - INFO - Iter [55150/160000]	lr: 3.932e-05, eta: 23:18:59, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3039, decode.acc_seg: 87.8101, aux.loss_ce: 0.1497, aux.acc_seg: 85.4835, loss: 0.4536
2023-12-28 18:16:55,561 - mmseg - INFO - Iter [55200/160000]	lr: 3.930e-05, eta: 23:18:18, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3053, decode.acc_seg: 87.4484, aux.loss_ce: 0.1514, aux.acc_seg: 85.1436, loss: 0.4566
2023-12-28 18:17:34,118 - mmseg - INFO - Iter [55250/160000]	lr: 3.928e-05, eta: 23:17:35, time: 0.771, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3074, decode.acc_seg: 87.5491, aux.loss_ce: 0.1527, aux.acc_seg: 85.2273, loss: 0.4601
2023-12-28 18:18:14,937 - mmseg - INFO - Iter [55300/160000]	lr: 3.926e-05, eta: 23:16:56, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3072, decode.acc_seg: 87.7337, aux.loss_ce: 0.1511, aux.acc_seg: 85.5390, loss: 0.4583
2023-12-28 18:18:55,977 - mmseg - INFO - Iter [55350/160000]	lr: 3.924e-05, eta: 23:16:18, time: 0.819, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3289, decode.acc_seg: 86.9745, aux.loss_ce: 0.1582, aux.acc_seg: 84.5316, loss: 0.4871
2023-12-28 18:19:36,865 - mmseg - INFO - Iter [55400/160000]	lr: 3.923e-05, eta: 23:15:40, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3175, decode.acc_seg: 86.8328, aux.loss_ce: 0.1542, aux.acc_seg: 84.9655, loss: 0.4717
2023-12-28 18:20:16,340 - mmseg - INFO - Iter [55450/160000]	lr: 3.921e-05, eta: 23:14:59, time: 0.790, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3152, decode.acc_seg: 87.5548, aux.loss_ce: 0.1565, aux.acc_seg: 84.8370, loss: 0.4717
2023-12-28 18:20:55,577 - mmseg - INFO - Iter [55500/160000]	lr: 3.919e-05, eta: 23:14:17, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3197, decode.acc_seg: 87.2364, aux.loss_ce: 0.1563, aux.acc_seg: 84.9801, loss: 0.4760
2023-12-28 18:21:36,287 - mmseg - INFO - Iter [55550/160000]	lr: 3.917e-05, eta: 23:13:38, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3172, decode.acc_seg: 86.9936, aux.loss_ce: 0.1537, aux.acc_seg: 84.9227, loss: 0.4709
2023-12-28 18:22:17,927 - mmseg - INFO - Iter [55600/160000]	lr: 3.915e-05, eta: 23:13:02, time: 0.834, data_time: 0.056, memory: 18256, decode.loss_ce: 0.2918, decode.acc_seg: 87.7745, aux.loss_ce: 0.1438, aux.acc_seg: 85.7948, loss: 0.4356
2023-12-28 18:22:56,611 - mmseg - INFO - Iter [55650/160000]	lr: 3.913e-05, eta: 23:12:19, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3335, decode.acc_seg: 86.8509, aux.loss_ce: 0.1650, aux.acc_seg: 84.2446, loss: 0.4985
2023-12-28 18:23:36,821 - mmseg - INFO - Iter [55700/160000]	lr: 3.911e-05, eta: 23:11:39, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3073, decode.acc_seg: 87.8567, aux.loss_ce: 0.1508, aux.acc_seg: 85.5848, loss: 0.4582
2023-12-28 18:24:17,518 - mmseg - INFO - Iter [55750/160000]	lr: 3.909e-05, eta: 23:11:00, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2939, decode.acc_seg: 88.3099, aux.loss_ce: 0.1453, aux.acc_seg: 86.0935, loss: 0.4391
2023-12-28 18:24:54,756 - mmseg - INFO - Iter [55800/160000]	lr: 3.908e-05, eta: 23:10:15, time: 0.746, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3078, decode.acc_seg: 87.3562, aux.loss_ce: 0.1526, aux.acc_seg: 84.8833, loss: 0.4603
2023-12-28 18:25:35,380 - mmseg - INFO - Iter [55850/160000]	lr: 3.906e-05, eta: 23:09:36, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3101, decode.acc_seg: 87.6342, aux.loss_ce: 0.1547, aux.acc_seg: 84.9921, loss: 0.4647
2023-12-28 18:26:13,651 - mmseg - INFO - Iter [55900/160000]	lr: 3.904e-05, eta: 23:08:53, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3195, decode.acc_seg: 87.1619, aux.loss_ce: 0.1557, aux.acc_seg: 85.0247, loss: 0.4752
2023-12-28 18:26:53,156 - mmseg - INFO - Iter [55950/160000]	lr: 3.902e-05, eta: 23:08:12, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3016, decode.acc_seg: 87.8568, aux.loss_ce: 0.1500, aux.acc_seg: 85.7403, loss: 0.4517
2023-12-28 18:27:32,584 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 18:27:32,584 - mmseg - INFO - Iter [56000/160000]	lr: 3.900e-05, eta: 23:07:31, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2979, decode.acc_seg: 88.1278, aux.loss_ce: 0.1480, aux.acc_seg: 85.8586, loss: 0.4459
2023-12-28 18:28:10,178 - mmseg - INFO - Iter [56050/160000]	lr: 3.898e-05, eta: 23:06:46, time: 0.752, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2981, decode.acc_seg: 87.9527, aux.loss_ce: 0.1482, aux.acc_seg: 85.8357, loss: 0.4463
2023-12-28 18:28:49,514 - mmseg - INFO - Iter [56100/160000]	lr: 3.896e-05, eta: 23:06:05, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3145, decode.acc_seg: 87.5255, aux.loss_ce: 0.1549, aux.acc_seg: 85.1409, loss: 0.4694
2023-12-28 18:29:28,760 - mmseg - INFO - Iter [56150/160000]	lr: 3.894e-05, eta: 23:05:24, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3118, decode.acc_seg: 87.5120, aux.loss_ce: 0.1518, aux.acc_seg: 85.4137, loss: 0.4637
2023-12-28 18:30:09,701 - mmseg - INFO - Iter [56200/160000]	lr: 3.893e-05, eta: 23:04:45, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3089, decode.acc_seg: 87.3059, aux.loss_ce: 0.1516, aux.acc_seg: 85.4633, loss: 0.4606
2023-12-28 18:30:49,878 - mmseg - INFO - Iter [56250/160000]	lr: 3.891e-05, eta: 23:04:06, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3046, decode.acc_seg: 87.7117, aux.loss_ce: 0.1436, aux.acc_seg: 85.8761, loss: 0.4482
2023-12-28 18:31:31,129 - mmseg - INFO - Iter [56300/160000]	lr: 3.889e-05, eta: 23:03:28, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3341, decode.acc_seg: 86.5624, aux.loss_ce: 0.1581, aux.acc_seg: 84.7051, loss: 0.4922
2023-12-28 18:32:12,121 - mmseg - INFO - Iter [56350/160000]	lr: 3.887e-05, eta: 23:02:50, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3188, decode.acc_seg: 87.3366, aux.loss_ce: 0.1555, aux.acc_seg: 85.2099, loss: 0.4743
2023-12-28 18:32:52,353 - mmseg - INFO - Iter [56400/160000]	lr: 3.885e-05, eta: 23:02:10, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3180, decode.acc_seg: 87.4657, aux.loss_ce: 0.1525, aux.acc_seg: 85.4589, loss: 0.4705
2023-12-28 18:33:33,123 - mmseg - INFO - Iter [56450/160000]	lr: 3.883e-05, eta: 23:01:31, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3159, decode.acc_seg: 87.4339, aux.loss_ce: 0.1520, aux.acc_seg: 85.3769, loss: 0.4679
2023-12-28 18:34:13,246 - mmseg - INFO - Iter [56500/160000]	lr: 3.881e-05, eta: 23:00:51, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2964, decode.acc_seg: 87.9604, aux.loss_ce: 0.1435, aux.acc_seg: 86.2163, loss: 0.4399
2023-12-28 18:34:53,622 - mmseg - INFO - Iter [56550/160000]	lr: 3.879e-05, eta: 23:00:12, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3209, decode.acc_seg: 87.5056, aux.loss_ce: 0.1549, aux.acc_seg: 85.5388, loss: 0.4757
2023-12-28 18:35:34,515 - mmseg - INFO - Iter [56600/160000]	lr: 3.878e-05, eta: 22:59:34, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3117, decode.acc_seg: 87.5260, aux.loss_ce: 0.1526, aux.acc_seg: 85.3268, loss: 0.4643
2023-12-28 18:36:11,828 - mmseg - INFO - Iter [56650/160000]	lr: 3.876e-05, eta: 22:58:49, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3035, decode.acc_seg: 87.5642, aux.loss_ce: 0.1472, aux.acc_seg: 85.5394, loss: 0.4506
2023-12-28 18:36:52,174 - mmseg - INFO - Iter [56700/160000]	lr: 3.874e-05, eta: 22:58:09, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3138, decode.acc_seg: 87.0988, aux.loss_ce: 0.1483, aux.acc_seg: 85.2004, loss: 0.4621
2023-12-28 18:37:31,046 - mmseg - INFO - Iter [56750/160000]	lr: 3.872e-05, eta: 22:57:27, time: 0.778, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3199, decode.acc_seg: 87.4368, aux.loss_ce: 0.1561, aux.acc_seg: 85.1372, loss: 0.4759
2023-12-28 18:38:10,877 - mmseg - INFO - Iter [56800/160000]	lr: 3.870e-05, eta: 22:56:47, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3079, decode.acc_seg: 87.9200, aux.loss_ce: 0.1502, aux.acc_seg: 85.7083, loss: 0.4581
2023-12-28 18:38:53,104 - mmseg - INFO - Iter [56850/160000]	lr: 3.868e-05, eta: 22:56:11, time: 0.844, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3197, decode.acc_seg: 87.3334, aux.loss_ce: 0.1558, aux.acc_seg: 85.0244, loss: 0.4755
2023-12-28 18:39:33,100 - mmseg - INFO - Iter [56900/160000]	lr: 3.866e-05, eta: 22:55:31, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3240, decode.acc_seg: 87.1418, aux.loss_ce: 0.1565, aux.acc_seg: 85.2421, loss: 0.4805
2023-12-28 18:40:13,094 - mmseg - INFO - Iter [56950/160000]	lr: 3.864e-05, eta: 22:54:50, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3200, decode.acc_seg: 87.4563, aux.loss_ce: 0.1569, aux.acc_seg: 85.2791, loss: 0.4769
2023-12-28 18:40:51,357 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 18:40:51,358 - mmseg - INFO - Iter [57000/160000]	lr: 3.863e-05, eta: 22:54:07, time: 0.766, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3047, decode.acc_seg: 87.9631, aux.loss_ce: 0.1504, aux.acc_seg: 85.7374, loss: 0.4551
2023-12-28 18:41:33,204 - mmseg - INFO - Iter [57050/160000]	lr: 3.861e-05, eta: 22:53:31, time: 0.836, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3124, decode.acc_seg: 87.4229, aux.loss_ce: 0.1513, aux.acc_seg: 85.3932, loss: 0.4637
2023-12-28 18:42:13,029 - mmseg - INFO - Iter [57100/160000]	lr: 3.859e-05, eta: 22:52:50, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3071, decode.acc_seg: 87.5118, aux.loss_ce: 0.1490, aux.acc_seg: 85.3678, loss: 0.4561
2023-12-28 18:42:52,238 - mmseg - INFO - Iter [57150/160000]	lr: 3.857e-05, eta: 22:52:09, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3034, decode.acc_seg: 87.7476, aux.loss_ce: 0.1513, aux.acc_seg: 85.3066, loss: 0.4547
2023-12-28 18:43:32,369 - mmseg - INFO - Iter [57200/160000]	lr: 3.855e-05, eta: 22:51:29, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2946, decode.acc_seg: 88.0493, aux.loss_ce: 0.1459, aux.acc_seg: 85.5547, loss: 0.4405
2023-12-28 18:44:11,777 - mmseg - INFO - Iter [57250/160000]	lr: 3.853e-05, eta: 22:50:48, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2953, decode.acc_seg: 87.8338, aux.loss_ce: 0.1468, aux.acc_seg: 85.5668, loss: 0.4421
2023-12-28 18:44:52,732 - mmseg - INFO - Iter [57300/160000]	lr: 3.851e-05, eta: 22:50:09, time: 0.820, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2973, decode.acc_seg: 87.8609, aux.loss_ce: 0.1451, aux.acc_seg: 85.8088, loss: 0.4424
2023-12-28 18:45:32,069 - mmseg - INFO - Iter [57350/160000]	lr: 3.849e-05, eta: 22:49:28, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2930, decode.acc_seg: 88.6064, aux.loss_ce: 0.1460, aux.acc_seg: 86.3706, loss: 0.4390
2023-12-28 18:46:11,138 - mmseg - INFO - Iter [57400/160000]	lr: 3.848e-05, eta: 22:48:46, time: 0.782, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2748, decode.acc_seg: 88.7028, aux.loss_ce: 0.1395, aux.acc_seg: 86.0550, loss: 0.4143
2023-12-28 18:46:52,587 - mmseg - INFO - Iter [57450/160000]	lr: 3.846e-05, eta: 22:48:09, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2908, decode.acc_seg: 88.1946, aux.loss_ce: 0.1445, aux.acc_seg: 85.9277, loss: 0.4353
2023-12-28 18:47:32,883 - mmseg - INFO - Iter [57500/160000]	lr: 3.844e-05, eta: 22:47:29, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2822, decode.acc_seg: 88.0908, aux.loss_ce: 0.1396, aux.acc_seg: 85.9735, loss: 0.4217
2023-12-28 18:48:10,973 - mmseg - INFO - Iter [57550/160000]	lr: 3.842e-05, eta: 22:46:46, time: 0.762, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3070, decode.acc_seg: 87.5057, aux.loss_ce: 0.1504, aux.acc_seg: 85.2912, loss: 0.4574
2023-12-28 18:48:49,312 - mmseg - INFO - Iter [57600/160000]	lr: 3.840e-05, eta: 22:46:03, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2990, decode.acc_seg: 87.9663, aux.loss_ce: 0.1469, aux.acc_seg: 85.6944, loss: 0.4459
2023-12-28 18:49:28,942 - mmseg - INFO - Iter [57650/160000]	lr: 3.838e-05, eta: 22:45:22, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3217, decode.acc_seg: 87.2771, aux.loss_ce: 0.1586, aux.acc_seg: 84.9905, loss: 0.4803
2023-12-28 18:50:08,569 - mmseg - INFO - Iter [57700/160000]	lr: 3.836e-05, eta: 22:44:42, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2957, decode.acc_seg: 87.8520, aux.loss_ce: 0.1464, aux.acc_seg: 85.7848, loss: 0.4421
2023-12-28 18:50:47,981 - mmseg - INFO - Iter [57750/160000]	lr: 3.834e-05, eta: 22:44:00, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3084, decode.acc_seg: 87.6223, aux.loss_ce: 0.1543, aux.acc_seg: 85.2208, loss: 0.4626
2023-12-28 18:51:27,896 - mmseg - INFO - Iter [57800/160000]	lr: 3.833e-05, eta: 22:43:20, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3113, decode.acc_seg: 87.6619, aux.loss_ce: 0.1526, aux.acc_seg: 85.5553, loss: 0.4639
2023-12-28 18:52:08,368 - mmseg - INFO - Iter [57850/160000]	lr: 3.831e-05, eta: 22:42:41, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3043, decode.acc_seg: 87.5073, aux.loss_ce: 0.1536, aux.acc_seg: 85.1084, loss: 0.4579
2023-12-28 18:52:46,963 - mmseg - INFO - Iter [57900/160000]	lr: 3.829e-05, eta: 22:41:58, time: 0.772, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3048, decode.acc_seg: 88.1249, aux.loss_ce: 0.1518, aux.acc_seg: 85.8325, loss: 0.4566
2023-12-28 18:53:27,536 - mmseg - INFO - Iter [57950/160000]	lr: 3.827e-05, eta: 22:41:19, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3185, decode.acc_seg: 87.4105, aux.loss_ce: 0.1549, aux.acc_seg: 85.0464, loss: 0.4734
2023-12-28 18:54:08,665 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 18:54:08,665 - mmseg - INFO - Iter [58000/160000]	lr: 3.825e-05, eta: 22:40:41, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3062, decode.acc_seg: 87.5839, aux.loss_ce: 0.1496, aux.acc_seg: 85.2939, loss: 0.4558
2023-12-28 18:54:48,455 - mmseg - INFO - Iter [58050/160000]	lr: 3.823e-05, eta: 22:40:01, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2987, decode.acc_seg: 87.9853, aux.loss_ce: 0.1491, aux.acc_seg: 85.3683, loss: 0.4478
2023-12-28 18:55:30,555 - mmseg - INFO - Iter [58100/160000]	lr: 3.821e-05, eta: 22:39:25, time: 0.842, data_time: 0.053, memory: 18256, decode.loss_ce: 0.3036, decode.acc_seg: 87.2488, aux.loss_ce: 0.1498, aux.acc_seg: 85.0533, loss: 0.4533
2023-12-28 18:56:10,177 - mmseg - INFO - Iter [58150/160000]	lr: 3.819e-05, eta: 22:38:44, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2961, decode.acc_seg: 88.1904, aux.loss_ce: 0.1428, aux.acc_seg: 86.3354, loss: 0.4390
2023-12-28 18:56:48,150 - mmseg - INFO - Iter [58200/160000]	lr: 3.818e-05, eta: 22:38:00, time: 0.758, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2817, decode.acc_seg: 88.0615, aux.loss_ce: 0.1376, aux.acc_seg: 86.1713, loss: 0.4193
2023-12-28 18:57:28,116 - mmseg - INFO - Iter [58250/160000]	lr: 3.816e-05, eta: 22:37:20, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3189, decode.acc_seg: 87.3875, aux.loss_ce: 0.1518, aux.acc_seg: 85.4843, loss: 0.4707
2023-12-28 18:58:09,088 - mmseg - INFO - Iter [58300/160000]	lr: 3.814e-05, eta: 22:36:42, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2880, decode.acc_seg: 88.5396, aux.loss_ce: 0.1417, aux.acc_seg: 86.4807, loss: 0.4297
2023-12-28 18:58:49,188 - mmseg - INFO - Iter [58350/160000]	lr: 3.812e-05, eta: 22:36:02, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2766, decode.acc_seg: 88.8316, aux.loss_ce: 0.1366, aux.acc_seg: 86.6918, loss: 0.4132
2023-12-28 18:59:28,496 - mmseg - INFO - Iter [58400/160000]	lr: 3.810e-05, eta: 22:35:21, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2828, decode.acc_seg: 88.7991, aux.loss_ce: 0.1452, aux.acc_seg: 86.3332, loss: 0.4280
2023-12-28 19:00:08,646 - mmseg - INFO - Iter [58450/160000]	lr: 3.808e-05, eta: 22:34:41, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2901, decode.acc_seg: 88.2921, aux.loss_ce: 0.1493, aux.acc_seg: 85.6828, loss: 0.4394
2023-12-28 19:00:49,256 - mmseg - INFO - Iter [58500/160000]	lr: 3.806e-05, eta: 22:34:02, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2905, decode.acc_seg: 88.0470, aux.loss_ce: 0.1454, aux.acc_seg: 85.6465, loss: 0.4360
2023-12-28 19:01:31,202 - mmseg - INFO - Iter [58550/160000]	lr: 3.804e-05, eta: 22:33:25, time: 0.840, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2811, decode.acc_seg: 88.7281, aux.loss_ce: 0.1384, aux.acc_seg: 86.6710, loss: 0.4195
2023-12-28 19:02:11,843 - mmseg - INFO - Iter [58600/160000]	lr: 3.803e-05, eta: 22:32:46, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3009, decode.acc_seg: 87.7502, aux.loss_ce: 0.1461, aux.acc_seg: 85.9403, loss: 0.4470
2023-12-28 19:02:52,388 - mmseg - INFO - Iter [58650/160000]	lr: 3.801e-05, eta: 22:32:07, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3036, decode.acc_seg: 87.8763, aux.loss_ce: 0.1472, aux.acc_seg: 85.8602, loss: 0.4508
2023-12-28 19:03:32,826 - mmseg - INFO - Iter [58700/160000]	lr: 3.799e-05, eta: 22:31:28, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2962, decode.acc_seg: 88.1573, aux.loss_ce: 0.1464, aux.acc_seg: 85.9774, loss: 0.4426
2023-12-28 19:04:14,285 - mmseg - INFO - Iter [58750/160000]	lr: 3.797e-05, eta: 22:30:50, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2993, decode.acc_seg: 87.8437, aux.loss_ce: 0.1461, aux.acc_seg: 85.8304, loss: 0.4454
2023-12-28 19:04:56,344 - mmseg - INFO - Iter [58800/160000]	lr: 3.795e-05, eta: 22:30:14, time: 0.840, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3000, decode.acc_seg: 87.9623, aux.loss_ce: 0.1463, aux.acc_seg: 85.7321, loss: 0.4463
2023-12-28 19:05:38,766 - mmseg - INFO - Iter [58850/160000]	lr: 3.793e-05, eta: 22:29:38, time: 0.849, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2950, decode.acc_seg: 87.9624, aux.loss_ce: 0.1470, aux.acc_seg: 85.7749, loss: 0.4420
2023-12-28 19:06:19,212 - mmseg - INFO - Iter [58900/160000]	lr: 3.791e-05, eta: 22:28:58, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3256, decode.acc_seg: 86.8347, aux.loss_ce: 0.1624, aux.acc_seg: 84.2790, loss: 0.4880
2023-12-28 19:07:00,247 - mmseg - INFO - Iter [58950/160000]	lr: 3.789e-05, eta: 22:28:20, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3126, decode.acc_seg: 87.6348, aux.loss_ce: 0.1526, aux.acc_seg: 85.5725, loss: 0.4652
2023-12-28 19:07:41,643 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 19:07:41,644 - mmseg - INFO - Iter [59000/160000]	lr: 3.788e-05, eta: 22:27:42, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3262, decode.acc_seg: 87.0941, aux.loss_ce: 0.1532, aux.acc_seg: 85.2355, loss: 0.4794
2023-12-28 19:08:21,255 - mmseg - INFO - Iter [59050/160000]	lr: 3.786e-05, eta: 22:27:02, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2920, decode.acc_seg: 88.2997, aux.loss_ce: 0.1441, aux.acc_seg: 86.2849, loss: 0.4361
2023-12-28 19:09:02,262 - mmseg - INFO - Iter [59100/160000]	lr: 3.784e-05, eta: 22:26:23, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3065, decode.acc_seg: 87.7624, aux.loss_ce: 0.1487, aux.acc_seg: 85.9905, loss: 0.4553
2023-12-28 19:09:42,043 - mmseg - INFO - Iter [59150/160000]	lr: 3.782e-05, eta: 22:25:43, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2984, decode.acc_seg: 87.9915, aux.loss_ce: 0.1450, aux.acc_seg: 86.0086, loss: 0.4434
2023-12-28 19:10:23,207 - mmseg - INFO - Iter [59200/160000]	lr: 3.780e-05, eta: 22:25:05, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3033, decode.acc_seg: 88.1333, aux.loss_ce: 0.1505, aux.acc_seg: 85.8863, loss: 0.4539
2023-12-28 19:11:04,306 - mmseg - INFO - Iter [59250/160000]	lr: 3.778e-05, eta: 22:24:27, time: 0.823, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3170, decode.acc_seg: 86.8432, aux.loss_ce: 0.1548, aux.acc_seg: 84.9929, loss: 0.4718
2023-12-28 19:11:43,534 - mmseg - INFO - Iter [59300/160000]	lr: 3.776e-05, eta: 22:23:45, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3069, decode.acc_seg: 87.6446, aux.loss_ce: 0.1527, aux.acc_seg: 85.5726, loss: 0.4596
2023-12-28 19:12:24,198 - mmseg - INFO - Iter [59350/160000]	lr: 3.774e-05, eta: 22:23:06, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3081, decode.acc_seg: 87.2050, aux.loss_ce: 0.1466, aux.acc_seg: 85.2740, loss: 0.4547
2023-12-28 19:13:07,654 - mmseg - INFO - Iter [59400/160000]	lr: 3.773e-05, eta: 22:22:32, time: 0.868, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2846, decode.acc_seg: 88.4846, aux.loss_ce: 0.1426, aux.acc_seg: 86.2565, loss: 0.4272
2023-12-28 19:13:49,028 - mmseg - INFO - Iter [59450/160000]	lr: 3.771e-05, eta: 22:21:54, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2945, decode.acc_seg: 87.7181, aux.loss_ce: 0.1434, aux.acc_seg: 85.4882, loss: 0.4380
2023-12-28 19:14:30,699 - mmseg - INFO - Iter [59500/160000]	lr: 3.769e-05, eta: 22:21:17, time: 0.833, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2725, decode.acc_seg: 89.0687, aux.loss_ce: 0.1353, aux.acc_seg: 86.8704, loss: 0.4078
2023-12-28 19:15:11,962 - mmseg - INFO - Iter [59550/160000]	lr: 3.767e-05, eta: 22:20:39, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2822, decode.acc_seg: 88.5001, aux.loss_ce: 0.1432, aux.acc_seg: 85.9155, loss: 0.4253
2023-12-28 19:15:50,975 - mmseg - INFO - Iter [59600/160000]	lr: 3.765e-05, eta: 22:19:57, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3019, decode.acc_seg: 87.7168, aux.loss_ce: 0.1480, aux.acc_seg: 85.6050, loss: 0.4499
2023-12-28 19:16:29,825 - mmseg - INFO - Iter [59650/160000]	lr: 3.763e-05, eta: 22:19:15, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2935, decode.acc_seg: 87.8330, aux.loss_ce: 0.1441, aux.acc_seg: 85.6935, loss: 0.4376
2023-12-28 19:17:09,195 - mmseg - INFO - Iter [59700/160000]	lr: 3.761e-05, eta: 22:18:34, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3126, decode.acc_seg: 87.6376, aux.loss_ce: 0.1553, aux.acc_seg: 85.1290, loss: 0.4680
2023-12-28 19:17:47,996 - mmseg - INFO - Iter [59750/160000]	lr: 3.759e-05, eta: 22:17:52, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2972, decode.acc_seg: 87.7537, aux.loss_ce: 0.1436, aux.acc_seg: 85.8858, loss: 0.4407
2023-12-28 19:18:27,182 - mmseg - INFO - Iter [59800/160000]	lr: 3.758e-05, eta: 22:17:10, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2855, decode.acc_seg: 88.5412, aux.loss_ce: 0.1425, aux.acc_seg: 86.0415, loss: 0.4280
2023-12-28 19:19:07,849 - mmseg - INFO - Iter [59850/160000]	lr: 3.756e-05, eta: 22:16:31, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2954, decode.acc_seg: 87.9326, aux.loss_ce: 0.1446, aux.acc_seg: 85.9054, loss: 0.4400
2023-12-28 19:19:49,089 - mmseg - INFO - Iter [59900/160000]	lr: 3.754e-05, eta: 22:15:53, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3024, decode.acc_seg: 87.5294, aux.loss_ce: 0.1479, aux.acc_seg: 85.5600, loss: 0.4503
2023-12-28 19:20:30,684 - mmseg - INFO - Iter [59950/160000]	lr: 3.752e-05, eta: 22:15:16, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3072, decode.acc_seg: 87.9078, aux.loss_ce: 0.1472, aux.acc_seg: 85.6730, loss: 0.4544
2023-12-28 19:21:11,989 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 19:21:11,990 - mmseg - INFO - Iter [60000/160000]	lr: 3.750e-05, eta: 22:14:38, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3034, decode.acc_seg: 88.1219, aux.loss_ce: 0.1468, aux.acc_seg: 85.9216, loss: 0.4502
2023-12-28 19:21:52,690 - mmseg - INFO - Iter [60050/160000]	lr: 3.748e-05, eta: 22:13:59, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3036, decode.acc_seg: 88.0302, aux.loss_ce: 0.1565, aux.acc_seg: 85.6302, loss: 0.4601
2023-12-28 19:22:34,097 - mmseg - INFO - Iter [60100/160000]	lr: 3.746e-05, eta: 22:13:21, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3067, decode.acc_seg: 87.5156, aux.loss_ce: 0.1507, aux.acc_seg: 85.4887, loss: 0.4574
2023-12-28 19:23:14,644 - mmseg - INFO - Iter [60150/160000]	lr: 3.744e-05, eta: 22:12:42, time: 0.812, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2945, decode.acc_seg: 88.1835, aux.loss_ce: 0.1431, aux.acc_seg: 86.1473, loss: 0.4376
2023-12-28 19:23:54,303 - mmseg - INFO - Iter [60200/160000]	lr: 3.743e-05, eta: 22:12:01, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2818, decode.acc_seg: 88.5786, aux.loss_ce: 0.1387, aux.acc_seg: 86.4347, loss: 0.4205
2023-12-28 19:24:33,875 - mmseg - INFO - Iter [60250/160000]	lr: 3.741e-05, eta: 22:11:21, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2948, decode.acc_seg: 87.9438, aux.loss_ce: 0.1441, aux.acc_seg: 86.0270, loss: 0.4389
2023-12-28 19:25:16,130 - mmseg - INFO - Iter [60300/160000]	lr: 3.739e-05, eta: 22:10:44, time: 0.845, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3010, decode.acc_seg: 87.5525, aux.loss_ce: 0.1479, aux.acc_seg: 85.3664, loss: 0.4489
2023-12-28 19:25:58,374 - mmseg - INFO - Iter [60350/160000]	lr: 3.737e-05, eta: 22:10:08, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3100, decode.acc_seg: 87.4353, aux.loss_ce: 0.1516, aux.acc_seg: 85.1839, loss: 0.4616
2023-12-28 19:26:38,662 - mmseg - INFO - Iter [60400/160000]	lr: 3.735e-05, eta: 22:09:28, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2790, decode.acc_seg: 88.5595, aux.loss_ce: 0.1358, aux.acc_seg: 86.6105, loss: 0.4148
2023-12-28 19:27:19,419 - mmseg - INFO - Iter [60450/160000]	lr: 3.733e-05, eta: 22:08:49, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2927, decode.acc_seg: 88.0520, aux.loss_ce: 0.1474, aux.acc_seg: 85.7056, loss: 0.4401
2023-12-28 19:27:59,969 - mmseg - INFO - Iter [60500/160000]	lr: 3.731e-05, eta: 22:08:10, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3006, decode.acc_seg: 87.9828, aux.loss_ce: 0.1493, aux.acc_seg: 85.6019, loss: 0.4499
2023-12-28 19:28:41,023 - mmseg - INFO - Iter [60550/160000]	lr: 3.729e-05, eta: 22:07:32, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3081, decode.acc_seg: 87.7274, aux.loss_ce: 0.1511, aux.acc_seg: 85.7415, loss: 0.4592
2023-12-28 19:29:21,649 - mmseg - INFO - Iter [60600/160000]	lr: 3.728e-05, eta: 22:06:53, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2889, decode.acc_seg: 88.7717, aux.loss_ce: 0.1464, aux.acc_seg: 86.3220, loss: 0.4353
2023-12-28 19:30:02,178 - mmseg - INFO - Iter [60650/160000]	lr: 3.726e-05, eta: 22:06:13, time: 0.811, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2857, decode.acc_seg: 88.2706, aux.loss_ce: 0.1424, aux.acc_seg: 86.0253, loss: 0.4282
2023-12-28 19:30:42,134 - mmseg - INFO - Iter [60700/160000]	lr: 3.724e-05, eta: 22:05:33, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2715, decode.acc_seg: 88.9282, aux.loss_ce: 0.1337, aux.acc_seg: 86.9071, loss: 0.4053
2023-12-28 19:31:22,183 - mmseg - INFO - Iter [60750/160000]	lr: 3.722e-05, eta: 22:04:53, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2831, decode.acc_seg: 88.3935, aux.loss_ce: 0.1405, aux.acc_seg: 86.2586, loss: 0.4236
2023-12-28 19:32:02,450 - mmseg - INFO - Iter [60800/160000]	lr: 3.720e-05, eta: 22:04:13, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2860, decode.acc_seg: 88.2950, aux.loss_ce: 0.1419, aux.acc_seg: 86.2523, loss: 0.4279
2023-12-28 19:32:43,337 - mmseg - INFO - Iter [60850/160000]	lr: 3.718e-05, eta: 22:03:35, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2953, decode.acc_seg: 87.9767, aux.loss_ce: 0.1467, aux.acc_seg: 85.7262, loss: 0.4420
2023-12-28 19:33:24,070 - mmseg - INFO - Iter [60900/160000]	lr: 3.716e-05, eta: 22:02:56, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2861, decode.acc_seg: 87.9907, aux.loss_ce: 0.1421, aux.acc_seg: 85.7318, loss: 0.4282
2023-12-28 19:34:02,941 - mmseg - INFO - Iter [60950/160000]	lr: 3.714e-05, eta: 22:02:14, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2954, decode.acc_seg: 87.9800, aux.loss_ce: 0.1507, aux.acc_seg: 85.4073, loss: 0.4461
2023-12-28 19:34:41,968 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 19:34:41,968 - mmseg - INFO - Iter [61000/160000]	lr: 3.713e-05, eta: 22:01:32, time: 0.780, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2847, decode.acc_seg: 88.7329, aux.loss_ce: 0.1417, aux.acc_seg: 86.5602, loss: 0.4265
2023-12-28 19:35:23,319 - mmseg - INFO - Iter [61050/160000]	lr: 3.711e-05, eta: 22:00:54, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2908, decode.acc_seg: 88.3465, aux.loss_ce: 0.1445, aux.acc_seg: 86.1625, loss: 0.4353
2023-12-28 19:36:04,151 - mmseg - INFO - Iter [61100/160000]	lr: 3.709e-05, eta: 22:00:15, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2669, decode.acc_seg: 88.9102, aux.loss_ce: 0.1334, aux.acc_seg: 86.9695, loss: 0.4003
2023-12-28 19:36:44,848 - mmseg - INFO - Iter [61150/160000]	lr: 3.707e-05, eta: 21:59:36, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2978, decode.acc_seg: 87.9583, aux.loss_ce: 0.1440, aux.acc_seg: 85.8673, loss: 0.4418
2023-12-28 19:37:26,691 - mmseg - INFO - Iter [61200/160000]	lr: 3.705e-05, eta: 21:58:59, time: 0.837, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2843, decode.acc_seg: 88.4171, aux.loss_ce: 0.1427, aux.acc_seg: 86.0459, loss: 0.4270
2023-12-28 19:38:08,392 - mmseg - INFO - Iter [61250/160000]	lr: 3.703e-05, eta: 21:58:22, time: 0.834, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3004, decode.acc_seg: 87.9742, aux.loss_ce: 0.1444, aux.acc_seg: 85.9601, loss: 0.4448
2023-12-28 19:38:49,720 - mmseg - INFO - Iter [61300/160000]	lr: 3.701e-05, eta: 21:57:44, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2884, decode.acc_seg: 88.1475, aux.loss_ce: 0.1442, aux.acc_seg: 85.8185, loss: 0.4327
2023-12-28 19:39:30,815 - mmseg - INFO - Iter [61350/160000]	lr: 3.699e-05, eta: 21:57:05, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2829, decode.acc_seg: 88.3383, aux.loss_ce: 0.1411, aux.acc_seg: 85.9834, loss: 0.4240
2023-12-28 19:40:11,933 - mmseg - INFO - Iter [61400/160000]	lr: 3.698e-05, eta: 21:56:27, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2969, decode.acc_seg: 87.8910, aux.loss_ce: 0.1452, aux.acc_seg: 85.9515, loss: 0.4421
2023-12-28 19:40:53,359 - mmseg - INFO - Iter [61450/160000]	lr: 3.696e-05, eta: 21:55:49, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2989, decode.acc_seg: 88.1645, aux.loss_ce: 0.1474, aux.acc_seg: 85.8800, loss: 0.4463
2023-12-28 19:41:34,848 - mmseg - INFO - Iter [61500/160000]	lr: 3.694e-05, eta: 21:55:12, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2984, decode.acc_seg: 88.0192, aux.loss_ce: 0.1478, aux.acc_seg: 85.9027, loss: 0.4462
2023-12-28 19:42:16,197 - mmseg - INFO - Iter [61550/160000]	lr: 3.692e-05, eta: 21:54:34, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3026, decode.acc_seg: 88.0531, aux.loss_ce: 0.1459, aux.acc_seg: 86.2778, loss: 0.4485
2023-12-28 19:42:57,433 - mmseg - INFO - Iter [61600/160000]	lr: 3.690e-05, eta: 21:53:55, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2896, decode.acc_seg: 88.0452, aux.loss_ce: 0.1476, aux.acc_seg: 85.7075, loss: 0.4372
2023-12-28 19:43:38,784 - mmseg - INFO - Iter [61650/160000]	lr: 3.688e-05, eta: 21:53:17, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2994, decode.acc_seg: 87.9565, aux.loss_ce: 0.1470, aux.acc_seg: 85.7281, loss: 0.4464
2023-12-28 19:44:19,817 - mmseg - INFO - Iter [61700/160000]	lr: 3.686e-05, eta: 21:52:39, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2983, decode.acc_seg: 87.7394, aux.loss_ce: 0.1433, aux.acc_seg: 85.9499, loss: 0.4416
2023-12-28 19:45:01,667 - mmseg - INFO - Iter [61750/160000]	lr: 3.684e-05, eta: 21:52:02, time: 0.837, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2984, decode.acc_seg: 88.4353, aux.loss_ce: 0.1438, aux.acc_seg: 86.1739, loss: 0.4422
2023-12-28 19:45:42,864 - mmseg - INFO - Iter [61800/160000]	lr: 3.683e-05, eta: 21:51:23, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2956, decode.acc_seg: 87.8147, aux.loss_ce: 0.1410, aux.acc_seg: 86.2075, loss: 0.4366
2023-12-28 19:46:22,932 - mmseg - INFO - Iter [61850/160000]	lr: 3.681e-05, eta: 21:50:43, time: 0.802, data_time: 0.014, memory: 18256, decode.loss_ce: 0.3025, decode.acc_seg: 87.9573, aux.loss_ce: 0.1502, aux.acc_seg: 85.5451, loss: 0.4527
2023-12-28 19:47:06,863 - mmseg - INFO - Iter [61900/160000]	lr: 3.679e-05, eta: 21:50:09, time: 0.879, data_time: 0.056, memory: 18256, decode.loss_ce: 0.2933, decode.acc_seg: 88.2897, aux.loss_ce: 0.1447, aux.acc_seg: 86.2824, loss: 0.4380
2023-12-28 19:47:47,795 - mmseg - INFO - Iter [61950/160000]	lr: 3.677e-05, eta: 21:49:31, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2766, decode.acc_seg: 88.8422, aux.loss_ce: 0.1402, aux.acc_seg: 86.6599, loss: 0.4168
2023-12-28 19:48:29,192 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 19:48:29,192 - mmseg - INFO - Iter [62000/160000]	lr: 3.675e-05, eta: 21:48:53, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2586, decode.acc_seg: 89.5535, aux.loss_ce: 0.1298, aux.acc_seg: 87.4345, loss: 0.3884
2023-12-28 19:49:10,747 - mmseg - INFO - Iter [62050/160000]	lr: 3.673e-05, eta: 21:48:15, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2947, decode.acc_seg: 87.9231, aux.loss_ce: 0.1463, aux.acc_seg: 85.8667, loss: 0.4410
2023-12-28 19:49:52,273 - mmseg - INFO - Iter [62100/160000]	lr: 3.671e-05, eta: 21:47:37, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2948, decode.acc_seg: 88.2497, aux.loss_ce: 0.1457, aux.acc_seg: 86.2866, loss: 0.4405
2023-12-28 19:50:33,578 - mmseg - INFO - Iter [62150/160000]	lr: 3.669e-05, eta: 21:46:59, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2889, decode.acc_seg: 88.9953, aux.loss_ce: 0.1456, aux.acc_seg: 86.2643, loss: 0.4345
2023-12-28 19:51:15,034 - mmseg - INFO - Iter [62200/160000]	lr: 3.668e-05, eta: 21:46:21, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2850, decode.acc_seg: 88.2036, aux.loss_ce: 0.1430, aux.acc_seg: 85.9450, loss: 0.4280
2023-12-28 19:51:58,417 - mmseg - INFO - Iter [62250/160000]	lr: 3.666e-05, eta: 21:45:46, time: 0.868, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2991, decode.acc_seg: 88.0090, aux.loss_ce: 0.1471, aux.acc_seg: 85.5957, loss: 0.4462
2023-12-28 19:52:41,671 - mmseg - INFO - Iter [62300/160000]	lr: 3.664e-05, eta: 21:45:11, time: 0.865, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2762, decode.acc_seg: 88.7350, aux.loss_ce: 0.1351, aux.acc_seg: 86.7137, loss: 0.4113
2023-12-28 19:53:22,836 - mmseg - INFO - Iter [62350/160000]	lr: 3.662e-05, eta: 21:44:33, time: 0.825, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2718, decode.acc_seg: 88.7611, aux.loss_ce: 0.1397, aux.acc_seg: 86.4096, loss: 0.4115
2023-12-28 19:54:01,949 - mmseg - INFO - Iter [62400/160000]	lr: 3.660e-05, eta: 21:43:51, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2847, decode.acc_seg: 88.5549, aux.loss_ce: 0.1433, aux.acc_seg: 86.3176, loss: 0.4280
2023-12-28 19:54:43,273 - mmseg - INFO - Iter [62450/160000]	lr: 3.658e-05, eta: 21:43:13, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2888, decode.acc_seg: 88.1414, aux.loss_ce: 0.1467, aux.acc_seg: 85.6761, loss: 0.4355
2023-12-28 19:55:24,835 - mmseg - INFO - Iter [62500/160000]	lr: 3.656e-05, eta: 21:42:35, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2849, decode.acc_seg: 87.9773, aux.loss_ce: 0.1416, aux.acc_seg: 85.7104, loss: 0.4265
2023-12-28 19:56:04,679 - mmseg - INFO - Iter [62550/160000]	lr: 3.654e-05, eta: 21:41:55, time: 0.798, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2938, decode.acc_seg: 88.2668, aux.loss_ce: 0.1443, aux.acc_seg: 85.9356, loss: 0.4381
2023-12-28 19:56:43,453 - mmseg - INFO - Iter [62600/160000]	lr: 3.653e-05, eta: 21:41:13, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2865, decode.acc_seg: 88.1800, aux.loss_ce: 0.1428, aux.acc_seg: 85.9899, loss: 0.4292
2023-12-28 19:57:22,442 - mmseg - INFO - Iter [62650/160000]	lr: 3.651e-05, eta: 21:40:31, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2838, decode.acc_seg: 88.4886, aux.loss_ce: 0.1393, aux.acc_seg: 86.6632, loss: 0.4231
2023-12-28 19:58:01,498 - mmseg - INFO - Iter [62700/160000]	lr: 3.649e-05, eta: 21:39:49, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2997, decode.acc_seg: 88.0593, aux.loss_ce: 0.1485, aux.acc_seg: 85.8444, loss: 0.4482
2023-12-28 19:58:41,335 - mmseg - INFO - Iter [62750/160000]	lr: 3.647e-05, eta: 21:39:09, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2968, decode.acc_seg: 88.2206, aux.loss_ce: 0.1462, aux.acc_seg: 86.2572, loss: 0.4430
2023-12-28 19:59:22,141 - mmseg - INFO - Iter [62800/160000]	lr: 3.645e-05, eta: 21:38:30, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2886, decode.acc_seg: 88.3947, aux.loss_ce: 0.1441, aux.acc_seg: 86.0541, loss: 0.4327
2023-12-28 20:00:02,247 - mmseg - INFO - Iter [62850/160000]	lr: 3.643e-05, eta: 21:37:50, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2971, decode.acc_seg: 87.9380, aux.loss_ce: 0.1450, aux.acc_seg: 85.9020, loss: 0.4420
2023-12-28 20:00:42,653 - mmseg - INFO - Iter [62900/160000]	lr: 3.641e-05, eta: 21:37:10, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2954, decode.acc_seg: 87.9543, aux.loss_ce: 0.1463, aux.acc_seg: 85.6765, loss: 0.4416
2023-12-28 20:01:23,743 - mmseg - INFO - Iter [62950/160000]	lr: 3.639e-05, eta: 21:36:32, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2944, decode.acc_seg: 88.0523, aux.loss_ce: 0.1442, aux.acc_seg: 86.2282, loss: 0.4387
2023-12-28 20:02:04,158 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:02:04,158 - mmseg - INFO - Iter [63000/160000]	lr: 3.638e-05, eta: 21:35:52, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2871, decode.acc_seg: 88.2344, aux.loss_ce: 0.1415, aux.acc_seg: 86.0138, loss: 0.4286
2023-12-28 20:02:44,062 - mmseg - INFO - Iter [63050/160000]	lr: 3.636e-05, eta: 21:35:12, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2899, decode.acc_seg: 88.3693, aux.loss_ce: 0.1416, aux.acc_seg: 86.2711, loss: 0.4315
2023-12-28 20:03:24,958 - mmseg - INFO - Iter [63100/160000]	lr: 3.634e-05, eta: 21:34:33, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2829, decode.acc_seg: 88.6583, aux.loss_ce: 0.1376, aux.acc_seg: 87.0305, loss: 0.4205
2023-12-28 20:04:05,492 - mmseg - INFO - Iter [63150/160000]	lr: 3.632e-05, eta: 21:33:54, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2872, decode.acc_seg: 88.5287, aux.loss_ce: 0.1430, aux.acc_seg: 86.4656, loss: 0.4302
2023-12-28 20:04:46,852 - mmseg - INFO - Iter [63200/160000]	lr: 3.630e-05, eta: 21:33:16, time: 0.828, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2750, decode.acc_seg: 88.7023, aux.loss_ce: 0.1411, aux.acc_seg: 86.2614, loss: 0.4161
2023-12-28 20:05:27,414 - mmseg - INFO - Iter [63250/160000]	lr: 3.628e-05, eta: 21:32:36, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2694, decode.acc_seg: 89.2592, aux.loss_ce: 0.1325, aux.acc_seg: 87.2043, loss: 0.4019
2023-12-28 20:06:10,666 - mmseg - INFO - Iter [63300/160000]	lr: 3.626e-05, eta: 21:32:01, time: 0.864, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2850, decode.acc_seg: 88.7207, aux.loss_ce: 0.1394, aux.acc_seg: 86.6886, loss: 0.4245
2023-12-28 20:06:51,813 - mmseg - INFO - Iter [63350/160000]	lr: 3.624e-05, eta: 21:31:23, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2962, decode.acc_seg: 87.7223, aux.loss_ce: 0.1457, aux.acc_seg: 85.4606, loss: 0.4418
2023-12-28 20:07:32,447 - mmseg - INFO - Iter [63400/160000]	lr: 3.623e-05, eta: 21:30:43, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2918, decode.acc_seg: 88.0940, aux.loss_ce: 0.1431, aux.acc_seg: 85.8580, loss: 0.4349
2023-12-28 20:08:11,868 - mmseg - INFO - Iter [63450/160000]	lr: 3.621e-05, eta: 21:30:02, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2783, decode.acc_seg: 88.7204, aux.loss_ce: 0.1412, aux.acc_seg: 86.4929, loss: 0.4195
2023-12-28 20:08:53,242 - mmseg - INFO - Iter [63500/160000]	lr: 3.619e-05, eta: 21:29:24, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2948, decode.acc_seg: 87.8673, aux.loss_ce: 0.1447, aux.acc_seg: 85.9798, loss: 0.4395
2023-12-28 20:09:34,367 - mmseg - INFO - Iter [63550/160000]	lr: 3.617e-05, eta: 21:28:46, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2869, decode.acc_seg: 87.9634, aux.loss_ce: 0.1424, aux.acc_seg: 86.0944, loss: 0.4293
2023-12-28 20:10:16,278 - mmseg - INFO - Iter [63600/160000]	lr: 3.615e-05, eta: 21:28:08, time: 0.838, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2688, decode.acc_seg: 88.9996, aux.loss_ce: 0.1332, aux.acc_seg: 87.1493, loss: 0.4021
2023-12-28 20:10:56,993 - mmseg - INFO - Iter [63650/160000]	lr: 3.613e-05, eta: 21:27:29, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2835, decode.acc_seg: 88.4678, aux.loss_ce: 0.1421, aux.acc_seg: 86.2916, loss: 0.4256
2023-12-28 20:11:36,857 - mmseg - INFO - Iter [63700/160000]	lr: 3.611e-05, eta: 21:26:49, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2856, decode.acc_seg: 88.4216, aux.loss_ce: 0.1401, aux.acc_seg: 86.3651, loss: 0.4257
2023-12-28 20:12:15,854 - mmseg - INFO - Iter [63750/160000]	lr: 3.609e-05, eta: 21:26:07, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2792, decode.acc_seg: 88.4512, aux.loss_ce: 0.1405, aux.acc_seg: 86.1779, loss: 0.4198
2023-12-28 20:12:56,025 - mmseg - INFO - Iter [63800/160000]	lr: 3.608e-05, eta: 21:25:27, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2702, decode.acc_seg: 88.9545, aux.loss_ce: 0.1340, aux.acc_seg: 86.8233, loss: 0.4042
2023-12-28 20:13:37,005 - mmseg - INFO - Iter [63850/160000]	lr: 3.606e-05, eta: 21:24:48, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2744, decode.acc_seg: 88.7121, aux.loss_ce: 0.1340, aux.acc_seg: 86.9479, loss: 0.4084
2023-12-28 20:14:19,026 - mmseg - INFO - Iter [63900/160000]	lr: 3.604e-05, eta: 21:24:11, time: 0.840, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2929, decode.acc_seg: 87.8687, aux.loss_ce: 0.1479, aux.acc_seg: 85.5824, loss: 0.4408
2023-12-28 20:14:59,218 - mmseg - INFO - Iter [63950/160000]	lr: 3.602e-05, eta: 21:23:31, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2866, decode.acc_seg: 88.2044, aux.loss_ce: 0.1433, aux.acc_seg: 86.1290, loss: 0.4299
2023-12-28 20:15:39,475 - mmseg - INFO - Saving checkpoint at 64000 iterations
2023-12-28 20:15:43,876 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:15:43,876 - mmseg - INFO - Iter [64000/160000]	lr: 3.600e-05, eta: 21:22:58, time: 0.895, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2785, decode.acc_seg: 88.8849, aux.loss_ce: 0.1390, aux.acc_seg: 86.8709, loss: 0.4175
2023-12-28 20:17:19,647 - mmseg - INFO - per class results:
2023-12-28 20:17:19,660 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 76.43 | 87.46 |
|       building      | 82.91 | 90.54 |
|         sky         | 94.48 | 97.52 |
|        floor        | 81.04 | 89.85 |
|         tree        | 74.97 | 87.17 |
|       ceiling       | 82.99 | 88.89 |
|         road        | 83.94 | 90.73 |
|         bed         | 86.53 | 95.14 |
|      windowpane     |  61.9 |  77.2 |
|        grass        | 65.77 | 83.28 |
|       cabinet       | 59.31 | 73.69 |
|       sidewalk      | 66.73 | 78.18 |
|        person       | 80.59 |  90.6 |
|        earth        | 34.31 | 47.09 |
|         door        | 50.84 |  66.3 |
|        table        | 55.65 | 70.66 |
|       mountain      | 55.61 | 77.45 |
|        plant        | 52.03 | 62.34 |
|       curtain       | 73.33 | 84.14 |
|        chair        | 53.13 |  66.1 |
|         car         | 82.36 |  91.7 |
|        water        | 56.21 | 67.14 |
|       painting      | 67.43 | 88.15 |
|         sofa        | 60.94 | 76.58 |
|        shelf        | 40.75 | 57.78 |
|        house        | 51.88 | 79.12 |
|         sea         | 56.78 | 75.08 |
|        mirror       | 62.57 | 73.18 |
|         rug         |  64.5 | 75.66 |
|        field        | 28.65 | 45.43 |
|       armchair      | 39.56 | 68.51 |
|         seat        | 62.13 | 82.74 |
|        fence        | 40.27 | 54.36 |
|         desk        | 48.71 | 72.04 |
|         rock        | 39.26 | 60.73 |
|       wardrobe      | 52.44 |  66.0 |
|         lamp        |  61.0 | 77.05 |
|       bathtub       | 75.73 | 84.78 |
|       railing       | 34.54 | 46.53 |
|       cushion       | 54.67 | 64.55 |
|         base        | 32.34 | 53.49 |
|         box         | 26.68 | 36.13 |
|        column       | 45.14 | 53.65 |
|      signboard      | 36.62 | 54.32 |
|   chest of drawers  | 37.32 | 51.73 |
|       counter       | 37.78 | 43.87 |
|         sand        | 38.74 | 68.34 |
|         sink        | 66.76 | 72.04 |
|      skyscraper     | 41.56 | 50.77 |
|      fireplace      |  65.2 | 90.12 |
|     refrigerator    | 69.84 | 82.95 |
|      grandstand     | 34.11 | 73.97 |
|         path        |  25.6 | 40.61 |
|        stairs       | 11.76 | 12.55 |
|        runway       | 70.65 |  92.3 |
|         case        | 57.31 | 80.58 |
|      pool table     | 92.55 | 96.66 |
|        pillow       | 59.79 |  76.8 |
|     screen door     | 63.98 | 71.21 |
|       stairway      | 27.26 | 42.75 |
|        river        | 13.82 | 36.69 |
|        bridge       | 68.23 | 82.18 |
|       bookcase      |  36.8 | 58.25 |
|        blind        | 38.71 |  45.4 |
|     coffee table    |  53.9 | 78.02 |
|        toilet       | 80.28 | 92.69 |
|        flower       |  41.1 | 58.43 |
|         book        | 42.75 | 63.22 |
|         hill        |  5.45 | 13.21 |
|        bench        | 44.59 | 54.74 |
|      countertop     |  59.1 | 76.47 |
|        stove        | 66.61 | 80.93 |
|         palm        | 50.44 | 71.73 |
|    kitchen island   |  42.5 | 88.61 |
|       computer      | 74.66 | 90.45 |
|     swivel chair    | 40.42 | 66.69 |
|         boat        | 33.06 | 49.87 |
|         bar         | 42.97 | 57.99 |
|    arcade machine   | 83.15 | 94.17 |
|        hovel        | 62.68 | 76.18 |
|         bus         | 82.62 | 95.79 |
|        towel        | 55.05 | 71.01 |
|        light        | 54.47 | 64.02 |
|        truck        | 31.98 | 45.58 |
|        tower        | 26.32 |  44.5 |
|      chandelier     | 66.71 | 79.85 |
|        awning       | 27.62 | 33.78 |
|     streetlight     |  22.5 | 28.12 |
|        booth        | 66.17 | 74.04 |
| television receiver | 64.97 | 76.13 |
|       airplane      | 52.72 | 66.45 |
|      dirt track     |  4.82 | 27.09 |
|       apparel       | 37.19 | 55.57 |
|         pole        | 22.33 | 29.79 |
|         land        |  0.0  |  0.0  |
|      bannister      |  9.58 | 11.48 |
|      escalator      | 22.65 | 24.04 |
|       ottoman       | 42.14 | 54.13 |
|        bottle       | 33.59 | 47.85 |
|        buffet       | 52.51 | 67.69 |
|        poster       | 25.13 | 32.23 |
|        stage        | 18.28 | 28.18 |
|         van         | 41.54 | 53.53 |
|         ship        | 53.33 | 87.82 |
|       fountain      | 24.07 | 24.35 |
|    conveyer belt    | 51.65 |  66.6 |
|        canopy       | 22.43 | 38.47 |
|        washer       | 77.84 | 96.25 |
|      plaything      | 20.88 | 32.95 |
|    swimming pool    | 72.01 | 82.24 |
|        stool        | 35.75 |  52.5 |
|        barrel       | 29.82 | 65.01 |
|        basket       | 33.38 | 44.92 |
|      waterfall      | 69.79 | 87.75 |
|         tent        | 88.61 | 98.32 |
|         bag         |  6.71 |  7.57 |
|       minibike      |  60.2 | 78.57 |
|        cradle       | 78.61 | 97.69 |
|         oven        | 35.77 | 42.49 |
|         ball        | 29.07 |  29.9 |
|         food        | 46.09 | 58.36 |
|         step        |  7.74 | 15.61 |
|         tank        | 58.54 |  65.0 |
|      trade name     | 20.46 | 24.93 |
|      microwave      | 78.98 | 90.18 |
|         pot         | 46.59 | 53.44 |
|        animal       | 55.55 | 57.83 |
|       bicycle       | 55.12 | 74.91 |
|         lake        | 59.22 | 66.68 |
|      dishwasher     | 43.69 |  49.9 |
|        screen       | 55.22 | 83.82 |
|       blanket       |  7.98 |  9.95 |
|      sculpture      | 57.81 | 70.25 |
|         hood        | 56.18 | 67.63 |
|        sconce       | 38.99 |  49.0 |
|         vase        | 36.36 | 48.41 |
|    traffic light    | 27.03 | 44.49 |
|         tray        |  2.32 |  2.55 |
|        ashcan       |  41.4 | 54.26 |
|         fan         | 51.38 | 73.24 |
|         pier        | 45.02 | 66.24 |
|      crt screen     |  3.91 | 11.29 |
|        plate        | 49.16 | 69.51 |
|       monitor       | 13.86 | 15.82 |
|    bulletin board   | 36.06 |  49.3 |
|        shower       |  1.76 |  6.94 |
|       radiator      | 48.91 | 62.47 |
|        glass        |  11.3 | 11.93 |
|        clock        |  34.3 | 37.69 |
|         flag        | 49.14 | 52.41 |
+---------------------+-------+-------+
2023-12-28 20:17:19,661 - mmseg - INFO - Summary:
2023-12-28 20:17:19,661 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 82.39 | 47.77 | 61.2 |
+-------+-------+------+
2023-12-28 20:17:19,687 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:17:19,687 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8239, mIoU: 0.4777, mAcc: 0.6120, IoU.wall: 0.7643, IoU.building: 0.8291, IoU.sky: 0.9448, IoU.floor: 0.8104, IoU.tree: 0.7497, IoU.ceiling: 0.8299, IoU.road: 0.8394, IoU.bed : 0.8653, IoU.windowpane: 0.6190, IoU.grass: 0.6577, IoU.cabinet: 0.5931, IoU.sidewalk: 0.6673, IoU.person: 0.8059, IoU.earth: 0.3431, IoU.door: 0.5084, IoU.table: 0.5565, IoU.mountain: 0.5561, IoU.plant: 0.5203, IoU.curtain: 0.7333, IoU.chair: 0.5313, IoU.car: 0.8236, IoU.water: 0.5621, IoU.painting: 0.6743, IoU.sofa: 0.6094, IoU.shelf: 0.4075, IoU.house: 0.5188, IoU.sea: 0.5678, IoU.mirror: 0.6257, IoU.rug: 0.6450, IoU.field: 0.2865, IoU.armchair: 0.3956, IoU.seat: 0.6213, IoU.fence: 0.4027, IoU.desk: 0.4871, IoU.rock: 0.3926, IoU.wardrobe: 0.5244, IoU.lamp: 0.6100, IoU.bathtub: 0.7573, IoU.railing: 0.3454, IoU.cushion: 0.5467, IoU.base: 0.3234, IoU.box: 0.2668, IoU.column: 0.4514, IoU.signboard: 0.3662, IoU.chest of drawers: 0.3732, IoU.counter: 0.3778, IoU.sand: 0.3874, IoU.sink: 0.6676, IoU.skyscraper: 0.4156, IoU.fireplace: 0.6520, IoU.refrigerator: 0.6984, IoU.grandstand: 0.3411, IoU.path: 0.2560, IoU.stairs: 0.1176, IoU.runway: 0.7065, IoU.case: 0.5731, IoU.pool table: 0.9255, IoU.pillow: 0.5979, IoU.screen door: 0.6398, IoU.stairway: 0.2726, IoU.river: 0.1382, IoU.bridge: 0.6823, IoU.bookcase: 0.3680, IoU.blind: 0.3871, IoU.coffee table: 0.5390, IoU.toilet: 0.8028, IoU.flower: 0.4110, IoU.book: 0.4275, IoU.hill: 0.0545, IoU.bench: 0.4459, IoU.countertop: 0.5910, IoU.stove: 0.6661, IoU.palm: 0.5044, IoU.kitchen island: 0.4250, IoU.computer: 0.7466, IoU.swivel chair: 0.4042, IoU.boat: 0.3306, IoU.bar: 0.4297, IoU.arcade machine: 0.8315, IoU.hovel: 0.6268, IoU.bus: 0.8262, IoU.towel: 0.5505, IoU.light: 0.5447, IoU.truck: 0.3198, IoU.tower: 0.2632, IoU.chandelier: 0.6671, IoU.awning: 0.2762, IoU.streetlight: 0.2250, IoU.booth: 0.6617, IoU.television receiver: 0.6497, IoU.airplane: 0.5272, IoU.dirt track: 0.0482, IoU.apparel: 0.3719, IoU.pole: 0.2233, IoU.land: 0.0000, IoU.bannister: 0.0958, IoU.escalator: 0.2265, IoU.ottoman: 0.4214, IoU.bottle: 0.3359, IoU.buffet: 0.5251, IoU.poster: 0.2513, IoU.stage: 0.1828, IoU.van: 0.4154, IoU.ship: 0.5333, IoU.fountain: 0.2407, IoU.conveyer belt: 0.5165, IoU.canopy: 0.2243, IoU.washer: 0.7784, IoU.plaything: 0.2088, IoU.swimming pool: 0.7201, IoU.stool: 0.3575, IoU.barrel: 0.2982, IoU.basket: 0.3338, IoU.waterfall: 0.6979, IoU.tent: 0.8861, IoU.bag: 0.0671, IoU.minibike: 0.6020, IoU.cradle: 0.7861, IoU.oven: 0.3577, IoU.ball: 0.2907, IoU.food: 0.4609, IoU.step: 0.0774, IoU.tank: 0.5854, IoU.trade name: 0.2046, IoU.microwave: 0.7898, IoU.pot: 0.4659, IoU.animal: 0.5555, IoU.bicycle: 0.5512, IoU.lake: 0.5922, IoU.dishwasher: 0.4369, IoU.screen: 0.5522, IoU.blanket: 0.0798, IoU.sculpture: 0.5781, IoU.hood: 0.5618, IoU.sconce: 0.3899, IoU.vase: 0.3636, IoU.traffic light: 0.2703, IoU.tray: 0.0232, IoU.ashcan: 0.4140, IoU.fan: 0.5138, IoU.pier: 0.4502, IoU.crt screen: 0.0391, IoU.plate: 0.4916, IoU.monitor: 0.1386, IoU.bulletin board: 0.3606, IoU.shower: 0.0176, IoU.radiator: 0.4891, IoU.glass: 0.1130, IoU.clock: 0.3430, IoU.flag: 0.4914, Acc.wall: 0.8746, Acc.building: 0.9054, Acc.sky: 0.9752, Acc.floor: 0.8985, Acc.tree: 0.8717, Acc.ceiling: 0.8889, Acc.road: 0.9073, Acc.bed : 0.9514, Acc.windowpane: 0.7720, Acc.grass: 0.8328, Acc.cabinet: 0.7369, Acc.sidewalk: 0.7818, Acc.person: 0.9060, Acc.earth: 0.4709, Acc.door: 0.6630, Acc.table: 0.7066, Acc.mountain: 0.7745, Acc.plant: 0.6234, Acc.curtain: 0.8414, Acc.chair: 0.6610, Acc.car: 0.9170, Acc.water: 0.6714, Acc.painting: 0.8815, Acc.sofa: 0.7658, Acc.shelf: 0.5778, Acc.house: 0.7912, Acc.sea: 0.7508, Acc.mirror: 0.7318, Acc.rug: 0.7566, Acc.field: 0.4543, Acc.armchair: 0.6851, Acc.seat: 0.8274, Acc.fence: 0.5436, Acc.desk: 0.7204, Acc.rock: 0.6073, Acc.wardrobe: 0.6600, Acc.lamp: 0.7705, Acc.bathtub: 0.8478, Acc.railing: 0.4653, Acc.cushion: 0.6455, Acc.base: 0.5349, Acc.box: 0.3613, Acc.column: 0.5365, Acc.signboard: 0.5432, Acc.chest of drawers: 0.5173, Acc.counter: 0.4387, Acc.sand: 0.6834, Acc.sink: 0.7204, Acc.skyscraper: 0.5077, Acc.fireplace: 0.9012, Acc.refrigerator: 0.8295, Acc.grandstand: 0.7397, Acc.path: 0.4061, Acc.stairs: 0.1255, Acc.runway: 0.9230, Acc.case: 0.8058, Acc.pool table: 0.9666, Acc.pillow: 0.7680, Acc.screen door: 0.7121, Acc.stairway: 0.4275, Acc.river: 0.3669, Acc.bridge: 0.8218, Acc.bookcase: 0.5825, Acc.blind: 0.4540, Acc.coffee table: 0.7802, Acc.toilet: 0.9269, Acc.flower: 0.5843, Acc.book: 0.6322, Acc.hill: 0.1321, Acc.bench: 0.5474, Acc.countertop: 0.7647, Acc.stove: 0.8093, Acc.palm: 0.7173, Acc.kitchen island: 0.8861, Acc.computer: 0.9045, Acc.swivel chair: 0.6669, Acc.boat: 0.4987, Acc.bar: 0.5799, Acc.arcade machine: 0.9417, Acc.hovel: 0.7618, Acc.bus: 0.9579, Acc.towel: 0.7101, Acc.light: 0.6402, Acc.truck: 0.4558, Acc.tower: 0.4450, Acc.chandelier: 0.7985, Acc.awning: 0.3378, Acc.streetlight: 0.2812, Acc.booth: 0.7404, Acc.television receiver: 0.7613, Acc.airplane: 0.6645, Acc.dirt track: 0.2709, Acc.apparel: 0.5557, Acc.pole: 0.2979, Acc.land: 0.0000, Acc.bannister: 0.1148, Acc.escalator: 0.2404, Acc.ottoman: 0.5413, Acc.bottle: 0.4785, Acc.buffet: 0.6769, Acc.poster: 0.3223, Acc.stage: 0.2818, Acc.van: 0.5353, Acc.ship: 0.8782, Acc.fountain: 0.2435, Acc.conveyer belt: 0.6660, Acc.canopy: 0.3847, Acc.washer: 0.9625, Acc.plaything: 0.3295, Acc.swimming pool: 0.8224, Acc.stool: 0.5250, Acc.barrel: 0.6501, Acc.basket: 0.4492, Acc.waterfall: 0.8775, Acc.tent: 0.9832, Acc.bag: 0.0757, Acc.minibike: 0.7857, Acc.cradle: 0.9769, Acc.oven: 0.4249, Acc.ball: 0.2990, Acc.food: 0.5836, Acc.step: 0.1561, Acc.tank: 0.6500, Acc.trade name: 0.2493, Acc.microwave: 0.9018, Acc.pot: 0.5344, Acc.animal: 0.5783, Acc.bicycle: 0.7491, Acc.lake: 0.6668, Acc.dishwasher: 0.4990, Acc.screen: 0.8382, Acc.blanket: 0.0995, Acc.sculpture: 0.7025, Acc.hood: 0.6763, Acc.sconce: 0.4900, Acc.vase: 0.4841, Acc.traffic light: 0.4449, Acc.tray: 0.0255, Acc.ashcan: 0.5426, Acc.fan: 0.7324, Acc.pier: 0.6624, Acc.crt screen: 0.1129, Acc.plate: 0.6951, Acc.monitor: 0.1582, Acc.bulletin board: 0.4930, Acc.shower: 0.0694, Acc.radiator: 0.6247, Acc.glass: 0.1193, Acc.clock: 0.3769, Acc.flag: 0.5241
2023-12-28 20:18:01,664 - mmseg - INFO - Iter [64050/160000]	lr: 3.598e-05, eta: 21:24:44, time: 2.756, data_time: 1.927, memory: 18256, decode.loss_ce: 0.3041, decode.acc_seg: 87.7711, aux.loss_ce: 0.1499, aux.acc_seg: 85.6265, loss: 0.4539
2023-12-28 20:18:41,535 - mmseg - INFO - Iter [64100/160000]	lr: 3.596e-05, eta: 21:24:04, time: 0.797, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2839, decode.acc_seg: 88.1820, aux.loss_ce: 0.1425, aux.acc_seg: 85.9351, loss: 0.4264
2023-12-28 20:19:21,337 - mmseg - INFO - Iter [64150/160000]	lr: 3.594e-05, eta: 21:23:23, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3015, decode.acc_seg: 87.8428, aux.loss_ce: 0.1492, aux.acc_seg: 85.7295, loss: 0.4507
2023-12-28 20:19:59,699 - mmseg - INFO - Iter [64200/160000]	lr: 3.593e-05, eta: 21:22:40, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2863, decode.acc_seg: 88.6948, aux.loss_ce: 0.1404, aux.acc_seg: 86.5205, loss: 0.4267
2023-12-28 20:20:37,463 - mmseg - INFO - Iter [64250/160000]	lr: 3.591e-05, eta: 21:21:56, time: 0.754, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2896, decode.acc_seg: 88.2171, aux.loss_ce: 0.1445, aux.acc_seg: 86.0653, loss: 0.4341
2023-12-28 20:21:16,149 - mmseg - INFO - Iter [64300/160000]	lr: 3.589e-05, eta: 21:21:14, time: 0.774, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2795, decode.acc_seg: 88.7034, aux.loss_ce: 0.1380, aux.acc_seg: 86.5846, loss: 0.4174
2023-12-28 20:21:55,710 - mmseg - INFO - Iter [64350/160000]	lr: 3.587e-05, eta: 21:20:33, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2862, decode.acc_seg: 88.6114, aux.loss_ce: 0.1404, aux.acc_seg: 86.3277, loss: 0.4266
2023-12-28 20:22:34,702 - mmseg - INFO - Iter [64400/160000]	lr: 3.585e-05, eta: 21:19:51, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2895, decode.acc_seg: 87.9945, aux.loss_ce: 0.1464, aux.acc_seg: 85.7893, loss: 0.4360
2023-12-28 20:23:16,478 - mmseg - INFO - Iter [64450/160000]	lr: 3.583e-05, eta: 21:19:13, time: 0.836, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2683, decode.acc_seg: 88.9860, aux.loss_ce: 0.1320, aux.acc_seg: 87.3854, loss: 0.4003
2023-12-28 20:23:56,743 - mmseg - INFO - Iter [64500/160000]	lr: 3.581e-05, eta: 21:18:33, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2852, decode.acc_seg: 88.4385, aux.loss_ce: 0.1388, aux.acc_seg: 86.4092, loss: 0.4240
2023-12-28 20:24:36,955 - mmseg - INFO - Iter [64550/160000]	lr: 3.579e-05, eta: 21:17:53, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2760, decode.acc_seg: 88.8460, aux.loss_ce: 0.1380, aux.acc_seg: 86.5993, loss: 0.4140
2023-12-28 20:25:14,564 - mmseg - INFO - Iter [64600/160000]	lr: 3.578e-05, eta: 21:17:09, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2847, decode.acc_seg: 88.5041, aux.loss_ce: 0.1385, aux.acc_seg: 86.5623, loss: 0.4232
2023-12-28 20:25:52,085 - mmseg - INFO - Iter [64650/160000]	lr: 3.576e-05, eta: 21:16:25, time: 0.750, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2911, decode.acc_seg: 88.3088, aux.loss_ce: 0.1412, aux.acc_seg: 86.4629, loss: 0.4323
2023-12-28 20:26:29,782 - mmseg - INFO - Iter [64700/160000]	lr: 3.574e-05, eta: 21:15:41, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2799, decode.acc_seg: 88.4470, aux.loss_ce: 0.1430, aux.acc_seg: 86.0667, loss: 0.4229
2023-12-28 20:27:08,750 - mmseg - INFO - Iter [64750/160000]	lr: 3.572e-05, eta: 21:14:59, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2821, decode.acc_seg: 88.4174, aux.loss_ce: 0.1414, aux.acc_seg: 86.1326, loss: 0.4235
2023-12-28 20:27:46,674 - mmseg - INFO - Iter [64800/160000]	lr: 3.570e-05, eta: 21:14:16, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2911, decode.acc_seg: 87.7774, aux.loss_ce: 0.1467, aux.acc_seg: 85.4873, loss: 0.4379
2023-12-28 20:28:27,212 - mmseg - INFO - Iter [64850/160000]	lr: 3.568e-05, eta: 21:13:36, time: 0.810, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2859, decode.acc_seg: 88.2939, aux.loss_ce: 0.1434, aux.acc_seg: 85.8425, loss: 0.4293
2023-12-28 20:29:07,407 - mmseg - INFO - Iter [64900/160000]	lr: 3.566e-05, eta: 21:12:56, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2691, decode.acc_seg: 89.1225, aux.loss_ce: 0.1354, aux.acc_seg: 86.8316, loss: 0.4045
2023-12-28 20:29:45,156 - mmseg - INFO - Iter [64950/160000]	lr: 3.564e-05, eta: 21:12:13, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2990, decode.acc_seg: 88.0308, aux.loss_ce: 0.1448, aux.acc_seg: 85.9668, loss: 0.4438
2023-12-28 20:30:25,239 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:30:25,239 - mmseg - INFO - Iter [65000/160000]	lr: 3.563e-05, eta: 21:11:32, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3079, decode.acc_seg: 87.5676, aux.loss_ce: 0.1508, aux.acc_seg: 85.1585, loss: 0.4587
2023-12-28 20:31:05,361 - mmseg - INFO - Iter [65050/160000]	lr: 3.561e-05, eta: 21:10:52, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2825, decode.acc_seg: 88.6124, aux.loss_ce: 0.1432, aux.acc_seg: 86.0851, loss: 0.4256
2023-12-28 20:31:44,664 - mmseg - INFO - Iter [65100/160000]	lr: 3.559e-05, eta: 21:10:11, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2732, decode.acc_seg: 88.8706, aux.loss_ce: 0.1345, aux.acc_seg: 86.6447, loss: 0.4077
2023-12-28 20:32:22,937 - mmseg - INFO - Iter [65150/160000]	lr: 3.557e-05, eta: 21:09:28, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2899, decode.acc_seg: 88.0711, aux.loss_ce: 0.1446, aux.acc_seg: 85.8201, loss: 0.4345
2023-12-28 20:33:02,838 - mmseg - INFO - Iter [65200/160000]	lr: 3.555e-05, eta: 21:08:47, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2749, decode.acc_seg: 88.7277, aux.loss_ce: 0.1377, aux.acc_seg: 86.4669, loss: 0.4126
2023-12-28 20:33:42,776 - mmseg - INFO - Iter [65250/160000]	lr: 3.553e-05, eta: 21:08:07, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2923, decode.acc_seg: 87.9843, aux.loss_ce: 0.1445, aux.acc_seg: 85.7833, loss: 0.4368
2023-12-28 20:34:22,532 - mmseg - INFO - Iter [65300/160000]	lr: 3.551e-05, eta: 21:07:26, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2872, decode.acc_seg: 88.4007, aux.loss_ce: 0.1437, aux.acc_seg: 85.9774, loss: 0.4309
2023-12-28 20:35:03,375 - mmseg - INFO - Iter [65350/160000]	lr: 3.549e-05, eta: 21:06:47, time: 0.816, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2708, decode.acc_seg: 89.2496, aux.loss_ce: 0.1331, aux.acc_seg: 87.2596, loss: 0.4039
2023-12-28 20:35:43,831 - mmseg - INFO - Iter [65400/160000]	lr: 3.548e-05, eta: 21:06:07, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2729, decode.acc_seg: 88.8437, aux.loss_ce: 0.1326, aux.acc_seg: 86.9312, loss: 0.4055
2023-12-28 20:36:24,994 - mmseg - INFO - Iter [65450/160000]	lr: 3.546e-05, eta: 21:05:28, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2936, decode.acc_seg: 88.2590, aux.loss_ce: 0.1446, aux.acc_seg: 86.0927, loss: 0.4382
2023-12-28 20:37:06,051 - mmseg - INFO - Iter [65500/160000]	lr: 3.544e-05, eta: 21:04:50, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2800, decode.acc_seg: 88.5622, aux.loss_ce: 0.1402, aux.acc_seg: 86.4988, loss: 0.4203
2023-12-28 20:37:46,604 - mmseg - INFO - Iter [65550/160000]	lr: 3.542e-05, eta: 21:04:10, time: 0.812, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2828, decode.acc_seg: 88.4923, aux.loss_ce: 0.1410, aux.acc_seg: 86.3123, loss: 0.4239
2023-12-28 20:38:27,577 - mmseg - INFO - Iter [65600/160000]	lr: 3.540e-05, eta: 21:03:31, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2846, decode.acc_seg: 88.6484, aux.loss_ce: 0.1452, aux.acc_seg: 85.9773, loss: 0.4298
2023-12-28 20:39:06,901 - mmseg - INFO - Iter [65650/160000]	lr: 3.538e-05, eta: 21:02:50, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2922, decode.acc_seg: 88.2751, aux.loss_ce: 0.1476, aux.acc_seg: 86.0393, loss: 0.4397
2023-12-28 20:39:48,117 - mmseg - INFO - Iter [65700/160000]	lr: 3.536e-05, eta: 21:02:11, time: 0.824, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2943, decode.acc_seg: 88.0778, aux.loss_ce: 0.1456, aux.acc_seg: 86.1597, loss: 0.4398
2023-12-28 20:40:26,074 - mmseg - INFO - Iter [65750/160000]	lr: 3.534e-05, eta: 21:01:28, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2744, decode.acc_seg: 88.9428, aux.loss_ce: 0.1378, aux.acc_seg: 86.7895, loss: 0.4121
2023-12-28 20:41:06,078 - mmseg - INFO - Iter [65800/160000]	lr: 3.533e-05, eta: 21:00:47, time: 0.800, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2753, decode.acc_seg: 88.6777, aux.loss_ce: 0.1354, aux.acc_seg: 86.6681, loss: 0.4107
2023-12-28 20:41:43,902 - mmseg - INFO - Iter [65850/160000]	lr: 3.531e-05, eta: 21:00:04, time: 0.756, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2723, decode.acc_seg: 88.8119, aux.loss_ce: 0.1346, aux.acc_seg: 86.9386, loss: 0.4069
2023-12-28 20:42:22,843 - mmseg - INFO - Iter [65900/160000]	lr: 3.529e-05, eta: 20:59:22, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2781, decode.acc_seg: 88.8302, aux.loss_ce: 0.1409, aux.acc_seg: 86.2897, loss: 0.4190
2023-12-28 20:43:00,680 - mmseg - INFO - Iter [65950/160000]	lr: 3.527e-05, eta: 20:58:39, time: 0.758, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2824, decode.acc_seg: 88.2900, aux.loss_ce: 0.1411, aux.acc_seg: 86.2724, loss: 0.4235
2023-12-28 20:43:38,726 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:43:38,726 - mmseg - INFO - Iter [66000/160000]	lr: 3.525e-05, eta: 20:57:55, time: 0.761, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2749, decode.acc_seg: 89.0285, aux.loss_ce: 0.1349, aux.acc_seg: 87.0531, loss: 0.4098
2023-12-28 20:44:19,067 - mmseg - INFO - Iter [66050/160000]	lr: 3.523e-05, eta: 20:57:16, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.3027, decode.acc_seg: 87.8808, aux.loss_ce: 0.1475, aux.acc_seg: 85.4816, loss: 0.4503
2023-12-28 20:44:59,490 - mmseg - INFO - Iter [66100/160000]	lr: 3.521e-05, eta: 20:56:36, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2865, decode.acc_seg: 88.5324, aux.loss_ce: 0.1453, aux.acc_seg: 86.0482, loss: 0.4318
2023-12-28 20:45:39,682 - mmseg - INFO - Iter [66150/160000]	lr: 3.519e-05, eta: 20:55:56, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2891, decode.acc_seg: 88.0688, aux.loss_ce: 0.1398, aux.acc_seg: 86.3614, loss: 0.4289
2023-12-28 20:46:18,541 - mmseg - INFO - Iter [66200/160000]	lr: 3.518e-05, eta: 20:55:14, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2819, decode.acc_seg: 88.0579, aux.loss_ce: 0.1382, aux.acc_seg: 86.2490, loss: 0.4201
2023-12-28 20:46:59,097 - mmseg - INFO - Iter [66250/160000]	lr: 3.516e-05, eta: 20:54:34, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2870, decode.acc_seg: 88.2172, aux.loss_ce: 0.1444, aux.acc_seg: 86.0382, loss: 0.4315
2023-12-28 20:47:40,149 - mmseg - INFO - Iter [66300/160000]	lr: 3.514e-05, eta: 20:53:55, time: 0.820, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2804, decode.acc_seg: 88.5351, aux.loss_ce: 0.1401, aux.acc_seg: 86.4247, loss: 0.4204
2023-12-28 20:48:21,366 - mmseg - INFO - Iter [66350/160000]	lr: 3.512e-05, eta: 20:53:17, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2736, decode.acc_seg: 88.9044, aux.loss_ce: 0.1329, aux.acc_seg: 86.8941, loss: 0.4065
2023-12-28 20:49:02,764 - mmseg - INFO - Iter [66400/160000]	lr: 3.510e-05, eta: 20:52:38, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2832, decode.acc_seg: 88.2832, aux.loss_ce: 0.1412, aux.acc_seg: 86.0361, loss: 0.4243
2023-12-28 20:49:44,296 - mmseg - INFO - Iter [66450/160000]	lr: 3.508e-05, eta: 20:52:00, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.3023, decode.acc_seg: 87.5681, aux.loss_ce: 0.1513, aux.acc_seg: 85.5919, loss: 0.4536
2023-12-28 20:50:24,280 - mmseg - INFO - Iter [66500/160000]	lr: 3.506e-05, eta: 20:51:20, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2837, decode.acc_seg: 88.5542, aux.loss_ce: 0.1393, aux.acc_seg: 86.2473, loss: 0.4229
2023-12-28 20:51:02,018 - mmseg - INFO - Iter [66550/160000]	lr: 3.504e-05, eta: 20:50:36, time: 0.755, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2827, decode.acc_seg: 88.6305, aux.loss_ce: 0.1456, aux.acc_seg: 86.0921, loss: 0.4283
2023-12-28 20:51:42,175 - mmseg - INFO - Iter [66600/160000]	lr: 3.503e-05, eta: 20:49:56, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2808, decode.acc_seg: 88.6200, aux.loss_ce: 0.1393, aux.acc_seg: 86.7399, loss: 0.4201
2023-12-28 20:52:23,772 - mmseg - INFO - Iter [66650/160000]	lr: 3.501e-05, eta: 20:49:18, time: 0.831, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2726, decode.acc_seg: 88.9124, aux.loss_ce: 0.1371, aux.acc_seg: 86.6576, loss: 0.4097
2023-12-28 20:53:05,669 - mmseg - INFO - Iter [66700/160000]	lr: 3.499e-05, eta: 20:48:40, time: 0.838, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2888, decode.acc_seg: 88.4725, aux.loss_ce: 0.1437, aux.acc_seg: 86.2908, loss: 0.4325
2023-12-28 20:53:46,227 - mmseg - INFO - Iter [66750/160000]	lr: 3.497e-05, eta: 20:48:01, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2752, decode.acc_seg: 89.1063, aux.loss_ce: 0.1392, aux.acc_seg: 86.7413, loss: 0.4144
2023-12-28 20:54:23,898 - mmseg - INFO - Iter [66800/160000]	lr: 3.495e-05, eta: 20:47:17, time: 0.753, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2598, decode.acc_seg: 89.2551, aux.loss_ce: 0.1305, aux.acc_seg: 86.9140, loss: 0.3903
2023-12-28 20:55:03,244 - mmseg - INFO - Iter [66850/160000]	lr: 3.493e-05, eta: 20:46:36, time: 0.786, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2875, decode.acc_seg: 88.0744, aux.loss_ce: 0.1425, aux.acc_seg: 85.9865, loss: 0.4299
2023-12-28 20:55:41,415 - mmseg - INFO - Iter [66900/160000]	lr: 3.491e-05, eta: 20:45:53, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2939, decode.acc_seg: 88.2214, aux.loss_ce: 0.1451, aux.acc_seg: 86.2318, loss: 0.4389
2023-12-28 20:56:22,564 - mmseg - INFO - Iter [66950/160000]	lr: 3.489e-05, eta: 20:45:14, time: 0.824, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2849, decode.acc_seg: 88.4117, aux.loss_ce: 0.1426, aux.acc_seg: 85.9371, loss: 0.4276
2023-12-28 20:57:02,288 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 20:57:02,288 - mmseg - INFO - Iter [67000/160000]	lr: 3.488e-05, eta: 20:44:33, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2862, decode.acc_seg: 88.2614, aux.loss_ce: 0.1446, aux.acc_seg: 86.1586, loss: 0.4308
2023-12-28 20:57:42,802 - mmseg - INFO - Iter [67050/160000]	lr: 3.486e-05, eta: 20:43:54, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2768, decode.acc_seg: 88.9466, aux.loss_ce: 0.1373, aux.acc_seg: 86.7944, loss: 0.4141
2023-12-28 20:58:21,687 - mmseg - INFO - Iter [67100/160000]	lr: 3.484e-05, eta: 20:43:12, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2851, decode.acc_seg: 88.3956, aux.loss_ce: 0.1414, aux.acc_seg: 86.3923, loss: 0.4265
2023-12-28 20:58:58,616 - mmseg - INFO - Iter [67150/160000]	lr: 3.482e-05, eta: 20:42:27, time: 0.738, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2834, decode.acc_seg: 88.4942, aux.loss_ce: 0.1394, aux.acc_seg: 86.4705, loss: 0.4229
2023-12-28 20:59:35,843 - mmseg - INFO - Iter [67200/160000]	lr: 3.480e-05, eta: 20:41:43, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2594, decode.acc_seg: 89.3215, aux.loss_ce: 0.1292, aux.acc_seg: 87.2469, loss: 0.3885
2023-12-28 21:00:15,746 - mmseg - INFO - Iter [67250/160000]	lr: 3.478e-05, eta: 20:41:03, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2811, decode.acc_seg: 88.4978, aux.loss_ce: 0.1410, aux.acc_seg: 86.6757, loss: 0.4221
2023-12-28 21:00:55,458 - mmseg - INFO - Iter [67300/160000]	lr: 3.476e-05, eta: 20:40:22, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2734, decode.acc_seg: 89.1080, aux.loss_ce: 0.1360, aux.acc_seg: 87.0456, loss: 0.4093
2023-12-28 21:01:35,885 - mmseg - INFO - Iter [67350/160000]	lr: 3.474e-05, eta: 20:39:42, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2651, decode.acc_seg: 89.1385, aux.loss_ce: 0.1333, aux.acc_seg: 86.8588, loss: 0.3984
2023-12-28 21:02:15,116 - mmseg - INFO - Iter [67400/160000]	lr: 3.473e-05, eta: 20:39:01, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.3026, decode.acc_seg: 87.7336, aux.loss_ce: 0.1464, aux.acc_seg: 85.8821, loss: 0.4490
2023-12-28 21:02:55,569 - mmseg - INFO - Iter [67450/160000]	lr: 3.471e-05, eta: 20:38:21, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2809, decode.acc_seg: 88.4449, aux.loss_ce: 0.1417, aux.acc_seg: 86.0842, loss: 0.4227
2023-12-28 21:03:34,535 - mmseg - INFO - Iter [67500/160000]	lr: 3.469e-05, eta: 20:37:39, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2888, decode.acc_seg: 88.5779, aux.loss_ce: 0.1446, aux.acc_seg: 86.2526, loss: 0.4334
2023-12-28 21:04:13,336 - mmseg - INFO - Iter [67550/160000]	lr: 3.467e-05, eta: 20:36:57, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2680, decode.acc_seg: 89.1593, aux.loss_ce: 0.1364, aux.acc_seg: 86.9542, loss: 0.4043
2023-12-28 21:04:51,903 - mmseg - INFO - Iter [67600/160000]	lr: 3.465e-05, eta: 20:36:15, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2737, decode.acc_seg: 88.7449, aux.loss_ce: 0.1427, aux.acc_seg: 86.0130, loss: 0.4164
2023-12-28 21:05:29,842 - mmseg - INFO - Iter [67650/160000]	lr: 3.463e-05, eta: 20:35:32, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2698, decode.acc_seg: 88.9580, aux.loss_ce: 0.1343, aux.acc_seg: 86.9091, loss: 0.4041
2023-12-28 21:06:07,481 - mmseg - INFO - Iter [67700/160000]	lr: 3.461e-05, eta: 20:34:48, time: 0.753, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2725, decode.acc_seg: 88.8322, aux.loss_ce: 0.1349, aux.acc_seg: 86.7376, loss: 0.4074
2023-12-28 21:06:46,531 - mmseg - INFO - Iter [67750/160000]	lr: 3.459e-05, eta: 20:34:07, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2948, decode.acc_seg: 87.8892, aux.loss_ce: 0.1440, aux.acc_seg: 85.9520, loss: 0.4388
2023-12-28 21:07:27,270 - mmseg - INFO - Iter [67800/160000]	lr: 3.458e-05, eta: 20:33:27, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2719, decode.acc_seg: 88.9331, aux.loss_ce: 0.1353, aux.acc_seg: 86.9038, loss: 0.4071
2023-12-28 21:08:08,627 - mmseg - INFO - Iter [67850/160000]	lr: 3.456e-05, eta: 20:32:49, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2766, decode.acc_seg: 88.6579, aux.loss_ce: 0.1389, aux.acc_seg: 86.2000, loss: 0.4155
2023-12-28 21:08:49,826 - mmseg - INFO - Iter [67900/160000]	lr: 3.454e-05, eta: 20:32:10, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2798, decode.acc_seg: 88.4682, aux.loss_ce: 0.1402, aux.acc_seg: 86.2253, loss: 0.4201
2023-12-28 21:09:28,096 - mmseg - INFO - Iter [67950/160000]	lr: 3.452e-05, eta: 20:31:28, time: 0.766, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2774, decode.acc_seg: 88.7482, aux.loss_ce: 0.1363, aux.acc_seg: 86.8060, loss: 0.4137
2023-12-28 21:10:05,661 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 21:10:05,662 - mmseg - INFO - Iter [68000/160000]	lr: 3.450e-05, eta: 20:30:44, time: 0.751, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2744, decode.acc_seg: 88.7993, aux.loss_ce: 0.1354, aux.acc_seg: 86.8371, loss: 0.4098
2023-12-28 21:10:43,575 - mmseg - INFO - Iter [68050/160000]	lr: 3.448e-05, eta: 20:30:01, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2778, decode.acc_seg: 88.8988, aux.loss_ce: 0.1373, aux.acc_seg: 86.9760, loss: 0.4151
2023-12-28 21:11:23,353 - mmseg - INFO - Iter [68100/160000]	lr: 3.446e-05, eta: 20:29:20, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2664, decode.acc_seg: 88.9980, aux.loss_ce: 0.1351, aux.acc_seg: 86.6757, loss: 0.4015
2023-12-28 21:12:04,602 - mmseg - INFO - Iter [68150/160000]	lr: 3.444e-05, eta: 20:28:42, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2761, decode.acc_seg: 88.5789, aux.loss_ce: 0.1356, aux.acc_seg: 86.8517, loss: 0.4117
2023-12-28 21:12:43,816 - mmseg - INFO - Iter [68200/160000]	lr: 3.443e-05, eta: 20:28:00, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2735, decode.acc_seg: 88.7467, aux.loss_ce: 0.1342, aux.acc_seg: 86.7493, loss: 0.4077
2023-12-28 21:13:25,853 - mmseg - INFO - Iter [68250/160000]	lr: 3.441e-05, eta: 20:27:23, time: 0.840, data_time: 0.052, memory: 18256, decode.loss_ce: 0.2690, decode.acc_seg: 88.7823, aux.loss_ce: 0.1332, aux.acc_seg: 86.6578, loss: 0.4022
2023-12-28 21:14:03,097 - mmseg - INFO - Iter [68300/160000]	lr: 3.439e-05, eta: 20:26:39, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2732, decode.acc_seg: 88.9121, aux.loss_ce: 0.1352, aux.acc_seg: 86.9565, loss: 0.4084
2023-12-28 21:14:41,114 - mmseg - INFO - Iter [68350/160000]	lr: 3.437e-05, eta: 20:25:56, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2689, decode.acc_seg: 89.0414, aux.loss_ce: 0.1366, aux.acc_seg: 86.6737, loss: 0.4056
2023-12-28 21:15:20,849 - mmseg - INFO - Iter [68400/160000]	lr: 3.435e-05, eta: 20:25:15, time: 0.794, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2703, decode.acc_seg: 88.7540, aux.loss_ce: 0.1351, aux.acc_seg: 86.4300, loss: 0.4054
2023-12-28 21:16:00,216 - mmseg - INFO - Iter [68450/160000]	lr: 3.433e-05, eta: 20:24:34, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2903, decode.acc_seg: 88.4004, aux.loss_ce: 0.1434, aux.acc_seg: 86.2926, loss: 0.4337
2023-12-28 21:16:39,227 - mmseg - INFO - Iter [68500/160000]	lr: 3.431e-05, eta: 20:23:52, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2661, decode.acc_seg: 88.9207, aux.loss_ce: 0.1333, aux.acc_seg: 86.5933, loss: 0.3993
2023-12-28 21:17:17,447 - mmseg - INFO - Iter [68550/160000]	lr: 3.429e-05, eta: 20:23:10, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2812, decode.acc_seg: 88.3508, aux.loss_ce: 0.1369, aux.acc_seg: 86.5185, loss: 0.4181
2023-12-28 21:17:54,737 - mmseg - INFO - Iter [68600/160000]	lr: 3.428e-05, eta: 20:22:26, time: 0.746, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2809, decode.acc_seg: 88.5954, aux.loss_ce: 0.1382, aux.acc_seg: 86.4158, loss: 0.4191
2023-12-28 21:18:33,139 - mmseg - INFO - Iter [68650/160000]	lr: 3.426e-05, eta: 20:21:43, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2808, decode.acc_seg: 88.4209, aux.loss_ce: 0.1393, aux.acc_seg: 86.1021, loss: 0.4201
2023-12-28 21:19:11,742 - mmseg - INFO - Iter [68700/160000]	lr: 3.424e-05, eta: 20:21:01, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2748, decode.acc_seg: 88.9859, aux.loss_ce: 0.1374, aux.acc_seg: 86.9009, loss: 0.4122
2023-12-28 21:19:50,218 - mmseg - INFO - Iter [68750/160000]	lr: 3.422e-05, eta: 20:20:19, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2621, decode.acc_seg: 89.1982, aux.loss_ce: 0.1290, aux.acc_seg: 87.3363, loss: 0.3911
2023-12-28 21:20:29,372 - mmseg - INFO - Iter [68800/160000]	lr: 3.420e-05, eta: 20:19:37, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2791, decode.acc_seg: 88.5687, aux.loss_ce: 0.1379, aux.acc_seg: 86.2779, loss: 0.4170
2023-12-28 21:21:08,479 - mmseg - INFO - Iter [68850/160000]	lr: 3.418e-05, eta: 20:18:56, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2946, decode.acc_seg: 88.2150, aux.loss_ce: 0.1485, aux.acc_seg: 85.6860, loss: 0.4432
2023-12-28 21:21:48,966 - mmseg - INFO - Iter [68900/160000]	lr: 3.416e-05, eta: 20:18:16, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2680, decode.acc_seg: 89.0733, aux.loss_ce: 0.1328, aux.acc_seg: 87.0537, loss: 0.4008
2023-12-28 21:22:29,384 - mmseg - INFO - Iter [68950/160000]	lr: 3.414e-05, eta: 20:17:37, time: 0.810, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2731, decode.acc_seg: 89.0722, aux.loss_ce: 0.1358, aux.acc_seg: 87.0338, loss: 0.4089
2023-12-28 21:23:09,426 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 21:23:09,427 - mmseg - INFO - Iter [69000/160000]	lr: 3.413e-05, eta: 20:16:56, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2854, decode.acc_seg: 88.3580, aux.loss_ce: 0.1437, aux.acc_seg: 85.8565, loss: 0.4291
2023-12-28 21:23:48,393 - mmseg - INFO - Iter [69050/160000]	lr: 3.411e-05, eta: 20:16:15, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2778, decode.acc_seg: 88.7121, aux.loss_ce: 0.1375, aux.acc_seg: 86.6500, loss: 0.4152
2023-12-28 21:24:28,634 - mmseg - INFO - Iter [69100/160000]	lr: 3.409e-05, eta: 20:15:35, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2735, decode.acc_seg: 88.8953, aux.loss_ce: 0.1339, aux.acc_seg: 87.1117, loss: 0.4074
2023-12-28 21:25:08,628 - mmseg - INFO - Iter [69150/160000]	lr: 3.407e-05, eta: 20:14:54, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2790, decode.acc_seg: 89.0137, aux.loss_ce: 0.1356, aux.acc_seg: 87.1989, loss: 0.4147
2023-12-28 21:25:48,360 - mmseg - INFO - Iter [69200/160000]	lr: 3.405e-05, eta: 20:14:14, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2707, decode.acc_seg: 88.7264, aux.loss_ce: 0.1353, aux.acc_seg: 86.4394, loss: 0.4060
2023-12-28 21:26:27,693 - mmseg - INFO - Iter [69250/160000]	lr: 3.403e-05, eta: 20:13:33, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2830, decode.acc_seg: 88.2909, aux.loss_ce: 0.1420, aux.acc_seg: 85.9561, loss: 0.4250
2023-12-28 21:27:06,343 - mmseg - INFO - Iter [69300/160000]	lr: 3.401e-05, eta: 20:12:51, time: 0.773, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2637, decode.acc_seg: 89.0655, aux.loss_ce: 0.1318, aux.acc_seg: 87.0201, loss: 0.3955
2023-12-28 21:27:45,656 - mmseg - INFO - Iter [69350/160000]	lr: 3.399e-05, eta: 20:12:09, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2832, decode.acc_seg: 88.5703, aux.loss_ce: 0.1393, aux.acc_seg: 86.5097, loss: 0.4225
2023-12-28 21:28:24,827 - mmseg - INFO - Iter [69400/160000]	lr: 3.398e-05, eta: 20:11:28, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2829, decode.acc_seg: 88.3016, aux.loss_ce: 0.1413, aux.acc_seg: 86.2190, loss: 0.4242
2023-12-28 21:29:03,173 - mmseg - INFO - Iter [69450/160000]	lr: 3.396e-05, eta: 20:10:46, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2916, decode.acc_seg: 88.2313, aux.loss_ce: 0.1429, aux.acc_seg: 86.1063, loss: 0.4344
2023-12-28 21:29:45,195 - mmseg - INFO - Iter [69500/160000]	lr: 3.394e-05, eta: 20:10:08, time: 0.841, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2607, decode.acc_seg: 88.9927, aux.loss_ce: 0.1315, aux.acc_seg: 86.9437, loss: 0.3922
2023-12-28 21:30:25,340 - mmseg - INFO - Iter [69550/160000]	lr: 3.392e-05, eta: 20:09:28, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2720, decode.acc_seg: 88.9381, aux.loss_ce: 0.1416, aux.acc_seg: 86.3372, loss: 0.4136
2023-12-28 21:31:05,752 - mmseg - INFO - Iter [69600/160000]	lr: 3.390e-05, eta: 20:08:48, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2754, decode.acc_seg: 88.7024, aux.loss_ce: 0.1387, aux.acc_seg: 86.4839, loss: 0.4141
2023-12-28 21:31:45,662 - mmseg - INFO - Iter [69650/160000]	lr: 3.388e-05, eta: 20:08:08, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2628, decode.acc_seg: 89.0696, aux.loss_ce: 0.1337, aux.acc_seg: 86.8965, loss: 0.3965
2023-12-28 21:32:25,699 - mmseg - INFO - Iter [69700/160000]	lr: 3.386e-05, eta: 20:07:28, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2589, decode.acc_seg: 89.4651, aux.loss_ce: 0.1321, aux.acc_seg: 86.9186, loss: 0.3910
2023-12-28 21:33:03,399 - mmseg - INFO - Iter [69750/160000]	lr: 3.384e-05, eta: 20:06:44, time: 0.755, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2768, decode.acc_seg: 88.9732, aux.loss_ce: 0.1377, aux.acc_seg: 87.0185, loss: 0.4146
2023-12-28 21:33:40,841 - mmseg - INFO - Iter [69800/160000]	lr: 3.383e-05, eta: 20:06:01, time: 0.749, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2819, decode.acc_seg: 88.8051, aux.loss_ce: 0.1422, aux.acc_seg: 86.6419, loss: 0.4241
2023-12-28 21:34:18,857 - mmseg - INFO - Iter [69850/160000]	lr: 3.381e-05, eta: 20:05:18, time: 0.760, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2650, decode.acc_seg: 89.0047, aux.loss_ce: 0.1313, aux.acc_seg: 86.9150, loss: 0.3963
2023-12-28 21:34:57,566 - mmseg - INFO - Iter [69900/160000]	lr: 3.379e-05, eta: 20:04:36, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2598, decode.acc_seg: 89.3742, aux.loss_ce: 0.1291, aux.acc_seg: 87.4100, loss: 0.3890
2023-12-28 21:35:36,815 - mmseg - INFO - Iter [69950/160000]	lr: 3.377e-05, eta: 20:03:55, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2781, decode.acc_seg: 88.9110, aux.loss_ce: 0.1420, aux.acc_seg: 86.6388, loss: 0.4201
2023-12-28 21:36:14,188 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 21:36:14,189 - mmseg - INFO - Iter [70000/160000]	lr: 3.375e-05, eta: 20:03:11, time: 0.748, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2758, decode.acc_seg: 88.6920, aux.loss_ce: 0.1387, aux.acc_seg: 86.5135, loss: 0.4145
2023-12-28 21:36:55,141 - mmseg - INFO - Iter [70050/160000]	lr: 3.373e-05, eta: 20:02:32, time: 0.818, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2796, decode.acc_seg: 88.8364, aux.loss_ce: 0.1387, aux.acc_seg: 86.4405, loss: 0.4183
2023-12-28 21:37:35,199 - mmseg - INFO - Iter [70100/160000]	lr: 3.371e-05, eta: 20:01:52, time: 0.803, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2780, decode.acc_seg: 88.5335, aux.loss_ce: 0.1390, aux.acc_seg: 86.2822, loss: 0.4170
2023-12-28 21:38:16,983 - mmseg - INFO - Iter [70150/160000]	lr: 3.369e-05, eta: 20:01:14, time: 0.835, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2757, decode.acc_seg: 88.6707, aux.loss_ce: 0.1393, aux.acc_seg: 86.4271, loss: 0.4150
2023-12-28 21:38:57,452 - mmseg - INFO - Iter [70200/160000]	lr: 3.368e-05, eta: 20:00:35, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2679, decode.acc_seg: 89.0188, aux.loss_ce: 0.1345, aux.acc_seg: 87.0429, loss: 0.4023
2023-12-28 21:39:35,093 - mmseg - INFO - Iter [70250/160000]	lr: 3.366e-05, eta: 19:59:51, time: 0.753, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2758, decode.acc_seg: 88.9454, aux.loss_ce: 0.1360, aux.acc_seg: 86.7828, loss: 0.4118
2023-12-28 21:40:16,301 - mmseg - INFO - Iter [70300/160000]	lr: 3.364e-05, eta: 19:59:13, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2719, decode.acc_seg: 89.2725, aux.loss_ce: 0.1380, aux.acc_seg: 87.0877, loss: 0.4099
2023-12-28 21:40:54,937 - mmseg - INFO - Iter [70350/160000]	lr: 3.362e-05, eta: 19:58:31, time: 0.773, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2693, decode.acc_seg: 89.1184, aux.loss_ce: 0.1342, aux.acc_seg: 86.9751, loss: 0.4036
2023-12-28 21:41:34,672 - mmseg - INFO - Iter [70400/160000]	lr: 3.360e-05, eta: 19:57:50, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2803, decode.acc_seg: 88.6448, aux.loss_ce: 0.1388, aux.acc_seg: 86.7939, loss: 0.4191
2023-12-28 21:42:14,367 - mmseg - INFO - Iter [70450/160000]	lr: 3.358e-05, eta: 19:57:09, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2710, decode.acc_seg: 88.9168, aux.loss_ce: 0.1347, aux.acc_seg: 86.6933, loss: 0.4057
2023-12-28 21:42:54,618 - mmseg - INFO - Iter [70500/160000]	lr: 3.356e-05, eta: 19:56:29, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2811, decode.acc_seg: 88.6480, aux.loss_ce: 0.1378, aux.acc_seg: 86.6370, loss: 0.4190
2023-12-28 21:43:35,423 - mmseg - INFO - Iter [70550/160000]	lr: 3.354e-05, eta: 19:55:50, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2640, decode.acc_seg: 89.0902, aux.loss_ce: 0.1301, aux.acc_seg: 87.0373, loss: 0.3941
2023-12-28 21:44:16,458 - mmseg - INFO - Iter [70600/160000]	lr: 3.353e-05, eta: 19:55:11, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2802, decode.acc_seg: 88.5604, aux.loss_ce: 0.1388, aux.acc_seg: 86.2307, loss: 0.4190
2023-12-28 21:44:57,569 - mmseg - INFO - Iter [70650/160000]	lr: 3.351e-05, eta: 19:54:32, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2647, decode.acc_seg: 88.8429, aux.loss_ce: 0.1325, aux.acc_seg: 86.7565, loss: 0.3972
2023-12-28 21:45:38,704 - mmseg - INFO - Iter [70700/160000]	lr: 3.349e-05, eta: 19:53:54, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2710, decode.acc_seg: 89.2783, aux.loss_ce: 0.1352, aux.acc_seg: 87.3329, loss: 0.4062
2023-12-28 21:46:19,524 - mmseg - INFO - Iter [70750/160000]	lr: 3.347e-05, eta: 19:53:14, time: 0.818, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2876, decode.acc_seg: 88.3091, aux.loss_ce: 0.1421, aux.acc_seg: 86.1539, loss: 0.4297
2023-12-28 21:46:58,660 - mmseg - INFO - Iter [70800/160000]	lr: 3.345e-05, eta: 19:52:33, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2694, decode.acc_seg: 88.8807, aux.loss_ce: 0.1328, aux.acc_seg: 86.6514, loss: 0.4022
2023-12-28 21:47:39,572 - mmseg - INFO - Iter [70850/160000]	lr: 3.343e-05, eta: 19:51:54, time: 0.819, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2759, decode.acc_seg: 88.7834, aux.loss_ce: 0.1351, aux.acc_seg: 87.0049, loss: 0.4111
2023-12-28 21:48:17,958 - mmseg - INFO - Iter [70900/160000]	lr: 3.341e-05, eta: 19:51:12, time: 0.768, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2568, decode.acc_seg: 89.4852, aux.loss_ce: 0.1300, aux.acc_seg: 87.0190, loss: 0.3868
2023-12-28 21:48:56,124 - mmseg - INFO - Iter [70950/160000]	lr: 3.339e-05, eta: 19:50:29, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2619, decode.acc_seg: 89.3013, aux.loss_ce: 0.1323, aux.acc_seg: 87.1676, loss: 0.3942
2023-12-28 21:49:37,443 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 21:49:37,443 - mmseg - INFO - Iter [71000/160000]	lr: 3.338e-05, eta: 19:49:51, time: 0.827, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2582, decode.acc_seg: 89.1008, aux.loss_ce: 0.1260, aux.acc_seg: 87.3245, loss: 0.3842
2023-12-28 21:50:18,748 - mmseg - INFO - Iter [71050/160000]	lr: 3.336e-05, eta: 19:49:12, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2644, decode.acc_seg: 89.1816, aux.loss_ce: 0.1327, aux.acc_seg: 86.9468, loss: 0.3971
2023-12-28 21:50:58,165 - mmseg - INFO - Iter [71100/160000]	lr: 3.334e-05, eta: 19:48:31, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2567, decode.acc_seg: 89.5934, aux.loss_ce: 0.1317, aux.acc_seg: 87.3468, loss: 0.3884
2023-12-28 21:51:39,513 - mmseg - INFO - Iter [71150/160000]	lr: 3.332e-05, eta: 19:47:52, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2545, decode.acc_seg: 89.5696, aux.loss_ce: 0.1297, aux.acc_seg: 87.1077, loss: 0.3842
2023-12-28 21:52:19,662 - mmseg - INFO - Iter [71200/160000]	lr: 3.330e-05, eta: 19:47:12, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2822, decode.acc_seg: 88.5186, aux.loss_ce: 0.1401, aux.acc_seg: 86.3626, loss: 0.4223
2023-12-28 21:52:59,736 - mmseg - INFO - Iter [71250/160000]	lr: 3.328e-05, eta: 19:46:32, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2652, decode.acc_seg: 89.3701, aux.loss_ce: 0.1344, aux.acc_seg: 87.0017, loss: 0.3996
2023-12-28 21:53:39,833 - mmseg - INFO - Iter [71300/160000]	lr: 3.326e-05, eta: 19:45:52, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2708, decode.acc_seg: 88.7584, aux.loss_ce: 0.1342, aux.acc_seg: 86.6333, loss: 0.4050
2023-12-28 21:54:17,589 - mmseg - INFO - Iter [71350/160000]	lr: 3.324e-05, eta: 19:45:09, time: 0.755, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2615, decode.acc_seg: 89.2901, aux.loss_ce: 0.1283, aux.acc_seg: 87.4756, loss: 0.3898
2023-12-28 21:54:55,186 - mmseg - INFO - Iter [71400/160000]	lr: 3.323e-05, eta: 19:44:26, time: 0.752, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2684, decode.acc_seg: 88.8396, aux.loss_ce: 0.1350, aux.acc_seg: 86.6749, loss: 0.4034
2023-12-28 21:55:35,368 - mmseg - INFO - Iter [71450/160000]	lr: 3.321e-05, eta: 19:43:46, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2842, decode.acc_seg: 88.1365, aux.loss_ce: 0.1405, aux.acc_seg: 86.1568, loss: 0.4248
2023-12-28 21:56:15,974 - mmseg - INFO - Iter [71500/160000]	lr: 3.319e-05, eta: 19:43:06, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2793, decode.acc_seg: 88.8207, aux.loss_ce: 0.1400, aux.acc_seg: 86.4879, loss: 0.4192
2023-12-28 21:56:55,925 - mmseg - INFO - Iter [71550/160000]	lr: 3.317e-05, eta: 19:42:26, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2785, decode.acc_seg: 89.0176, aux.loss_ce: 0.1430, aux.acc_seg: 86.3885, loss: 0.4215
2023-12-28 21:57:36,015 - mmseg - INFO - Iter [71600/160000]	lr: 3.315e-05, eta: 19:41:46, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2767, decode.acc_seg: 88.6739, aux.loss_ce: 0.1377, aux.acc_seg: 86.6001, loss: 0.4144
2023-12-28 21:58:16,836 - mmseg - INFO - Iter [71650/160000]	lr: 3.313e-05, eta: 19:41:07, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2673, decode.acc_seg: 89.3420, aux.loss_ce: 0.1346, aux.acc_seg: 87.0941, loss: 0.4019
2023-12-28 21:58:55,294 - mmseg - INFO - Iter [71700/160000]	lr: 3.311e-05, eta: 19:40:25, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2678, decode.acc_seg: 89.2406, aux.loss_ce: 0.1353, aux.acc_seg: 86.9887, loss: 0.4031
2023-12-28 21:59:35,245 - mmseg - INFO - Iter [71750/160000]	lr: 3.309e-05, eta: 19:39:44, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2706, decode.acc_seg: 88.8162, aux.loss_ce: 0.1365, aux.acc_seg: 86.6065, loss: 0.4072
2023-12-28 22:00:15,272 - mmseg - INFO - Iter [71800/160000]	lr: 3.308e-05, eta: 19:39:04, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2834, decode.acc_seg: 88.5827, aux.loss_ce: 0.1357, aux.acc_seg: 86.7578, loss: 0.4191
2023-12-28 22:00:55,386 - mmseg - INFO - Iter [71850/160000]	lr: 3.306e-05, eta: 19:38:24, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2851, decode.acc_seg: 88.5249, aux.loss_ce: 0.1370, aux.acc_seg: 86.6197, loss: 0.4221
2023-12-28 22:01:36,235 - mmseg - INFO - Iter [71900/160000]	lr: 3.304e-05, eta: 19:37:45, time: 0.816, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2782, decode.acc_seg: 88.8653, aux.loss_ce: 0.1382, aux.acc_seg: 86.8258, loss: 0.4164
2023-12-28 22:02:17,192 - mmseg - INFO - Iter [71950/160000]	lr: 3.302e-05, eta: 19:37:06, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2691, decode.acc_seg: 88.8057, aux.loss_ce: 0.1340, aux.acc_seg: 86.6662, loss: 0.4031
2023-12-28 22:03:00,222 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 22:03:00,222 - mmseg - INFO - Iter [72000/160000]	lr: 3.300e-05, eta: 19:36:29, time: 0.859, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2695, decode.acc_seg: 89.1310, aux.loss_ce: 0.1360, aux.acc_seg: 86.8818, loss: 0.4055
2023-12-28 22:03:42,128 - mmseg - INFO - Iter [72050/160000]	lr: 3.298e-05, eta: 19:35:51, time: 0.838, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2553, decode.acc_seg: 89.2910, aux.loss_ce: 0.1313, aux.acc_seg: 86.7820, loss: 0.3866
2023-12-28 22:04:23,111 - mmseg - INFO - Iter [72100/160000]	lr: 3.296e-05, eta: 19:35:12, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2673, decode.acc_seg: 89.1304, aux.loss_ce: 0.1364, aux.acc_seg: 86.9433, loss: 0.4037
2023-12-28 22:05:01,394 - mmseg - INFO - Iter [72150/160000]	lr: 3.294e-05, eta: 19:34:30, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2735, decode.acc_seg: 88.8722, aux.loss_ce: 0.1362, aux.acc_seg: 86.7831, loss: 0.4097
2023-12-28 22:05:39,659 - mmseg - INFO - Iter [72200/160000]	lr: 3.293e-05, eta: 19:33:48, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2563, decode.acc_seg: 89.7866, aux.loss_ce: 0.1293, aux.acc_seg: 87.4839, loss: 0.3856
2023-12-28 22:06:19,880 - mmseg - INFO - Iter [72250/160000]	lr: 3.291e-05, eta: 19:33:08, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2676, decode.acc_seg: 89.2389, aux.loss_ce: 0.1305, aux.acc_seg: 87.5612, loss: 0.3980
2023-12-28 22:07:00,880 - mmseg - INFO - Iter [72300/160000]	lr: 3.289e-05, eta: 19:32:29, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2756, decode.acc_seg: 88.7543, aux.loss_ce: 0.1360, aux.acc_seg: 86.9266, loss: 0.4117
2023-12-28 22:07:42,123 - mmseg - INFO - Iter [72350/160000]	lr: 3.287e-05, eta: 19:31:50, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2587, decode.acc_seg: 89.3674, aux.loss_ce: 0.1312, aux.acc_seg: 87.2058, loss: 0.3899
2023-12-28 22:08:20,532 - mmseg - INFO - Iter [72400/160000]	lr: 3.285e-05, eta: 19:31:08, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2583, decode.acc_seg: 89.5212, aux.loss_ce: 0.1301, aux.acc_seg: 87.2696, loss: 0.3884
2023-12-28 22:09:01,555 - mmseg - INFO - Iter [72450/160000]	lr: 3.283e-05, eta: 19:30:29, time: 0.819, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2764, decode.acc_seg: 88.6289, aux.loss_ce: 0.1383, aux.acc_seg: 86.5940, loss: 0.4147
2023-12-28 22:09:43,848 - mmseg - INFO - Iter [72500/160000]	lr: 3.281e-05, eta: 19:29:51, time: 0.847, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2631, decode.acc_seg: 89.0004, aux.loss_ce: 0.1322, aux.acc_seg: 86.8976, loss: 0.3953
2023-12-28 22:10:24,216 - mmseg - INFO - Iter [72550/160000]	lr: 3.279e-05, eta: 19:29:11, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2762, decode.acc_seg: 88.6951, aux.loss_ce: 0.1358, aux.acc_seg: 86.4852, loss: 0.4120
2023-12-28 22:11:03,517 - mmseg - INFO - Iter [72600/160000]	lr: 3.278e-05, eta: 19:28:30, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2568, decode.acc_seg: 89.6653, aux.loss_ce: 0.1330, aux.acc_seg: 87.4118, loss: 0.3898
2023-12-28 22:11:43,657 - mmseg - INFO - Iter [72650/160000]	lr: 3.276e-05, eta: 19:27:50, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2712, decode.acc_seg: 89.1021, aux.loss_ce: 0.1357, aux.acc_seg: 86.9396, loss: 0.4069
2023-12-28 22:12:22,577 - mmseg - INFO - Iter [72700/160000]	lr: 3.274e-05, eta: 19:27:09, time: 0.778, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2633, decode.acc_seg: 89.2368, aux.loss_ce: 0.1310, aux.acc_seg: 87.3705, loss: 0.3943
2023-12-28 22:13:02,841 - mmseg - INFO - Iter [72750/160000]	lr: 3.272e-05, eta: 19:26:29, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2537, decode.acc_seg: 89.6336, aux.loss_ce: 0.1288, aux.acc_seg: 87.4251, loss: 0.3825
2023-12-28 22:13:41,571 - mmseg - INFO - Iter [72800/160000]	lr: 3.270e-05, eta: 19:25:47, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2801, decode.acc_seg: 88.5884, aux.loss_ce: 0.1349, aux.acc_seg: 86.8347, loss: 0.4150
2023-12-28 22:14:20,390 - mmseg - INFO - Iter [72850/160000]	lr: 3.268e-05, eta: 19:25:05, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2805, decode.acc_seg: 88.6296, aux.loss_ce: 0.1373, aux.acc_seg: 86.6530, loss: 0.4178
2023-12-28 22:15:01,030 - mmseg - INFO - Iter [72900/160000]	lr: 3.266e-05, eta: 19:24:26, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2686, decode.acc_seg: 89.1913, aux.loss_ce: 0.1350, aux.acc_seg: 87.1358, loss: 0.4037
2023-12-28 22:15:40,808 - mmseg - INFO - Iter [72950/160000]	lr: 3.264e-05, eta: 19:23:45, time: 0.797, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2709, decode.acc_seg: 88.5487, aux.loss_ce: 0.1350, aux.acc_seg: 86.4341, loss: 0.4059
2023-12-28 22:16:20,854 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 22:16:20,854 - mmseg - INFO - Iter [73000/160000]	lr: 3.263e-05, eta: 19:23:05, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2593, decode.acc_seg: 89.2055, aux.loss_ce: 0.1341, aux.acc_seg: 86.9063, loss: 0.3935
2023-12-28 22:17:00,224 - mmseg - INFO - Iter [73050/160000]	lr: 3.261e-05, eta: 19:22:24, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2754, decode.acc_seg: 89.0544, aux.loss_ce: 0.1366, aux.acc_seg: 86.8660, loss: 0.4120
2023-12-28 22:17:37,178 - mmseg - INFO - Iter [73100/160000]	lr: 3.259e-05, eta: 19:21:40, time: 0.739, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2727, decode.acc_seg: 88.7076, aux.loss_ce: 0.1344, aux.acc_seg: 86.7517, loss: 0.4070
2023-12-28 22:18:17,868 - mmseg - INFO - Iter [73150/160000]	lr: 3.257e-05, eta: 19:21:01, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2736, decode.acc_seg: 88.6367, aux.loss_ce: 0.1385, aux.acc_seg: 86.5269, loss: 0.4121
2023-12-28 22:18:59,131 - mmseg - INFO - Iter [73200/160000]	lr: 3.255e-05, eta: 19:20:22, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2697, decode.acc_seg: 88.7468, aux.loss_ce: 0.1333, aux.acc_seg: 86.8555, loss: 0.4030
2023-12-28 22:19:38,091 - mmseg - INFO - Iter [73250/160000]	lr: 3.253e-05, eta: 19:19:41, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2616, decode.acc_seg: 89.2557, aux.loss_ce: 0.1308, aux.acc_seg: 86.9795, loss: 0.3924
2023-12-28 22:20:19,499 - mmseg - INFO - Iter [73300/160000]	lr: 3.251e-05, eta: 19:19:02, time: 0.827, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2672, decode.acc_seg: 89.2794, aux.loss_ce: 0.1354, aux.acc_seg: 87.0163, loss: 0.4026
2023-12-28 22:20:58,444 - mmseg - INFO - Iter [73350/160000]	lr: 3.249e-05, eta: 19:18:21, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2425, decode.acc_seg: 90.0865, aux.loss_ce: 0.1233, aux.acc_seg: 88.1358, loss: 0.3659
2023-12-28 22:21:39,166 - mmseg - INFO - Iter [73400/160000]	lr: 3.248e-05, eta: 19:17:41, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2591, decode.acc_seg: 89.4837, aux.loss_ce: 0.1267, aux.acc_seg: 87.6309, loss: 0.3859
2023-12-28 22:22:19,461 - mmseg - INFO - Iter [73450/160000]	lr: 3.246e-05, eta: 19:17:01, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2666, decode.acc_seg: 89.2749, aux.loss_ce: 0.1334, aux.acc_seg: 86.9906, loss: 0.4000
2023-12-28 22:22:59,750 - mmseg - INFO - Iter [73500/160000]	lr: 3.244e-05, eta: 19:16:22, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2476, decode.acc_seg: 89.6746, aux.loss_ce: 0.1240, aux.acc_seg: 87.5961, loss: 0.3716
2023-12-28 22:23:40,781 - mmseg - INFO - Iter [73550/160000]	lr: 3.242e-05, eta: 19:15:43, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2466, decode.acc_seg: 89.7809, aux.loss_ce: 0.1244, aux.acc_seg: 87.8927, loss: 0.3710
2023-12-28 22:24:23,202 - mmseg - INFO - Iter [73600/160000]	lr: 3.240e-05, eta: 19:15:05, time: 0.848, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2509, decode.acc_seg: 89.4761, aux.loss_ce: 0.1309, aux.acc_seg: 87.1836, loss: 0.3819
2023-12-28 22:25:05,751 - mmseg - INFO - Iter [73650/160000]	lr: 3.238e-05, eta: 19:14:28, time: 0.851, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2574, decode.acc_seg: 89.6017, aux.loss_ce: 0.1273, aux.acc_seg: 87.5650, loss: 0.3847
2023-12-28 22:25:46,516 - mmseg - INFO - Iter [73700/160000]	lr: 3.236e-05, eta: 19:13:49, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2767, decode.acc_seg: 88.9160, aux.loss_ce: 0.1365, aux.acc_seg: 86.9335, loss: 0.4132
2023-12-28 22:26:27,660 - mmseg - INFO - Iter [73750/160000]	lr: 3.234e-05, eta: 19:13:10, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2644, decode.acc_seg: 89.0211, aux.loss_ce: 0.1329, aux.acc_seg: 86.8287, loss: 0.3973
2023-12-28 22:27:08,426 - mmseg - INFO - Iter [73800/160000]	lr: 3.233e-05, eta: 19:12:30, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2675, decode.acc_seg: 89.0679, aux.loss_ce: 0.1343, aux.acc_seg: 86.7847, loss: 0.4018
2023-12-28 22:27:48,820 - mmseg - INFO - Iter [73850/160000]	lr: 3.231e-05, eta: 19:11:51, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2746, decode.acc_seg: 88.4904, aux.loss_ce: 0.1346, aux.acc_seg: 86.5119, loss: 0.4092
2023-12-28 22:28:28,041 - mmseg - INFO - Iter [73900/160000]	lr: 3.229e-05, eta: 19:11:09, time: 0.785, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2707, decode.acc_seg: 89.1387, aux.loss_ce: 0.1350, aux.acc_seg: 87.1677, loss: 0.4056
2023-12-28 22:29:07,354 - mmseg - INFO - Iter [73950/160000]	lr: 3.227e-05, eta: 19:10:28, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2696, decode.acc_seg: 89.2829, aux.loss_ce: 0.1330, aux.acc_seg: 87.2135, loss: 0.4027
2023-12-28 22:29:47,746 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 22:29:47,746 - mmseg - INFO - Iter [74000/160000]	lr: 3.225e-05, eta: 19:09:49, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2664, decode.acc_seg: 89.1208, aux.loss_ce: 0.1337, aux.acc_seg: 86.8721, loss: 0.4001
2023-12-28 22:30:28,325 - mmseg - INFO - Iter [74050/160000]	lr: 3.223e-05, eta: 19:09:09, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2580, decode.acc_seg: 89.0015, aux.loss_ce: 0.1284, aux.acc_seg: 87.0488, loss: 0.3864
2023-12-28 22:31:08,877 - mmseg - INFO - Iter [74100/160000]	lr: 3.221e-05, eta: 19:08:29, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2534, decode.acc_seg: 89.4328, aux.loss_ce: 0.1292, aux.acc_seg: 87.3681, loss: 0.3825
2023-12-28 22:31:49,889 - mmseg - INFO - Iter [74150/160000]	lr: 3.219e-05, eta: 19:07:50, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2868, decode.acc_seg: 88.2568, aux.loss_ce: 0.1413, aux.acc_seg: 86.3459, loss: 0.4281
2023-12-28 22:32:30,919 - mmseg - INFO - Iter [74200/160000]	lr: 3.218e-05, eta: 19:07:11, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2568, decode.acc_seg: 89.0326, aux.loss_ce: 0.1287, aux.acc_seg: 86.9729, loss: 0.3854
2023-12-28 22:33:10,271 - mmseg - INFO - Iter [74250/160000]	lr: 3.216e-05, eta: 19:06:30, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2645, decode.acc_seg: 89.1960, aux.loss_ce: 0.1328, aux.acc_seg: 86.9837, loss: 0.3973
2023-12-28 22:33:50,468 - mmseg - INFO - Iter [74300/160000]	lr: 3.214e-05, eta: 19:05:50, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2609, decode.acc_seg: 89.6550, aux.loss_ce: 0.1288, aux.acc_seg: 87.7748, loss: 0.3897
2023-12-28 22:34:29,960 - mmseg - INFO - Iter [74350/160000]	lr: 3.212e-05, eta: 19:05:09, time: 0.789, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2637, decode.acc_seg: 88.9132, aux.loss_ce: 0.1310, aux.acc_seg: 86.7836, loss: 0.3947
2023-12-28 22:35:11,200 - mmseg - INFO - Iter [74400/160000]	lr: 3.210e-05, eta: 19:04:31, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2774, decode.acc_seg: 89.1240, aux.loss_ce: 0.1384, aux.acc_seg: 86.9298, loss: 0.4158
2023-12-28 22:35:52,914 - mmseg - INFO - Iter [74450/160000]	lr: 3.208e-05, eta: 19:03:52, time: 0.834, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2497, decode.acc_seg: 89.6696, aux.loss_ce: 0.1309, aux.acc_seg: 87.4161, loss: 0.3806
2023-12-28 22:36:33,737 - mmseg - INFO - Iter [74500/160000]	lr: 3.206e-05, eta: 19:03:13, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2769, decode.acc_seg: 88.8065, aux.loss_ce: 0.1365, aux.acc_seg: 86.8044, loss: 0.4134
2023-12-28 22:37:16,465 - mmseg - INFO - Iter [74550/160000]	lr: 3.204e-05, eta: 19:02:36, time: 0.855, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2692, decode.acc_seg: 89.2011, aux.loss_ce: 0.1328, aux.acc_seg: 87.1559, loss: 0.4020
2023-12-28 22:37:56,911 - mmseg - INFO - Iter [74600/160000]	lr: 3.203e-05, eta: 19:01:56, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2595, decode.acc_seg: 89.0614, aux.loss_ce: 0.1290, aux.acc_seg: 87.2092, loss: 0.3885
2023-12-28 22:38:34,870 - mmseg - INFO - Iter [74650/160000]	lr: 3.201e-05, eta: 19:01:14, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2576, decode.acc_seg: 89.5434, aux.loss_ce: 0.1316, aux.acc_seg: 87.1138, loss: 0.3892
2023-12-28 22:39:17,294 - mmseg - INFO - Iter [74700/160000]	lr: 3.199e-05, eta: 19:00:36, time: 0.849, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2662, decode.acc_seg: 88.9884, aux.loss_ce: 0.1345, aux.acc_seg: 87.0071, loss: 0.4007
2023-12-28 22:39:59,286 - mmseg - INFO - Iter [74750/160000]	lr: 3.197e-05, eta: 18:59:58, time: 0.840, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2498, decode.acc_seg: 89.8539, aux.loss_ce: 0.1276, aux.acc_seg: 87.3591, loss: 0.3774
2023-12-28 22:40:39,130 - mmseg - INFO - Iter [74800/160000]	lr: 3.195e-05, eta: 18:59:18, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2638, decode.acc_seg: 89.0426, aux.loss_ce: 0.1307, aux.acc_seg: 86.9556, loss: 0.3946
2023-12-28 22:41:18,508 - mmseg - INFO - Iter [74850/160000]	lr: 3.193e-05, eta: 18:58:37, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2643, decode.acc_seg: 89.2314, aux.loss_ce: 0.1322, aux.acc_seg: 87.2925, loss: 0.3964
2023-12-28 22:41:59,099 - mmseg - INFO - Iter [74900/160000]	lr: 3.191e-05, eta: 18:57:57, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2728, decode.acc_seg: 88.9459, aux.loss_ce: 0.1340, aux.acc_seg: 86.8042, loss: 0.4068
2023-12-28 22:42:39,552 - mmseg - INFO - Iter [74950/160000]	lr: 3.189e-05, eta: 18:57:18, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2692, decode.acc_seg: 88.8519, aux.loss_ce: 0.1340, aux.acc_seg: 86.7590, loss: 0.4032
2023-12-28 22:43:19,962 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 22:43:19,962 - mmseg - INFO - Iter [75000/160000]	lr: 3.188e-05, eta: 18:56:38, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2743, decode.acc_seg: 88.9440, aux.loss_ce: 0.1369, aux.acc_seg: 86.7318, loss: 0.4112
2023-12-28 22:43:58,707 - mmseg - INFO - Iter [75050/160000]	lr: 3.186e-05, eta: 18:55:56, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2638, decode.acc_seg: 89.2734, aux.loss_ce: 0.1360, aux.acc_seg: 87.0094, loss: 0.3998
2023-12-28 22:44:37,439 - mmseg - INFO - Iter [75100/160000]	lr: 3.184e-05, eta: 18:55:14, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2768, decode.acc_seg: 88.5925, aux.loss_ce: 0.1415, aux.acc_seg: 86.1531, loss: 0.4183
2023-12-28 22:45:18,632 - mmseg - INFO - Iter [75150/160000]	lr: 3.182e-05, eta: 18:54:35, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2527, decode.acc_seg: 89.5078, aux.loss_ce: 0.1254, aux.acc_seg: 87.7165, loss: 0.3782
2023-12-28 22:45:58,811 - mmseg - INFO - Iter [75200/160000]	lr: 3.180e-05, eta: 18:53:55, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2752, decode.acc_seg: 88.8620, aux.loss_ce: 0.1376, aux.acc_seg: 86.8174, loss: 0.4128
2023-12-28 22:46:38,495 - mmseg - INFO - Iter [75250/160000]	lr: 3.178e-05, eta: 18:53:15, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2537, decode.acc_seg: 89.7399, aux.loss_ce: 0.1280, aux.acc_seg: 87.4700, loss: 0.3817
2023-12-28 22:47:19,077 - mmseg - INFO - Iter [75300/160000]	lr: 3.176e-05, eta: 18:52:35, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2612, decode.acc_seg: 89.6892, aux.loss_ce: 0.1291, aux.acc_seg: 87.6203, loss: 0.3903
2023-12-28 22:48:00,055 - mmseg - INFO - Iter [75350/160000]	lr: 3.174e-05, eta: 18:51:56, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2647, decode.acc_seg: 89.0981, aux.loss_ce: 0.1343, aux.acc_seg: 86.7617, loss: 0.3990
2023-12-28 22:48:40,936 - mmseg - INFO - Iter [75400/160000]	lr: 3.173e-05, eta: 18:51:17, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2581, decode.acc_seg: 89.6600, aux.loss_ce: 0.1271, aux.acc_seg: 87.8172, loss: 0.3852
2023-12-28 22:49:22,362 - mmseg - INFO - Iter [75450/160000]	lr: 3.171e-05, eta: 18:50:38, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2564, decode.acc_seg: 89.6000, aux.loss_ce: 0.1288, aux.acc_seg: 87.3501, loss: 0.3852
2023-12-28 22:50:03,539 - mmseg - INFO - Iter [75500/160000]	lr: 3.169e-05, eta: 18:49:59, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2786, decode.acc_seg: 88.4806, aux.loss_ce: 0.1354, aux.acc_seg: 86.8959, loss: 0.4140
2023-12-28 22:50:44,030 - mmseg - INFO - Iter [75550/160000]	lr: 3.167e-05, eta: 18:49:20, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2646, decode.acc_seg: 88.9444, aux.loss_ce: 0.1317, aux.acc_seg: 87.0356, loss: 0.3963
2023-12-28 22:51:25,817 - mmseg - INFO - Iter [75600/160000]	lr: 3.165e-05, eta: 18:48:41, time: 0.836, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2581, decode.acc_seg: 89.3614, aux.loss_ce: 0.1277, aux.acc_seg: 87.3730, loss: 0.3858
2023-12-28 22:52:05,706 - mmseg - INFO - Iter [75650/160000]	lr: 3.163e-05, eta: 18:48:01, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2601, decode.acc_seg: 89.3578, aux.loss_ce: 0.1344, aux.acc_seg: 86.8243, loss: 0.3945
2023-12-28 22:52:46,338 - mmseg - INFO - Iter [75700/160000]	lr: 3.161e-05, eta: 18:47:21, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2417, decode.acc_seg: 90.0577, aux.loss_ce: 0.1244, aux.acc_seg: 87.6316, loss: 0.3660
2023-12-28 22:53:24,752 - mmseg - INFO - Iter [75750/160000]	lr: 3.159e-05, eta: 18:46:39, time: 0.768, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2669, decode.acc_seg: 88.7786, aux.loss_ce: 0.1337, aux.acc_seg: 86.8269, loss: 0.4006
2023-12-28 22:54:04,770 - mmseg - INFO - Iter [75800/160000]	lr: 3.158e-05, eta: 18:45:59, time: 0.802, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2676, decode.acc_seg: 89.2951, aux.loss_ce: 0.1341, aux.acc_seg: 87.0952, loss: 0.4018
2023-12-28 22:54:45,616 - mmseg - INFO - Iter [75850/160000]	lr: 3.156e-05, eta: 18:45:20, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2433, decode.acc_seg: 89.8758, aux.loss_ce: 0.1255, aux.acc_seg: 87.5411, loss: 0.3688
2023-12-28 22:55:24,755 - mmseg - INFO - Iter [75900/160000]	lr: 3.154e-05, eta: 18:44:39, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2330, decode.acc_seg: 89.9232, aux.loss_ce: 0.1178, aux.acc_seg: 88.1011, loss: 0.3508
2023-12-28 22:56:06,001 - mmseg - INFO - Iter [75950/160000]	lr: 3.152e-05, eta: 18:44:00, time: 0.824, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2514, decode.acc_seg: 89.5341, aux.loss_ce: 0.1267, aux.acc_seg: 87.4347, loss: 0.3781
2023-12-28 22:56:49,648 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 22:56:49,649 - mmseg - INFO - Iter [76000/160000]	lr: 3.150e-05, eta: 18:43:24, time: 0.874, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2700, decode.acc_seg: 89.0444, aux.loss_ce: 0.1362, aux.acc_seg: 86.7033, loss: 0.4062
2023-12-28 22:57:29,181 - mmseg - INFO - Iter [76050/160000]	lr: 3.148e-05, eta: 18:42:43, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2575, decode.acc_seg: 89.2935, aux.loss_ce: 0.1297, aux.acc_seg: 86.9928, loss: 0.3872
2023-12-28 22:58:10,471 - mmseg - INFO - Iter [76100/160000]	lr: 3.146e-05, eta: 18:42:04, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2462, decode.acc_seg: 89.7430, aux.loss_ce: 0.1257, aux.acc_seg: 87.7856, loss: 0.3719
2023-12-28 22:58:51,328 - mmseg - INFO - Iter [76150/160000]	lr: 3.144e-05, eta: 18:41:25, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2459, decode.acc_seg: 90.0554, aux.loss_ce: 0.1246, aux.acc_seg: 87.9287, loss: 0.3705
2023-12-28 22:59:32,228 - mmseg - INFO - Iter [76200/160000]	lr: 3.143e-05, eta: 18:40:45, time: 0.818, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2669, decode.acc_seg: 89.0449, aux.loss_ce: 0.1322, aux.acc_seg: 87.1708, loss: 0.3991
2023-12-28 23:00:13,034 - mmseg - INFO - Iter [76250/160000]	lr: 3.141e-05, eta: 18:40:06, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2731, decode.acc_seg: 88.7444, aux.loss_ce: 0.1371, aux.acc_seg: 86.4010, loss: 0.4101
2023-12-28 23:00:53,030 - mmseg - INFO - Iter [76300/160000]	lr: 3.139e-05, eta: 18:39:26, time: 0.801, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2626, decode.acc_seg: 89.3443, aux.loss_ce: 0.1342, aux.acc_seg: 86.7968, loss: 0.3968
2023-12-28 23:01:31,446 - mmseg - INFO - Iter [76350/160000]	lr: 3.137e-05, eta: 18:38:44, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2525, decode.acc_seg: 89.5973, aux.loss_ce: 0.1252, aux.acc_seg: 87.5190, loss: 0.3777
2023-12-28 23:02:09,810 - mmseg - INFO - Iter [76400/160000]	lr: 3.135e-05, eta: 18:38:02, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2891, decode.acc_seg: 88.3686, aux.loss_ce: 0.1422, aux.acc_seg: 86.4122, loss: 0.4314
2023-12-28 23:02:47,808 - mmseg - INFO - Iter [76450/160000]	lr: 3.133e-05, eta: 18:37:19, time: 0.760, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2715, decode.acc_seg: 88.8921, aux.loss_ce: 0.1331, aux.acc_seg: 86.9545, loss: 0.4046
2023-12-28 23:03:26,412 - mmseg - INFO - Iter [76500/160000]	lr: 3.131e-05, eta: 18:36:37, time: 0.773, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2774, decode.acc_seg: 88.9227, aux.loss_ce: 0.1403, aux.acc_seg: 86.6681, loss: 0.4177
2023-12-28 23:04:06,879 - mmseg - INFO - Iter [76550/160000]	lr: 3.129e-05, eta: 18:35:58, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2587, decode.acc_seg: 89.5240, aux.loss_ce: 0.1284, aux.acc_seg: 87.5901, loss: 0.3871
2023-12-28 23:04:46,476 - mmseg - INFO - Iter [76600/160000]	lr: 3.128e-05, eta: 18:35:17, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2678, decode.acc_seg: 89.1683, aux.loss_ce: 0.1319, aux.acc_seg: 87.2825, loss: 0.3997
2023-12-28 23:05:27,065 - mmseg - INFO - Iter [76650/160000]	lr: 3.126e-05, eta: 18:34:37, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2764, decode.acc_seg: 88.5260, aux.loss_ce: 0.1382, aux.acc_seg: 86.1328, loss: 0.4146
2023-12-28 23:06:07,636 - mmseg - INFO - Iter [76700/160000]	lr: 3.124e-05, eta: 18:33:58, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2562, decode.acc_seg: 89.5441, aux.loss_ce: 0.1293, aux.acc_seg: 87.2207, loss: 0.3856
2023-12-28 23:06:48,000 - mmseg - INFO - Iter [76750/160000]	lr: 3.122e-05, eta: 18:33:18, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2629, decode.acc_seg: 89.1036, aux.loss_ce: 0.1338, aux.acc_seg: 86.8877, loss: 0.3967
2023-12-28 23:07:27,335 - mmseg - INFO - Iter [76800/160000]	lr: 3.120e-05, eta: 18:32:37, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2587, decode.acc_seg: 89.1662, aux.loss_ce: 0.1298, aux.acc_seg: 86.9603, loss: 0.3885
2023-12-28 23:08:05,931 - mmseg - INFO - Iter [76850/160000]	lr: 3.118e-05, eta: 18:31:55, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2736, decode.acc_seg: 88.8701, aux.loss_ce: 0.1333, aux.acc_seg: 86.9496, loss: 0.4069
2023-12-28 23:08:44,179 - mmseg - INFO - Iter [76900/160000]	lr: 3.116e-05, eta: 18:31:13, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2634, decode.acc_seg: 89.0451, aux.loss_ce: 0.1314, aux.acc_seg: 86.9171, loss: 0.3948
2023-12-28 23:09:23,097 - mmseg - INFO - Iter [76950/160000]	lr: 3.114e-05, eta: 18:30:32, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2563, decode.acc_seg: 89.5252, aux.loss_ce: 0.1327, aux.acc_seg: 86.9931, loss: 0.3890
2023-12-28 23:10:04,085 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 23:10:04,085 - mmseg - INFO - Iter [77000/160000]	lr: 3.113e-05, eta: 18:29:52, time: 0.820, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2671, decode.acc_seg: 89.2041, aux.loss_ce: 0.1334, aux.acc_seg: 87.0738, loss: 0.4004
2023-12-28 23:10:45,798 - mmseg - INFO - Iter [77050/160000]	lr: 3.111e-05, eta: 18:29:14, time: 0.834, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2458, decode.acc_seg: 89.8443, aux.loss_ce: 0.1222, aux.acc_seg: 87.7308, loss: 0.3680
2023-12-28 23:11:25,132 - mmseg - INFO - Iter [77100/160000]	lr: 3.109e-05, eta: 18:28:33, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2835, decode.acc_seg: 88.8718, aux.loss_ce: 0.1434, aux.acc_seg: 86.7168, loss: 0.4269
2023-12-28 23:12:02,687 - mmseg - INFO - Iter [77150/160000]	lr: 3.107e-05, eta: 18:27:50, time: 0.751, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2657, decode.acc_seg: 89.4292, aux.loss_ce: 0.1339, aux.acc_seg: 87.1268, loss: 0.3996
2023-12-28 23:12:42,285 - mmseg - INFO - Iter [77200/160000]	lr: 3.105e-05, eta: 18:27:10, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2555, decode.acc_seg: 89.7992, aux.loss_ce: 0.1280, aux.acc_seg: 87.6934, loss: 0.3834
2023-12-28 23:13:22,412 - mmseg - INFO - Iter [77250/160000]	lr: 3.103e-05, eta: 18:26:29, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2735, decode.acc_seg: 88.9040, aux.loss_ce: 0.1371, aux.acc_seg: 86.7772, loss: 0.4105
2023-12-28 23:14:00,816 - mmseg - INFO - Iter [77300/160000]	lr: 3.101e-05, eta: 18:25:47, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2549, decode.acc_seg: 89.5983, aux.loss_ce: 0.1282, aux.acc_seg: 87.4867, loss: 0.3831
2023-12-28 23:14:39,335 - mmseg - INFO - Iter [77350/160000]	lr: 3.099e-05, eta: 18:25:06, time: 0.771, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2535, decode.acc_seg: 89.5446, aux.loss_ce: 0.1267, aux.acc_seg: 87.4147, loss: 0.3801
2023-12-28 23:15:16,435 - mmseg - INFO - Iter [77400/160000]	lr: 3.098e-05, eta: 18:24:22, time: 0.742, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2621, decode.acc_seg: 89.0488, aux.loss_ce: 0.1374, aux.acc_seg: 86.3413, loss: 0.3996
2023-12-28 23:15:56,916 - mmseg - INFO - Iter [77450/160000]	lr: 3.096e-05, eta: 18:23:43, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2617, decode.acc_seg: 89.0664, aux.loss_ce: 0.1307, aux.acc_seg: 87.0247, loss: 0.3924
2023-12-28 23:16:37,501 - mmseg - INFO - Iter [77500/160000]	lr: 3.094e-05, eta: 18:23:03, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2721, decode.acc_seg: 89.0347, aux.loss_ce: 0.1330, aux.acc_seg: 87.2636, loss: 0.4051
2023-12-28 23:17:17,822 - mmseg - INFO - Iter [77550/160000]	lr: 3.092e-05, eta: 18:22:23, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2525, decode.acc_seg: 89.5989, aux.loss_ce: 0.1317, aux.acc_seg: 87.1618, loss: 0.3842
2023-12-28 23:17:58,088 - mmseg - INFO - Iter [77600/160000]	lr: 3.090e-05, eta: 18:21:43, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2651, decode.acc_seg: 89.2268, aux.loss_ce: 0.1324, aux.acc_seg: 87.0102, loss: 0.3975
2023-12-28 23:18:36,884 - mmseg - INFO - Iter [77650/160000]	lr: 3.088e-05, eta: 18:21:02, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2549, decode.acc_seg: 89.4348, aux.loss_ce: 0.1284, aux.acc_seg: 87.3666, loss: 0.3833
2023-12-28 23:19:17,724 - mmseg - INFO - Iter [77700/160000]	lr: 3.086e-05, eta: 18:20:22, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2626, decode.acc_seg: 89.3185, aux.loss_ce: 0.1305, aux.acc_seg: 87.0789, loss: 0.3931
2023-12-28 23:19:57,362 - mmseg - INFO - Iter [77750/160000]	lr: 3.084e-05, eta: 18:19:42, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2755, decode.acc_seg: 88.7442, aux.loss_ce: 0.1352, aux.acc_seg: 86.9458, loss: 0.4107
2023-12-28 23:20:38,355 - mmseg - INFO - Iter [77800/160000]	lr: 3.083e-05, eta: 18:19:03, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2665, decode.acc_seg: 89.1205, aux.loss_ce: 0.1348, aux.acc_seg: 86.8487, loss: 0.4013
2023-12-28 23:21:17,567 - mmseg - INFO - Iter [77850/160000]	lr: 3.081e-05, eta: 18:18:22, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2808, decode.acc_seg: 88.3278, aux.loss_ce: 0.1390, aux.acc_seg: 86.2013, loss: 0.4198
2023-12-28 23:21:57,457 - mmseg - INFO - Iter [77900/160000]	lr: 3.079e-05, eta: 18:17:41, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2623, decode.acc_seg: 89.3833, aux.loss_ce: 0.1314, aux.acc_seg: 87.1986, loss: 0.3937
2023-12-28 23:22:37,653 - mmseg - INFO - Iter [77950/160000]	lr: 3.077e-05, eta: 18:17:01, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2657, decode.acc_seg: 89.1241, aux.loss_ce: 0.1317, aux.acc_seg: 87.2891, loss: 0.3974
2023-12-28 23:23:17,386 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 23:23:17,386 - mmseg - INFO - Iter [78000/160000]	lr: 3.075e-05, eta: 18:16:21, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2691, decode.acc_seg: 89.0020, aux.loss_ce: 0.1312, aux.acc_seg: 87.2489, loss: 0.4003
2023-12-28 23:23:58,273 - mmseg - INFO - Iter [78050/160000]	lr: 3.073e-05, eta: 18:15:41, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2737, decode.acc_seg: 89.0279, aux.loss_ce: 0.1363, aux.acc_seg: 86.8437, loss: 0.4099
2023-12-28 23:24:39,276 - mmseg - INFO - Iter [78100/160000]	lr: 3.071e-05, eta: 18:15:02, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2567, decode.acc_seg: 89.5406, aux.loss_ce: 0.1290, aux.acc_seg: 87.3429, loss: 0.3857
2023-12-28 23:25:20,065 - mmseg - INFO - Iter [78150/160000]	lr: 3.069e-05, eta: 18:14:23, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2559, decode.acc_seg: 89.5861, aux.loss_ce: 0.1284, aux.acc_seg: 87.4287, loss: 0.3843
2023-12-28 23:26:00,492 - mmseg - INFO - Iter [78200/160000]	lr: 3.068e-05, eta: 18:13:43, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2718, decode.acc_seg: 88.7496, aux.loss_ce: 0.1366, aux.acc_seg: 86.3439, loss: 0.4084
2023-12-28 23:26:40,419 - mmseg - INFO - Iter [78250/160000]	lr: 3.066e-05, eta: 18:13:03, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2600, decode.acc_seg: 89.4573, aux.loss_ce: 0.1303, aux.acc_seg: 86.9360, loss: 0.3903
2023-12-28 23:27:20,907 - mmseg - INFO - Iter [78300/160000]	lr: 3.064e-05, eta: 18:12:23, time: 0.810, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2543, decode.acc_seg: 89.1752, aux.loss_ce: 0.1285, aux.acc_seg: 86.9329, loss: 0.3829
2023-12-28 23:28:01,209 - mmseg - INFO - Iter [78350/160000]	lr: 3.062e-05, eta: 18:11:43, time: 0.806, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2493, decode.acc_seg: 89.6459, aux.loss_ce: 0.1250, aux.acc_seg: 87.4694, loss: 0.3744
2023-12-28 23:28:38,179 - mmseg - INFO - Iter [78400/160000]	lr: 3.060e-05, eta: 18:11:00, time: 0.739, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2572, decode.acc_seg: 89.6242, aux.loss_ce: 0.1321, aux.acc_seg: 87.3286, loss: 0.3893
2023-12-28 23:29:18,397 - mmseg - INFO - Iter [78450/160000]	lr: 3.058e-05, eta: 18:10:20, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2525, decode.acc_seg: 89.9274, aux.loss_ce: 0.1288, aux.acc_seg: 87.6412, loss: 0.3813
2023-12-28 23:29:58,246 - mmseg - INFO - Iter [78500/160000]	lr: 3.056e-05, eta: 18:09:39, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2564, decode.acc_seg: 89.6391, aux.loss_ce: 0.1254, aux.acc_seg: 87.7445, loss: 0.3818
2023-12-28 23:30:35,110 - mmseg - INFO - Iter [78550/160000]	lr: 3.054e-05, eta: 18:08:56, time: 0.737, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2473, decode.acc_seg: 89.7536, aux.loss_ce: 0.1235, aux.acc_seg: 87.9967, loss: 0.3708
2023-12-28 23:31:14,861 - mmseg - INFO - Iter [78600/160000]	lr: 3.053e-05, eta: 18:08:15, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2643, decode.acc_seg: 89.0888, aux.loss_ce: 0.1333, aux.acc_seg: 86.9182, loss: 0.3976
2023-12-28 23:31:54,243 - mmseg - INFO - Iter [78650/160000]	lr: 3.051e-05, eta: 18:07:34, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2612, decode.acc_seg: 89.4103, aux.loss_ce: 0.1351, aux.acc_seg: 86.9768, loss: 0.3963
2023-12-28 23:32:33,981 - mmseg - INFO - Iter [78700/160000]	lr: 3.049e-05, eta: 18:06:54, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2676, decode.acc_seg: 89.1427, aux.loss_ce: 0.1319, aux.acc_seg: 86.9573, loss: 0.3996
2023-12-28 23:33:13,298 - mmseg - INFO - Iter [78750/160000]	lr: 3.047e-05, eta: 18:06:13, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2439, decode.acc_seg: 89.7913, aux.loss_ce: 0.1248, aux.acc_seg: 87.5989, loss: 0.3687
2023-12-28 23:33:52,603 - mmseg - INFO - Iter [78800/160000]	lr: 3.045e-05, eta: 18:05:32, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2489, decode.acc_seg: 89.9150, aux.loss_ce: 0.1261, aux.acc_seg: 87.7349, loss: 0.3750
2023-12-28 23:34:32,142 - mmseg - INFO - Iter [78850/160000]	lr: 3.043e-05, eta: 18:04:51, time: 0.791, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2539, decode.acc_seg: 89.3057, aux.loss_ce: 0.1301, aux.acc_seg: 87.0390, loss: 0.3840
2023-12-28 23:35:12,361 - mmseg - INFO - Iter [78900/160000]	lr: 3.041e-05, eta: 18:04:11, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2558, decode.acc_seg: 89.4538, aux.loss_ce: 0.1274, aux.acc_seg: 87.3549, loss: 0.3832
2023-12-28 23:35:50,279 - mmseg - INFO - Iter [78950/160000]	lr: 3.039e-05, eta: 18:03:29, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2692, decode.acc_seg: 89.1584, aux.loss_ce: 0.1354, aux.acc_seg: 86.9795, loss: 0.4046
2023-12-28 23:36:31,485 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 23:36:31,485 - mmseg - INFO - Iter [79000/160000]	lr: 3.038e-05, eta: 18:02:50, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2557, decode.acc_seg: 89.6720, aux.loss_ce: 0.1310, aux.acc_seg: 87.4234, loss: 0.3867
2023-12-28 23:37:12,208 - mmseg - INFO - Iter [79050/160000]	lr: 3.036e-05, eta: 18:02:11, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2719, decode.acc_seg: 88.9746, aux.loss_ce: 0.1355, aux.acc_seg: 86.7707, loss: 0.4074
2023-12-28 23:37:54,815 - mmseg - INFO - Iter [79100/160000]	lr: 3.034e-05, eta: 18:01:33, time: 0.852, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2703, decode.acc_seg: 88.9187, aux.loss_ce: 0.1354, aux.acc_seg: 86.7208, loss: 0.4057
2023-12-28 23:38:33,801 - mmseg - INFO - Iter [79150/160000]	lr: 3.032e-05, eta: 18:00:52, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2580, decode.acc_seg: 89.4947, aux.loss_ce: 0.1289, aux.acc_seg: 87.6006, loss: 0.3868
2023-12-28 23:39:14,310 - mmseg - INFO - Iter [79200/160000]	lr: 3.030e-05, eta: 18:00:12, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2525, decode.acc_seg: 89.5581, aux.loss_ce: 0.1275, aux.acc_seg: 87.5312, loss: 0.3800
2023-12-28 23:39:54,406 - mmseg - INFO - Iter [79250/160000]	lr: 3.028e-05, eta: 17:59:32, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2439, decode.acc_seg: 90.0179, aux.loss_ce: 0.1225, aux.acc_seg: 88.0282, loss: 0.3664
2023-12-28 23:40:34,091 - mmseg - INFO - Iter [79300/160000]	lr: 3.026e-05, eta: 17:58:51, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2461, decode.acc_seg: 89.9672, aux.loss_ce: 0.1237, aux.acc_seg: 87.8982, loss: 0.3697
2023-12-28 23:41:14,694 - mmseg - INFO - Iter [79350/160000]	lr: 3.024e-05, eta: 17:58:12, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2615, decode.acc_seg: 89.5260, aux.loss_ce: 0.1294, aux.acc_seg: 87.2797, loss: 0.3909
2023-12-28 23:41:55,291 - mmseg - INFO - Iter [79400/160000]	lr: 3.023e-05, eta: 17:57:32, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2576, decode.acc_seg: 89.3307, aux.loss_ce: 0.1309, aux.acc_seg: 87.1815, loss: 0.3885
2023-12-28 23:42:33,305 - mmseg - INFO - Iter [79450/160000]	lr: 3.021e-05, eta: 17:56:50, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2672, decode.acc_seg: 89.0837, aux.loss_ce: 0.1317, aux.acc_seg: 87.1492, loss: 0.3990
2023-12-28 23:43:11,563 - mmseg - INFO - Iter [79500/160000]	lr: 3.019e-05, eta: 17:56:08, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2601, decode.acc_seg: 89.5062, aux.loss_ce: 0.1292, aux.acc_seg: 87.6260, loss: 0.3893
2023-12-28 23:43:50,562 - mmseg - INFO - Iter [79550/160000]	lr: 3.017e-05, eta: 17:55:27, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2647, decode.acc_seg: 89.2866, aux.loss_ce: 0.1331, aux.acc_seg: 86.9877, loss: 0.3978
2023-12-28 23:44:30,646 - mmseg - INFO - Iter [79600/160000]	lr: 3.015e-05, eta: 17:54:47, time: 0.801, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2552, decode.acc_seg: 89.4825, aux.loss_ce: 0.1308, aux.acc_seg: 87.3979, loss: 0.3859
2023-12-28 23:45:11,369 - mmseg - INFO - Iter [79650/160000]	lr: 3.013e-05, eta: 17:54:07, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2468, decode.acc_seg: 89.9399, aux.loss_ce: 0.1250, aux.acc_seg: 87.5681, loss: 0.3718
2023-12-28 23:45:50,573 - mmseg - INFO - Iter [79700/160000]	lr: 3.011e-05, eta: 17:53:26, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2616, decode.acc_seg: 89.2161, aux.loss_ce: 0.1334, aux.acc_seg: 87.0664, loss: 0.3950
2023-12-28 23:46:32,221 - mmseg - INFO - Iter [79750/160000]	lr: 3.009e-05, eta: 17:52:48, time: 0.832, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2568, decode.acc_seg: 89.4768, aux.loss_ce: 0.1277, aux.acc_seg: 87.7123, loss: 0.3845
2023-12-28 23:47:13,810 - mmseg - INFO - Iter [79800/160000]	lr: 3.008e-05, eta: 17:52:09, time: 0.832, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2510, decode.acc_seg: 89.6532, aux.loss_ce: 0.1257, aux.acc_seg: 87.5936, loss: 0.3767
2023-12-28 23:47:53,605 - mmseg - INFO - Iter [79850/160000]	lr: 3.006e-05, eta: 17:51:29, time: 0.797, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2473, decode.acc_seg: 89.7315, aux.loss_ce: 0.1247, aux.acc_seg: 87.5441, loss: 0.3720
2023-12-28 23:48:30,803 - mmseg - INFO - Iter [79900/160000]	lr: 3.004e-05, eta: 17:50:46, time: 0.744, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2504, decode.acc_seg: 90.0323, aux.loss_ce: 0.1282, aux.acc_seg: 87.9038, loss: 0.3786
2023-12-28 23:49:08,796 - mmseg - INFO - Iter [79950/160000]	lr: 3.002e-05, eta: 17:50:03, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2536, decode.acc_seg: 89.5373, aux.loss_ce: 0.1287, aux.acc_seg: 87.3231, loss: 0.3823
2023-12-28 23:49:49,668 - mmseg - INFO - Saving checkpoint at 80000 iterations
2023-12-28 23:49:56,190 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 23:49:56,190 - mmseg - INFO - Iter [80000/160000]	lr: 3.000e-05, eta: 17:49:31, time: 0.949, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2563, decode.acc_seg: 89.6998, aux.loss_ce: 0.1323, aux.acc_seg: 87.2913, loss: 0.3885
2023-12-28 23:51:32,270 - mmseg - INFO - per class results:
2023-12-28 23:51:32,283 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 76.68 | 86.91 |
|       building      | 81.84 |  88.9 |
|         sky         | 94.45 | 97.47 |
|        floor        | 81.51 | 89.55 |
|         tree        | 74.74 | 91.02 |
|       ceiling       | 82.97 | 92.35 |
|         road        | 84.73 | 91.73 |
|         bed         | 89.65 | 94.83 |
|      windowpane     | 61.93 | 79.51 |
|        grass        | 68.65 | 82.15 |
|       cabinet       | 58.83 | 72.84 |
|       sidewalk      | 66.18 |  76.6 |
|        person       | 80.08 | 93.54 |
|        earth        | 35.84 | 49.84 |
|         door        | 51.53 | 69.61 |
|        table        | 58.69 | 75.86 |
|       mountain      |  58.0 |  77.6 |
|        plant        | 50.23 | 59.51 |
|       curtain       | 75.84 | 87.17 |
|        chair        | 53.39 | 64.01 |
|         car         | 83.59 | 90.35 |
|        water        | 50.83 | 61.75 |
|       painting      |  69.7 | 85.74 |
|         sofa        | 63.28 | 79.73 |
|        shelf        | 42.79 | 64.21 |
|        house        | 49.75 | 74.81 |
|         sea         | 53.32 | 78.28 |
|        mirror       | 66.89 | 77.47 |
|         rug         | 61.41 | 76.75 |
|        field        | 32.13 | 57.03 |
|       armchair      |  40.4 | 60.73 |
|         seat        | 58.76 |  81.4 |
|        fence        | 46.26 | 58.78 |
|         desk        | 50.43 | 67.65 |
|         rock        | 41.52 | 66.15 |
|       wardrobe      | 49.82 | 66.44 |
|         lamp        | 61.89 | 76.81 |
|       bathtub       | 76.13 | 84.95 |
|       railing       | 35.26 | 47.34 |
|       cushion       | 57.66 | 72.13 |
|         base        | 26.36 | 34.01 |
|         box         | 21.91 | 26.31 |
|        column       | 44.99 | 58.46 |
|      signboard      |  36.2 | 49.22 |
|   chest of drawers  |  42.2 | 55.99 |
|       counter       | 30.76 | 38.52 |
|         sand        | 35.16 |  49.2 |
|         sink        | 67.09 |  75.3 |
|      skyscraper     | 47.73 | 65.63 |
|      fireplace      | 67.71 | 86.26 |
|     refrigerator    | 73.09 |  84.8 |
|      grandstand     | 35.76 | 69.98 |
|         path        | 25.49 | 42.76 |
|        stairs       | 31.26 | 39.36 |
|        runway       | 68.01 | 93.97 |
|         case        |  52.8 | 71.65 |
|      pool table     | 92.28 | 97.44 |
|        pillow       | 60.91 | 81.88 |
|     screen door     | 74.09 | 79.02 |
|       stairway      | 30.24 | 37.18 |
|        river        | 11.14 | 31.45 |
|        bridge       | 58.91 | 81.18 |
|       bookcase      |  33.9 | 51.27 |
|        blind        | 35.15 | 38.57 |
|     coffee table    | 56.39 | 78.85 |
|        toilet       | 82.62 |  92.3 |
|        flower       |  36.1 | 54.25 |
|         book        |  39.8 | 66.97 |
|         hill        |  9.41 | 14.98 |
|        bench        | 43.35 | 49.06 |
|      countertop     | 60.29 | 80.31 |
|        stove        | 71.25 | 90.16 |
|         palm        | 47.06 | 64.28 |
|    kitchen island   | 41.36 | 88.38 |
|       computer      | 72.86 | 92.15 |
|     swivel chair    | 38.81 | 71.28 |
|         boat        | 37.15 | 46.98 |
|         bar         | 29.57 | 40.09 |
|    arcade machine   | 87.16 | 97.14 |
|        hovel        | 51.69 |  57.5 |
|         bus         | 83.98 | 96.55 |
|        towel        | 60.03 | 74.38 |
|        light        | 53.64 | 60.37 |
|        truck        | 32.36 | 41.06 |
|        tower        | 26.07 | 59.58 |
|      chandelier     | 68.33 | 82.28 |
|        awning       | 26.32 |  33.9 |
|     streetlight     | 24.31 | 33.27 |
|        booth        | 53.81 | 57.32 |
| television receiver |  61.1 | 76.25 |
|       airplane      | 58.69 | 74.61 |
|      dirt track     |  6.92 | 10.77 |
|       apparel       |  41.6 | 58.48 |
|         pole        | 19.08 | 24.84 |
|         land        |  2.92 |  3.71 |
|      bannister      | 11.36 | 14.23 |
|      escalator      | 37.64 |  43.3 |
|       ottoman       | 37.56 | 53.37 |
|        bottle       | 23.85 | 28.44 |
|        buffet       | 36.16 | 43.13 |
|        poster       | 25.58 | 34.08 |
|        stage        | 15.11 | 31.27 |
|         van         | 44.93 | 65.66 |
|         ship        | 57.14 | 97.84 |
|       fountain      | 22.92 | 23.21 |
|    conveyer belt    | 79.57 | 88.55 |
|        canopy       | 24.08 | 31.36 |
|        washer       | 90.22 | 95.95 |
|      plaything      | 23.84 | 41.69 |
|    swimming pool    | 72.01 | 90.19 |
|        stool        | 37.05 | 55.46 |
|        barrel       | 12.82 | 64.89 |
|        basket       | 31.04 |  45.3 |
|      waterfall      | 74.62 | 81.35 |
|         tent        | 90.48 | 98.25 |
|         bag         | 11.37 | 13.25 |
|       minibike      | 68.14 | 76.61 |
|        cradle       | 71.37 | 98.25 |
|         oven        | 35.78 | 46.16 |
|         ball        | 47.49 | 66.59 |
|         food        | 40.14 | 47.25 |
|         step        |  7.7  |  10.4 |
|         tank        | 42.34 | 43.41 |
|      trade name     | 21.49 | 25.34 |
|      microwave      | 79.23 | 89.06 |
|         pot         | 40.07 | 45.89 |
|        animal       | 55.73 | 60.12 |
|       bicycle       | 55.56 |  77.0 |
|         lake        | 49.76 | 63.67 |
|      dishwasher     | 51.62 | 62.38 |
|        screen       | 64.88 | 88.53 |
|       blanket       | 12.53 | 14.81 |
|      sculpture      | 52.14 | 62.71 |
|         hood        | 56.24 | 77.83 |
|        sconce       | 38.28 | 45.71 |
|         vase        | 38.81 | 48.56 |
|    traffic light    | 24.79 | 38.72 |
|         tray        |  7.94 | 10.69 |
|        ashcan       |  38.7 | 49.05 |
|         fan         | 51.48 | 75.56 |
|         pier        | 56.03 | 77.75 |
|      crt screen     |  4.4  | 11.57 |
|        plate        | 51.41 | 68.56 |
|       monitor       | 11.83 | 12.78 |
|    bulletin board   | 50.95 | 60.72 |
|        shower       |  3.8  |  4.41 |
|       radiator      | 48.42 | 62.92 |
|        glass        | 12.97 | 14.13 |
|        clock        | 29.97 | 32.86 |
|         flag        | 58.08 | 64.99 |
+---------------------+-------+-------+
2023-12-28 23:51:32,284 - mmseg - INFO - Summary:
2023-12-28 23:51:32,284 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 82.62 | 48.29 | 61.58 |
+-------+-------+-------+
2023-12-28 23:51:32,311 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-28 23:51:32,311 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8262, mIoU: 0.4829, mAcc: 0.6158, IoU.wall: 0.7668, IoU.building: 0.8184, IoU.sky: 0.9445, IoU.floor: 0.8151, IoU.tree: 0.7474, IoU.ceiling: 0.8297, IoU.road: 0.8473, IoU.bed : 0.8965, IoU.windowpane: 0.6193, IoU.grass: 0.6865, IoU.cabinet: 0.5883, IoU.sidewalk: 0.6618, IoU.person: 0.8008, IoU.earth: 0.3584, IoU.door: 0.5153, IoU.table: 0.5869, IoU.mountain: 0.5800, IoU.plant: 0.5023, IoU.curtain: 0.7584, IoU.chair: 0.5339, IoU.car: 0.8359, IoU.water: 0.5083, IoU.painting: 0.6970, IoU.sofa: 0.6328, IoU.shelf: 0.4279, IoU.house: 0.4975, IoU.sea: 0.5332, IoU.mirror: 0.6689, IoU.rug: 0.6141, IoU.field: 0.3213, IoU.armchair: 0.4040, IoU.seat: 0.5876, IoU.fence: 0.4626, IoU.desk: 0.5043, IoU.rock: 0.4152, IoU.wardrobe: 0.4982, IoU.lamp: 0.6189, IoU.bathtub: 0.7613, IoU.railing: 0.3526, IoU.cushion: 0.5766, IoU.base: 0.2636, IoU.box: 0.2191, IoU.column: 0.4499, IoU.signboard: 0.3620, IoU.chest of drawers: 0.4220, IoU.counter: 0.3076, IoU.sand: 0.3516, IoU.sink: 0.6709, IoU.skyscraper: 0.4773, IoU.fireplace: 0.6771, IoU.refrigerator: 0.7309, IoU.grandstand: 0.3576, IoU.path: 0.2549, IoU.stairs: 0.3126, IoU.runway: 0.6801, IoU.case: 0.5280, IoU.pool table: 0.9228, IoU.pillow: 0.6091, IoU.screen door: 0.7409, IoU.stairway: 0.3024, IoU.river: 0.1114, IoU.bridge: 0.5891, IoU.bookcase: 0.3390, IoU.blind: 0.3515, IoU.coffee table: 0.5639, IoU.toilet: 0.8262, IoU.flower: 0.3610, IoU.book: 0.3980, IoU.hill: 0.0941, IoU.bench: 0.4335, IoU.countertop: 0.6029, IoU.stove: 0.7125, IoU.palm: 0.4706, IoU.kitchen island: 0.4136, IoU.computer: 0.7286, IoU.swivel chair: 0.3881, IoU.boat: 0.3715, IoU.bar: 0.2957, IoU.arcade machine: 0.8716, IoU.hovel: 0.5169, IoU.bus: 0.8398, IoU.towel: 0.6003, IoU.light: 0.5364, IoU.truck: 0.3236, IoU.tower: 0.2607, IoU.chandelier: 0.6833, IoU.awning: 0.2632, IoU.streetlight: 0.2431, IoU.booth: 0.5381, IoU.television receiver: 0.6110, IoU.airplane: 0.5869, IoU.dirt track: 0.0692, IoU.apparel: 0.4160, IoU.pole: 0.1908, IoU.land: 0.0292, IoU.bannister: 0.1136, IoU.escalator: 0.3764, IoU.ottoman: 0.3756, IoU.bottle: 0.2385, IoU.buffet: 0.3616, IoU.poster: 0.2558, IoU.stage: 0.1511, IoU.van: 0.4493, IoU.ship: 0.5714, IoU.fountain: 0.2292, IoU.conveyer belt: 0.7957, IoU.canopy: 0.2408, IoU.washer: 0.9022, IoU.plaything: 0.2384, IoU.swimming pool: 0.7201, IoU.stool: 0.3705, IoU.barrel: 0.1282, IoU.basket: 0.3104, IoU.waterfall: 0.7462, IoU.tent: 0.9048, IoU.bag: 0.1137, IoU.minibike: 0.6814, IoU.cradle: 0.7137, IoU.oven: 0.3578, IoU.ball: 0.4749, IoU.food: 0.4014, IoU.step: 0.0770, IoU.tank: 0.4234, IoU.trade name: 0.2149, IoU.microwave: 0.7923, IoU.pot: 0.4007, IoU.animal: 0.5573, IoU.bicycle: 0.5556, IoU.lake: 0.4976, IoU.dishwasher: 0.5162, IoU.screen: 0.6488, IoU.blanket: 0.1253, IoU.sculpture: 0.5214, IoU.hood: 0.5624, IoU.sconce: 0.3828, IoU.vase: 0.3881, IoU.traffic light: 0.2479, IoU.tray: 0.0794, IoU.ashcan: 0.3870, IoU.fan: 0.5148, IoU.pier: 0.5603, IoU.crt screen: 0.0440, IoU.plate: 0.5141, IoU.monitor: 0.1183, IoU.bulletin board: 0.5095, IoU.shower: 0.0380, IoU.radiator: 0.4842, IoU.glass: 0.1297, IoU.clock: 0.2997, IoU.flag: 0.5808, Acc.wall: 0.8691, Acc.building: 0.8890, Acc.sky: 0.9747, Acc.floor: 0.8955, Acc.tree: 0.9102, Acc.ceiling: 0.9235, Acc.road: 0.9173, Acc.bed : 0.9483, Acc.windowpane: 0.7951, Acc.grass: 0.8215, Acc.cabinet: 0.7284, Acc.sidewalk: 0.7660, Acc.person: 0.9354, Acc.earth: 0.4984, Acc.door: 0.6961, Acc.table: 0.7586, Acc.mountain: 0.7760, Acc.plant: 0.5951, Acc.curtain: 0.8717, Acc.chair: 0.6401, Acc.car: 0.9035, Acc.water: 0.6175, Acc.painting: 0.8574, Acc.sofa: 0.7973, Acc.shelf: 0.6421, Acc.house: 0.7481, Acc.sea: 0.7828, Acc.mirror: 0.7747, Acc.rug: 0.7675, Acc.field: 0.5703, Acc.armchair: 0.6073, Acc.seat: 0.8140, Acc.fence: 0.5878, Acc.desk: 0.6765, Acc.rock: 0.6615, Acc.wardrobe: 0.6644, Acc.lamp: 0.7681, Acc.bathtub: 0.8495, Acc.railing: 0.4734, Acc.cushion: 0.7213, Acc.base: 0.3401, Acc.box: 0.2631, Acc.column: 0.5846, Acc.signboard: 0.4922, Acc.chest of drawers: 0.5599, Acc.counter: 0.3852, Acc.sand: 0.4920, Acc.sink: 0.7530, Acc.skyscraper: 0.6563, Acc.fireplace: 0.8626, Acc.refrigerator: 0.8480, Acc.grandstand: 0.6998, Acc.path: 0.4276, Acc.stairs: 0.3936, Acc.runway: 0.9397, Acc.case: 0.7165, Acc.pool table: 0.9744, Acc.pillow: 0.8188, Acc.screen door: 0.7902, Acc.stairway: 0.3718, Acc.river: 0.3145, Acc.bridge: 0.8118, Acc.bookcase: 0.5127, Acc.blind: 0.3857, Acc.coffee table: 0.7885, Acc.toilet: 0.9230, Acc.flower: 0.5425, Acc.book: 0.6697, Acc.hill: 0.1498, Acc.bench: 0.4906, Acc.countertop: 0.8031, Acc.stove: 0.9016, Acc.palm: 0.6428, Acc.kitchen island: 0.8838, Acc.computer: 0.9215, Acc.swivel chair: 0.7128, Acc.boat: 0.4698, Acc.bar: 0.4009, Acc.arcade machine: 0.9714, Acc.hovel: 0.5750, Acc.bus: 0.9655, Acc.towel: 0.7438, Acc.light: 0.6037, Acc.truck: 0.4106, Acc.tower: 0.5958, Acc.chandelier: 0.8228, Acc.awning: 0.3390, Acc.streetlight: 0.3327, Acc.booth: 0.5732, Acc.television receiver: 0.7625, Acc.airplane: 0.7461, Acc.dirt track: 0.1077, Acc.apparel: 0.5848, Acc.pole: 0.2484, Acc.land: 0.0371, Acc.bannister: 0.1423, Acc.escalator: 0.4330, Acc.ottoman: 0.5337, Acc.bottle: 0.2844, Acc.buffet: 0.4313, Acc.poster: 0.3408, Acc.stage: 0.3127, Acc.van: 0.6566, Acc.ship: 0.9784, Acc.fountain: 0.2321, Acc.conveyer belt: 0.8855, Acc.canopy: 0.3136, Acc.washer: 0.9595, Acc.plaything: 0.4169, Acc.swimming pool: 0.9019, Acc.stool: 0.5546, Acc.barrel: 0.6489, Acc.basket: 0.4530, Acc.waterfall: 0.8135, Acc.tent: 0.9825, Acc.bag: 0.1325, Acc.minibike: 0.7661, Acc.cradle: 0.9825, Acc.oven: 0.4616, Acc.ball: 0.6659, Acc.food: 0.4725, Acc.step: 0.1040, Acc.tank: 0.4341, Acc.trade name: 0.2534, Acc.microwave: 0.8906, Acc.pot: 0.4589, Acc.animal: 0.6012, Acc.bicycle: 0.7700, Acc.lake: 0.6367, Acc.dishwasher: 0.6238, Acc.screen: 0.8853, Acc.blanket: 0.1481, Acc.sculpture: 0.6271, Acc.hood: 0.7783, Acc.sconce: 0.4571, Acc.vase: 0.4856, Acc.traffic light: 0.3872, Acc.tray: 0.1069, Acc.ashcan: 0.4905, Acc.fan: 0.7556, Acc.pier: 0.7775, Acc.crt screen: 0.1157, Acc.plate: 0.6856, Acc.monitor: 0.1278, Acc.bulletin board: 0.6072, Acc.shower: 0.0441, Acc.radiator: 0.6292, Acc.glass: 0.1413, Acc.clock: 0.3286, Acc.flag: 0.6499
2023-12-28 23:52:13,072 - mmseg - INFO - Iter [80050/160000]	lr: 2.998e-05, eta: 17:50:27, time: 2.736, data_time: 1.933, memory: 18256, decode.loss_ce: 0.2564, decode.acc_seg: 89.5579, aux.loss_ce: 0.1310, aux.acc_seg: 87.2961, loss: 0.3874
2023-12-28 23:52:53,551 - mmseg - INFO - Iter [80100/160000]	lr: 2.996e-05, eta: 17:49:47, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2378, decode.acc_seg: 90.1618, aux.loss_ce: 0.1207, aux.acc_seg: 88.1247, loss: 0.3586
2023-12-28 23:53:33,981 - mmseg - INFO - Iter [80150/160000]	lr: 2.994e-05, eta: 17:49:07, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 89.9465, aux.loss_ce: 0.1254, aux.acc_seg: 87.7337, loss: 0.3685
2023-12-28 23:54:13,059 - mmseg - INFO - Iter [80200/160000]	lr: 2.993e-05, eta: 17:48:26, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2693, decode.acc_seg: 88.9491, aux.loss_ce: 0.1328, aux.acc_seg: 86.8597, loss: 0.4021
2023-12-28 23:54:52,942 - mmseg - INFO - Iter [80250/160000]	lr: 2.991e-05, eta: 17:47:46, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2474, decode.acc_seg: 89.9585, aux.loss_ce: 0.1273, aux.acc_seg: 87.6786, loss: 0.3747
2023-12-28 23:55:32,670 - mmseg - INFO - Iter [80300/160000]	lr: 2.989e-05, eta: 17:47:05, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2473, decode.acc_seg: 89.6133, aux.loss_ce: 0.1249, aux.acc_seg: 87.5207, loss: 0.3721
2023-12-28 23:56:13,012 - mmseg - INFO - Iter [80350/160000]	lr: 2.987e-05, eta: 17:46:25, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2541, decode.acc_seg: 89.7840, aux.loss_ce: 0.1298, aux.acc_seg: 87.3597, loss: 0.3839
2023-12-28 23:56:52,264 - mmseg - INFO - Iter [80400/160000]	lr: 2.985e-05, eta: 17:45:44, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2513, decode.acc_seg: 89.4682, aux.loss_ce: 0.1293, aux.acc_seg: 87.0416, loss: 0.3806
2023-12-28 23:57:30,285 - mmseg - INFO - Iter [80450/160000]	lr: 2.983e-05, eta: 17:45:02, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2632, decode.acc_seg: 89.2840, aux.loss_ce: 0.1359, aux.acc_seg: 86.7751, loss: 0.3991
2023-12-28 23:58:09,568 - mmseg - INFO - Iter [80500/160000]	lr: 2.981e-05, eta: 17:44:21, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2596, decode.acc_seg: 89.2940, aux.loss_ce: 0.1286, aux.acc_seg: 87.2378, loss: 0.3882
2023-12-28 23:58:49,378 - mmseg - INFO - Iter [80550/160000]	lr: 2.979e-05, eta: 17:43:40, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2483, decode.acc_seg: 89.9824, aux.loss_ce: 0.1281, aux.acc_seg: 87.6383, loss: 0.3764
2023-12-28 23:59:27,852 - mmseg - INFO - Iter [80600/160000]	lr: 2.978e-05, eta: 17:42:58, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2597, decode.acc_seg: 89.1754, aux.loss_ce: 0.1297, aux.acc_seg: 87.3754, loss: 0.3894
2023-12-29 00:00:07,146 - mmseg - INFO - Iter [80650/160000]	lr: 2.976e-05, eta: 17:42:17, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2520, decode.acc_seg: 89.5777, aux.loss_ce: 0.1306, aux.acc_seg: 87.1449, loss: 0.3826
2023-12-29 00:00:46,417 - mmseg - INFO - Iter [80700/160000]	lr: 2.974e-05, eta: 17:41:36, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2577, decode.acc_seg: 89.1406, aux.loss_ce: 0.1312, aux.acc_seg: 86.8157, loss: 0.3889
2023-12-29 00:01:25,381 - mmseg - INFO - Iter [80750/160000]	lr: 2.972e-05, eta: 17:40:55, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2701, decode.acc_seg: 88.9746, aux.loss_ce: 0.1352, aux.acc_seg: 86.9642, loss: 0.4053
2023-12-29 00:02:05,730 - mmseg - INFO - Iter [80800/160000]	lr: 2.970e-05, eta: 17:40:15, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2571, decode.acc_seg: 89.7294, aux.loss_ce: 0.1257, aux.acc_seg: 87.7543, loss: 0.3828
2023-12-29 00:02:46,632 - mmseg - INFO - Iter [80850/160000]	lr: 2.968e-05, eta: 17:39:36, time: 0.818, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2688, decode.acc_seg: 89.2093, aux.loss_ce: 0.1343, aux.acc_seg: 87.3357, loss: 0.4031
2023-12-29 00:03:27,722 - mmseg - INFO - Iter [80900/160000]	lr: 2.966e-05, eta: 17:38:56, time: 0.821, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2649, decode.acc_seg: 89.3497, aux.loss_ce: 0.1295, aux.acc_seg: 87.3600, loss: 0.3944
2023-12-29 00:04:08,596 - mmseg - INFO - Iter [80950/160000]	lr: 2.964e-05, eta: 17:38:17, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2479, decode.acc_seg: 89.9742, aux.loss_ce: 0.1254, aux.acc_seg: 87.7361, loss: 0.3733
2023-12-29 00:04:47,597 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 00:04:47,597 - mmseg - INFO - Iter [81000/160000]	lr: 2.963e-05, eta: 17:37:35, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2494, decode.acc_seg: 89.5856, aux.loss_ce: 0.1262, aux.acc_seg: 87.3806, loss: 0.3756
2023-12-29 00:05:27,765 - mmseg - INFO - Iter [81050/160000]	lr: 2.961e-05, eta: 17:36:55, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2529, decode.acc_seg: 89.8212, aux.loss_ce: 0.1300, aux.acc_seg: 87.3429, loss: 0.3829
2023-12-29 00:06:05,288 - mmseg - INFO - Iter [81100/160000]	lr: 2.959e-05, eta: 17:36:13, time: 0.751, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2414, decode.acc_seg: 90.0233, aux.loss_ce: 0.1237, aux.acc_seg: 87.9774, loss: 0.3651
2023-12-29 00:06:44,692 - mmseg - INFO - Iter [81150/160000]	lr: 2.957e-05, eta: 17:35:32, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2556, decode.acc_seg: 89.5868, aux.loss_ce: 0.1308, aux.acc_seg: 87.3566, loss: 0.3864
2023-12-29 00:07:24,132 - mmseg - INFO - Iter [81200/160000]	lr: 2.955e-05, eta: 17:34:51, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2447, decode.acc_seg: 89.8602, aux.loss_ce: 0.1222, aux.acc_seg: 87.7609, loss: 0.3668
2023-12-29 00:08:05,026 - mmseg - INFO - Iter [81250/160000]	lr: 2.953e-05, eta: 17:34:11, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2714, decode.acc_seg: 88.9572, aux.loss_ce: 0.1339, aux.acc_seg: 86.9184, loss: 0.4053
2023-12-29 00:08:44,857 - mmseg - INFO - Iter [81300/160000]	lr: 2.951e-05, eta: 17:33:31, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2540, decode.acc_seg: 89.7748, aux.loss_ce: 0.1307, aux.acc_seg: 87.3307, loss: 0.3847
2023-12-29 00:09:22,783 - mmseg - INFO - Iter [81350/160000]	lr: 2.949e-05, eta: 17:32:49, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2532, decode.acc_seg: 89.6859, aux.loss_ce: 0.1274, aux.acc_seg: 87.6731, loss: 0.3806
2023-12-29 00:10:01,090 - mmseg - INFO - Iter [81400/160000]	lr: 2.948e-05, eta: 17:32:07, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2572, decode.acc_seg: 89.4174, aux.loss_ce: 0.1306, aux.acc_seg: 87.1575, loss: 0.3878
2023-12-29 00:10:41,227 - mmseg - INFO - Iter [81450/160000]	lr: 2.946e-05, eta: 17:31:27, time: 0.804, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2557, decode.acc_seg: 89.5529, aux.loss_ce: 0.1315, aux.acc_seg: 87.0830, loss: 0.3872
2023-12-29 00:11:21,690 - mmseg - INFO - Iter [81500/160000]	lr: 2.944e-05, eta: 17:30:47, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2613, decode.acc_seg: 89.4243, aux.loss_ce: 0.1321, aux.acc_seg: 87.4780, loss: 0.3933
2023-12-29 00:12:02,210 - mmseg - INFO - Iter [81550/160000]	lr: 2.942e-05, eta: 17:30:07, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2481, decode.acc_seg: 89.9827, aux.loss_ce: 0.1262, aux.acc_seg: 88.0974, loss: 0.3744
2023-12-29 00:12:41,178 - mmseg - INFO - Iter [81600/160000]	lr: 2.940e-05, eta: 17:29:25, time: 0.779, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2471, decode.acc_seg: 90.0922, aux.loss_ce: 0.1273, aux.acc_seg: 87.7206, loss: 0.3744
2023-12-29 00:13:19,682 - mmseg - INFO - Iter [81650/160000]	lr: 2.938e-05, eta: 17:28:44, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2635, decode.acc_seg: 89.2019, aux.loss_ce: 0.1319, aux.acc_seg: 87.0692, loss: 0.3954
2023-12-29 00:13:59,629 - mmseg - INFO - Iter [81700/160000]	lr: 2.936e-05, eta: 17:28:03, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2516, decode.acc_seg: 89.7757, aux.loss_ce: 0.1283, aux.acc_seg: 87.5252, loss: 0.3799
2023-12-29 00:14:39,538 - mmseg - INFO - Iter [81750/160000]	lr: 2.934e-05, eta: 17:27:23, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2656, decode.acc_seg: 89.0252, aux.loss_ce: 0.1330, aux.acc_seg: 86.8373, loss: 0.3986
2023-12-29 00:15:19,399 - mmseg - INFO - Iter [81800/160000]	lr: 2.933e-05, eta: 17:26:43, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2537, decode.acc_seg: 89.6831, aux.loss_ce: 0.1289, aux.acc_seg: 87.4654, loss: 0.3827
2023-12-29 00:15:59,143 - mmseg - INFO - Iter [81850/160000]	lr: 2.931e-05, eta: 17:26:02, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2461, decode.acc_seg: 90.1103, aux.loss_ce: 0.1249, aux.acc_seg: 87.9859, loss: 0.3710
2023-12-29 00:16:37,995 - mmseg - INFO - Iter [81900/160000]	lr: 2.929e-05, eta: 17:25:21, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2506, decode.acc_seg: 89.4822, aux.loss_ce: 0.1282, aux.acc_seg: 87.1855, loss: 0.3788
2023-12-29 00:17:17,009 - mmseg - INFO - Iter [81950/160000]	lr: 2.927e-05, eta: 17:24:39, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2454, decode.acc_seg: 89.6532, aux.loss_ce: 0.1231, aux.acc_seg: 87.7825, loss: 0.3685
2023-12-29 00:17:56,434 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 00:17:56,434 - mmseg - INFO - Iter [82000/160000]	lr: 2.925e-05, eta: 17:23:58, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2468, decode.acc_seg: 89.6945, aux.loss_ce: 0.1248, aux.acc_seg: 87.5698, loss: 0.3716
2023-12-29 00:18:37,125 - mmseg - INFO - Iter [82050/160000]	lr: 2.923e-05, eta: 17:23:19, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2407, decode.acc_seg: 89.8386, aux.loss_ce: 0.1235, aux.acc_seg: 87.6222, loss: 0.3642
2023-12-29 00:19:21,060 - mmseg - INFO - Iter [82100/160000]	lr: 2.921e-05, eta: 17:22:42, time: 0.879, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2572, decode.acc_seg: 89.6216, aux.loss_ce: 0.1303, aux.acc_seg: 87.1471, loss: 0.3876
2023-12-29 00:20:00,772 - mmseg - INFO - Iter [82150/160000]	lr: 2.919e-05, eta: 17:22:02, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2452, decode.acc_seg: 90.1269, aux.loss_ce: 0.1239, aux.acc_seg: 88.2450, loss: 0.3691
2023-12-29 00:20:40,896 - mmseg - INFO - Iter [82200/160000]	lr: 2.918e-05, eta: 17:21:22, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2571, decode.acc_seg: 89.3696, aux.loss_ce: 0.1305, aux.acc_seg: 87.4185, loss: 0.3876
2023-12-29 00:21:20,587 - mmseg - INFO - Iter [82250/160000]	lr: 2.916e-05, eta: 17:20:41, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2393, decode.acc_seg: 90.0207, aux.loss_ce: 0.1221, aux.acc_seg: 87.8640, loss: 0.3614
2023-12-29 00:21:59,713 - mmseg - INFO - Iter [82300/160000]	lr: 2.914e-05, eta: 17:20:00, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2508, decode.acc_seg: 89.5802, aux.loss_ce: 0.1261, aux.acc_seg: 87.4025, loss: 0.3769
2023-12-29 00:22:40,258 - mmseg - INFO - Iter [82350/160000]	lr: 2.912e-05, eta: 17:19:20, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2432, decode.acc_seg: 89.9369, aux.loss_ce: 0.1231, aux.acc_seg: 87.8493, loss: 0.3663
2023-12-29 00:23:18,138 - mmseg - INFO - Iter [82400/160000]	lr: 2.910e-05, eta: 17:18:38, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2511, decode.acc_seg: 89.4915, aux.loss_ce: 0.1223, aux.acc_seg: 87.7383, loss: 0.3734
2023-12-29 00:23:56,174 - mmseg - INFO - Iter [82450/160000]	lr: 2.908e-05, eta: 17:17:56, time: 0.760, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2458, decode.acc_seg: 89.6317, aux.loss_ce: 0.1244, aux.acc_seg: 87.7495, loss: 0.3702
2023-12-29 00:24:36,889 - mmseg - INFO - Iter [82500/160000]	lr: 2.906e-05, eta: 17:17:16, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2578, decode.acc_seg: 89.5251, aux.loss_ce: 0.1286, aux.acc_seg: 87.5435, loss: 0.3865
2023-12-29 00:25:16,253 - mmseg - INFO - Iter [82550/160000]	lr: 2.904e-05, eta: 17:16:35, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2423, decode.acc_seg: 90.1723, aux.loss_ce: 0.1250, aux.acc_seg: 87.9818, loss: 0.3673
2023-12-29 00:25:54,839 - mmseg - INFO - Iter [82600/160000]	lr: 2.903e-05, eta: 17:15:53, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2361, decode.acc_seg: 90.0854, aux.loss_ce: 0.1191, aux.acc_seg: 88.0567, loss: 0.3552
2023-12-29 00:26:34,815 - mmseg - INFO - Iter [82650/160000]	lr: 2.901e-05, eta: 17:15:13, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2508, decode.acc_seg: 89.8506, aux.loss_ce: 0.1265, aux.acc_seg: 87.7172, loss: 0.3773
2023-12-29 00:27:15,036 - mmseg - INFO - Iter [82700/160000]	lr: 2.899e-05, eta: 17:14:33, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2427, decode.acc_seg: 90.1632, aux.loss_ce: 0.1214, aux.acc_seg: 88.1993, loss: 0.3641
2023-12-29 00:27:55,376 - mmseg - INFO - Iter [82750/160000]	lr: 2.897e-05, eta: 17:13:53, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2562, decode.acc_seg: 89.5409, aux.loss_ce: 0.1288, aux.acc_seg: 87.4164, loss: 0.3850
2023-12-29 00:28:35,887 - mmseg - INFO - Iter [82800/160000]	lr: 2.895e-05, eta: 17:13:13, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2581, decode.acc_seg: 89.6260, aux.loss_ce: 0.1317, aux.acc_seg: 87.4768, loss: 0.3898
2023-12-29 00:29:15,037 - mmseg - INFO - Iter [82850/160000]	lr: 2.893e-05, eta: 17:12:32, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2450, decode.acc_seg: 89.7347, aux.loss_ce: 0.1223, aux.acc_seg: 87.8982, loss: 0.3673
2023-12-29 00:29:55,260 - mmseg - INFO - Iter [82900/160000]	lr: 2.891e-05, eta: 17:11:52, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2511, decode.acc_seg: 90.0297, aux.loss_ce: 0.1265, aux.acc_seg: 87.9060, loss: 0.3776
2023-12-29 00:30:35,775 - mmseg - INFO - Iter [82950/160000]	lr: 2.889e-05, eta: 17:11:12, time: 0.810, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2611, decode.acc_seg: 89.0474, aux.loss_ce: 0.1329, aux.acc_seg: 86.9838, loss: 0.3940
2023-12-29 00:31:14,981 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 00:31:14,982 - mmseg - INFO - Iter [83000/160000]	lr: 2.888e-05, eta: 17:10:31, time: 0.785, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2598, decode.acc_seg: 89.3068, aux.loss_ce: 0.1334, aux.acc_seg: 87.1098, loss: 0.3933
2023-12-29 00:31:54,695 - mmseg - INFO - Iter [83050/160000]	lr: 2.886e-05, eta: 17:09:51, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 89.9403, aux.loss_ce: 0.1245, aux.acc_seg: 87.8122, loss: 0.3677
2023-12-29 00:32:33,238 - mmseg - INFO - Iter [83100/160000]	lr: 2.884e-05, eta: 17:09:09, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2681, decode.acc_seg: 89.2507, aux.loss_ce: 0.1329, aux.acc_seg: 87.0694, loss: 0.4010
2023-12-29 00:33:12,224 - mmseg - INFO - Iter [83150/160000]	lr: 2.882e-05, eta: 17:08:28, time: 0.779, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2493, decode.acc_seg: 89.7452, aux.loss_ce: 0.1283, aux.acc_seg: 87.3872, loss: 0.3776
2023-12-29 00:33:51,315 - mmseg - INFO - Iter [83200/160000]	lr: 2.880e-05, eta: 17:07:47, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2550, decode.acc_seg: 89.6803, aux.loss_ce: 0.1256, aux.acc_seg: 87.9191, loss: 0.3806
2023-12-29 00:34:30,957 - mmseg - INFO - Iter [83250/160000]	lr: 2.878e-05, eta: 17:07:06, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2580, decode.acc_seg: 89.4171, aux.loss_ce: 0.1311, aux.acc_seg: 87.0194, loss: 0.3890
2023-12-29 00:35:12,207 - mmseg - INFO - Iter [83300/160000]	lr: 2.876e-05, eta: 17:06:27, time: 0.824, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2432, decode.acc_seg: 89.9363, aux.loss_ce: 0.1223, aux.acc_seg: 87.9253, loss: 0.3655
2023-12-29 00:35:51,115 - mmseg - INFO - Iter [83350/160000]	lr: 2.874e-05, eta: 17:05:46, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2543, decode.acc_seg: 89.7435, aux.loss_ce: 0.1290, aux.acc_seg: 87.6647, loss: 0.3833
2023-12-29 00:36:30,331 - mmseg - INFO - Iter [83400/160000]	lr: 2.873e-05, eta: 17:05:05, time: 0.784, data_time: 0.052, memory: 18256, decode.loss_ce: 0.2398, decode.acc_seg: 90.1313, aux.loss_ce: 0.1226, aux.acc_seg: 87.8726, loss: 0.3624
2023-12-29 00:37:08,413 - mmseg - INFO - Iter [83450/160000]	lr: 2.871e-05, eta: 17:04:23, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2455, decode.acc_seg: 89.9309, aux.loss_ce: 0.1262, aux.acc_seg: 87.8625, loss: 0.3718
2023-12-29 00:37:48,963 - mmseg - INFO - Iter [83500/160000]	lr: 2.869e-05, eta: 17:03:43, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2348, decode.acc_seg: 90.2836, aux.loss_ce: 0.1220, aux.acc_seg: 87.8617, loss: 0.3567
2023-12-29 00:38:27,714 - mmseg - INFO - Iter [83550/160000]	lr: 2.867e-05, eta: 17:03:01, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2448, decode.acc_seg: 89.8430, aux.loss_ce: 0.1272, aux.acc_seg: 87.4437, loss: 0.3720
2023-12-29 00:39:05,756 - mmseg - INFO - Iter [83600/160000]	lr: 2.865e-05, eta: 17:02:19, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2379, decode.acc_seg: 89.9119, aux.loss_ce: 0.1228, aux.acc_seg: 87.6071, loss: 0.3606
2023-12-29 00:39:44,237 - mmseg - INFO - Iter [83650/160000]	lr: 2.863e-05, eta: 17:01:38, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2474, decode.acc_seg: 89.8987, aux.loss_ce: 0.1265, aux.acc_seg: 87.7259, loss: 0.3739
2023-12-29 00:40:24,144 - mmseg - INFO - Iter [83700/160000]	lr: 2.861e-05, eta: 17:00:57, time: 0.800, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2647, decode.acc_seg: 89.2842, aux.loss_ce: 0.1299, aux.acc_seg: 87.1064, loss: 0.3946
2023-12-29 00:41:01,981 - mmseg - INFO - Iter [83750/160000]	lr: 2.859e-05, eta: 17:00:15, time: 0.757, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2395, decode.acc_seg: 90.1115, aux.loss_ce: 0.1237, aux.acc_seg: 87.7012, loss: 0.3632
2023-12-29 00:41:40,109 - mmseg - INFO - Iter [83800/160000]	lr: 2.858e-05, eta: 16:59:33, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2605, decode.acc_seg: 89.1168, aux.loss_ce: 0.1299, aux.acc_seg: 87.0297, loss: 0.3904
2023-12-29 00:42:18,255 - mmseg - INFO - Iter [83850/160000]	lr: 2.856e-05, eta: 16:58:51, time: 0.762, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2403, decode.acc_seg: 90.1451, aux.loss_ce: 0.1218, aux.acc_seg: 88.0685, loss: 0.3621
2023-12-29 00:42:57,733 - mmseg - INFO - Iter [83900/160000]	lr: 2.854e-05, eta: 16:58:10, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2496, decode.acc_seg: 89.6673, aux.loss_ce: 0.1246, aux.acc_seg: 87.6280, loss: 0.3742
2023-12-29 00:43:35,628 - mmseg - INFO - Iter [83950/160000]	lr: 2.852e-05, eta: 16:57:28, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2494, decode.acc_seg: 89.6960, aux.loss_ce: 0.1237, aux.acc_seg: 87.8611, loss: 0.3730
2023-12-29 00:44:14,176 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 00:44:14,177 - mmseg - INFO - Iter [84000/160000]	lr: 2.850e-05, eta: 16:56:47, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2391, decode.acc_seg: 90.0804, aux.loss_ce: 0.1245, aux.acc_seg: 87.5929, loss: 0.3637
2023-12-29 00:44:54,605 - mmseg - INFO - Iter [84050/160000]	lr: 2.848e-05, eta: 16:56:07, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2484, decode.acc_seg: 89.7666, aux.loss_ce: 0.1257, aux.acc_seg: 87.8161, loss: 0.3741
2023-12-29 00:45:33,859 - mmseg - INFO - Iter [84100/160000]	lr: 2.846e-05, eta: 16:55:26, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2473, decode.acc_seg: 89.8266, aux.loss_ce: 0.1240, aux.acc_seg: 87.9066, loss: 0.3712
2023-12-29 00:46:14,088 - mmseg - INFO - Iter [84150/160000]	lr: 2.844e-05, eta: 16:54:46, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2407, decode.acc_seg: 89.8050, aux.loss_ce: 0.1218, aux.acc_seg: 87.6357, loss: 0.3625
2023-12-29 00:46:53,082 - mmseg - INFO - Iter [84200/160000]	lr: 2.843e-05, eta: 16:54:05, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2426, decode.acc_seg: 89.9812, aux.loss_ce: 0.1239, aux.acc_seg: 87.9927, loss: 0.3665
2023-12-29 00:47:32,755 - mmseg - INFO - Iter [84250/160000]	lr: 2.841e-05, eta: 16:53:24, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2551, decode.acc_seg: 89.2467, aux.loss_ce: 0.1239, aux.acc_seg: 87.5237, loss: 0.3790
2023-12-29 00:48:13,169 - mmseg - INFO - Iter [84300/160000]	lr: 2.839e-05, eta: 16:52:44, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2475, decode.acc_seg: 89.6470, aux.loss_ce: 0.1269, aux.acc_seg: 87.2777, loss: 0.3744
2023-12-29 00:48:53,091 - mmseg - INFO - Iter [84350/160000]	lr: 2.837e-05, eta: 16:52:04, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2511, decode.acc_seg: 89.7988, aux.loss_ce: 0.1280, aux.acc_seg: 87.5334, loss: 0.3791
2023-12-29 00:49:29,989 - mmseg - INFO - Iter [84400/160000]	lr: 2.835e-05, eta: 16:51:21, time: 0.738, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2510, decode.acc_seg: 89.7824, aux.loss_ce: 0.1271, aux.acc_seg: 87.6902, loss: 0.3781
2023-12-29 00:50:08,506 - mmseg - INFO - Iter [84450/160000]	lr: 2.833e-05, eta: 16:50:39, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2478, decode.acc_seg: 89.7720, aux.loss_ce: 0.1231, aux.acc_seg: 87.8179, loss: 0.3709
2023-12-29 00:50:44,993 - mmseg - INFO - Iter [84500/160000]	lr: 2.831e-05, eta: 16:49:56, time: 0.730, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2389, decode.acc_seg: 89.9448, aux.loss_ce: 0.1195, aux.acc_seg: 87.9933, loss: 0.3583
2023-12-29 00:51:22,723 - mmseg - INFO - Iter [84550/160000]	lr: 2.829e-05, eta: 16:49:14, time: 0.753, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2532, decode.acc_seg: 89.4436, aux.loss_ce: 0.1278, aux.acc_seg: 87.2326, loss: 0.3810
2023-12-29 00:52:03,267 - mmseg - INFO - Iter [84600/160000]	lr: 2.828e-05, eta: 16:48:34, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2446, decode.acc_seg: 90.1542, aux.loss_ce: 0.1248, aux.acc_seg: 87.9633, loss: 0.3694
2023-12-29 00:52:43,435 - mmseg - INFO - Iter [84650/160000]	lr: 2.826e-05, eta: 16:47:54, time: 0.804, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2530, decode.acc_seg: 89.5956, aux.loss_ce: 0.1304, aux.acc_seg: 87.1536, loss: 0.3834
2023-12-29 00:53:22,875 - mmseg - INFO - Iter [84700/160000]	lr: 2.824e-05, eta: 16:47:13, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2447, decode.acc_seg: 90.0045, aux.loss_ce: 0.1253, aux.acc_seg: 87.7794, loss: 0.3700
2023-12-29 00:54:03,801 - mmseg - INFO - Iter [84750/160000]	lr: 2.822e-05, eta: 16:46:34, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2468, decode.acc_seg: 89.7232, aux.loss_ce: 0.1247, aux.acc_seg: 87.6824, loss: 0.3715
2023-12-29 00:54:44,961 - mmseg - INFO - Iter [84800/160000]	lr: 2.820e-05, eta: 16:45:54, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2299, decode.acc_seg: 90.3499, aux.loss_ce: 0.1180, aux.acc_seg: 88.1327, loss: 0.3478
2023-12-29 00:55:24,900 - mmseg - INFO - Iter [84850/160000]	lr: 2.818e-05, eta: 16:45:14, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2560, decode.acc_seg: 89.7154, aux.loss_ce: 0.1302, aux.acc_seg: 87.5081, loss: 0.3862
2023-12-29 00:56:03,756 - mmseg - INFO - Iter [84900/160000]	lr: 2.816e-05, eta: 16:44:33, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2594, decode.acc_seg: 89.3487, aux.loss_ce: 0.1270, aux.acc_seg: 87.2994, loss: 0.3864
2023-12-29 00:56:40,489 - mmseg - INFO - Iter [84950/160000]	lr: 2.814e-05, eta: 16:43:50, time: 0.735, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2445, decode.acc_seg: 89.8205, aux.loss_ce: 0.1258, aux.acc_seg: 87.4426, loss: 0.3703
2023-12-29 00:57:18,751 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 00:57:18,752 - mmseg - INFO - Iter [85000/160000]	lr: 2.813e-05, eta: 16:43:08, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2456, decode.acc_seg: 89.6282, aux.loss_ce: 0.1287, aux.acc_seg: 87.3891, loss: 0.3743
2023-12-29 00:57:59,133 - mmseg - INFO - Iter [85050/160000]	lr: 2.811e-05, eta: 16:42:28, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2487, decode.acc_seg: 89.7318, aux.loss_ce: 0.1263, aux.acc_seg: 87.6803, loss: 0.3750
2023-12-29 00:58:39,065 - mmseg - INFO - Iter [85100/160000]	lr: 2.809e-05, eta: 16:41:48, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2691, decode.acc_seg: 89.3162, aux.loss_ce: 0.1343, aux.acc_seg: 87.3084, loss: 0.4034
2023-12-29 00:59:18,359 - mmseg - INFO - Iter [85150/160000]	lr: 2.807e-05, eta: 16:41:07, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2532, decode.acc_seg: 89.7169, aux.loss_ce: 0.1292, aux.acc_seg: 87.7862, loss: 0.3824
2023-12-29 00:59:58,782 - mmseg - INFO - Iter [85200/160000]	lr: 2.805e-05, eta: 16:40:27, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2446, decode.acc_seg: 89.7922, aux.loss_ce: 0.1229, aux.acc_seg: 87.7649, loss: 0.3675
2023-12-29 01:00:38,700 - mmseg - INFO - Iter [85250/160000]	lr: 2.803e-05, eta: 16:39:47, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2528, decode.acc_seg: 89.5186, aux.loss_ce: 0.1275, aux.acc_seg: 87.3381, loss: 0.3803
2023-12-29 01:01:18,664 - mmseg - INFO - Iter [85300/160000]	lr: 2.801e-05, eta: 16:39:06, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2424, decode.acc_seg: 89.7362, aux.loss_ce: 0.1234, aux.acc_seg: 87.7885, loss: 0.3659
2023-12-29 01:01:56,321 - mmseg - INFO - Iter [85350/160000]	lr: 2.799e-05, eta: 16:38:24, time: 0.753, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2335, decode.acc_seg: 90.2112, aux.loss_ce: 0.1204, aux.acc_seg: 88.0857, loss: 0.3539
2023-12-29 01:02:35,741 - mmseg - INFO - Iter [85400/160000]	lr: 2.798e-05, eta: 16:37:43, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2399, decode.acc_seg: 89.9344, aux.loss_ce: 0.1218, aux.acc_seg: 87.8635, loss: 0.3617
2023-12-29 01:03:15,574 - mmseg - INFO - Iter [85450/160000]	lr: 2.796e-05, eta: 16:37:03, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2461, decode.acc_seg: 89.7774, aux.loss_ce: 0.1221, aux.acc_seg: 87.7879, loss: 0.3682
2023-12-29 01:03:55,014 - mmseg - INFO - Iter [85500/160000]	lr: 2.794e-05, eta: 16:36:22, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2438, decode.acc_seg: 90.2787, aux.loss_ce: 0.1286, aux.acc_seg: 87.8824, loss: 0.3724
2023-12-29 01:04:33,647 - mmseg - INFO - Iter [85550/160000]	lr: 2.792e-05, eta: 16:35:41, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2378, decode.acc_seg: 90.2766, aux.loss_ce: 0.1221, aux.acc_seg: 88.1658, loss: 0.3599
2023-12-29 01:05:12,252 - mmseg - INFO - Iter [85600/160000]	lr: 2.790e-05, eta: 16:35:00, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2454, decode.acc_seg: 89.6293, aux.loss_ce: 0.1261, aux.acc_seg: 87.1700, loss: 0.3715
2023-12-29 01:05:52,826 - mmseg - INFO - Iter [85650/160000]	lr: 2.788e-05, eta: 16:34:20, time: 0.810, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2574, decode.acc_seg: 89.5165, aux.loss_ce: 0.1293, aux.acc_seg: 87.4446, loss: 0.3868
2023-12-29 01:06:32,083 - mmseg - INFO - Iter [85700/160000]	lr: 2.786e-05, eta: 16:33:39, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 89.8231, aux.loss_ce: 0.1244, aux.acc_seg: 87.5741, loss: 0.3676
2023-12-29 01:07:11,207 - mmseg - INFO - Iter [85750/160000]	lr: 2.784e-05, eta: 16:32:58, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2335, decode.acc_seg: 90.2963, aux.loss_ce: 0.1173, aux.acc_seg: 88.5763, loss: 0.3508
2023-12-29 01:07:53,082 - mmseg - INFO - Iter [85800/160000]	lr: 2.783e-05, eta: 16:32:19, time: 0.837, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2460, decode.acc_seg: 89.8145, aux.loss_ce: 0.1228, aux.acc_seg: 87.8598, loss: 0.3688
2023-12-29 01:08:34,918 - mmseg - INFO - Iter [85850/160000]	lr: 2.781e-05, eta: 16:31:41, time: 0.837, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2451, decode.acc_seg: 89.7825, aux.loss_ce: 0.1251, aux.acc_seg: 87.4677, loss: 0.3702
2023-12-29 01:09:16,449 - mmseg - INFO - Iter [85900/160000]	lr: 2.779e-05, eta: 16:31:02, time: 0.832, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2540, decode.acc_seg: 89.6274, aux.loss_ce: 0.1297, aux.acc_seg: 87.3927, loss: 0.3838
2023-12-29 01:09:57,515 - mmseg - INFO - Iter [85950/160000]	lr: 2.777e-05, eta: 16:30:22, time: 0.820, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2367, decode.acc_seg: 90.1622, aux.loss_ce: 0.1228, aux.acc_seg: 87.8477, loss: 0.3596
2023-12-29 01:10:37,406 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 01:10:37,407 - mmseg - INFO - Iter [86000/160000]	lr: 2.775e-05, eta: 16:29:42, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2543, decode.acc_seg: 89.6075, aux.loss_ce: 0.1295, aux.acc_seg: 87.3400, loss: 0.3837
2023-12-29 01:11:18,592 - mmseg - INFO - Iter [86050/160000]	lr: 2.773e-05, eta: 16:29:03, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2508, decode.acc_seg: 89.5681, aux.loss_ce: 0.1232, aux.acc_seg: 87.7119, loss: 0.3740
2023-12-29 01:12:00,038 - mmseg - INFO - Iter [86100/160000]	lr: 2.771e-05, eta: 16:28:24, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2435, decode.acc_seg: 89.8050, aux.loss_ce: 0.1216, aux.acc_seg: 87.9763, loss: 0.3651
2023-12-29 01:12:40,576 - mmseg - INFO - Iter [86150/160000]	lr: 2.769e-05, eta: 16:27:44, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2455, decode.acc_seg: 89.9244, aux.loss_ce: 0.1239, aux.acc_seg: 87.8410, loss: 0.3694
2023-12-29 01:13:20,650 - mmseg - INFO - Iter [86200/160000]	lr: 2.768e-05, eta: 16:27:04, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2245, decode.acc_seg: 90.5614, aux.loss_ce: 0.1162, aux.acc_seg: 88.5130, loss: 0.3407
2023-12-29 01:14:00,505 - mmseg - INFO - Iter [86250/160000]	lr: 2.766e-05, eta: 16:26:24, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2405, decode.acc_seg: 90.1018, aux.loss_ce: 0.1203, aux.acc_seg: 88.2038, loss: 0.3609
2023-12-29 01:14:40,180 - mmseg - INFO - Iter [86300/160000]	lr: 2.764e-05, eta: 16:25:43, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2416, decode.acc_seg: 89.9659, aux.loss_ce: 0.1231, aux.acc_seg: 87.7201, loss: 0.3647
2023-12-29 01:15:19,191 - mmseg - INFO - Iter [86350/160000]	lr: 2.762e-05, eta: 16:25:02, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2638, decode.acc_seg: 89.5317, aux.loss_ce: 0.1288, aux.acc_seg: 87.4994, loss: 0.3927
2023-12-29 01:15:56,351 - mmseg - INFO - Iter [86400/160000]	lr: 2.760e-05, eta: 16:24:19, time: 0.743, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2295, decode.acc_seg: 90.3354, aux.loss_ce: 0.1202, aux.acc_seg: 88.1055, loss: 0.3497
2023-12-29 01:16:36,078 - mmseg - INFO - Iter [86450/160000]	lr: 2.758e-05, eta: 16:23:39, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2573, decode.acc_seg: 89.6100, aux.loss_ce: 0.1279, aux.acc_seg: 87.5944, loss: 0.3852
2023-12-29 01:17:15,114 - mmseg - INFO - Iter [86500/160000]	lr: 2.756e-05, eta: 16:22:58, time: 0.782, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2491, decode.acc_seg: 89.9099, aux.loss_ce: 0.1260, aux.acc_seg: 87.7000, loss: 0.3751
2023-12-29 01:17:53,556 - mmseg - INFO - Iter [86550/160000]	lr: 2.754e-05, eta: 16:22:16, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2360, decode.acc_seg: 90.0719, aux.loss_ce: 0.1190, aux.acc_seg: 87.9393, loss: 0.3550
2023-12-29 01:18:33,360 - mmseg - INFO - Iter [86600/160000]	lr: 2.753e-05, eta: 16:21:36, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2433, decode.acc_seg: 89.8768, aux.loss_ce: 0.1261, aux.acc_seg: 87.6436, loss: 0.3694
2023-12-29 01:19:10,226 - mmseg - INFO - Iter [86650/160000]	lr: 2.751e-05, eta: 16:20:53, time: 0.736, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2421, decode.acc_seg: 90.1778, aux.loss_ce: 0.1226, aux.acc_seg: 88.1246, loss: 0.3646
2023-12-29 01:19:49,620 - mmseg - INFO - Iter [86700/160000]	lr: 2.749e-05, eta: 16:20:12, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2440, decode.acc_seg: 90.0988, aux.loss_ce: 0.1249, aux.acc_seg: 87.8357, loss: 0.3689
2023-12-29 01:20:28,979 - mmseg - INFO - Iter [86750/160000]	lr: 2.747e-05, eta: 16:19:32, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2405, decode.acc_seg: 90.1335, aux.loss_ce: 0.1230, aux.acc_seg: 87.9980, loss: 0.3635
2023-12-29 01:21:08,434 - mmseg - INFO - Iter [86800/160000]	lr: 2.745e-05, eta: 16:18:51, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2467, decode.acc_seg: 89.8514, aux.loss_ce: 0.1269, aux.acc_seg: 87.5776, loss: 0.3737
2023-12-29 01:21:48,271 - mmseg - INFO - Iter [86850/160000]	lr: 2.743e-05, eta: 16:18:11, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2523, decode.acc_seg: 89.8141, aux.loss_ce: 0.1274, aux.acc_seg: 87.4889, loss: 0.3797
2023-12-29 01:22:29,146 - mmseg - INFO - Iter [86900/160000]	lr: 2.741e-05, eta: 16:17:31, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2399, decode.acc_seg: 89.7679, aux.loss_ce: 0.1217, aux.acc_seg: 87.7366, loss: 0.3616
2023-12-29 01:23:07,323 - mmseg - INFO - Iter [86950/160000]	lr: 2.739e-05, eta: 16:16:49, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2447, decode.acc_seg: 90.2131, aux.loss_ce: 0.1242, aux.acc_seg: 88.0758, loss: 0.3689
2023-12-29 01:23:45,719 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 01:23:45,719 - mmseg - INFO - Iter [87000/160000]	lr: 2.738e-05, eta: 16:16:08, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2430, decode.acc_seg: 89.8997, aux.loss_ce: 0.1251, aux.acc_seg: 87.6356, loss: 0.3681
2023-12-29 01:24:25,200 - mmseg - INFO - Iter [87050/160000]	lr: 2.736e-05, eta: 16:15:27, time: 0.789, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2423, decode.acc_seg: 89.8270, aux.loss_ce: 0.1259, aux.acc_seg: 87.6249, loss: 0.3682
2023-12-29 01:25:02,923 - mmseg - INFO - Iter [87100/160000]	lr: 2.734e-05, eta: 16:14:45, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2618, decode.acc_seg: 89.3740, aux.loss_ce: 0.1327, aux.acc_seg: 87.2173, loss: 0.3945
2023-12-29 01:25:45,064 - mmseg - INFO - Iter [87150/160000]	lr: 2.732e-05, eta: 16:14:07, time: 0.844, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2538, decode.acc_seg: 89.6066, aux.loss_ce: 0.1298, aux.acc_seg: 87.4031, loss: 0.3836
2023-12-29 01:26:23,981 - mmseg - INFO - Iter [87200/160000]	lr: 2.730e-05, eta: 16:13:25, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2376, decode.acc_seg: 89.9991, aux.loss_ce: 0.1203, aux.acc_seg: 88.1760, loss: 0.3579
2023-12-29 01:27:03,868 - mmseg - INFO - Iter [87250/160000]	lr: 2.728e-05, eta: 16:12:45, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2500, decode.acc_seg: 89.6622, aux.loss_ce: 0.1264, aux.acc_seg: 87.6882, loss: 0.3764
2023-12-29 01:27:43,363 - mmseg - INFO - Iter [87300/160000]	lr: 2.726e-05, eta: 16:12:05, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2362, decode.acc_seg: 90.2996, aux.loss_ce: 0.1214, aux.acc_seg: 88.1425, loss: 0.3576
2023-12-29 01:28:22,750 - mmseg - INFO - Iter [87350/160000]	lr: 2.724e-05, eta: 16:11:24, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2376, decode.acc_seg: 90.4630, aux.loss_ce: 0.1217, aux.acc_seg: 88.3189, loss: 0.3593
2023-12-29 01:29:02,789 - mmseg - INFO - Iter [87400/160000]	lr: 2.723e-05, eta: 16:10:44, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2379, decode.acc_seg: 90.0149, aux.loss_ce: 0.1209, aux.acc_seg: 88.0256, loss: 0.3588
2023-12-29 01:29:42,901 - mmseg - INFO - Iter [87450/160000]	lr: 2.721e-05, eta: 16:10:03, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2311, decode.acc_seg: 90.3449, aux.loss_ce: 0.1184, aux.acc_seg: 88.0901, loss: 0.3496
2023-12-29 01:30:21,743 - mmseg - INFO - Iter [87500/160000]	lr: 2.719e-05, eta: 16:09:22, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2529, decode.acc_seg: 89.5307, aux.loss_ce: 0.1294, aux.acc_seg: 87.4021, loss: 0.3822
2023-12-29 01:31:00,237 - mmseg - INFO - Iter [87550/160000]	lr: 2.717e-05, eta: 16:08:41, time: 0.770, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2428, decode.acc_seg: 89.8460, aux.loss_ce: 0.1240, aux.acc_seg: 87.6588, loss: 0.3667
2023-12-29 01:31:40,213 - mmseg - INFO - Iter [87600/160000]	lr: 2.715e-05, eta: 16:08:01, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2411, decode.acc_seg: 90.0029, aux.loss_ce: 0.1207, aux.acc_seg: 88.0488, loss: 0.3618
2023-12-29 01:32:20,173 - mmseg - INFO - Iter [87650/160000]	lr: 2.713e-05, eta: 16:07:20, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2278, decode.acc_seg: 90.5346, aux.loss_ce: 0.1156, aux.acc_seg: 88.5177, loss: 0.3434
2023-12-29 01:33:00,270 - mmseg - INFO - Iter [87700/160000]	lr: 2.711e-05, eta: 16:06:40, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 89.8412, aux.loss_ce: 0.1207, aux.acc_seg: 87.9716, loss: 0.3638
2023-12-29 01:33:40,438 - mmseg - INFO - Iter [87750/160000]	lr: 2.709e-05, eta: 16:06:00, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2432, decode.acc_seg: 89.8455, aux.loss_ce: 0.1245, aux.acc_seg: 87.8482, loss: 0.3677
2023-12-29 01:34:19,722 - mmseg - INFO - Iter [87800/160000]	lr: 2.708e-05, eta: 16:05:19, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2412, decode.acc_seg: 89.8524, aux.loss_ce: 0.1217, aux.acc_seg: 87.6604, loss: 0.3629
2023-12-29 01:34:58,335 - mmseg - INFO - Iter [87850/160000]	lr: 2.706e-05, eta: 16:04:38, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2534, decode.acc_seg: 89.7345, aux.loss_ce: 0.1284, aux.acc_seg: 87.5294, loss: 0.3818
2023-12-29 01:35:36,270 - mmseg - INFO - Iter [87900/160000]	lr: 2.704e-05, eta: 16:03:56, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2415, decode.acc_seg: 90.1321, aux.loss_ce: 0.1199, aux.acc_seg: 88.1482, loss: 0.3614
2023-12-29 01:36:15,274 - mmseg - INFO - Iter [87950/160000]	lr: 2.702e-05, eta: 16:03:15, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2396, decode.acc_seg: 90.1100, aux.loss_ce: 0.1194, aux.acc_seg: 88.0468, loss: 0.3590
2023-12-29 01:36:54,908 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 01:36:54,909 - mmseg - INFO - Iter [88000/160000]	lr: 2.700e-05, eta: 16:02:35, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2494, decode.acc_seg: 89.7740, aux.loss_ce: 0.1260, aux.acc_seg: 87.6151, loss: 0.3753
2023-12-29 01:37:32,239 - mmseg - INFO - Iter [88050/160000]	lr: 2.698e-05, eta: 16:01:52, time: 0.746, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2375, decode.acc_seg: 89.9896, aux.loss_ce: 0.1204, aux.acc_seg: 87.9145, loss: 0.3579
2023-12-29 01:38:12,555 - mmseg - INFO - Iter [88100/160000]	lr: 2.696e-05, eta: 16:01:12, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2326, decode.acc_seg: 90.4483, aux.loss_ce: 0.1168, aux.acc_seg: 88.5842, loss: 0.3494
2023-12-29 01:38:50,860 - mmseg - INFO - Iter [88150/160000]	lr: 2.694e-05, eta: 16:00:31, time: 0.767, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2498, decode.acc_seg: 89.5959, aux.loss_ce: 0.1251, aux.acc_seg: 87.7912, loss: 0.3749
2023-12-29 01:39:30,280 - mmseg - INFO - Iter [88200/160000]	lr: 2.693e-05, eta: 15:59:50, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2338, decode.acc_seg: 90.2549, aux.loss_ce: 0.1197, aux.acc_seg: 88.0348, loss: 0.3535
2023-12-29 01:40:07,548 - mmseg - INFO - Iter [88250/160000]	lr: 2.691e-05, eta: 15:59:08, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2393, decode.acc_seg: 89.9207, aux.loss_ce: 0.1262, aux.acc_seg: 87.6178, loss: 0.3655
2023-12-29 01:40:46,953 - mmseg - INFO - Iter [88300/160000]	lr: 2.689e-05, eta: 15:58:27, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2385, decode.acc_seg: 90.2893, aux.loss_ce: 0.1200, aux.acc_seg: 88.3125, loss: 0.3585
2023-12-29 01:41:25,054 - mmseg - INFO - Iter [88350/160000]	lr: 2.687e-05, eta: 15:57:45, time: 0.762, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2342, decode.acc_seg: 90.2514, aux.loss_ce: 0.1185, aux.acc_seg: 88.2243, loss: 0.3527
2023-12-29 01:42:04,703 - mmseg - INFO - Iter [88400/160000]	lr: 2.685e-05, eta: 15:57:05, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2302, decode.acc_seg: 90.3200, aux.loss_ce: 0.1165, aux.acc_seg: 88.5458, loss: 0.3467
2023-12-29 01:42:46,757 - mmseg - INFO - Iter [88450/160000]	lr: 2.683e-05, eta: 15:56:26, time: 0.841, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2225, decode.acc_seg: 90.8639, aux.loss_ce: 0.1137, aux.acc_seg: 88.8289, loss: 0.3362
2023-12-29 01:43:26,562 - mmseg - INFO - Iter [88500/160000]	lr: 2.681e-05, eta: 15:55:46, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2281, decode.acc_seg: 90.4668, aux.loss_ce: 0.1177, aux.acc_seg: 88.6235, loss: 0.3458
2023-12-29 01:44:06,150 - mmseg - INFO - Iter [88550/160000]	lr: 2.679e-05, eta: 15:55:05, time: 0.791, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2318, decode.acc_seg: 90.6254, aux.loss_ce: 0.1162, aux.acc_seg: 88.7077, loss: 0.3481
2023-12-29 01:44:44,989 - mmseg - INFO - Iter [88600/160000]	lr: 2.678e-05, eta: 15:54:24, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2391, decode.acc_seg: 90.3368, aux.loss_ce: 0.1226, aux.acc_seg: 88.3320, loss: 0.3617
2023-12-29 01:45:23,407 - mmseg - INFO - Iter [88650/160000]	lr: 2.676e-05, eta: 15:53:43, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2374, decode.acc_seg: 89.9623, aux.loss_ce: 0.1204, aux.acc_seg: 88.0558, loss: 0.3578
2023-12-29 01:46:03,889 - mmseg - INFO - Iter [88700/160000]	lr: 2.674e-05, eta: 15:53:03, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2383, decode.acc_seg: 90.2871, aux.loss_ce: 0.1207, aux.acc_seg: 88.4505, loss: 0.3590
2023-12-29 01:46:45,244 - mmseg - INFO - Iter [88750/160000]	lr: 2.672e-05, eta: 15:52:24, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2344, decode.acc_seg: 90.0416, aux.loss_ce: 0.1195, aux.acc_seg: 88.0055, loss: 0.3538
2023-12-29 01:47:26,478 - mmseg - INFO - Iter [88800/160000]	lr: 2.670e-05, eta: 15:51:45, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2514, decode.acc_seg: 89.7335, aux.loss_ce: 0.1269, aux.acc_seg: 87.6669, loss: 0.3782
2023-12-29 01:48:06,220 - mmseg - INFO - Iter [88850/160000]	lr: 2.668e-05, eta: 15:51:04, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2311, decode.acc_seg: 90.1608, aux.loss_ce: 0.1195, aux.acc_seg: 87.8976, loss: 0.3506
2023-12-29 01:48:45,882 - mmseg - INFO - Iter [88900/160000]	lr: 2.666e-05, eta: 15:50:24, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2399, decode.acc_seg: 90.2070, aux.loss_ce: 0.1215, aux.acc_seg: 88.1597, loss: 0.3614
2023-12-29 01:49:24,322 - mmseg - INFO - Iter [88950/160000]	lr: 2.664e-05, eta: 15:49:43, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2377, decode.acc_seg: 90.2986, aux.loss_ce: 0.1213, aux.acc_seg: 88.2659, loss: 0.3591
2023-12-29 01:50:03,364 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 01:50:03,364 - mmseg - INFO - Iter [89000/160000]	lr: 2.663e-05, eta: 15:49:02, time: 0.781, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2373, decode.acc_seg: 90.1407, aux.loss_ce: 0.1225, aux.acc_seg: 87.9921, loss: 0.3598
2023-12-29 01:50:41,744 - mmseg - INFO - Iter [89050/160000]	lr: 2.661e-05, eta: 15:48:20, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2462, decode.acc_seg: 90.0551, aux.loss_ce: 0.1286, aux.acc_seg: 87.7195, loss: 0.3749
2023-12-29 01:51:20,590 - mmseg - INFO - Iter [89100/160000]	lr: 2.659e-05, eta: 15:47:39, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2429, decode.acc_seg: 89.9374, aux.loss_ce: 0.1212, aux.acc_seg: 87.9435, loss: 0.3642
2023-12-29 01:51:59,938 - mmseg - INFO - Iter [89150/160000]	lr: 2.657e-05, eta: 15:46:58, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2460, decode.acc_seg: 89.6049, aux.loss_ce: 0.1226, aux.acc_seg: 87.5086, loss: 0.3686
2023-12-29 01:52:39,532 - mmseg - INFO - Iter [89200/160000]	lr: 2.655e-05, eta: 15:46:18, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2499, decode.acc_seg: 89.5756, aux.loss_ce: 0.1261, aux.acc_seg: 87.4413, loss: 0.3760
2023-12-29 01:53:19,325 - mmseg - INFO - Iter [89250/160000]	lr: 2.653e-05, eta: 15:45:38, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2401, decode.acc_seg: 89.9409, aux.loss_ce: 0.1213, aux.acc_seg: 87.8173, loss: 0.3614
2023-12-29 01:53:59,759 - mmseg - INFO - Iter [89300/160000]	lr: 2.651e-05, eta: 15:44:58, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2358, decode.acc_seg: 90.2770, aux.loss_ce: 0.1216, aux.acc_seg: 87.7932, loss: 0.3574
2023-12-29 01:54:39,811 - mmseg - INFO - Iter [89350/160000]	lr: 2.649e-05, eta: 15:44:18, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2436, decode.acc_seg: 89.8420, aux.loss_ce: 0.1228, aux.acc_seg: 87.7552, loss: 0.3664
2023-12-29 01:55:18,191 - mmseg - INFO - Iter [89400/160000]	lr: 2.648e-05, eta: 15:43:36, time: 0.767, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2313, decode.acc_seg: 90.3413, aux.loss_ce: 0.1203, aux.acc_seg: 88.0660, loss: 0.3516
2023-12-29 01:55:56,222 - mmseg - INFO - Iter [89450/160000]	lr: 2.646e-05, eta: 15:42:54, time: 0.761, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2715, decode.acc_seg: 88.7279, aux.loss_ce: 0.1372, aux.acc_seg: 86.7815, loss: 0.4087
2023-12-29 01:56:36,047 - mmseg - INFO - Iter [89500/160000]	lr: 2.644e-05, eta: 15:42:14, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2401, decode.acc_seg: 90.0172, aux.loss_ce: 0.1258, aux.acc_seg: 87.7395, loss: 0.3659
2023-12-29 01:57:16,292 - mmseg - INFO - Iter [89550/160000]	lr: 2.642e-05, eta: 15:41:34, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2560, decode.acc_seg: 89.5367, aux.loss_ce: 0.1289, aux.acc_seg: 87.3851, loss: 0.3849
2023-12-29 01:57:55,148 - mmseg - INFO - Iter [89600/160000]	lr: 2.640e-05, eta: 15:40:53, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2401, decode.acc_seg: 90.1075, aux.loss_ce: 0.1215, aux.acc_seg: 88.1940, loss: 0.3616
2023-12-29 01:58:34,928 - mmseg - INFO - Iter [89650/160000]	lr: 2.638e-05, eta: 15:40:13, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2593, decode.acc_seg: 89.7666, aux.loss_ce: 0.1303, aux.acc_seg: 87.8675, loss: 0.3896
2023-12-29 01:59:14,646 - mmseg - INFO - Iter [89700/160000]	lr: 2.636e-05, eta: 15:39:32, time: 0.793, data_time: 0.052, memory: 18256, decode.loss_ce: 0.2681, decode.acc_seg: 89.0822, aux.loss_ce: 0.1335, aux.acc_seg: 87.1576, loss: 0.4017
2023-12-29 01:59:55,053 - mmseg - INFO - Iter [89750/160000]	lr: 2.634e-05, eta: 15:38:52, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2477, decode.acc_seg: 89.4065, aux.loss_ce: 0.1258, aux.acc_seg: 87.4584, loss: 0.3735
2023-12-29 02:00:34,924 - mmseg - INFO - Iter [89800/160000]	lr: 2.633e-05, eta: 15:38:12, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2365, decode.acc_seg: 90.0451, aux.loss_ce: 0.1212, aux.acc_seg: 87.8613, loss: 0.3577
2023-12-29 02:01:13,643 - mmseg - INFO - Iter [89850/160000]	lr: 2.631e-05, eta: 15:37:31, time: 0.774, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2446, decode.acc_seg: 89.8949, aux.loss_ce: 0.1271, aux.acc_seg: 87.5286, loss: 0.3717
2023-12-29 02:01:53,330 - mmseg - INFO - Iter [89900/160000]	lr: 2.629e-05, eta: 15:36:51, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 90.2858, aux.loss_ce: 0.1196, aux.acc_seg: 88.4260, loss: 0.3627
2023-12-29 02:02:34,132 - mmseg - INFO - Iter [89950/160000]	lr: 2.627e-05, eta: 15:36:11, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2421, decode.acc_seg: 89.9772, aux.loss_ce: 0.1252, aux.acc_seg: 87.6294, loss: 0.3673
2023-12-29 02:03:14,156 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 02:03:14,157 - mmseg - INFO - Iter [90000/160000]	lr: 2.625e-05, eta: 15:35:31, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2271, decode.acc_seg: 90.4870, aux.loss_ce: 0.1173, aux.acc_seg: 88.5519, loss: 0.3444
2023-12-29 02:03:52,094 - mmseg - INFO - Iter [90050/160000]	lr: 2.623e-05, eta: 15:34:49, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2484, decode.acc_seg: 89.7759, aux.loss_ce: 0.1269, aux.acc_seg: 87.3348, loss: 0.3753
2023-12-29 02:04:33,644 - mmseg - INFO - Iter [90100/160000]	lr: 2.621e-05, eta: 15:34:10, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2201, decode.acc_seg: 90.7602, aux.loss_ce: 0.1165, aux.acc_seg: 88.3103, loss: 0.3366
2023-12-29 02:05:14,362 - mmseg - INFO - Iter [90150/160000]	lr: 2.619e-05, eta: 15:33:31, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2247, decode.acc_seg: 90.6107, aux.loss_ce: 0.1139, aux.acc_seg: 88.4857, loss: 0.3386
2023-12-29 02:05:54,811 - mmseg - INFO - Iter [90200/160000]	lr: 2.618e-05, eta: 15:32:51, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2295, decode.acc_seg: 90.5793, aux.loss_ce: 0.1192, aux.acc_seg: 88.4564, loss: 0.3488
2023-12-29 02:06:35,313 - mmseg - INFO - Iter [90250/160000]	lr: 2.616e-05, eta: 15:32:11, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2585, decode.acc_seg: 89.5428, aux.loss_ce: 0.1281, aux.acc_seg: 87.7073, loss: 0.3866
2023-12-29 02:07:15,845 - mmseg - INFO - Iter [90300/160000]	lr: 2.614e-05, eta: 15:31:31, time: 0.809, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2366, decode.acc_seg: 90.2920, aux.loss_ce: 0.1203, aux.acc_seg: 88.0077, loss: 0.3569
2023-12-29 02:07:55,642 - mmseg - INFO - Iter [90350/160000]	lr: 2.612e-05, eta: 15:30:51, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2392, decode.acc_seg: 90.0277, aux.loss_ce: 0.1211, aux.acc_seg: 88.0837, loss: 0.3603
2023-12-29 02:08:33,312 - mmseg - INFO - Iter [90400/160000]	lr: 2.610e-05, eta: 15:30:09, time: 0.753, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2294, decode.acc_seg: 90.3627, aux.loss_ce: 0.1217, aux.acc_seg: 87.9872, loss: 0.3511
2023-12-29 02:09:13,796 - mmseg - INFO - Iter [90450/160000]	lr: 2.608e-05, eta: 15:29:29, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2468, decode.acc_seg: 89.7489, aux.loss_ce: 0.1220, aux.acc_seg: 87.9008, loss: 0.3688
2023-12-29 02:09:53,716 - mmseg - INFO - Iter [90500/160000]	lr: 2.606e-05, eta: 15:28:49, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2474, decode.acc_seg: 89.5725, aux.loss_ce: 0.1263, aux.acc_seg: 87.3350, loss: 0.3737
2023-12-29 02:10:34,451 - mmseg - INFO - Iter [90550/160000]	lr: 2.604e-05, eta: 15:28:09, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2381, decode.acc_seg: 90.2788, aux.loss_ce: 0.1210, aux.acc_seg: 88.4191, loss: 0.3591
2023-12-29 02:11:13,068 - mmseg - INFO - Iter [90600/160000]	lr: 2.603e-05, eta: 15:27:28, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2463, decode.acc_seg: 90.0121, aux.loss_ce: 0.1262, aux.acc_seg: 87.9178, loss: 0.3724
2023-12-29 02:11:50,888 - mmseg - INFO - Iter [90650/160000]	lr: 2.601e-05, eta: 15:26:46, time: 0.756, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2516, decode.acc_seg: 89.8675, aux.loss_ce: 0.1287, aux.acc_seg: 87.5990, loss: 0.3803
2023-12-29 02:12:29,651 - mmseg - INFO - Iter [90700/160000]	lr: 2.599e-05, eta: 15:26:05, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2247, decode.acc_seg: 90.6300, aux.loss_ce: 0.1173, aux.acc_seg: 88.4021, loss: 0.3420
2023-12-29 02:13:09,511 - mmseg - INFO - Iter [90750/160000]	lr: 2.597e-05, eta: 15:25:25, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2350, decode.acc_seg: 90.2309, aux.loss_ce: 0.1178, aux.acc_seg: 88.3266, loss: 0.3528
2023-12-29 02:13:50,347 - mmseg - INFO - Iter [90800/160000]	lr: 2.595e-05, eta: 15:24:45, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2298, decode.acc_seg: 90.4768, aux.loss_ce: 0.1197, aux.acc_seg: 88.2366, loss: 0.3495
2023-12-29 02:14:30,799 - mmseg - INFO - Iter [90850/160000]	lr: 2.593e-05, eta: 15:24:06, time: 0.808, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2464, decode.acc_seg: 89.7028, aux.loss_ce: 0.1241, aux.acc_seg: 87.7072, loss: 0.3705
2023-12-29 02:15:09,510 - mmseg - INFO - Iter [90900/160000]	lr: 2.591e-05, eta: 15:23:24, time: 0.774, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2388, decode.acc_seg: 89.9473, aux.loss_ce: 0.1196, aux.acc_seg: 88.0823, loss: 0.3584
2023-12-29 02:15:51,696 - mmseg - INFO - Iter [90950/160000]	lr: 2.589e-05, eta: 15:22:46, time: 0.845, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2352, decode.acc_seg: 90.3952, aux.loss_ce: 0.1174, aux.acc_seg: 88.4689, loss: 0.3526
2023-12-29 02:16:31,870 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 02:16:31,870 - mmseg - INFO - Iter [91000/160000]	lr: 2.588e-05, eta: 15:22:06, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2390, decode.acc_seg: 90.4899, aux.loss_ce: 0.1216, aux.acc_seg: 88.3597, loss: 0.3605
2023-12-29 02:17:11,320 - mmseg - INFO - Iter [91050/160000]	lr: 2.586e-05, eta: 15:21:25, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2374, decode.acc_seg: 90.4364, aux.loss_ce: 0.1193, aux.acc_seg: 88.4074, loss: 0.3567
2023-12-29 02:17:49,428 - mmseg - INFO - Iter [91100/160000]	lr: 2.584e-05, eta: 15:20:44, time: 0.762, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2417, decode.acc_seg: 90.0139, aux.loss_ce: 0.1257, aux.acc_seg: 87.9043, loss: 0.3674
2023-12-29 02:18:29,617 - mmseg - INFO - Iter [91150/160000]	lr: 2.582e-05, eta: 15:20:04, time: 0.803, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2312, decode.acc_seg: 90.2458, aux.loss_ce: 0.1203, aux.acc_seg: 87.8431, loss: 0.3515
2023-12-29 02:19:07,845 - mmseg - INFO - Iter [91200/160000]	lr: 2.580e-05, eta: 15:19:22, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2282, decode.acc_seg: 90.4658, aux.loss_ce: 0.1149, aux.acc_seg: 88.5546, loss: 0.3430
2023-12-29 02:19:45,691 - mmseg - INFO - Iter [91250/160000]	lr: 2.578e-05, eta: 15:18:40, time: 0.757, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2353, decode.acc_seg: 90.5390, aux.loss_ce: 0.1188, aux.acc_seg: 88.6238, loss: 0.3541
2023-12-29 02:20:24,205 - mmseg - INFO - Iter [91300/160000]	lr: 2.576e-05, eta: 15:17:59, time: 0.770, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2299, decode.acc_seg: 90.2622, aux.loss_ce: 0.1181, aux.acc_seg: 88.0969, loss: 0.3480
2023-12-29 02:21:03,599 - mmseg - INFO - Iter [91350/160000]	lr: 2.574e-05, eta: 15:17:19, time: 0.787, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2364, decode.acc_seg: 89.9784, aux.loss_ce: 0.1208, aux.acc_seg: 87.7925, loss: 0.3572
2023-12-29 02:21:43,395 - mmseg - INFO - Iter [91400/160000]	lr: 2.573e-05, eta: 15:16:38, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2285, decode.acc_seg: 90.3772, aux.loss_ce: 0.1162, aux.acc_seg: 88.3715, loss: 0.3447
2023-12-29 02:22:21,589 - mmseg - INFO - Iter [91450/160000]	lr: 2.571e-05, eta: 15:15:57, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2362, decode.acc_seg: 90.2252, aux.loss_ce: 0.1213, aux.acc_seg: 88.0100, loss: 0.3575
2023-12-29 02:23:01,715 - mmseg - INFO - Iter [91500/160000]	lr: 2.569e-05, eta: 15:15:17, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2331, decode.acc_seg: 90.2013, aux.loss_ce: 0.1221, aux.acc_seg: 87.7850, loss: 0.3552
2023-12-29 02:23:41,142 - mmseg - INFO - Iter [91550/160000]	lr: 2.567e-05, eta: 15:14:36, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2294, decode.acc_seg: 90.2422, aux.loss_ce: 0.1174, aux.acc_seg: 88.1812, loss: 0.3468
2023-12-29 02:24:22,218 - mmseg - INFO - Iter [91600/160000]	lr: 2.565e-05, eta: 15:13:57, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2271, decode.acc_seg: 90.4785, aux.loss_ce: 0.1143, aux.acc_seg: 88.6026, loss: 0.3414
2023-12-29 02:24:59,645 - mmseg - INFO - Iter [91650/160000]	lr: 2.563e-05, eta: 15:13:15, time: 0.750, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2431, decode.acc_seg: 90.0643, aux.loss_ce: 0.1243, aux.acc_seg: 87.8565, loss: 0.3674
2023-12-29 02:25:37,362 - mmseg - INFO - Iter [91700/160000]	lr: 2.561e-05, eta: 15:12:33, time: 0.754, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2358, decode.acc_seg: 89.9569, aux.loss_ce: 0.1191, aux.acc_seg: 87.9587, loss: 0.3549
2023-12-29 02:26:16,069 - mmseg - INFO - Iter [91750/160000]	lr: 2.559e-05, eta: 15:11:52, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2418, decode.acc_seg: 90.0630, aux.loss_ce: 0.1240, aux.acc_seg: 88.0928, loss: 0.3658
2023-12-29 02:26:55,858 - mmseg - INFO - Iter [91800/160000]	lr: 2.558e-05, eta: 15:11:11, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2499, decode.acc_seg: 89.7736, aux.loss_ce: 0.1261, aux.acc_seg: 87.4800, loss: 0.3760
2023-12-29 02:27:36,506 - mmseg - INFO - Iter [91850/160000]	lr: 2.556e-05, eta: 15:10:32, time: 0.812, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2415, decode.acc_seg: 90.2800, aux.loss_ce: 0.1239, aux.acc_seg: 88.1880, loss: 0.3654
2023-12-29 02:28:16,004 - mmseg - INFO - Iter [91900/160000]	lr: 2.554e-05, eta: 15:09:51, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2389, decode.acc_seg: 89.8913, aux.loss_ce: 0.1196, aux.acc_seg: 87.9822, loss: 0.3585
2023-12-29 02:28:55,535 - mmseg - INFO - Iter [91950/160000]	lr: 2.552e-05, eta: 15:09:11, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2592, decode.acc_seg: 89.6141, aux.loss_ce: 0.1308, aux.acc_seg: 87.4461, loss: 0.3900
2023-12-29 02:29:35,944 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 02:29:35,945 - mmseg - INFO - Iter [92000/160000]	lr: 2.550e-05, eta: 15:08:31, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2411, decode.acc_seg: 89.9086, aux.loss_ce: 0.1234, aux.acc_seg: 87.7880, loss: 0.3645
2023-12-29 02:30:17,319 - mmseg - INFO - Iter [92050/160000]	lr: 2.548e-05, eta: 15:07:52, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2298, decode.acc_seg: 90.4718, aux.loss_ce: 0.1186, aux.acc_seg: 88.4083, loss: 0.3484
2023-12-29 02:30:56,903 - mmseg - INFO - Iter [92100/160000]	lr: 2.546e-05, eta: 15:07:11, time: 0.793, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2306, decode.acc_seg: 90.2555, aux.loss_ce: 0.1193, aux.acc_seg: 88.0960, loss: 0.3498
2023-12-29 02:31:35,542 - mmseg - INFO - Iter [92150/160000]	lr: 2.544e-05, eta: 15:06:30, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2373, decode.acc_seg: 90.0039, aux.loss_ce: 0.1194, aux.acc_seg: 88.0232, loss: 0.3567
2023-12-29 02:32:18,035 - mmseg - INFO - Iter [92200/160000]	lr: 2.543e-05, eta: 15:05:52, time: 0.849, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2509, decode.acc_seg: 89.7354, aux.loss_ce: 0.1276, aux.acc_seg: 87.6051, loss: 0.3784
2023-12-29 02:32:59,455 - mmseg - INFO - Iter [92250/160000]	lr: 2.541e-05, eta: 15:05:13, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2229, decode.acc_seg: 90.7732, aux.loss_ce: 0.1168, aux.acc_seg: 88.6855, loss: 0.3397
2023-12-29 02:33:38,912 - mmseg - INFO - Iter [92300/160000]	lr: 2.539e-05, eta: 15:04:32, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2606, decode.acc_seg: 89.3357, aux.loss_ce: 0.1319, aux.acc_seg: 86.9253, loss: 0.3924
2023-12-29 02:34:18,301 - mmseg - INFO - Iter [92350/160000]	lr: 2.537e-05, eta: 15:03:52, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2393, decode.acc_seg: 89.8414, aux.loss_ce: 0.1225, aux.acc_seg: 87.8100, loss: 0.3618
2023-12-29 02:34:57,628 - mmseg - INFO - Iter [92400/160000]	lr: 2.535e-05, eta: 15:03:11, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2339, decode.acc_seg: 90.2585, aux.loss_ce: 0.1179, aux.acc_seg: 88.2751, loss: 0.3519
2023-12-29 02:35:34,975 - mmseg - INFO - Iter [92450/160000]	lr: 2.533e-05, eta: 15:02:29, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2328, decode.acc_seg: 90.4286, aux.loss_ce: 0.1187, aux.acc_seg: 88.4560, loss: 0.3515
2023-12-29 02:36:15,136 - mmseg - INFO - Iter [92500/160000]	lr: 2.531e-05, eta: 15:01:49, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2290, decode.acc_seg: 90.7642, aux.loss_ce: 0.1154, aux.acc_seg: 88.7780, loss: 0.3443
2023-12-29 02:36:54,321 - mmseg - INFO - Iter [92550/160000]	lr: 2.529e-05, eta: 15:01:08, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2329, decode.acc_seg: 90.3732, aux.loss_ce: 0.1192, aux.acc_seg: 88.3147, loss: 0.3521
2023-12-29 02:37:32,887 - mmseg - INFO - Iter [92600/160000]	lr: 2.528e-05, eta: 15:00:27, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2304, decode.acc_seg: 90.6001, aux.loss_ce: 0.1207, aux.acc_seg: 88.3053, loss: 0.3511
2023-12-29 02:38:11,170 - mmseg - INFO - Iter [92650/160000]	lr: 2.526e-05, eta: 14:59:46, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2389, decode.acc_seg: 90.1461, aux.loss_ce: 0.1207, aux.acc_seg: 88.0088, loss: 0.3596
2023-12-29 02:38:49,915 - mmseg - INFO - Iter [92700/160000]	lr: 2.524e-05, eta: 14:59:05, time: 0.774, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2279, decode.acc_seg: 90.4457, aux.loss_ce: 0.1176, aux.acc_seg: 88.2284, loss: 0.3456
2023-12-29 02:39:27,353 - mmseg - INFO - Iter [92750/160000]	lr: 2.522e-05, eta: 14:58:23, time: 0.749, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2228, decode.acc_seg: 90.6892, aux.loss_ce: 0.1168, aux.acc_seg: 88.3734, loss: 0.3396
2023-12-29 02:40:05,375 - mmseg - INFO - Iter [92800/160000]	lr: 2.520e-05, eta: 14:57:41, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2458, decode.acc_seg: 89.7489, aux.loss_ce: 0.1283, aux.acc_seg: 87.3182, loss: 0.3741
2023-12-29 02:40:45,693 - mmseg - INFO - Iter [92850/160000]	lr: 2.518e-05, eta: 14:57:01, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2361, decode.acc_seg: 90.4653, aux.loss_ce: 0.1207, aux.acc_seg: 88.3049, loss: 0.3568
2023-12-29 02:41:26,268 - mmseg - INFO - Iter [92900/160000]	lr: 2.516e-05, eta: 14:56:21, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2204, decode.acc_seg: 90.7610, aux.loss_ce: 0.1149, aux.acc_seg: 88.7002, loss: 0.3353
2023-12-29 02:42:05,699 - mmseg - INFO - Iter [92950/160000]	lr: 2.514e-05, eta: 14:55:41, time: 0.789, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2327, decode.acc_seg: 90.4524, aux.loss_ce: 0.1193, aux.acc_seg: 88.1094, loss: 0.3520
2023-12-29 02:42:45,108 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 02:42:45,108 - mmseg - INFO - Iter [93000/160000]	lr: 2.513e-05, eta: 14:55:00, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2338, decode.acc_seg: 90.2698, aux.loss_ce: 0.1192, aux.acc_seg: 88.0868, loss: 0.3529
2023-12-29 02:43:25,910 - mmseg - INFO - Iter [93050/160000]	lr: 2.511e-05, eta: 14:54:21, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2350, decode.acc_seg: 90.3715, aux.loss_ce: 0.1198, aux.acc_seg: 88.4284, loss: 0.3548
2023-12-29 02:44:05,796 - mmseg - INFO - Iter [93100/160000]	lr: 2.509e-05, eta: 14:53:40, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2414, decode.acc_seg: 89.8465, aux.loss_ce: 0.1241, aux.acc_seg: 87.7510, loss: 0.3654
2023-12-29 02:44:44,583 - mmseg - INFO - Iter [93150/160000]	lr: 2.507e-05, eta: 14:52:59, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2352, decode.acc_seg: 90.2748, aux.loss_ce: 0.1189, aux.acc_seg: 88.3005, loss: 0.3541
2023-12-29 02:45:24,642 - mmseg - INFO - Iter [93200/160000]	lr: 2.505e-05, eta: 14:52:19, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2454, decode.acc_seg: 89.8400, aux.loss_ce: 0.1217, aux.acc_seg: 88.0028, loss: 0.3671
2023-12-29 02:46:04,954 - mmseg - INFO - Iter [93250/160000]	lr: 2.503e-05, eta: 14:51:39, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2285, decode.acc_seg: 90.6094, aux.loss_ce: 0.1160, aux.acc_seg: 88.7239, loss: 0.3445
2023-12-29 02:46:45,456 - mmseg - INFO - Iter [93300/160000]	lr: 2.501e-05, eta: 14:51:00, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2221, decode.acc_seg: 90.5039, aux.loss_ce: 0.1159, aux.acc_seg: 88.2188, loss: 0.3380
2023-12-29 02:47:24,352 - mmseg - INFO - Iter [93350/160000]	lr: 2.499e-05, eta: 14:50:19, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2282, decode.acc_seg: 90.5220, aux.loss_ce: 0.1182, aux.acc_seg: 88.3178, loss: 0.3464
2023-12-29 02:48:03,783 - mmseg - INFO - Iter [93400/160000]	lr: 2.498e-05, eta: 14:49:38, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2295, decode.acc_seg: 90.3314, aux.loss_ce: 0.1159, aux.acc_seg: 88.3315, loss: 0.3454
2023-12-29 02:48:43,478 - mmseg - INFO - Iter [93450/160000]	lr: 2.496e-05, eta: 14:48:58, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2442, decode.acc_seg: 90.1252, aux.loss_ce: 0.1216, aux.acc_seg: 88.0446, loss: 0.3658
2023-12-29 02:49:24,954 - mmseg - INFO - Iter [93500/160000]	lr: 2.494e-05, eta: 14:48:19, time: 0.828, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2303, decode.acc_seg: 90.3392, aux.loss_ce: 0.1195, aux.acc_seg: 88.2066, loss: 0.3498
2023-12-29 02:50:04,226 - mmseg - INFO - Iter [93550/160000]	lr: 2.492e-05, eta: 14:47:38, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2350, decode.acc_seg: 90.2649, aux.loss_ce: 0.1232, aux.acc_seg: 87.9870, loss: 0.3583
2023-12-29 02:50:44,196 - mmseg - INFO - Iter [93600/160000]	lr: 2.490e-05, eta: 14:46:58, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2301, decode.acc_seg: 90.3789, aux.loss_ce: 0.1185, aux.acc_seg: 87.9357, loss: 0.3486
2023-12-29 02:51:26,112 - mmseg - INFO - Iter [93650/160000]	lr: 2.488e-05, eta: 14:46:19, time: 0.839, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2400, decode.acc_seg: 90.1073, aux.loss_ce: 0.1218, aux.acc_seg: 88.2057, loss: 0.3618
2023-12-29 02:52:06,144 - mmseg - INFO - Iter [93700/160000]	lr: 2.486e-05, eta: 14:45:39, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2210, decode.acc_seg: 90.8597, aux.loss_ce: 0.1145, aux.acc_seg: 88.8416, loss: 0.3356
2023-12-29 02:52:46,527 - mmseg - INFO - Iter [93750/160000]	lr: 2.484e-05, eta: 14:44:59, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2418, decode.acc_seg: 89.8732, aux.loss_ce: 0.1238, aux.acc_seg: 87.6280, loss: 0.3656
2023-12-29 02:53:26,942 - mmseg - INFO - Iter [93800/160000]	lr: 2.483e-05, eta: 14:44:20, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2423, decode.acc_seg: 89.9878, aux.loss_ce: 0.1218, aux.acc_seg: 88.1229, loss: 0.3641
2023-12-29 02:54:07,641 - mmseg - INFO - Iter [93850/160000]	lr: 2.481e-05, eta: 14:43:40, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2261, decode.acc_seg: 90.5957, aux.loss_ce: 0.1148, aux.acc_seg: 88.7007, loss: 0.3409
2023-12-29 02:54:48,368 - mmseg - INFO - Iter [93900/160000]	lr: 2.479e-05, eta: 14:43:00, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2341, decode.acc_seg: 90.6374, aux.loss_ce: 0.1194, aux.acc_seg: 88.5505, loss: 0.3535
2023-12-29 02:55:29,190 - mmseg - INFO - Iter [93950/160000]	lr: 2.477e-05, eta: 14:42:21, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2408, decode.acc_seg: 90.2396, aux.loss_ce: 0.1248, aux.acc_seg: 88.0219, loss: 0.3656
2023-12-29 02:56:10,214 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 02:56:10,214 - mmseg - INFO - Iter [94000/160000]	lr: 2.475e-05, eta: 14:41:41, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2237, decode.acc_seg: 90.8698, aux.loss_ce: 0.1136, aux.acc_seg: 88.8143, loss: 0.3372
2023-12-29 02:56:50,522 - mmseg - INFO - Iter [94050/160000]	lr: 2.473e-05, eta: 14:41:01, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2228, decode.acc_seg: 90.8021, aux.loss_ce: 0.1173, aux.acc_seg: 88.6331, loss: 0.3401
2023-12-29 02:57:29,884 - mmseg - INFO - Iter [94100/160000]	lr: 2.471e-05, eta: 14:40:21, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2345, decode.acc_seg: 90.4173, aux.loss_ce: 0.1180, aux.acc_seg: 88.3749, loss: 0.3525
2023-12-29 02:58:07,632 - mmseg - INFO - Iter [94150/160000]	lr: 2.469e-05, eta: 14:39:39, time: 0.754, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2267, decode.acc_seg: 90.5889, aux.loss_ce: 0.1183, aux.acc_seg: 88.5862, loss: 0.3450
2023-12-29 02:58:47,150 - mmseg - INFO - Iter [94200/160000]	lr: 2.468e-05, eta: 14:38:59, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2272, decode.acc_seg: 90.5644, aux.loss_ce: 0.1145, aux.acc_seg: 88.4863, loss: 0.3417
2023-12-29 02:59:26,707 - mmseg - INFO - Iter [94250/160000]	lr: 2.466e-05, eta: 14:38:18, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2209, decode.acc_seg: 90.8678, aux.loss_ce: 0.1156, aux.acc_seg: 88.6423, loss: 0.3365
2023-12-29 03:00:07,110 - mmseg - INFO - Iter [94300/160000]	lr: 2.464e-05, eta: 14:37:38, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2382, decode.acc_seg: 90.2239, aux.loss_ce: 0.1227, aux.acc_seg: 87.9200, loss: 0.3609
2023-12-29 03:00:48,110 - mmseg - INFO - Iter [94350/160000]	lr: 2.462e-05, eta: 14:36:59, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2435, decode.acc_seg: 90.0491, aux.loss_ce: 0.1230, aux.acc_seg: 88.0382, loss: 0.3665
2023-12-29 03:01:28,758 - mmseg - INFO - Iter [94400/160000]	lr: 2.460e-05, eta: 14:36:19, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2469, decode.acc_seg: 89.8000, aux.loss_ce: 0.1279, aux.acc_seg: 87.4917, loss: 0.3748
2023-12-29 03:02:08,403 - mmseg - INFO - Iter [94450/160000]	lr: 2.458e-05, eta: 14:35:39, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2467, decode.acc_seg: 90.0274, aux.loss_ce: 0.1243, aux.acc_seg: 87.7834, loss: 0.3710
2023-12-29 03:02:47,766 - mmseg - INFO - Iter [94500/160000]	lr: 2.456e-05, eta: 14:34:58, time: 0.786, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2344, decode.acc_seg: 90.2025, aux.loss_ce: 0.1206, aux.acc_seg: 88.1364, loss: 0.3549
2023-12-29 03:03:24,921 - mmseg - INFO - Iter [94550/160000]	lr: 2.454e-05, eta: 14:34:16, time: 0.744, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2469, decode.acc_seg: 89.6877, aux.loss_ce: 0.1252, aux.acc_seg: 87.6686, loss: 0.3722
2023-12-29 03:04:03,345 - mmseg - INFO - Iter [94600/160000]	lr: 2.453e-05, eta: 14:33:35, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2253, decode.acc_seg: 90.4174, aux.loss_ce: 0.1175, aux.acc_seg: 88.3210, loss: 0.3427
2023-12-29 03:04:41,788 - mmseg - INFO - Iter [94650/160000]	lr: 2.451e-05, eta: 14:32:54, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2352, decode.acc_seg: 90.4619, aux.loss_ce: 0.1224, aux.acc_seg: 88.2232, loss: 0.3576
2023-12-29 03:05:19,146 - mmseg - INFO - Iter [94700/160000]	lr: 2.449e-05, eta: 14:32:12, time: 0.748, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2235, decode.acc_seg: 90.8600, aux.loss_ce: 0.1161, aux.acc_seg: 88.6448, loss: 0.3396
2023-12-29 03:05:59,573 - mmseg - INFO - Iter [94750/160000]	lr: 2.447e-05, eta: 14:31:32, time: 0.809, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2169, decode.acc_seg: 90.8352, aux.loss_ce: 0.1141, aux.acc_seg: 88.5915, loss: 0.3309
2023-12-29 03:06:38,560 - mmseg - INFO - Iter [94800/160000]	lr: 2.445e-05, eta: 14:30:51, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2197, decode.acc_seg: 90.8320, aux.loss_ce: 0.1123, aux.acc_seg: 88.8670, loss: 0.3320
2023-12-29 03:07:18,290 - mmseg - INFO - Iter [94850/160000]	lr: 2.443e-05, eta: 14:30:11, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2302, decode.acc_seg: 90.5534, aux.loss_ce: 0.1185, aux.acc_seg: 88.4667, loss: 0.3487
2023-12-29 03:07:58,917 - mmseg - INFO - Iter [94900/160000]	lr: 2.441e-05, eta: 14:29:31, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2285, decode.acc_seg: 90.7883, aux.loss_ce: 0.1176, aux.acc_seg: 88.6624, loss: 0.3461
2023-12-29 03:08:39,228 - mmseg - INFO - Iter [94950/160000]	lr: 2.439e-05, eta: 14:28:51, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2475, decode.acc_seg: 89.9200, aux.loss_ce: 0.1241, aux.acc_seg: 87.9354, loss: 0.3716
2023-12-29 03:09:19,685 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 03:09:19,685 - mmseg - INFO - Iter [95000/160000]	lr: 2.438e-05, eta: 14:28:11, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2396, decode.acc_seg: 90.0357, aux.loss_ce: 0.1230, aux.acc_seg: 87.8348, loss: 0.3626
2023-12-29 03:09:58,785 - mmseg - INFO - Iter [95050/160000]	lr: 2.436e-05, eta: 14:27:31, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2164, decode.acc_seg: 90.8848, aux.loss_ce: 0.1092, aux.acc_seg: 88.8738, loss: 0.3256
2023-12-29 03:10:38,026 - mmseg - INFO - Iter [95100/160000]	lr: 2.434e-05, eta: 14:26:50, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2233, decode.acc_seg: 90.6585, aux.loss_ce: 0.1163, aux.acc_seg: 88.4813, loss: 0.3396
2023-12-29 03:11:17,301 - mmseg - INFO - Iter [95150/160000]	lr: 2.432e-05, eta: 14:26:09, time: 0.784, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2224, decode.acc_seg: 90.6235, aux.loss_ce: 0.1163, aux.acc_seg: 88.5588, loss: 0.3387
2023-12-29 03:11:57,585 - mmseg - INFO - Iter [95200/160000]	lr: 2.430e-05, eta: 14:25:30, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2407, decode.acc_seg: 90.0120, aux.loss_ce: 0.1247, aux.acc_seg: 87.6770, loss: 0.3654
2023-12-29 03:12:37,326 - mmseg - INFO - Iter [95250/160000]	lr: 2.428e-05, eta: 14:24:49, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2359, decode.acc_seg: 90.3666, aux.loss_ce: 0.1207, aux.acc_seg: 88.3074, loss: 0.3566
2023-12-29 03:13:16,228 - mmseg - INFO - Iter [95300/160000]	lr: 2.426e-05, eta: 14:24:08, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2242, decode.acc_seg: 90.3203, aux.loss_ce: 0.1164, aux.acc_seg: 88.0580, loss: 0.3405
2023-12-29 03:13:56,421 - mmseg - INFO - Iter [95350/160000]	lr: 2.424e-05, eta: 14:23:28, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2248, decode.acc_seg: 90.4388, aux.loss_ce: 0.1148, aux.acc_seg: 88.4646, loss: 0.3396
2023-12-29 03:14:37,892 - mmseg - INFO - Iter [95400/160000]	lr: 2.423e-05, eta: 14:22:49, time: 0.828, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2349, decode.acc_seg: 90.3268, aux.loss_ce: 0.1200, aux.acc_seg: 88.0958, loss: 0.3549
2023-12-29 03:15:19,399 - mmseg - INFO - Iter [95450/160000]	lr: 2.421e-05, eta: 14:22:10, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2274, decode.acc_seg: 90.3524, aux.loss_ce: 0.1154, aux.acc_seg: 88.3371, loss: 0.3428
2023-12-29 03:16:00,268 - mmseg - INFO - Iter [95500/160000]	lr: 2.419e-05, eta: 14:21:31, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2206, decode.acc_seg: 90.7426, aux.loss_ce: 0.1133, aux.acc_seg: 88.5935, loss: 0.3339
2023-12-29 03:16:42,373 - mmseg - INFO - Iter [95550/160000]	lr: 2.417e-05, eta: 14:20:52, time: 0.841, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2103, decode.acc_seg: 91.2760, aux.loss_ce: 0.1071, aux.acc_seg: 89.4899, loss: 0.3174
2023-12-29 03:17:21,205 - mmseg - INFO - Iter [95600/160000]	lr: 2.415e-05, eta: 14:20:11, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2292, decode.acc_seg: 90.6019, aux.loss_ce: 0.1177, aux.acc_seg: 88.5380, loss: 0.3469
2023-12-29 03:18:02,899 - mmseg - INFO - Iter [95650/160000]	lr: 2.413e-05, eta: 14:19:32, time: 0.833, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2369, decode.acc_seg: 90.5183, aux.loss_ce: 0.1230, aux.acc_seg: 88.2132, loss: 0.3599
2023-12-29 03:18:41,147 - mmseg - INFO - Iter [95700/160000]	lr: 2.411e-05, eta: 14:18:51, time: 0.765, data_time: 0.015, memory: 18256, decode.loss_ce: 0.2441, decode.acc_seg: 90.2264, aux.loss_ce: 0.1266, aux.acc_seg: 87.9218, loss: 0.3706
2023-12-29 03:19:21,600 - mmseg - INFO - Iter [95750/160000]	lr: 2.409e-05, eta: 14:18:11, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2206, decode.acc_seg: 90.8227, aux.loss_ce: 0.1139, aux.acc_seg: 88.7581, loss: 0.3345
2023-12-29 03:19:59,704 - mmseg - INFO - Iter [95800/160000]	lr: 2.408e-05, eta: 14:17:30, time: 0.763, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2342, decode.acc_seg: 90.3871, aux.loss_ce: 0.1203, aux.acc_seg: 88.1173, loss: 0.3545
2023-12-29 03:20:40,212 - mmseg - INFO - Iter [95850/160000]	lr: 2.406e-05, eta: 14:16:50, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2369, decode.acc_seg: 90.3242, aux.loss_ce: 0.1210, aux.acc_seg: 88.1948, loss: 0.3580
2023-12-29 03:21:21,462 - mmseg - INFO - Iter [95900/160000]	lr: 2.404e-05, eta: 14:16:11, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2411, decode.acc_seg: 90.0454, aux.loss_ce: 0.1254, aux.acc_seg: 87.8268, loss: 0.3665
2023-12-29 03:22:02,435 - mmseg - INFO - Iter [95950/160000]	lr: 2.402e-05, eta: 14:15:31, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2425, decode.acc_seg: 89.8746, aux.loss_ce: 0.1233, aux.acc_seg: 87.7243, loss: 0.3659
2023-12-29 03:22:44,439 - mmseg - INFO - Saving checkpoint at 96000 iterations
2023-12-29 03:22:48,814 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 03:22:48,815 - mmseg - INFO - Iter [96000/160000]	lr: 2.400e-05, eta: 14:14:55, time: 0.929, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2249, decode.acc_seg: 90.5539, aux.loss_ce: 0.1178, aux.acc_seg: 88.2123, loss: 0.3427
2023-12-29 03:24:21,380 - mmseg - INFO - per class results:
2023-12-29 03:24:21,394 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 76.93 | 88.62 |
|       building      |  82.6 | 91.44 |
|         sky         | 94.35 | 97.67 |
|        floor        | 81.29 | 91.23 |
|         tree        | 74.79 | 87.29 |
|       ceiling       | 83.18 | 89.08 |
|         road        | 82.74 | 90.46 |
|         bed         | 89.49 | 95.55 |
|      windowpane     | 63.35 | 79.02 |
|        grass        | 68.15 | 85.55 |
|       cabinet       | 60.58 | 73.23 |
|       sidewalk      | 65.14 | 78.38 |
|        person       | 81.52 |  92.6 |
|        earth        | 36.46 | 49.79 |
|         door        |  53.3 | 68.42 |
|        table        | 58.43 | 72.18 |
|       mountain      | 59.31 | 76.26 |
|        plant        | 50.85 | 61.09 |
|       curtain       | 76.03 | 84.19 |
|        chair        | 55.06 | 66.09 |
|         car         | 84.13 | 91.61 |
|        water        | 56.27 | 68.65 |
|       painting      | 71.91 | 87.79 |
|         sofa        |  65.0 | 83.79 |
|        shelf        | 46.87 | 66.23 |
|        house        | 49.07 | 75.83 |
|         sea         | 56.15 | 73.22 |
|        mirror       | 66.89 | 75.56 |
|         rug         | 64.15 | 75.01 |
|        field        | 35.67 |  58.3 |
|       armchair      |  39.8 |  55.6 |
|         seat        | 60.45 | 83.08 |
|        fence        | 48.31 | 60.43 |
|         desk        | 47.72 | 68.82 |
|         rock        | 47.78 | 71.05 |
|       wardrobe      | 52.64 | 67.69 |
|         lamp        | 63.72 | 73.94 |
|       bathtub       |  75.6 | 84.73 |
|       railing       | 35.72 | 48.16 |
|       cushion       | 60.29 | 72.41 |
|         base        | 28.73 | 39.83 |
|         box         | 22.22 | 26.81 |
|        column       | 47.02 | 57.33 |
|      signboard      |  35.2 | 47.51 |
|   chest of drawers  | 35.33 |  49.5 |
|       counter       | 25.64 | 32.03 |
|         sand        | 41.95 | 73.46 |
|         sink        |  67.7 | 74.43 |
|      skyscraper     | 39.68 | 47.71 |
|      fireplace      |  70.8 | 88.29 |
|     refrigerator    |  76.0 | 82.17 |
|      grandstand     | 32.29 | 72.07 |
|         path        | 24.28 | 32.78 |
|        stairs       | 28.09 | 31.61 |
|        runway       | 70.43 |  91.3 |
|         case        | 60.04 | 68.27 |
|      pool table     | 92.62 |  97.1 |
|        pillow       | 63.72 | 77.81 |
|     screen door     | 72.86 | 76.17 |
|       stairway      | 28.75 | 39.86 |
|        river        | 10.47 | 24.61 |
|        bridge       | 60.04 | 70.79 |
|       bookcase      | 38.59 | 53.78 |
|        blind        | 40.35 | 45.75 |
|     coffee table    | 56.39 | 81.73 |
|        toilet       | 83.58 | 91.57 |
|        flower       | 38.92 |  56.6 |
|         book        | 45.78 |  64.5 |
|         hill        |  3.41 |  5.27 |
|        bench        | 47.23 | 54.99 |
|      countertop     | 59.05 | 84.58 |
|        stove        | 71.12 | 86.09 |
|         palm        | 48.85 | 74.06 |
|    kitchen island   | 35.61 | 76.37 |
|       computer      | 65.63 | 77.78 |
|     swivel chair    | 39.69 | 73.48 |
|         boat        | 39.87 | 49.09 |
|         bar         |  39.6 | 58.59 |
|    arcade machine   | 83.21 | 90.66 |
|        hovel        |  39.8 | 45.04 |
|         bus         | 81.23 | 96.27 |
|        towel        |  57.6 | 68.05 |
|        light        | 52.75 | 58.28 |
|        truck        | 29.07 | 39.32 |
|        tower        | 31.48 | 56.48 |
|      chandelier     | 70.02 |  84.8 |
|        awning       | 26.92 | 35.55 |
|     streetlight     |  22.7 | 27.68 |
|        booth        | 54.01 | 59.91 |
| television receiver | 65.68 | 77.28 |
|       airplane      | 53.28 | 67.18 |
|      dirt track     | 21.34 | 47.13 |
|       apparel       | 40.93 |  61.4 |
|         pole        | 21.54 | 29.48 |
|         land        |  3.94 |  6.08 |
|      bannister      | 13.97 | 17.46 |
|      escalator      | 25.47 | 27.25 |
|       ottoman       | 39.19 | 56.38 |
|        bottle       | 30.28 | 40.71 |
|        buffet       | 53.08 | 63.43 |
|        poster       | 30.46 | 37.93 |
|        stage        | 13.63 | 22.92 |
|         van         | 44.88 |  58.9 |
|         ship        | 47.66 |  82.1 |
|       fountain      | 21.95 | 22.11 |
|    conveyer belt    | 79.12 | 88.01 |
|        canopy       |  22.7 | 32.25 |
|        washer       | 89.91 | 93.55 |
|      plaything      | 22.86 | 43.97 |
|    swimming pool    | 70.99 | 85.01 |
|        stool        | 35.43 |  54.3 |
|        barrel       | 39.52 | 64.63 |
|        basket       | 31.86 |  46.5 |
|      waterfall      | 74.52 |  86.0 |
|         tent        | 92.17 | 98.58 |
|         bag         | 11.23 | 13.38 |
|       minibike      | 71.18 | 81.39 |
|        cradle       |  78.7 | 98.12 |
|         oven        | 39.14 | 53.97 |
|         ball        |  47.7 | 68.77 |
|         food        | 59.18 | 75.33 |
|         step        |  11.2 | 14.11 |
|         tank        | 55.52 | 56.97 |
|      trade name     |  14.7 | 16.21 |
|      microwave      | 78.28 | 86.16 |
|         pot         | 38.62 | 47.29 |
|        animal       | 46.36 | 57.78 |
|       bicycle       | 52.17 | 69.13 |
|         lake        | 57.39 | 63.78 |
|      dishwasher     |  59.0 | 66.38 |
|        screen       | 64.63 |  86.7 |
|       blanket       |  9.99 | 11.21 |
|      sculpture      | 61.91 | 69.11 |
|         hood        | 57.04 | 71.81 |
|        sconce       | 42.77 | 49.99 |
|         vase        |  40.8 |  51.5 |
|    traffic light    | 27.56 | 42.96 |
|         tray        | 11.95 | 20.01 |
|        ashcan       | 36.55 | 47.19 |
|         fan         | 51.69 | 73.39 |
|         pier        | 44.02 | 71.13 |
|      crt screen     |  4.6  | 10.92 |
|        plate        | 52.98 | 72.34 |
|       monitor       |  24.8 | 32.51 |
|    bulletin board   | 50.97 | 60.39 |
|        shower       |  4.01 |  5.13 |
|       radiator      | 54.81 | 62.33 |
|        glass        | 14.92 | 16.46 |
|        clock        | 32.18 | 36.31 |
|         flag        | 44.65 | 46.77 |
+---------------------+-------+-------+
2023-12-29 03:24:21,394 - mmseg - INFO - Summary:
2023-12-29 03:24:21,394 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.06 | 49.32 | 61.84 |
+-------+-------+-------+
2023-12-29 03:24:21,431 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 03:24:21,432 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8306, mIoU: 0.4932, mAcc: 0.6184, IoU.wall: 0.7693, IoU.building: 0.8260, IoU.sky: 0.9435, IoU.floor: 0.8129, IoU.tree: 0.7479, IoU.ceiling: 0.8318, IoU.road: 0.8274, IoU.bed : 0.8949, IoU.windowpane: 0.6335, IoU.grass: 0.6815, IoU.cabinet: 0.6058, IoU.sidewalk: 0.6514, IoU.person: 0.8152, IoU.earth: 0.3646, IoU.door: 0.5330, IoU.table: 0.5843, IoU.mountain: 0.5931, IoU.plant: 0.5085, IoU.curtain: 0.7603, IoU.chair: 0.5506, IoU.car: 0.8413, IoU.water: 0.5627, IoU.painting: 0.7191, IoU.sofa: 0.6500, IoU.shelf: 0.4687, IoU.house: 0.4907, IoU.sea: 0.5615, IoU.mirror: 0.6689, IoU.rug: 0.6415, IoU.field: 0.3567, IoU.armchair: 0.3980, IoU.seat: 0.6045, IoU.fence: 0.4831, IoU.desk: 0.4772, IoU.rock: 0.4778, IoU.wardrobe: 0.5264, IoU.lamp: 0.6372, IoU.bathtub: 0.7560, IoU.railing: 0.3572, IoU.cushion: 0.6029, IoU.base: 0.2873, IoU.box: 0.2222, IoU.column: 0.4702, IoU.signboard: 0.3520, IoU.chest of drawers: 0.3533, IoU.counter: 0.2564, IoU.sand: 0.4195, IoU.sink: 0.6770, IoU.skyscraper: 0.3968, IoU.fireplace: 0.7080, IoU.refrigerator: 0.7600, IoU.grandstand: 0.3229, IoU.path: 0.2428, IoU.stairs: 0.2809, IoU.runway: 0.7043, IoU.case: 0.6004, IoU.pool table: 0.9262, IoU.pillow: 0.6372, IoU.screen door: 0.7286, IoU.stairway: 0.2875, IoU.river: 0.1047, IoU.bridge: 0.6004, IoU.bookcase: 0.3859, IoU.blind: 0.4035, IoU.coffee table: 0.5639, IoU.toilet: 0.8358, IoU.flower: 0.3892, IoU.book: 0.4578, IoU.hill: 0.0341, IoU.bench: 0.4723, IoU.countertop: 0.5905, IoU.stove: 0.7112, IoU.palm: 0.4885, IoU.kitchen island: 0.3561, IoU.computer: 0.6563, IoU.swivel chair: 0.3969, IoU.boat: 0.3987, IoU.bar: 0.3960, IoU.arcade machine: 0.8321, IoU.hovel: 0.3980, IoU.bus: 0.8123, IoU.towel: 0.5760, IoU.light: 0.5275, IoU.truck: 0.2907, IoU.tower: 0.3148, IoU.chandelier: 0.7002, IoU.awning: 0.2692, IoU.streetlight: 0.2270, IoU.booth: 0.5401, IoU.television receiver: 0.6568, IoU.airplane: 0.5328, IoU.dirt track: 0.2134, IoU.apparel: 0.4093, IoU.pole: 0.2154, IoU.land: 0.0394, IoU.bannister: 0.1397, IoU.escalator: 0.2547, IoU.ottoman: 0.3919, IoU.bottle: 0.3028, IoU.buffet: 0.5308, IoU.poster: 0.3046, IoU.stage: 0.1363, IoU.van: 0.4488, IoU.ship: 0.4766, IoU.fountain: 0.2195, IoU.conveyer belt: 0.7912, IoU.canopy: 0.2270, IoU.washer: 0.8991, IoU.plaything: 0.2286, IoU.swimming pool: 0.7099, IoU.stool: 0.3543, IoU.barrel: 0.3952, IoU.basket: 0.3186, IoU.waterfall: 0.7452, IoU.tent: 0.9217, IoU.bag: 0.1123, IoU.minibike: 0.7118, IoU.cradle: 0.7870, IoU.oven: 0.3914, IoU.ball: 0.4770, IoU.food: 0.5918, IoU.step: 0.1120, IoU.tank: 0.5552, IoU.trade name: 0.1470, IoU.microwave: 0.7828, IoU.pot: 0.3862, IoU.animal: 0.4636, IoU.bicycle: 0.5217, IoU.lake: 0.5739, IoU.dishwasher: 0.5900, IoU.screen: 0.6463, IoU.blanket: 0.0999, IoU.sculpture: 0.6191, IoU.hood: 0.5704, IoU.sconce: 0.4277, IoU.vase: 0.4080, IoU.traffic light: 0.2756, IoU.tray: 0.1195, IoU.ashcan: 0.3655, IoU.fan: 0.5169, IoU.pier: 0.4402, IoU.crt screen: 0.0460, IoU.plate: 0.5298, IoU.monitor: 0.2480, IoU.bulletin board: 0.5097, IoU.shower: 0.0401, IoU.radiator: 0.5481, IoU.glass: 0.1492, IoU.clock: 0.3218, IoU.flag: 0.4465, Acc.wall: 0.8862, Acc.building: 0.9144, Acc.sky: 0.9767, Acc.floor: 0.9123, Acc.tree: 0.8729, Acc.ceiling: 0.8908, Acc.road: 0.9046, Acc.bed : 0.9555, Acc.windowpane: 0.7902, Acc.grass: 0.8555, Acc.cabinet: 0.7323, Acc.sidewalk: 0.7838, Acc.person: 0.9260, Acc.earth: 0.4979, Acc.door: 0.6842, Acc.table: 0.7218, Acc.mountain: 0.7626, Acc.plant: 0.6109, Acc.curtain: 0.8419, Acc.chair: 0.6609, Acc.car: 0.9161, Acc.water: 0.6865, Acc.painting: 0.8779, Acc.sofa: 0.8379, Acc.shelf: 0.6623, Acc.house: 0.7583, Acc.sea: 0.7322, Acc.mirror: 0.7556, Acc.rug: 0.7501, Acc.field: 0.5830, Acc.armchair: 0.5560, Acc.seat: 0.8308, Acc.fence: 0.6043, Acc.desk: 0.6882, Acc.rock: 0.7105, Acc.wardrobe: 0.6769, Acc.lamp: 0.7394, Acc.bathtub: 0.8473, Acc.railing: 0.4816, Acc.cushion: 0.7241, Acc.base: 0.3983, Acc.box: 0.2681, Acc.column: 0.5733, Acc.signboard: 0.4751, Acc.chest of drawers: 0.4950, Acc.counter: 0.3203, Acc.sand: 0.7346, Acc.sink: 0.7443, Acc.skyscraper: 0.4771, Acc.fireplace: 0.8829, Acc.refrigerator: 0.8217, Acc.grandstand: 0.7207, Acc.path: 0.3278, Acc.stairs: 0.3161, Acc.runway: 0.9130, Acc.case: 0.6827, Acc.pool table: 0.9710, Acc.pillow: 0.7781, Acc.screen door: 0.7617, Acc.stairway: 0.3986, Acc.river: 0.2461, Acc.bridge: 0.7079, Acc.bookcase: 0.5378, Acc.blind: 0.4575, Acc.coffee table: 0.8173, Acc.toilet: 0.9157, Acc.flower: 0.5660, Acc.book: 0.6450, Acc.hill: 0.0527, Acc.bench: 0.5499, Acc.countertop: 0.8458, Acc.stove: 0.8609, Acc.palm: 0.7406, Acc.kitchen island: 0.7637, Acc.computer: 0.7778, Acc.swivel chair: 0.7348, Acc.boat: 0.4909, Acc.bar: 0.5859, Acc.arcade machine: 0.9066, Acc.hovel: 0.4504, Acc.bus: 0.9627, Acc.towel: 0.6805, Acc.light: 0.5828, Acc.truck: 0.3932, Acc.tower: 0.5648, Acc.chandelier: 0.8480, Acc.awning: 0.3555, Acc.streetlight: 0.2768, Acc.booth: 0.5991, Acc.television receiver: 0.7728, Acc.airplane: 0.6718, Acc.dirt track: 0.4713, Acc.apparel: 0.6140, Acc.pole: 0.2948, Acc.land: 0.0608, Acc.bannister: 0.1746, Acc.escalator: 0.2725, Acc.ottoman: 0.5638, Acc.bottle: 0.4071, Acc.buffet: 0.6343, Acc.poster: 0.3793, Acc.stage: 0.2292, Acc.van: 0.5890, Acc.ship: 0.8210, Acc.fountain: 0.2211, Acc.conveyer belt: 0.8801, Acc.canopy: 0.3225, Acc.washer: 0.9355, Acc.plaything: 0.4397, Acc.swimming pool: 0.8501, Acc.stool: 0.5430, Acc.barrel: 0.6463, Acc.basket: 0.4650, Acc.waterfall: 0.8600, Acc.tent: 0.9858, Acc.bag: 0.1338, Acc.minibike: 0.8139, Acc.cradle: 0.9812, Acc.oven: 0.5397, Acc.ball: 0.6877, Acc.food: 0.7533, Acc.step: 0.1411, Acc.tank: 0.5697, Acc.trade name: 0.1621, Acc.microwave: 0.8616, Acc.pot: 0.4729, Acc.animal: 0.5778, Acc.bicycle: 0.6913, Acc.lake: 0.6378, Acc.dishwasher: 0.6638, Acc.screen: 0.8670, Acc.blanket: 0.1121, Acc.sculpture: 0.6911, Acc.hood: 0.7181, Acc.sconce: 0.4999, Acc.vase: 0.5150, Acc.traffic light: 0.4296, Acc.tray: 0.2001, Acc.ashcan: 0.4719, Acc.fan: 0.7339, Acc.pier: 0.7113, Acc.crt screen: 0.1092, Acc.plate: 0.7234, Acc.monitor: 0.3251, Acc.bulletin board: 0.6039, Acc.shower: 0.0513, Acc.radiator: 0.6233, Acc.glass: 0.1646, Acc.clock: 0.3631, Acc.flag: 0.4677
2023-12-29 03:24:59,583 - mmseg - INFO - Iter [96050/160000]	lr: 2.398e-05, eta: 14:15:15, time: 2.614, data_time: 1.864, memory: 18256, decode.loss_ce: 0.2354, decode.acc_seg: 90.0599, aux.loss_ce: 0.1214, aux.acc_seg: 87.8992, loss: 0.3568
2023-12-29 03:25:40,229 - mmseg - INFO - Iter [96100/160000]	lr: 2.396e-05, eta: 14:14:36, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2289, decode.acc_seg: 90.4532, aux.loss_ce: 0.1177, aux.acc_seg: 88.3880, loss: 0.3467
2023-12-29 03:26:20,013 - mmseg - INFO - Iter [96150/160000]	lr: 2.394e-05, eta: 14:13:55, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2172, decode.acc_seg: 91.0049, aux.loss_ce: 0.1130, aux.acc_seg: 88.8863, loss: 0.3302
2023-12-29 03:26:57,529 - mmseg - INFO - Iter [96200/160000]	lr: 2.393e-05, eta: 14:13:14, time: 0.751, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2139, decode.acc_seg: 90.9175, aux.loss_ce: 0.1106, aux.acc_seg: 88.8510, loss: 0.3245
2023-12-29 03:27:37,852 - mmseg - INFO - Iter [96250/160000]	lr: 2.391e-05, eta: 14:12:34, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2227, decode.acc_seg: 90.6995, aux.loss_ce: 0.1145, aux.acc_seg: 88.5812, loss: 0.3372
2023-12-29 03:28:16,012 - mmseg - INFO - Iter [96300/160000]	lr: 2.389e-05, eta: 14:11:52, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2143, decode.acc_seg: 91.1591, aux.loss_ce: 0.1079, aux.acc_seg: 89.3851, loss: 0.3222
2023-12-29 03:28:56,248 - mmseg - INFO - Iter [96350/160000]	lr: 2.387e-05, eta: 14:11:12, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2229, decode.acc_seg: 90.7805, aux.loss_ce: 0.1134, aux.acc_seg: 88.8801, loss: 0.3363
2023-12-29 03:29:36,925 - mmseg - INFO - Iter [96400/160000]	lr: 2.385e-05, eta: 14:10:32, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2219, decode.acc_seg: 90.6306, aux.loss_ce: 0.1149, aux.acc_seg: 88.4044, loss: 0.3368
2023-12-29 03:30:15,108 - mmseg - INFO - Iter [96450/160000]	lr: 2.383e-05, eta: 14:09:51, time: 0.763, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2209, decode.acc_seg: 90.6666, aux.loss_ce: 0.1145, aux.acc_seg: 88.6019, loss: 0.3354
2023-12-29 03:30:55,393 - mmseg - INFO - Iter [96500/160000]	lr: 2.381e-05, eta: 14:09:11, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2391, decode.acc_seg: 90.2356, aux.loss_ce: 0.1221, aux.acc_seg: 88.2204, loss: 0.3612
2023-12-29 03:31:32,988 - mmseg - INFO - Iter [96550/160000]	lr: 2.379e-05, eta: 14:08:29, time: 0.752, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2281, decode.acc_seg: 90.4050, aux.loss_ce: 0.1199, aux.acc_seg: 88.0387, loss: 0.3480
2023-12-29 03:32:11,906 - mmseg - INFO - Iter [96600/160000]	lr: 2.378e-05, eta: 14:07:48, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2272, decode.acc_seg: 90.6002, aux.loss_ce: 0.1174, aux.acc_seg: 88.4491, loss: 0.3446
2023-12-29 03:32:50,499 - mmseg - INFO - Iter [96650/160000]	lr: 2.376e-05, eta: 14:07:07, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2486, decode.acc_seg: 89.9071, aux.loss_ce: 0.1261, aux.acc_seg: 87.5716, loss: 0.3746
2023-12-29 03:33:27,793 - mmseg - INFO - Iter [96700/160000]	lr: 2.374e-05, eta: 14:06:25, time: 0.746, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2270, decode.acc_seg: 90.6857, aux.loss_ce: 0.1172, aux.acc_seg: 88.4630, loss: 0.3442
2023-12-29 03:34:07,267 - mmseg - INFO - Iter [96750/160000]	lr: 2.372e-05, eta: 14:05:45, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2319, decode.acc_seg: 90.2106, aux.loss_ce: 0.1189, aux.acc_seg: 88.2128, loss: 0.3508
2023-12-29 03:34:47,953 - mmseg - INFO - Iter [96800/160000]	lr: 2.370e-05, eta: 14:05:05, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2338, decode.acc_seg: 90.2676, aux.loss_ce: 0.1192, aux.acc_seg: 88.2463, loss: 0.3530
2023-12-29 03:35:28,160 - mmseg - INFO - Iter [96850/160000]	lr: 2.368e-05, eta: 14:04:25, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2249, decode.acc_seg: 90.7468, aux.loss_ce: 0.1164, aux.acc_seg: 88.6545, loss: 0.3413
2023-12-29 03:36:05,173 - mmseg - INFO - Iter [96900/160000]	lr: 2.366e-05, eta: 14:03:43, time: 0.742, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2395, decode.acc_seg: 90.1193, aux.loss_ce: 0.1273, aux.acc_seg: 87.5689, loss: 0.3668
2023-12-29 03:36:45,439 - mmseg - INFO - Iter [96950/160000]	lr: 2.364e-05, eta: 14:03:03, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2345, decode.acc_seg: 90.1489, aux.loss_ce: 0.1202, aux.acc_seg: 88.1311, loss: 0.3547
2023-12-29 03:37:25,698 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 03:37:25,699 - mmseg - INFO - Iter [97000/160000]	lr: 2.363e-05, eta: 14:02:23, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2403, decode.acc_seg: 90.0425, aux.loss_ce: 0.1228, aux.acc_seg: 87.8387, loss: 0.3631
2023-12-29 03:38:03,476 - mmseg - INFO - Iter [97050/160000]	lr: 2.361e-05, eta: 14:01:41, time: 0.756, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2272, decode.acc_seg: 90.6575, aux.loss_ce: 0.1165, aux.acc_seg: 88.4255, loss: 0.3437
2023-12-29 03:38:41,235 - mmseg - INFO - Iter [97100/160000]	lr: 2.359e-05, eta: 14:00:59, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2390, decode.acc_seg: 90.0541, aux.loss_ce: 0.1254, aux.acc_seg: 87.6673, loss: 0.3644
2023-12-29 03:39:19,525 - mmseg - INFO - Iter [97150/160000]	lr: 2.357e-05, eta: 14:00:18, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2406, decode.acc_seg: 89.9076, aux.loss_ce: 0.1249, aux.acc_seg: 87.3600, loss: 0.3655
2023-12-29 03:39:57,467 - mmseg - INFO - Iter [97200/160000]	lr: 2.355e-05, eta: 13:59:37, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2265, decode.acc_seg: 90.5299, aux.loss_ce: 0.1161, aux.acc_seg: 88.3714, loss: 0.3425
2023-12-29 03:40:38,203 - mmseg - INFO - Iter [97250/160000]	lr: 2.353e-05, eta: 13:58:57, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2350, decode.acc_seg: 90.4532, aux.loss_ce: 0.1179, aux.acc_seg: 88.6330, loss: 0.3529
2023-12-29 03:41:21,716 - mmseg - INFO - Iter [97300/160000]	lr: 2.351e-05, eta: 13:58:19, time: 0.870, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2197, decode.acc_seg: 90.7485, aux.loss_ce: 0.1133, aux.acc_seg: 88.7398, loss: 0.3330
2023-12-29 03:42:01,342 - mmseg - INFO - Iter [97350/160000]	lr: 2.349e-05, eta: 13:57:39, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2288, decode.acc_seg: 90.6167, aux.loss_ce: 0.1181, aux.acc_seg: 88.5381, loss: 0.3469
2023-12-29 03:42:40,932 - mmseg - INFO - Iter [97400/160000]	lr: 2.348e-05, eta: 13:56:58, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2221, decode.acc_seg: 90.8482, aux.loss_ce: 0.1142, aux.acc_seg: 88.9108, loss: 0.3363
2023-12-29 03:43:21,186 - mmseg - INFO - Iter [97450/160000]	lr: 2.346e-05, eta: 13:56:18, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2324, decode.acc_seg: 90.3036, aux.loss_ce: 0.1169, aux.acc_seg: 88.3716, loss: 0.3494
2023-12-29 03:43:59,496 - mmseg - INFO - Iter [97500/160000]	lr: 2.344e-05, eta: 13:55:37, time: 0.766, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2186, decode.acc_seg: 90.7110, aux.loss_ce: 0.1151, aux.acc_seg: 88.6105, loss: 0.3337
2023-12-29 03:44:39,574 - mmseg - INFO - Iter [97550/160000]	lr: 2.342e-05, eta: 13:54:57, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2315, decode.acc_seg: 90.1919, aux.loss_ce: 0.1189, aux.acc_seg: 88.1866, loss: 0.3503
2023-12-29 03:45:19,414 - mmseg - INFO - Iter [97600/160000]	lr: 2.340e-05, eta: 13:54:16, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2292, decode.acc_seg: 90.6676, aux.loss_ce: 0.1204, aux.acc_seg: 88.3249, loss: 0.3496
2023-12-29 03:46:01,307 - mmseg - INFO - Iter [97650/160000]	lr: 2.338e-05, eta: 13:53:37, time: 0.838, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2166, decode.acc_seg: 90.9837, aux.loss_ce: 0.1115, aux.acc_seg: 89.0728, loss: 0.3281
2023-12-29 03:46:39,672 - mmseg - INFO - Iter [97700/160000]	lr: 2.336e-05, eta: 13:52:56, time: 0.768, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2225, decode.acc_seg: 90.6795, aux.loss_ce: 0.1182, aux.acc_seg: 88.1277, loss: 0.3407
2023-12-29 03:47:18,073 - mmseg - INFO - Iter [97750/160000]	lr: 2.334e-05, eta: 13:52:15, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2303, decode.acc_seg: 90.3142, aux.loss_ce: 0.1169, aux.acc_seg: 88.4245, loss: 0.3471
2023-12-29 03:47:56,758 - mmseg - INFO - Iter [97800/160000]	lr: 2.333e-05, eta: 13:51:34, time: 0.775, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2224, decode.acc_seg: 90.6589, aux.loss_ce: 0.1151, aux.acc_seg: 88.4968, loss: 0.3375
2023-12-29 03:48:37,411 - mmseg - INFO - Iter [97850/160000]	lr: 2.331e-05, eta: 13:50:54, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2180, decode.acc_seg: 90.9217, aux.loss_ce: 0.1129, aux.acc_seg: 88.8113, loss: 0.3309
2023-12-29 03:49:16,686 - mmseg - INFO - Iter [97900/160000]	lr: 2.329e-05, eta: 13:50:14, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2280, decode.acc_seg: 90.6935, aux.loss_ce: 0.1185, aux.acc_seg: 88.5387, loss: 0.3465
2023-12-29 03:49:56,943 - mmseg - INFO - Iter [97950/160000]	lr: 2.327e-05, eta: 13:49:34, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2308, decode.acc_seg: 90.3528, aux.loss_ce: 0.1182, aux.acc_seg: 88.2195, loss: 0.3490
2023-12-29 03:50:36,364 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 03:50:36,364 - mmseg - INFO - Iter [98000/160000]	lr: 2.325e-05, eta: 13:48:53, time: 0.787, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2312, decode.acc_seg: 90.2934, aux.loss_ce: 0.1201, aux.acc_seg: 88.2343, loss: 0.3513
2023-12-29 03:51:16,660 - mmseg - INFO - Iter [98050/160000]	lr: 2.323e-05, eta: 13:48:13, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2363, decode.acc_seg: 90.0627, aux.loss_ce: 0.1218, aux.acc_seg: 87.8994, loss: 0.3581
2023-12-29 03:51:56,705 - mmseg - INFO - Iter [98100/160000]	lr: 2.321e-05, eta: 13:47:33, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2373, decode.acc_seg: 90.1689, aux.loss_ce: 0.1200, aux.acc_seg: 88.1903, loss: 0.3573
2023-12-29 03:52:36,179 - mmseg - INFO - Iter [98150/160000]	lr: 2.319e-05, eta: 13:46:52, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2344, decode.acc_seg: 90.2490, aux.loss_ce: 0.1205, aux.acc_seg: 88.2198, loss: 0.3548
2023-12-29 03:53:16,493 - mmseg - INFO - Iter [98200/160000]	lr: 2.318e-05, eta: 13:46:12, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2251, decode.acc_seg: 90.7468, aux.loss_ce: 0.1156, aux.acc_seg: 88.7336, loss: 0.3408
2023-12-29 03:53:56,175 - mmseg - INFO - Iter [98250/160000]	lr: 2.316e-05, eta: 13:45:32, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2512, decode.acc_seg: 89.5899, aux.loss_ce: 0.1268, aux.acc_seg: 87.4498, loss: 0.3780
2023-12-29 03:54:35,381 - mmseg - INFO - Iter [98300/160000]	lr: 2.314e-05, eta: 13:44:51, time: 0.784, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2298, decode.acc_seg: 90.3315, aux.loss_ce: 0.1192, aux.acc_seg: 88.1793, loss: 0.3490
2023-12-29 03:55:14,818 - mmseg - INFO - Iter [98350/160000]	lr: 2.312e-05, eta: 13:44:11, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2165, decode.acc_seg: 90.9353, aux.loss_ce: 0.1106, aux.acc_seg: 89.1721, loss: 0.3271
2023-12-29 03:55:54,038 - mmseg - INFO - Iter [98400/160000]	lr: 2.310e-05, eta: 13:43:30, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2298, decode.acc_seg: 90.5727, aux.loss_ce: 0.1208, aux.acc_seg: 88.2623, loss: 0.3506
2023-12-29 03:56:33,593 - mmseg - INFO - Iter [98450/160000]	lr: 2.308e-05, eta: 13:42:50, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2283, decode.acc_seg: 90.7223, aux.loss_ce: 0.1186, aux.acc_seg: 88.5086, loss: 0.3469
2023-12-29 03:57:10,579 - mmseg - INFO - Iter [98500/160000]	lr: 2.306e-05, eta: 13:42:08, time: 0.740, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2266, decode.acc_seg: 90.5838, aux.loss_ce: 0.1158, aux.acc_seg: 88.6992, loss: 0.3425
2023-12-29 03:57:51,236 - mmseg - INFO - Iter [98550/160000]	lr: 2.304e-05, eta: 13:41:28, time: 0.813, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2157, decode.acc_seg: 90.7700, aux.loss_ce: 0.1098, aux.acc_seg: 88.8723, loss: 0.3255
2023-12-29 03:58:32,083 - mmseg - INFO - Iter [98600/160000]	lr: 2.303e-05, eta: 13:40:48, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2222, decode.acc_seg: 90.7681, aux.loss_ce: 0.1147, aux.acc_seg: 88.6219, loss: 0.3369
2023-12-29 03:59:08,816 - mmseg - INFO - Iter [98650/160000]	lr: 2.301e-05, eta: 13:40:06, time: 0.734, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2202, decode.acc_seg: 90.7695, aux.loss_ce: 0.1157, aux.acc_seg: 88.6464, loss: 0.3359
2023-12-29 03:59:48,215 - mmseg - INFO - Iter [98700/160000]	lr: 2.299e-05, eta: 13:39:26, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2239, decode.acc_seg: 90.5889, aux.loss_ce: 0.1154, aux.acc_seg: 88.6413, loss: 0.3392
2023-12-29 04:00:27,815 - mmseg - INFO - Iter [98750/160000]	lr: 2.297e-05, eta: 13:38:45, time: 0.792, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2386, decode.acc_seg: 90.2196, aux.loss_ce: 0.1186, aux.acc_seg: 88.5557, loss: 0.3572
2023-12-29 04:01:07,351 - mmseg - INFO - Iter [98800/160000]	lr: 2.295e-05, eta: 13:38:05, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2332, decode.acc_seg: 90.3024, aux.loss_ce: 0.1206, aux.acc_seg: 88.3878, loss: 0.3538
2023-12-29 04:01:47,441 - mmseg - INFO - Iter [98850/160000]	lr: 2.293e-05, eta: 13:37:25, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2312, decode.acc_seg: 90.4880, aux.loss_ce: 0.1200, aux.acc_seg: 88.3427, loss: 0.3512
2023-12-29 04:02:25,144 - mmseg - INFO - Iter [98900/160000]	lr: 2.291e-05, eta: 13:36:43, time: 0.754, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2161, decode.acc_seg: 90.6213, aux.loss_ce: 0.1098, aux.acc_seg: 88.5149, loss: 0.3259
2023-12-29 04:03:03,394 - mmseg - INFO - Iter [98950/160000]	lr: 2.289e-05, eta: 13:36:02, time: 0.764, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2304, decode.acc_seg: 90.5294, aux.loss_ce: 0.1182, aux.acc_seg: 88.3233, loss: 0.3486
2023-12-29 04:03:41,224 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 04:03:41,225 - mmseg - INFO - Iter [99000/160000]	lr: 2.288e-05, eta: 13:35:20, time: 0.757, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2238, decode.acc_seg: 90.5977, aux.loss_ce: 0.1132, aux.acc_seg: 88.7964, loss: 0.3370
2023-12-29 04:04:21,995 - mmseg - INFO - Iter [99050/160000]	lr: 2.286e-05, eta: 13:34:41, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2341, decode.acc_seg: 90.0294, aux.loss_ce: 0.1223, aux.acc_seg: 87.8634, loss: 0.3565
2023-12-29 04:04:59,500 - mmseg - INFO - Iter [99100/160000]	lr: 2.284e-05, eta: 13:33:59, time: 0.750, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2287, decode.acc_seg: 90.5607, aux.loss_ce: 0.1173, aux.acc_seg: 88.6040, loss: 0.3460
2023-12-29 04:05:38,265 - mmseg - INFO - Iter [99150/160000]	lr: 2.282e-05, eta: 13:33:18, time: 0.776, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2152, decode.acc_seg: 91.0116, aux.loss_ce: 0.1124, aux.acc_seg: 88.8293, loss: 0.3276
2023-12-29 04:06:16,795 - mmseg - INFO - Iter [99200/160000]	lr: 2.280e-05, eta: 13:32:37, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2233, decode.acc_seg: 90.7650, aux.loss_ce: 0.1149, aux.acc_seg: 88.6309, loss: 0.3382
2023-12-29 04:06:57,003 - mmseg - INFO - Iter [99250/160000]	lr: 2.278e-05, eta: 13:31:57, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2193, decode.acc_seg: 90.9064, aux.loss_ce: 0.1134, aux.acc_seg: 88.7146, loss: 0.3327
2023-12-29 04:07:37,220 - mmseg - INFO - Iter [99300/160000]	lr: 2.276e-05, eta: 13:31:17, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2334, decode.acc_seg: 90.2677, aux.loss_ce: 0.1187, aux.acc_seg: 87.9546, loss: 0.3521
2023-12-29 04:08:17,597 - mmseg - INFO - Iter [99350/160000]	lr: 2.274e-05, eta: 13:30:37, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2262, decode.acc_seg: 90.7242, aux.loss_ce: 0.1177, aux.acc_seg: 88.3403, loss: 0.3439
2023-12-29 04:08:57,423 - mmseg - INFO - Iter [99400/160000]	lr: 2.273e-05, eta: 13:29:57, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2339, decode.acc_seg: 89.9470, aux.loss_ce: 0.1209, aux.acc_seg: 87.6025, loss: 0.3549
2023-12-29 04:09:35,356 - mmseg - INFO - Iter [99450/160000]	lr: 2.271e-05, eta: 13:29:15, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2371, decode.acc_seg: 90.2605, aux.loss_ce: 0.1210, aux.acc_seg: 88.1410, loss: 0.3581
2023-12-29 04:10:14,408 - mmseg - INFO - Iter [99500/160000]	lr: 2.269e-05, eta: 13:28:34, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.3920, aux.loss_ce: 0.1111, aux.acc_seg: 89.0369, loss: 0.3203
2023-12-29 04:10:52,961 - mmseg - INFO - Iter [99550/160000]	lr: 2.267e-05, eta: 13:27:53, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2126, decode.acc_seg: 90.9123, aux.loss_ce: 0.1091, aux.acc_seg: 89.0827, loss: 0.3217
2023-12-29 04:11:30,276 - mmseg - INFO - Iter [99600/160000]	lr: 2.265e-05, eta: 13:27:12, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2233, decode.acc_seg: 90.7906, aux.loss_ce: 0.1135, aux.acc_seg: 88.8947, loss: 0.3368
2023-12-29 04:12:09,691 - mmseg - INFO - Iter [99650/160000]	lr: 2.263e-05, eta: 13:26:31, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2357, decode.acc_seg: 90.2857, aux.loss_ce: 0.1201, aux.acc_seg: 88.1051, loss: 0.3558
2023-12-29 04:12:46,555 - mmseg - INFO - Iter [99700/160000]	lr: 2.261e-05, eta: 13:25:49, time: 0.737, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2304, decode.acc_seg: 90.6825, aux.loss_ce: 0.1202, aux.acc_seg: 88.4753, loss: 0.3506
2023-12-29 04:13:23,180 - mmseg - INFO - Iter [99750/160000]	lr: 2.259e-05, eta: 13:25:07, time: 0.732, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2234, decode.acc_seg: 90.8735, aux.loss_ce: 0.1189, aux.acc_seg: 88.3046, loss: 0.3423
2023-12-29 04:14:02,440 - mmseg - INFO - Iter [99800/160000]	lr: 2.258e-05, eta: 13:24:26, time: 0.785, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2163, decode.acc_seg: 90.8887, aux.loss_ce: 0.1119, aux.acc_seg: 88.7987, loss: 0.3282
2023-12-29 04:14:41,985 - mmseg - INFO - Iter [99850/160000]	lr: 2.256e-05, eta: 13:23:46, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2241, decode.acc_seg: 90.7346, aux.loss_ce: 0.1158, aux.acc_seg: 88.6927, loss: 0.3398
2023-12-29 04:15:20,674 - mmseg - INFO - Iter [99900/160000]	lr: 2.254e-05, eta: 13:23:05, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2226, decode.acc_seg: 90.7587, aux.loss_ce: 0.1160, aux.acc_seg: 88.5832, loss: 0.3386
2023-12-29 04:15:59,127 - mmseg - INFO - Iter [99950/160000]	lr: 2.252e-05, eta: 13:22:24, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2180, decode.acc_seg: 90.9253, aux.loss_ce: 0.1145, aux.acc_seg: 88.6669, loss: 0.3325
2023-12-29 04:16:37,440 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 04:16:37,441 - mmseg - INFO - Iter [100000/160000]	lr: 2.250e-05, eta: 13:21:43, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2093, decode.acc_seg: 91.1581, aux.loss_ce: 0.1087, aux.acc_seg: 89.1724, loss: 0.3180
2023-12-29 04:17:17,481 - mmseg - INFO - Iter [100050/160000]	lr: 2.248e-05, eta: 13:21:03, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2223, decode.acc_seg: 90.5501, aux.loss_ce: 0.1167, aux.acc_seg: 88.4018, loss: 0.3390
2023-12-29 04:17:58,040 - mmseg - INFO - Iter [100100/160000]	lr: 2.246e-05, eta: 13:20:23, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2167, decode.acc_seg: 90.9586, aux.loss_ce: 0.1110, aux.acc_seg: 88.8853, loss: 0.3277
2023-12-29 04:18:35,959 - mmseg - INFO - Iter [100150/160000]	lr: 2.244e-05, eta: 13:19:41, time: 0.758, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2167, decode.acc_seg: 90.9867, aux.loss_ce: 0.1091, aux.acc_seg: 89.3005, loss: 0.3258
2023-12-29 04:19:15,960 - mmseg - INFO - Iter [100200/160000]	lr: 2.243e-05, eta: 13:19:01, time: 0.799, data_time: 0.010, memory: 18256, decode.loss_ce: 0.2285, decode.acc_seg: 90.5205, aux.loss_ce: 0.1201, aux.acc_seg: 88.1387, loss: 0.3486
2023-12-29 04:19:56,600 - mmseg - INFO - Iter [100250/160000]	lr: 2.241e-05, eta: 13:18:22, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2142, decode.acc_seg: 90.9653, aux.loss_ce: 0.1124, aux.acc_seg: 88.6796, loss: 0.3266
2023-12-29 04:20:35,319 - mmseg - INFO - Iter [100300/160000]	lr: 2.239e-05, eta: 13:17:41, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2298, decode.acc_seg: 90.5557, aux.loss_ce: 0.1146, aux.acc_seg: 88.8958, loss: 0.3444
2023-12-29 04:21:12,624 - mmseg - INFO - Iter [100350/160000]	lr: 2.237e-05, eta: 13:16:59, time: 0.746, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2304, decode.acc_seg: 90.1693, aux.loss_ce: 0.1198, aux.acc_seg: 87.8584, loss: 0.3502
2023-12-29 04:21:50,606 - mmseg - INFO - Iter [100400/160000]	lr: 2.235e-05, eta: 13:16:18, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2264, decode.acc_seg: 90.6944, aux.loss_ce: 0.1173, aux.acc_seg: 88.4748, loss: 0.3437
2023-12-29 04:22:30,992 - mmseg - INFO - Iter [100450/160000]	lr: 2.233e-05, eta: 13:15:38, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2114, decode.acc_seg: 90.9917, aux.loss_ce: 0.1099, aux.acc_seg: 88.9387, loss: 0.3213
2023-12-29 04:23:11,186 - mmseg - INFO - Iter [100500/160000]	lr: 2.231e-05, eta: 13:14:58, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2260, decode.acc_seg: 90.6914, aux.loss_ce: 0.1178, aux.acc_seg: 88.5362, loss: 0.3438
2023-12-29 04:23:51,586 - mmseg - INFO - Iter [100550/160000]	lr: 2.229e-05, eta: 13:14:18, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2179, decode.acc_seg: 90.7543, aux.loss_ce: 0.1159, aux.acc_seg: 88.4539, loss: 0.3337
2023-12-29 04:24:32,062 - mmseg - INFO - Iter [100600/160000]	lr: 2.228e-05, eta: 13:13:38, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2223, decode.acc_seg: 90.7160, aux.loss_ce: 0.1133, aux.acc_seg: 88.9733, loss: 0.3356
2023-12-29 04:25:09,028 - mmseg - INFO - Iter [100650/160000]	lr: 2.226e-05, eta: 13:12:56, time: 0.739, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2219, decode.acc_seg: 90.7344, aux.loss_ce: 0.1117, aux.acc_seg: 88.8745, loss: 0.3336
2023-12-29 04:25:47,645 - mmseg - INFO - Iter [100700/160000]	lr: 2.224e-05, eta: 13:12:15, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2308, decode.acc_seg: 90.4153, aux.loss_ce: 0.1181, aux.acc_seg: 88.2782, loss: 0.3489
2023-12-29 04:26:25,055 - mmseg - INFO - Iter [100750/160000]	lr: 2.222e-05, eta: 13:11:33, time: 0.748, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2184, decode.acc_seg: 90.9121, aux.loss_ce: 0.1109, aux.acc_seg: 88.9842, loss: 0.3293
2023-12-29 04:27:03,359 - mmseg - INFO - Iter [100800/160000]	lr: 2.220e-05, eta: 13:10:52, time: 0.766, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2239, decode.acc_seg: 90.5853, aux.loss_ce: 0.1174, aux.acc_seg: 88.2049, loss: 0.3413
2023-12-29 04:27:42,643 - mmseg - INFO - Iter [100850/160000]	lr: 2.218e-05, eta: 13:10:12, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2250, decode.acc_seg: 90.5820, aux.loss_ce: 0.1138, aux.acc_seg: 88.9942, loss: 0.3388
2023-12-29 04:28:22,482 - mmseg - INFO - Iter [100900/160000]	lr: 2.216e-05, eta: 13:09:32, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2345, decode.acc_seg: 90.1914, aux.loss_ce: 0.1210, aux.acc_seg: 88.0407, loss: 0.3555
2023-12-29 04:29:02,194 - mmseg - INFO - Iter [100950/160000]	lr: 2.214e-05, eta: 13:08:51, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2178, decode.acc_seg: 90.8575, aux.loss_ce: 0.1124, aux.acc_seg: 88.6701, loss: 0.3302
2023-12-29 04:29:41,048 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 04:29:41,049 - mmseg - INFO - Iter [101000/160000]	lr: 2.213e-05, eta: 13:08:10, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2162, decode.acc_seg: 90.7720, aux.loss_ce: 0.1137, aux.acc_seg: 88.4781, loss: 0.3299
2023-12-29 04:30:21,144 - mmseg - INFO - Iter [101050/160000]	lr: 2.211e-05, eta: 13:07:30, time: 0.802, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2220, decode.acc_seg: 90.6982, aux.loss_ce: 0.1141, aux.acc_seg: 88.6133, loss: 0.3362
2023-12-29 04:31:02,183 - mmseg - INFO - Iter [101100/160000]	lr: 2.209e-05, eta: 13:06:51, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2333, decode.acc_seg: 90.3049, aux.loss_ce: 0.1185, aux.acc_seg: 88.4644, loss: 0.3519
2023-12-29 04:31:40,026 - mmseg - INFO - Iter [101150/160000]	lr: 2.207e-05, eta: 13:06:10, time: 0.757, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2157, decode.acc_seg: 91.0985, aux.loss_ce: 0.1092, aux.acc_seg: 89.1968, loss: 0.3248
2023-12-29 04:32:18,711 - mmseg - INFO - Iter [101200/160000]	lr: 2.205e-05, eta: 13:05:29, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2105, decode.acc_seg: 91.0763, aux.loss_ce: 0.1077, aux.acc_seg: 88.9546, loss: 0.3182
2023-12-29 04:32:56,949 - mmseg - INFO - Iter [101250/160000]	lr: 2.203e-05, eta: 13:04:47, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2176, decode.acc_seg: 90.9604, aux.loss_ce: 0.1128, aux.acc_seg: 88.8123, loss: 0.3304
2023-12-29 04:33:36,500 - mmseg - INFO - Iter [101300/160000]	lr: 2.201e-05, eta: 13:04:07, time: 0.790, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2120, decode.acc_seg: 91.2400, aux.loss_ce: 0.1119, aux.acc_seg: 89.0683, loss: 0.3239
2023-12-29 04:34:18,005 - mmseg - INFO - Iter [101350/160000]	lr: 2.199e-05, eta: 13:03:28, time: 0.831, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2236, decode.acc_seg: 90.6518, aux.loss_ce: 0.1167, aux.acc_seg: 88.4724, loss: 0.3403
2023-12-29 04:34:59,396 - mmseg - INFO - Iter [101400/160000]	lr: 2.198e-05, eta: 13:02:49, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2229, decode.acc_seg: 90.6844, aux.loss_ce: 0.1149, aux.acc_seg: 88.7564, loss: 0.3378
2023-12-29 04:35:40,611 - mmseg - INFO - Iter [101450/160000]	lr: 2.196e-05, eta: 13:02:09, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2166, decode.acc_seg: 90.6116, aux.loss_ce: 0.1116, aux.acc_seg: 88.6658, loss: 0.3281
2023-12-29 04:36:20,606 - mmseg - INFO - Iter [101500/160000]	lr: 2.194e-05, eta: 13:01:29, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2359, decode.acc_seg: 90.2513, aux.loss_ce: 0.1205, aux.acc_seg: 88.0494, loss: 0.3564
2023-12-29 04:36:59,700 - mmseg - INFO - Iter [101550/160000]	lr: 2.192e-05, eta: 13:00:48, time: 0.783, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2326, decode.acc_seg: 90.2119, aux.loss_ce: 0.1196, aux.acc_seg: 88.0835, loss: 0.3522
2023-12-29 04:37:40,477 - mmseg - INFO - Iter [101600/160000]	lr: 2.190e-05, eta: 13:00:09, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2176, decode.acc_seg: 91.2029, aux.loss_ce: 0.1135, aux.acc_seg: 89.0137, loss: 0.3311
2023-12-29 04:38:20,175 - mmseg - INFO - Iter [101650/160000]	lr: 2.188e-05, eta: 12:59:28, time: 0.795, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2219, decode.acc_seg: 91.0189, aux.loss_ce: 0.1118, aux.acc_seg: 89.0792, loss: 0.3337
2023-12-29 04:39:02,439 - mmseg - INFO - Iter [101700/160000]	lr: 2.186e-05, eta: 12:58:50, time: 0.846, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2238, decode.acc_seg: 90.7843, aux.loss_ce: 0.1172, aux.acc_seg: 88.4475, loss: 0.3410
2023-12-29 04:39:42,960 - mmseg - INFO - Iter [101750/160000]	lr: 2.184e-05, eta: 12:58:10, time: 0.809, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2343, decode.acc_seg: 90.1028, aux.loss_ce: 0.1213, aux.acc_seg: 87.7266, loss: 0.3556
2023-12-29 04:40:23,605 - mmseg - INFO - Iter [101800/160000]	lr: 2.183e-05, eta: 12:57:30, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2090, decode.acc_seg: 91.2189, aux.loss_ce: 0.1081, aux.acc_seg: 89.2274, loss: 0.3171
2023-12-29 04:41:04,705 - mmseg - INFO - Iter [101850/160000]	lr: 2.181e-05, eta: 12:56:50, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2261, decode.acc_seg: 90.4598, aux.loss_ce: 0.1187, aux.acc_seg: 88.3824, loss: 0.3447
2023-12-29 04:41:45,230 - mmseg - INFO - Iter [101900/160000]	lr: 2.179e-05, eta: 12:56:11, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2203, decode.acc_seg: 90.8502, aux.loss_ce: 0.1190, aux.acc_seg: 88.5250, loss: 0.3393
2023-12-29 04:42:24,152 - mmseg - INFO - Iter [101950/160000]	lr: 2.177e-05, eta: 12:55:30, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2229, decode.acc_seg: 90.8399, aux.loss_ce: 0.1161, aux.acc_seg: 88.6034, loss: 0.3389
2023-12-29 04:43:04,796 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 04:43:04,796 - mmseg - INFO - Iter [102000/160000]	lr: 2.175e-05, eta: 12:54:50, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2100, decode.acc_seg: 91.1371, aux.loss_ce: 0.1097, aux.acc_seg: 88.8315, loss: 0.3198
2023-12-29 04:43:46,013 - mmseg - INFO - Iter [102050/160000]	lr: 2.173e-05, eta: 12:54:11, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2115, decode.acc_seg: 91.1679, aux.loss_ce: 0.1074, aux.acc_seg: 89.1628, loss: 0.3189
2023-12-29 04:44:24,916 - mmseg - INFO - Iter [102100/160000]	lr: 2.171e-05, eta: 12:53:30, time: 0.779, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2161, decode.acc_seg: 91.0377, aux.loss_ce: 0.1124, aux.acc_seg: 88.8115, loss: 0.3284
2023-12-29 04:45:05,361 - mmseg - INFO - Iter [102150/160000]	lr: 2.169e-05, eta: 12:52:50, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2238, decode.acc_seg: 90.5790, aux.loss_ce: 0.1167, aux.acc_seg: 88.2706, loss: 0.3405
2023-12-29 04:45:46,130 - mmseg - INFO - Iter [102200/160000]	lr: 2.168e-05, eta: 12:52:10, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2335, decode.acc_seg: 90.1819, aux.loss_ce: 0.1196, aux.acc_seg: 88.1014, loss: 0.3531
2023-12-29 04:46:27,345 - mmseg - INFO - Iter [102250/160000]	lr: 2.166e-05, eta: 12:51:31, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2163, decode.acc_seg: 91.1238, aux.loss_ce: 0.1121, aux.acc_seg: 89.0622, loss: 0.3284
2023-12-29 04:47:06,667 - mmseg - INFO - Iter [102300/160000]	lr: 2.164e-05, eta: 12:50:51, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2219, decode.acc_seg: 90.6731, aux.loss_ce: 0.1129, aux.acc_seg: 88.9093, loss: 0.3348
2023-12-29 04:47:49,015 - mmseg - INFO - Iter [102350/160000]	lr: 2.162e-05, eta: 12:50:12, time: 0.847, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2192, decode.acc_seg: 90.6537, aux.loss_ce: 0.1154, aux.acc_seg: 88.5432, loss: 0.3346
2023-12-29 04:48:30,798 - mmseg - INFO - Iter [102400/160000]	lr: 2.160e-05, eta: 12:49:33, time: 0.834, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2063, decode.acc_seg: 91.4477, aux.loss_ce: 0.1063, aux.acc_seg: 89.4370, loss: 0.3126
2023-12-29 04:49:09,336 - mmseg - INFO - Iter [102450/160000]	lr: 2.158e-05, eta: 12:48:52, time: 0.771, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2173, decode.acc_seg: 91.0038, aux.loss_ce: 0.1118, aux.acc_seg: 89.1598, loss: 0.3290
2023-12-29 04:49:50,272 - mmseg - INFO - Iter [102500/160000]	lr: 2.156e-05, eta: 12:48:12, time: 0.819, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2208, decode.acc_seg: 90.7786, aux.loss_ce: 0.1150, aux.acc_seg: 88.8039, loss: 0.3357
2023-12-29 04:50:29,942 - mmseg - INFO - Iter [102550/160000]	lr: 2.154e-05, eta: 12:47:32, time: 0.793, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2312, decode.acc_seg: 90.4305, aux.loss_ce: 0.1188, aux.acc_seg: 88.2064, loss: 0.3500
2023-12-29 04:51:09,124 - mmseg - INFO - Iter [102600/160000]	lr: 2.153e-05, eta: 12:46:51, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2249, decode.acc_seg: 90.6786, aux.loss_ce: 0.1154, aux.acc_seg: 88.5439, loss: 0.3403
2023-12-29 04:51:47,842 - mmseg - INFO - Iter [102650/160000]	lr: 2.151e-05, eta: 12:46:10, time: 0.773, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2257, decode.acc_seg: 90.6931, aux.loss_ce: 0.1172, aux.acc_seg: 88.4598, loss: 0.3429
2023-12-29 04:52:27,762 - mmseg - INFO - Iter [102700/160000]	lr: 2.149e-05, eta: 12:45:30, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2100, decode.acc_seg: 91.1174, aux.loss_ce: 0.1055, aux.acc_seg: 89.4044, loss: 0.3155
2023-12-29 04:53:07,807 - mmseg - INFO - Iter [102750/160000]	lr: 2.147e-05, eta: 12:44:50, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2060, decode.acc_seg: 91.4967, aux.loss_ce: 0.1061, aux.acc_seg: 89.5535, loss: 0.3121
2023-12-29 04:53:45,350 - mmseg - INFO - Iter [102800/160000]	lr: 2.145e-05, eta: 12:44:09, time: 0.751, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2294, decode.acc_seg: 90.3568, aux.loss_ce: 0.1182, aux.acc_seg: 88.2922, loss: 0.3476
2023-12-29 04:54:23,559 - mmseg - INFO - Iter [102850/160000]	lr: 2.143e-05, eta: 12:43:27, time: 0.764, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2260, decode.acc_seg: 90.6688, aux.loss_ce: 0.1177, aux.acc_seg: 88.2881, loss: 0.3437
2023-12-29 04:55:03,488 - mmseg - INFO - Iter [102900/160000]	lr: 2.141e-05, eta: 12:42:47, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2139, decode.acc_seg: 90.8627, aux.loss_ce: 0.1097, aux.acc_seg: 88.9080, loss: 0.3236
2023-12-29 04:55:43,546 - mmseg - INFO - Iter [102950/160000]	lr: 2.139e-05, eta: 12:42:07, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2207, decode.acc_seg: 90.5798, aux.loss_ce: 0.1134, aux.acc_seg: 88.5737, loss: 0.3341
2023-12-29 04:56:24,471 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 04:56:24,472 - mmseg - INFO - Iter [103000/160000]	lr: 2.138e-05, eta: 12:41:28, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2253, decode.acc_seg: 90.5811, aux.loss_ce: 0.1160, aux.acc_seg: 88.4613, loss: 0.3413
2023-12-29 04:57:05,220 - mmseg - INFO - Iter [103050/160000]	lr: 2.136e-05, eta: 12:40:48, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2234, decode.acc_seg: 90.5067, aux.loss_ce: 0.1168, aux.acc_seg: 88.1959, loss: 0.3401
2023-12-29 04:57:44,848 - mmseg - INFO - Iter [103100/160000]	lr: 2.134e-05, eta: 12:40:08, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2232, decode.acc_seg: 90.8660, aux.loss_ce: 0.1119, aux.acc_seg: 88.8856, loss: 0.3352
2023-12-29 04:58:23,826 - mmseg - INFO - Iter [103150/160000]	lr: 2.132e-05, eta: 12:39:27, time: 0.780, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2188, decode.acc_seg: 90.7998, aux.loss_ce: 0.1116, aux.acc_seg: 88.8858, loss: 0.3305
2023-12-29 04:59:02,902 - mmseg - INFO - Iter [103200/160000]	lr: 2.130e-05, eta: 12:38:46, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2203, decode.acc_seg: 90.8830, aux.loss_ce: 0.1159, aux.acc_seg: 88.6600, loss: 0.3362
2023-12-29 04:59:42,428 - mmseg - INFO - Iter [103250/160000]	lr: 2.128e-05, eta: 12:38:06, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2149, decode.acc_seg: 90.9301, aux.loss_ce: 0.1099, aux.acc_seg: 89.0632, loss: 0.3248
2023-12-29 05:00:22,406 - mmseg - INFO - Iter [103300/160000]	lr: 2.126e-05, eta: 12:37:26, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2192, decode.acc_seg: 90.8745, aux.loss_ce: 0.1136, aux.acc_seg: 88.7140, loss: 0.3328
2023-12-29 05:01:00,919 - mmseg - INFO - Iter [103350/160000]	lr: 2.124e-05, eta: 12:36:45, time: 0.770, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2179, decode.acc_seg: 90.9225, aux.loss_ce: 0.1111, aux.acc_seg: 89.1264, loss: 0.3291
2023-12-29 05:01:40,110 - mmseg - INFO - Iter [103400/160000]	lr: 2.123e-05, eta: 12:36:04, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2270, decode.acc_seg: 90.6339, aux.loss_ce: 0.1143, aux.acc_seg: 88.8458, loss: 0.3413
2023-12-29 05:02:20,643 - mmseg - INFO - Iter [103450/160000]	lr: 2.121e-05, eta: 12:35:24, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2183, decode.acc_seg: 90.9169, aux.loss_ce: 0.1112, aux.acc_seg: 88.9782, loss: 0.3295
2023-12-29 05:02:59,119 - mmseg - INFO - Iter [103500/160000]	lr: 2.119e-05, eta: 12:34:43, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2209, decode.acc_seg: 90.7106, aux.loss_ce: 0.1165, aux.acc_seg: 88.1982, loss: 0.3374
2023-12-29 05:03:37,188 - mmseg - INFO - Iter [103550/160000]	lr: 2.117e-05, eta: 12:34:02, time: 0.761, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2146, decode.acc_seg: 91.0784, aux.loss_ce: 0.1117, aux.acc_seg: 89.1265, loss: 0.3263
2023-12-29 05:04:17,129 - mmseg - INFO - Iter [103600/160000]	lr: 2.115e-05, eta: 12:33:22, time: 0.798, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2122, decode.acc_seg: 91.0286, aux.loss_ce: 0.1086, aux.acc_seg: 89.0563, loss: 0.3209
2023-12-29 05:04:56,765 - mmseg - INFO - Iter [103650/160000]	lr: 2.113e-05, eta: 12:32:42, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2140, decode.acc_seg: 90.8575, aux.loss_ce: 0.1121, aux.acc_seg: 88.6099, loss: 0.3261
2023-12-29 05:05:34,827 - mmseg - INFO - Iter [103700/160000]	lr: 2.111e-05, eta: 12:32:01, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2318, decode.acc_seg: 90.3646, aux.loss_ce: 0.1218, aux.acc_seg: 88.0558, loss: 0.3536
2023-12-29 05:06:14,825 - mmseg - INFO - Iter [103750/160000]	lr: 2.109e-05, eta: 12:31:21, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2104, decode.acc_seg: 91.0234, aux.loss_ce: 0.1077, aux.acc_seg: 89.1159, loss: 0.3181
2023-12-29 05:06:54,824 - mmseg - INFO - Iter [103800/160000]	lr: 2.108e-05, eta: 12:30:40, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2151, decode.acc_seg: 90.8216, aux.loss_ce: 0.1119, aux.acc_seg: 88.7327, loss: 0.3271
2023-12-29 05:07:34,520 - mmseg - INFO - Iter [103850/160000]	lr: 2.106e-05, eta: 12:30:00, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2201, decode.acc_seg: 90.8462, aux.loss_ce: 0.1146, aux.acc_seg: 88.6600, loss: 0.3347
2023-12-29 05:08:14,500 - mmseg - INFO - Iter [103900/160000]	lr: 2.104e-05, eta: 12:29:20, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2258, decode.acc_seg: 90.8002, aux.loss_ce: 0.1182, aux.acc_seg: 88.4984, loss: 0.3440
2023-12-29 05:08:55,200 - mmseg - INFO - Iter [103950/160000]	lr: 2.102e-05, eta: 12:28:40, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2230, decode.acc_seg: 90.8104, aux.loss_ce: 0.1154, aux.acc_seg: 88.6977, loss: 0.3384
2023-12-29 05:09:35,072 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 05:09:35,072 - mmseg - INFO - Iter [104000/160000]	lr: 2.100e-05, eta: 12:28:00, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2111, decode.acc_seg: 91.1389, aux.loss_ce: 0.1088, aux.acc_seg: 89.2591, loss: 0.3199
2023-12-29 05:10:16,309 - mmseg - INFO - Iter [104050/160000]	lr: 2.098e-05, eta: 12:27:21, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2196, decode.acc_seg: 90.8701, aux.loss_ce: 0.1149, aux.acc_seg: 88.9813, loss: 0.3345
2023-12-29 05:10:56,393 - mmseg - INFO - Iter [104100/160000]	lr: 2.096e-05, eta: 12:26:41, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2334, decode.acc_seg: 90.3158, aux.loss_ce: 0.1193, aux.acc_seg: 88.2472, loss: 0.3527
2023-12-29 05:11:35,656 - mmseg - INFO - Iter [104150/160000]	lr: 2.094e-05, eta: 12:26:00, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2182, decode.acc_seg: 90.9183, aux.loss_ce: 0.1140, aux.acc_seg: 88.7487, loss: 0.3322
2023-12-29 05:12:15,370 - mmseg - INFO - Iter [104200/160000]	lr: 2.093e-05, eta: 12:25:20, time: 0.795, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2291, decode.acc_seg: 90.5696, aux.loss_ce: 0.1203, aux.acc_seg: 88.3176, loss: 0.3494
2023-12-29 05:12:54,946 - mmseg - INFO - Iter [104250/160000]	lr: 2.091e-05, eta: 12:24:40, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2168, decode.acc_seg: 90.7969, aux.loss_ce: 0.1117, aux.acc_seg: 88.8182, loss: 0.3284
2023-12-29 05:13:33,922 - mmseg - INFO - Iter [104300/160000]	lr: 2.089e-05, eta: 12:23:59, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2081, decode.acc_seg: 91.1987, aux.loss_ce: 0.1078, aux.acc_seg: 89.0616, loss: 0.3159
2023-12-29 05:14:12,166 - mmseg - INFO - Iter [104350/160000]	lr: 2.087e-05, eta: 12:23:18, time: 0.765, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2085, decode.acc_seg: 91.2026, aux.loss_ce: 0.1101, aux.acc_seg: 88.9250, loss: 0.3186
2023-12-29 05:14:50,684 - mmseg - INFO - Iter [104400/160000]	lr: 2.085e-05, eta: 12:22:37, time: 0.769, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2169, decode.acc_seg: 90.6600, aux.loss_ce: 0.1108, aux.acc_seg: 88.6375, loss: 0.3277
2023-12-29 05:15:31,825 - mmseg - INFO - Iter [104450/160000]	lr: 2.083e-05, eta: 12:21:57, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2195, decode.acc_seg: 90.6783, aux.loss_ce: 0.1122, aux.acc_seg: 88.6864, loss: 0.3317
2023-12-29 05:16:13,041 - mmseg - INFO - Iter [104500/160000]	lr: 2.081e-05, eta: 12:21:18, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2132, decode.acc_seg: 90.9581, aux.loss_ce: 0.1095, aux.acc_seg: 88.9384, loss: 0.3227
2023-12-29 05:16:51,714 - mmseg - INFO - Iter [104550/160000]	lr: 2.079e-05, eta: 12:20:37, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2182, decode.acc_seg: 90.9079, aux.loss_ce: 0.1101, aux.acc_seg: 89.1849, loss: 0.3283
2023-12-29 05:17:31,462 - mmseg - INFO - Iter [104600/160000]	lr: 2.078e-05, eta: 12:19:57, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2173, decode.acc_seg: 90.7806, aux.loss_ce: 0.1116, aux.acc_seg: 88.7597, loss: 0.3289
2023-12-29 05:18:12,211 - mmseg - INFO - Iter [104650/160000]	lr: 2.076e-05, eta: 12:19:17, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2183, decode.acc_seg: 90.7775, aux.loss_ce: 0.1134, aux.acc_seg: 88.7729, loss: 0.3317
2023-12-29 05:18:53,022 - mmseg - INFO - Iter [104700/160000]	lr: 2.074e-05, eta: 12:18:38, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2261, decode.acc_seg: 90.4897, aux.loss_ce: 0.1137, aux.acc_seg: 88.6228, loss: 0.3398
2023-12-29 05:19:34,123 - mmseg - INFO - Iter [104750/160000]	lr: 2.072e-05, eta: 12:17:58, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2053, decode.acc_seg: 91.4605, aux.loss_ce: 0.1053, aux.acc_seg: 89.5818, loss: 0.3106
2023-12-29 05:20:15,194 - mmseg - INFO - Iter [104800/160000]	lr: 2.070e-05, eta: 12:17:18, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2155, decode.acc_seg: 91.1454, aux.loss_ce: 0.1134, aux.acc_seg: 89.0274, loss: 0.3289
2023-12-29 05:20:57,474 - mmseg - INFO - Iter [104850/160000]	lr: 2.068e-05, eta: 12:16:40, time: 0.845, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2215, decode.acc_seg: 91.0349, aux.loss_ce: 0.1147, aux.acc_seg: 88.9128, loss: 0.3363
2023-12-29 05:21:38,095 - mmseg - INFO - Iter [104900/160000]	lr: 2.066e-05, eta: 12:16:00, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2101, decode.acc_seg: 90.9016, aux.loss_ce: 0.1109, aux.acc_seg: 88.7468, loss: 0.3210
2023-12-29 05:22:17,454 - mmseg - INFO - Iter [104950/160000]	lr: 2.064e-05, eta: 12:15:19, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2238, decode.acc_seg: 90.7732, aux.loss_ce: 0.1152, aux.acc_seg: 88.5710, loss: 0.3389
2023-12-29 05:22:59,095 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 05:22:59,095 - mmseg - INFO - Iter [105000/160000]	lr: 2.063e-05, eta: 12:14:40, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2175, decode.acc_seg: 91.0074, aux.loss_ce: 0.1151, aux.acc_seg: 88.8478, loss: 0.3325
2023-12-29 05:23:41,372 - mmseg - INFO - Iter [105050/160000]	lr: 2.061e-05, eta: 12:14:01, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2159, decode.acc_seg: 90.8759, aux.loss_ce: 0.1123, aux.acc_seg: 88.8215, loss: 0.3282
2023-12-29 05:24:22,527 - mmseg - INFO - Iter [105100/160000]	lr: 2.059e-05, eta: 12:13:22, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2117, decode.acc_seg: 91.2274, aux.loss_ce: 0.1093, aux.acc_seg: 89.2527, loss: 0.3210
2023-12-29 05:25:01,890 - mmseg - INFO - Iter [105150/160000]	lr: 2.057e-05, eta: 12:12:41, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2071, decode.acc_seg: 91.3914, aux.loss_ce: 0.1093, aux.acc_seg: 89.1103, loss: 0.3164
2023-12-29 05:25:42,565 - mmseg - INFO - Iter [105200/160000]	lr: 2.055e-05, eta: 12:12:01, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2105, decode.acc_seg: 91.1949, aux.loss_ce: 0.1075, aux.acc_seg: 89.2085, loss: 0.3180
2023-12-29 05:26:23,576 - mmseg - INFO - Iter [105250/160000]	lr: 2.053e-05, eta: 12:11:22, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2202, decode.acc_seg: 90.8843, aux.loss_ce: 0.1131, aux.acc_seg: 88.8653, loss: 0.3334
2023-12-29 05:27:04,573 - mmseg - INFO - Iter [105300/160000]	lr: 2.051e-05, eta: 12:10:42, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2021, decode.acc_seg: 91.4576, aux.loss_ce: 0.1066, aux.acc_seg: 89.3381, loss: 0.3088
2023-12-29 05:27:43,468 - mmseg - INFO - Iter [105350/160000]	lr: 2.049e-05, eta: 12:10:02, time: 0.779, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2130, decode.acc_seg: 91.1283, aux.loss_ce: 0.1089, aux.acc_seg: 88.9705, loss: 0.3219
2023-12-29 05:28:22,301 - mmseg - INFO - Iter [105400/160000]	lr: 2.048e-05, eta: 12:09:21, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2096, decode.acc_seg: 91.1974, aux.loss_ce: 0.1096, aux.acc_seg: 89.0261, loss: 0.3192
2023-12-29 05:29:02,229 - mmseg - INFO - Iter [105450/160000]	lr: 2.046e-05, eta: 12:08:41, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2273, decode.acc_seg: 90.6299, aux.loss_ce: 0.1177, aux.acc_seg: 88.4252, loss: 0.3450
2023-12-29 05:29:43,410 - mmseg - INFO - Iter [105500/160000]	lr: 2.044e-05, eta: 12:08:01, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2144, decode.acc_seg: 91.1251, aux.loss_ce: 0.1101, aux.acc_seg: 89.0948, loss: 0.3246
2023-12-29 05:30:22,807 - mmseg - INFO - Iter [105550/160000]	lr: 2.042e-05, eta: 12:07:21, time: 0.789, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2193, decode.acc_seg: 91.0481, aux.loss_ce: 0.1116, aux.acc_seg: 88.9616, loss: 0.3309
2023-12-29 05:31:03,863 - mmseg - INFO - Iter [105600/160000]	lr: 2.040e-05, eta: 12:06:41, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2159, decode.acc_seg: 90.8636, aux.loss_ce: 0.1094, aux.acc_seg: 88.9753, loss: 0.3253
2023-12-29 05:31:43,721 - mmseg - INFO - Iter [105650/160000]	lr: 2.038e-05, eta: 12:06:01, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2122, decode.acc_seg: 90.8587, aux.loss_ce: 0.1104, aux.acc_seg: 88.7461, loss: 0.3226
2023-12-29 05:32:23,083 - mmseg - INFO - Iter [105700/160000]	lr: 2.036e-05, eta: 12:05:21, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2211, decode.acc_seg: 90.6221, aux.loss_ce: 0.1132, aux.acc_seg: 88.4996, loss: 0.3343
2023-12-29 05:33:01,377 - mmseg - INFO - Iter [105750/160000]	lr: 2.034e-05, eta: 12:04:40, time: 0.766, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2192, decode.acc_seg: 90.8636, aux.loss_ce: 0.1133, aux.acc_seg: 88.6920, loss: 0.3325
2023-12-29 05:33:42,539 - mmseg - INFO - Iter [105800/160000]	lr: 2.033e-05, eta: 12:04:00, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2114, decode.acc_seg: 91.1344, aux.loss_ce: 0.1081, aux.acc_seg: 89.0560, loss: 0.3195
2023-12-29 05:34:23,683 - mmseg - INFO - Iter [105850/160000]	lr: 2.031e-05, eta: 12:03:20, time: 0.823, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2084, decode.acc_seg: 91.0579, aux.loss_ce: 0.1097, aux.acc_seg: 88.9419, loss: 0.3181
2023-12-29 05:35:04,339 - mmseg - INFO - Iter [105900/160000]	lr: 2.029e-05, eta: 12:02:41, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2109, decode.acc_seg: 91.1699, aux.loss_ce: 0.1106, aux.acc_seg: 88.9332, loss: 0.3215
2023-12-29 05:35:43,495 - mmseg - INFO - Iter [105950/160000]	lr: 2.027e-05, eta: 12:02:00, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2044, decode.acc_seg: 91.3808, aux.loss_ce: 0.1063, aux.acc_seg: 89.3009, loss: 0.3107
2023-12-29 05:36:22,597 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 05:36:22,598 - mmseg - INFO - Iter [106000/160000]	lr: 2.025e-05, eta: 12:01:20, time: 0.782, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2242, decode.acc_seg: 90.3932, aux.loss_ce: 0.1161, aux.acc_seg: 88.1575, loss: 0.3402
2023-12-29 05:37:03,145 - mmseg - INFO - Iter [106050/160000]	lr: 2.023e-05, eta: 12:00:40, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2212, decode.acc_seg: 90.9035, aux.loss_ce: 0.1161, aux.acc_seg: 88.6783, loss: 0.3373
2023-12-29 05:37:45,810 - mmseg - INFO - Iter [106100/160000]	lr: 2.021e-05, eta: 12:00:01, time: 0.854, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2235, decode.acc_seg: 90.6436, aux.loss_ce: 0.1152, aux.acc_seg: 88.5604, loss: 0.3388
2023-12-29 05:38:26,285 - mmseg - INFO - Iter [106150/160000]	lr: 2.019e-05, eta: 11:59:21, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2293, decode.acc_seg: 90.3441, aux.loss_ce: 0.1200, aux.acc_seg: 87.9267, loss: 0.3493
2023-12-29 05:39:06,375 - mmseg - INFO - Iter [106200/160000]	lr: 2.018e-05, eta: 11:58:41, time: 0.803, data_time: 0.015, memory: 18256, decode.loss_ce: 0.2343, decode.acc_seg: 90.4923, aux.loss_ce: 0.1202, aux.acc_seg: 88.3939, loss: 0.3545
2023-12-29 05:39:47,705 - mmseg - INFO - Iter [106250/160000]	lr: 2.016e-05, eta: 11:58:02, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2139, decode.acc_seg: 91.1878, aux.loss_ce: 0.1084, aux.acc_seg: 89.0943, loss: 0.3223
2023-12-29 05:40:28,489 - mmseg - INFO - Iter [106300/160000]	lr: 2.014e-05, eta: 11:57:22, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2284, decode.acc_seg: 90.5809, aux.loss_ce: 0.1165, aux.acc_seg: 88.5429, loss: 0.3448
2023-12-29 05:41:08,448 - mmseg - INFO - Iter [106350/160000]	lr: 2.012e-05, eta: 11:56:42, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.5269, aux.loss_ce: 0.1091, aux.acc_seg: 89.1839, loss: 0.3118
2023-12-29 05:41:49,813 - mmseg - INFO - Iter [106400/160000]	lr: 2.010e-05, eta: 11:56:02, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2083, decode.acc_seg: 91.2338, aux.loss_ce: 0.1100, aux.acc_seg: 89.0730, loss: 0.3182
2023-12-29 05:42:31,143 - mmseg - INFO - Iter [106450/160000]	lr: 2.008e-05, eta: 11:55:23, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.0379, aux.loss_ce: 0.1120, aux.acc_seg: 88.7101, loss: 0.3212
2023-12-29 05:43:12,485 - mmseg - INFO - Iter [106500/160000]	lr: 2.006e-05, eta: 11:54:43, time: 0.828, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2287, decode.acc_seg: 90.6998, aux.loss_ce: 0.1189, aux.acc_seg: 88.4021, loss: 0.3476
2023-12-29 05:43:53,259 - mmseg - INFO - Iter [106550/160000]	lr: 2.004e-05, eta: 11:54:04, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2177, decode.acc_seg: 91.1505, aux.loss_ce: 0.1111, aux.acc_seg: 89.1479, loss: 0.3288
2023-12-29 05:44:32,822 - mmseg - INFO - Iter [106600/160000]	lr: 2.003e-05, eta: 11:53:23, time: 0.791, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2139, decode.acc_seg: 90.8274, aux.loss_ce: 0.1104, aux.acc_seg: 88.6988, loss: 0.3243
2023-12-29 05:45:13,838 - mmseg - INFO - Iter [106650/160000]	lr: 2.001e-05, eta: 11:52:44, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2001, decode.acc_seg: 91.5748, aux.loss_ce: 0.1049, aux.acc_seg: 89.4614, loss: 0.3050
2023-12-29 05:45:54,505 - mmseg - INFO - Iter [106700/160000]	lr: 1.999e-05, eta: 11:52:04, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2069, decode.acc_seg: 91.3494, aux.loss_ce: 0.1075, aux.acc_seg: 89.1338, loss: 0.3143
2023-12-29 05:46:36,265 - mmseg - INFO - Iter [106750/160000]	lr: 1.997e-05, eta: 11:51:25, time: 0.834, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2059, decode.acc_seg: 91.4108, aux.loss_ce: 0.1090, aux.acc_seg: 89.3695, loss: 0.3149
2023-12-29 05:47:18,508 - mmseg - INFO - Iter [106800/160000]	lr: 1.995e-05, eta: 11:50:46, time: 0.845, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2226, decode.acc_seg: 90.5242, aux.loss_ce: 0.1150, aux.acc_seg: 88.4549, loss: 0.3376
2023-12-29 05:47:58,419 - mmseg - INFO - Iter [106850/160000]	lr: 1.993e-05, eta: 11:50:06, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2035, decode.acc_seg: 91.2357, aux.loss_ce: 0.1083, aux.acc_seg: 89.3143, loss: 0.3118
2023-12-29 05:48:39,555 - mmseg - INFO - Iter [106900/160000]	lr: 1.991e-05, eta: 11:49:26, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2198, decode.acc_seg: 91.0032, aux.loss_ce: 0.1128, aux.acc_seg: 89.0438, loss: 0.3326
2023-12-29 05:49:20,891 - mmseg - INFO - Iter [106950/160000]	lr: 1.989e-05, eta: 11:48:47, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2170, decode.acc_seg: 91.0205, aux.loss_ce: 0.1117, aux.acc_seg: 89.0248, loss: 0.3287
2023-12-29 05:50:02,072 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 05:50:02,073 - mmseg - INFO - Iter [107000/160000]	lr: 1.988e-05, eta: 11:48:07, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1968, decode.acc_seg: 91.5560, aux.loss_ce: 0.1033, aux.acc_seg: 89.5166, loss: 0.3000
2023-12-29 05:50:43,364 - mmseg - INFO - Iter [107050/160000]	lr: 1.986e-05, eta: 11:47:28, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2049, decode.acc_seg: 91.5446, aux.loss_ce: 0.1061, aux.acc_seg: 89.6530, loss: 0.3110
2023-12-29 05:51:24,824 - mmseg - INFO - Iter [107100/160000]	lr: 1.984e-05, eta: 11:46:48, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2159, decode.acc_seg: 91.0733, aux.loss_ce: 0.1108, aux.acc_seg: 88.9652, loss: 0.3267
2023-12-29 05:52:05,121 - mmseg - INFO - Iter [107150/160000]	lr: 1.982e-05, eta: 11:46:08, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2129, decode.acc_seg: 90.9189, aux.loss_ce: 0.1128, aux.acc_seg: 88.8936, loss: 0.3257
2023-12-29 05:52:45,086 - mmseg - INFO - Iter [107200/160000]	lr: 1.980e-05, eta: 11:45:28, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2142, decode.acc_seg: 90.8114, aux.loss_ce: 0.1105, aux.acc_seg: 88.8849, loss: 0.3247
2023-12-29 05:53:26,666 - mmseg - INFO - Iter [107250/160000]	lr: 1.978e-05, eta: 11:44:49, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2139, decode.acc_seg: 91.0674, aux.loss_ce: 0.1106, aux.acc_seg: 89.0337, loss: 0.3245
2023-12-29 05:54:08,416 - mmseg - INFO - Iter [107300/160000]	lr: 1.976e-05, eta: 11:44:09, time: 0.835, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2164, decode.acc_seg: 91.0132, aux.loss_ce: 0.1147, aux.acc_seg: 88.7710, loss: 0.3311
2023-12-29 05:54:51,240 - mmseg - INFO - Iter [107350/160000]	lr: 1.974e-05, eta: 11:43:31, time: 0.856, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2243, decode.acc_seg: 90.7042, aux.loss_ce: 0.1158, aux.acc_seg: 88.6144, loss: 0.3400
2023-12-29 05:55:35,584 - mmseg - INFO - Iter [107400/160000]	lr: 1.973e-05, eta: 11:42:53, time: 0.888, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2070, decode.acc_seg: 91.1923, aux.loss_ce: 0.1066, aux.acc_seg: 89.1784, loss: 0.3136
2023-12-29 05:56:16,515 - mmseg - INFO - Iter [107450/160000]	lr: 1.971e-05, eta: 11:42:13, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2180, decode.acc_seg: 90.7991, aux.loss_ce: 0.1136, aux.acc_seg: 88.4817, loss: 0.3316
2023-12-29 05:56:57,879 - mmseg - INFO - Iter [107500/160000]	lr: 1.969e-05, eta: 11:41:34, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2022, decode.acc_seg: 91.4452, aux.loss_ce: 0.1093, aux.acc_seg: 89.0227, loss: 0.3115
2023-12-29 05:57:39,453 - mmseg - INFO - Iter [107550/160000]	lr: 1.967e-05, eta: 11:40:54, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2269, decode.acc_seg: 90.6445, aux.loss_ce: 0.1164, aux.acc_seg: 88.6951, loss: 0.3434
2023-12-29 05:58:20,119 - mmseg - INFO - Iter [107600/160000]	lr: 1.965e-05, eta: 11:40:14, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2174, decode.acc_seg: 90.9090, aux.loss_ce: 0.1144, aux.acc_seg: 88.6854, loss: 0.3318
2023-12-29 05:59:01,504 - mmseg - INFO - Iter [107650/160000]	lr: 1.963e-05, eta: 11:39:35, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2195, decode.acc_seg: 90.8450, aux.loss_ce: 0.1138, aux.acc_seg: 88.7171, loss: 0.3333
2023-12-29 05:59:42,702 - mmseg - INFO - Iter [107700/160000]	lr: 1.961e-05, eta: 11:38:55, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2231, decode.acc_seg: 90.8860, aux.loss_ce: 0.1131, aux.acc_seg: 88.8732, loss: 0.3362
2023-12-29 06:00:21,850 - mmseg - INFO - Iter [107750/160000]	lr: 1.959e-05, eta: 11:38:15, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2256, decode.acc_seg: 90.5545, aux.loss_ce: 0.1158, aux.acc_seg: 88.4369, loss: 0.3414
2023-12-29 06:01:02,568 - mmseg - INFO - Iter [107800/160000]	lr: 1.958e-05, eta: 11:37:35, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2226, decode.acc_seg: 90.6753, aux.loss_ce: 0.1136, aux.acc_seg: 88.7897, loss: 0.3362
2023-12-29 06:01:43,395 - mmseg - INFO - Iter [107850/160000]	lr: 1.956e-05, eta: 11:36:55, time: 0.818, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2257, decode.acc_seg: 90.8191, aux.loss_ce: 0.1139, aux.acc_seg: 88.9285, loss: 0.3396
2023-12-29 06:02:23,055 - mmseg - INFO - Iter [107900/160000]	lr: 1.954e-05, eta: 11:36:15, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2090, decode.acc_seg: 91.2700, aux.loss_ce: 0.1087, aux.acc_seg: 89.1203, loss: 0.3177
2023-12-29 06:03:04,118 - mmseg - INFO - Iter [107950/160000]	lr: 1.952e-05, eta: 11:35:35, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2236, decode.acc_seg: 90.8475, aux.loss_ce: 0.1142, aux.acc_seg: 88.7828, loss: 0.3378
2023-12-29 06:03:43,914 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 06:03:43,914 - mmseg - INFO - Iter [108000/160000]	lr: 1.950e-05, eta: 11:34:55, time: 0.797, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2157, decode.acc_seg: 91.1926, aux.loss_ce: 0.1114, aux.acc_seg: 89.1852, loss: 0.3271
2023-12-29 06:04:24,680 - mmseg - INFO - Iter [108050/160000]	lr: 1.948e-05, eta: 11:34:15, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2156, decode.acc_seg: 91.0122, aux.loss_ce: 0.1098, aux.acc_seg: 89.0838, loss: 0.3254
2023-12-29 06:05:03,987 - mmseg - INFO - Iter [108100/160000]	lr: 1.946e-05, eta: 11:33:35, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2157, decode.acc_seg: 91.0509, aux.loss_ce: 0.1105, aux.acc_seg: 89.1806, loss: 0.3261
2023-12-29 06:05:43,746 - mmseg - INFO - Iter [108150/160000]	lr: 1.944e-05, eta: 11:32:55, time: 0.795, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2147, decode.acc_seg: 91.0285, aux.loss_ce: 0.1099, aux.acc_seg: 89.0406, loss: 0.3246
2023-12-29 06:06:23,315 - mmseg - INFO - Iter [108200/160000]	lr: 1.943e-05, eta: 11:32:14, time: 0.790, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2051, decode.acc_seg: 91.2750, aux.loss_ce: 0.1069, aux.acc_seg: 89.3932, loss: 0.3120
2023-12-29 06:07:03,672 - mmseg - INFO - Iter [108250/160000]	lr: 1.941e-05, eta: 11:31:34, time: 0.808, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2172, decode.acc_seg: 90.9666, aux.loss_ce: 0.1123, aux.acc_seg: 88.7955, loss: 0.3295
2023-12-29 06:07:45,185 - mmseg - INFO - Iter [108300/160000]	lr: 1.939e-05, eta: 11:30:55, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2035, decode.acc_seg: 91.6073, aux.loss_ce: 0.1071, aux.acc_seg: 89.4010, loss: 0.3106
2023-12-29 06:08:26,456 - mmseg - INFO - Iter [108350/160000]	lr: 1.937e-05, eta: 11:30:15, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2201, decode.acc_seg: 90.6074, aux.loss_ce: 0.1148, aux.acc_seg: 88.6342, loss: 0.3348
2023-12-29 06:09:05,968 - mmseg - INFO - Iter [108400/160000]	lr: 1.935e-05, eta: 11:29:35, time: 0.791, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2097, decode.acc_seg: 91.3123, aux.loss_ce: 0.1079, aux.acc_seg: 89.1832, loss: 0.3176
2023-12-29 06:09:47,617 - mmseg - INFO - Iter [108450/160000]	lr: 1.933e-05, eta: 11:28:56, time: 0.833, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2094, decode.acc_seg: 90.9275, aux.loss_ce: 0.1127, aux.acc_seg: 88.4134, loss: 0.3221
2023-12-29 06:10:30,406 - mmseg - INFO - Iter [108500/160000]	lr: 1.931e-05, eta: 11:28:17, time: 0.856, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2173, decode.acc_seg: 91.1186, aux.loss_ce: 0.1120, aux.acc_seg: 88.9882, loss: 0.3293
2023-12-29 06:11:12,295 - mmseg - INFO - Iter [108550/160000]	lr: 1.929e-05, eta: 11:27:38, time: 0.836, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2119, decode.acc_seg: 91.3097, aux.loss_ce: 0.1104, aux.acc_seg: 89.2445, loss: 0.3222
2023-12-29 06:11:53,661 - mmseg - INFO - Iter [108600/160000]	lr: 1.928e-05, eta: 11:26:58, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2133, decode.acc_seg: 91.1599, aux.loss_ce: 0.1132, aux.acc_seg: 88.7487, loss: 0.3265
2023-12-29 06:12:35,388 - mmseg - INFO - Iter [108650/160000]	lr: 1.926e-05, eta: 11:26:19, time: 0.835, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2152, decode.acc_seg: 91.0258, aux.loss_ce: 0.1123, aux.acc_seg: 88.9959, loss: 0.3275
2023-12-29 06:13:16,800 - mmseg - INFO - Iter [108700/160000]	lr: 1.924e-05, eta: 11:25:39, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2146, decode.acc_seg: 90.9683, aux.loss_ce: 0.1119, aux.acc_seg: 88.7885, loss: 0.3264
2023-12-29 06:13:58,291 - mmseg - INFO - Iter [108750/160000]	lr: 1.922e-05, eta: 11:25:00, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2153, decode.acc_seg: 90.9424, aux.loss_ce: 0.1096, aux.acc_seg: 89.1234, loss: 0.3249
2023-12-29 06:14:39,406 - mmseg - INFO - Iter [108800/160000]	lr: 1.920e-05, eta: 11:24:20, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2072, decode.acc_seg: 91.3402, aux.loss_ce: 0.1122, aux.acc_seg: 88.8685, loss: 0.3193
2023-12-29 06:15:23,250 - mmseg - INFO - Iter [108850/160000]	lr: 1.918e-05, eta: 11:23:42, time: 0.877, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2166, decode.acc_seg: 90.8810, aux.loss_ce: 0.1142, aux.acc_seg: 88.4987, loss: 0.3309
2023-12-29 06:16:05,512 - mmseg - INFO - Iter [108900/160000]	lr: 1.916e-05, eta: 11:23:03, time: 0.844, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2115, decode.acc_seg: 91.1144, aux.loss_ce: 0.1123, aux.acc_seg: 88.8035, loss: 0.3238
2023-12-29 06:16:46,593 - mmseg - INFO - Iter [108950/160000]	lr: 1.914e-05, eta: 11:22:23, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2134, decode.acc_seg: 90.9066, aux.loss_ce: 0.1090, aux.acc_seg: 89.1637, loss: 0.3224
2023-12-29 06:17:26,947 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 06:17:26,947 - mmseg - INFO - Iter [109000/160000]	lr: 1.913e-05, eta: 11:21:43, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2131, decode.acc_seg: 91.2123, aux.loss_ce: 0.1121, aux.acc_seg: 88.8765, loss: 0.3252
2023-12-29 06:18:09,173 - mmseg - INFO - Iter [109050/160000]	lr: 1.911e-05, eta: 11:21:04, time: 0.845, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2156, decode.acc_seg: 91.0294, aux.loss_ce: 0.1124, aux.acc_seg: 88.8981, loss: 0.3279
2023-12-29 06:18:49,763 - mmseg - INFO - Iter [109100/160000]	lr: 1.909e-05, eta: 11:20:24, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2121, decode.acc_seg: 91.2838, aux.loss_ce: 0.1097, aux.acc_seg: 89.3324, loss: 0.3218
2023-12-29 06:19:30,566 - mmseg - INFO - Iter [109150/160000]	lr: 1.907e-05, eta: 11:19:44, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2123, decode.acc_seg: 90.8927, aux.loss_ce: 0.1098, aux.acc_seg: 88.6820, loss: 0.3221
2023-12-29 06:20:11,821 - mmseg - INFO - Iter [109200/160000]	lr: 1.905e-05, eta: 11:19:05, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2099, decode.acc_seg: 91.0393, aux.loss_ce: 0.1083, aux.acc_seg: 88.9901, loss: 0.3181
2023-12-29 06:20:52,490 - mmseg - INFO - Iter [109250/160000]	lr: 1.903e-05, eta: 11:18:25, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2029, decode.acc_seg: 91.3041, aux.loss_ce: 0.1067, aux.acc_seg: 89.1637, loss: 0.3096
2023-12-29 06:21:33,589 - mmseg - INFO - Iter [109300/160000]	lr: 1.901e-05, eta: 11:17:45, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1989, decode.acc_seg: 91.5748, aux.loss_ce: 0.1026, aux.acc_seg: 89.6171, loss: 0.3015
2023-12-29 06:22:13,930 - mmseg - INFO - Iter [109350/160000]	lr: 1.899e-05, eta: 11:17:05, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2175, decode.acc_seg: 90.9468, aux.loss_ce: 0.1132, aux.acc_seg: 88.8953, loss: 0.3307
2023-12-29 06:22:54,076 - mmseg - INFO - Iter [109400/160000]	lr: 1.898e-05, eta: 11:16:25, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2195, decode.acc_seg: 90.7390, aux.loss_ce: 0.1179, aux.acc_seg: 88.2824, loss: 0.3374
2023-12-29 06:23:34,308 - mmseg - INFO - Iter [109450/160000]	lr: 1.896e-05, eta: 11:15:45, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2203, decode.acc_seg: 91.0867, aux.loss_ce: 0.1145, aux.acc_seg: 89.0153, loss: 0.3348
2023-12-29 06:24:14,351 - mmseg - INFO - Iter [109500/160000]	lr: 1.894e-05, eta: 11:15:05, time: 0.801, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2198, decode.acc_seg: 90.9582, aux.loss_ce: 0.1117, aux.acc_seg: 89.0929, loss: 0.3315
2023-12-29 06:24:56,075 - mmseg - INFO - Iter [109550/160000]	lr: 1.892e-05, eta: 11:14:26, time: 0.834, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2079, decode.acc_seg: 91.4920, aux.loss_ce: 0.1070, aux.acc_seg: 89.5860, loss: 0.3149
2023-12-29 06:25:36,646 - mmseg - INFO - Iter [109600/160000]	lr: 1.890e-05, eta: 11:13:46, time: 0.812, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2153, decode.acc_seg: 90.8085, aux.loss_ce: 0.1141, aux.acc_seg: 88.4469, loss: 0.3294
2023-12-29 06:26:17,645 - mmseg - INFO - Iter [109650/160000]	lr: 1.888e-05, eta: 11:13:06, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2109, decode.acc_seg: 91.1406, aux.loss_ce: 0.1094, aux.acc_seg: 89.0431, loss: 0.3203
2023-12-29 06:26:58,794 - mmseg - INFO - Iter [109700/160000]	lr: 1.886e-05, eta: 11:12:27, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2138, decode.acc_seg: 91.1345, aux.loss_ce: 0.1126, aux.acc_seg: 89.0993, loss: 0.3263
2023-12-29 06:27:38,893 - mmseg - INFO - Iter [109750/160000]	lr: 1.884e-05, eta: 11:11:46, time: 0.802, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2158, decode.acc_seg: 91.0161, aux.loss_ce: 0.1130, aux.acc_seg: 88.7847, loss: 0.3288
2023-12-29 06:28:20,508 - mmseg - INFO - Iter [109800/160000]	lr: 1.883e-05, eta: 11:11:07, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2182, decode.acc_seg: 91.0121, aux.loss_ce: 0.1127, aux.acc_seg: 88.8583, loss: 0.3308
2023-12-29 06:29:01,890 - mmseg - INFO - Iter [109850/160000]	lr: 1.881e-05, eta: 11:10:27, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2221, decode.acc_seg: 90.7668, aux.loss_ce: 0.1127, aux.acc_seg: 88.8430, loss: 0.3348
2023-12-29 06:29:44,251 - mmseg - INFO - Iter [109900/160000]	lr: 1.879e-05, eta: 11:09:48, time: 0.848, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2097, decode.acc_seg: 91.1590, aux.loss_ce: 0.1066, aux.acc_seg: 89.2550, loss: 0.3164
2023-12-29 06:30:24,686 - mmseg - INFO - Iter [109950/160000]	lr: 1.877e-05, eta: 11:09:08, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2079, decode.acc_seg: 91.4960, aux.loss_ce: 0.1071, aux.acc_seg: 89.4518, loss: 0.3149
2023-12-29 06:31:06,401 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 06:31:06,402 - mmseg - INFO - Iter [110000/160000]	lr: 1.875e-05, eta: 11:08:29, time: 0.836, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2105, decode.acc_seg: 91.2198, aux.loss_ce: 0.1079, aux.acc_seg: 89.0055, loss: 0.3184
2023-12-29 06:31:47,831 - mmseg - INFO - Iter [110050/160000]	lr: 1.873e-05, eta: 11:07:50, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2106, decode.acc_seg: 91.0032, aux.loss_ce: 0.1098, aux.acc_seg: 89.1419, loss: 0.3204
2023-12-29 06:32:29,108 - mmseg - INFO - Iter [110100/160000]	lr: 1.871e-05, eta: 11:07:10, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2126, decode.acc_seg: 91.0970, aux.loss_ce: 0.1104, aux.acc_seg: 89.1748, loss: 0.3231
2023-12-29 06:33:09,481 - mmseg - INFO - Iter [110150/160000]	lr: 1.869e-05, eta: 11:06:30, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2193, decode.acc_seg: 90.6167, aux.loss_ce: 0.1114, aux.acc_seg: 88.7856, loss: 0.3306
2023-12-29 06:33:50,660 - mmseg - INFO - Iter [110200/160000]	lr: 1.868e-05, eta: 11:05:50, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2171, decode.acc_seg: 90.9366, aux.loss_ce: 0.1144, aux.acc_seg: 88.6887, loss: 0.3316
2023-12-29 06:34:31,236 - mmseg - INFO - Iter [110250/160000]	lr: 1.866e-05, eta: 11:05:10, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2071, decode.acc_seg: 91.4042, aux.loss_ce: 0.1089, aux.acc_seg: 89.2872, loss: 0.3161
2023-12-29 06:35:12,642 - mmseg - INFO - Iter [110300/160000]	lr: 1.864e-05, eta: 11:04:31, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2126, decode.acc_seg: 91.2648, aux.loss_ce: 0.1153, aux.acc_seg: 88.7265, loss: 0.3279
2023-12-29 06:35:53,528 - mmseg - INFO - Iter [110350/160000]	lr: 1.862e-05, eta: 11:03:51, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2168, decode.acc_seg: 91.1306, aux.loss_ce: 0.1144, aux.acc_seg: 88.9694, loss: 0.3313
2023-12-29 06:36:33,915 - mmseg - INFO - Iter [110400/160000]	lr: 1.860e-05, eta: 11:03:11, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2090, decode.acc_seg: 91.2316, aux.loss_ce: 0.1098, aux.acc_seg: 89.1198, loss: 0.3188
2023-12-29 06:37:16,296 - mmseg - INFO - Iter [110450/160000]	lr: 1.858e-05, eta: 11:02:32, time: 0.846, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2106, decode.acc_seg: 90.8979, aux.loss_ce: 0.1127, aux.acc_seg: 88.5777, loss: 0.3234
2023-12-29 06:37:55,867 - mmseg - INFO - Iter [110500/160000]	lr: 1.856e-05, eta: 11:01:52, time: 0.792, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2016, decode.acc_seg: 91.4493, aux.loss_ce: 0.1054, aux.acc_seg: 89.3338, loss: 0.3070
2023-12-29 06:38:35,824 - mmseg - INFO - Iter [110550/160000]	lr: 1.854e-05, eta: 11:01:12, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2206, decode.acc_seg: 90.5755, aux.loss_ce: 0.1152, aux.acc_seg: 88.4540, loss: 0.3359
2023-12-29 06:39:15,099 - mmseg - INFO - Iter [110600/160000]	lr: 1.853e-05, eta: 11:00:31, time: 0.785, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2129, decode.acc_seg: 91.1176, aux.loss_ce: 0.1104, aux.acc_seg: 88.9938, loss: 0.3233
2023-12-29 06:39:54,732 - mmseg - INFO - Iter [110650/160000]	lr: 1.851e-05, eta: 10:59:51, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2112, decode.acc_seg: 91.2881, aux.loss_ce: 0.1132, aux.acc_seg: 89.1545, loss: 0.3244
2023-12-29 06:40:34,700 - mmseg - INFO - Iter [110700/160000]	lr: 1.849e-05, eta: 10:59:11, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2022, decode.acc_seg: 91.1409, aux.loss_ce: 0.1094, aux.acc_seg: 88.6935, loss: 0.3115
2023-12-29 06:41:15,594 - mmseg - INFO - Iter [110750/160000]	lr: 1.847e-05, eta: 10:58:31, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2188, decode.acc_seg: 90.8987, aux.loss_ce: 0.1131, aux.acc_seg: 88.6870, loss: 0.3319
2023-12-29 06:41:56,915 - mmseg - INFO - Iter [110800/160000]	lr: 1.845e-05, eta: 10:57:51, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2109, decode.acc_seg: 91.1573, aux.loss_ce: 0.1078, aux.acc_seg: 89.2753, loss: 0.3186
2023-12-29 06:42:37,670 - mmseg - INFO - Iter [110850/160000]	lr: 1.843e-05, eta: 10:57:11, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2152, decode.acc_seg: 90.9434, aux.loss_ce: 0.1114, aux.acc_seg: 88.8819, loss: 0.3266
2023-12-29 06:43:18,449 - mmseg - INFO - Iter [110900/160000]	lr: 1.841e-05, eta: 10:56:32, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2045, decode.acc_seg: 91.2956, aux.loss_ce: 0.1049, aux.acc_seg: 89.4039, loss: 0.3094
2023-12-29 06:43:59,454 - mmseg - INFO - Iter [110950/160000]	lr: 1.839e-05, eta: 10:55:52, time: 0.820, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1999, decode.acc_seg: 91.5237, aux.loss_ce: 0.1049, aux.acc_seg: 89.5216, loss: 0.3048
2023-12-29 06:44:40,832 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 06:44:40,832 - mmseg - INFO - Iter [111000/160000]	lr: 1.838e-05, eta: 10:55:12, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2126, decode.acc_seg: 90.9807, aux.loss_ce: 0.1105, aux.acc_seg: 88.9699, loss: 0.3231
2023-12-29 06:45:21,552 - mmseg - INFO - Iter [111050/160000]	lr: 1.836e-05, eta: 10:54:32, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2123, decode.acc_seg: 91.1377, aux.loss_ce: 0.1111, aux.acc_seg: 89.0255, loss: 0.3234
2023-12-29 06:46:02,090 - mmseg - INFO - Iter [111100/160000]	lr: 1.834e-05, eta: 10:53:52, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2088, decode.acc_seg: 91.2021, aux.loss_ce: 0.1098, aux.acc_seg: 89.0070, loss: 0.3186
2023-12-29 06:46:44,499 - mmseg - INFO - Iter [111150/160000]	lr: 1.832e-05, eta: 10:53:13, time: 0.848, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2205, decode.acc_seg: 90.9122, aux.loss_ce: 0.1115, aux.acc_seg: 89.1280, loss: 0.3319
2023-12-29 06:47:25,121 - mmseg - INFO - Iter [111200/160000]	lr: 1.830e-05, eta: 10:52:33, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2003, decode.acc_seg: 91.5859, aux.loss_ce: 0.1046, aux.acc_seg: 89.4788, loss: 0.3048
2023-12-29 06:48:05,250 - mmseg - INFO - Iter [111250/160000]	lr: 1.828e-05, eta: 10:51:53, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.4217, aux.loss_ce: 0.1114, aux.acc_seg: 89.3247, loss: 0.3206
2023-12-29 06:48:46,541 - mmseg - INFO - Iter [111300/160000]	lr: 1.826e-05, eta: 10:51:14, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2162, decode.acc_seg: 91.1158, aux.loss_ce: 0.1092, aux.acc_seg: 89.1954, loss: 0.3255
2023-12-29 06:49:26,295 - mmseg - INFO - Iter [111350/160000]	lr: 1.824e-05, eta: 10:50:33, time: 0.795, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2050, decode.acc_seg: 91.4123, aux.loss_ce: 0.1037, aux.acc_seg: 89.6767, loss: 0.3087
2023-12-29 06:50:05,757 - mmseg - INFO - Iter [111400/160000]	lr: 1.823e-05, eta: 10:49:53, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1956, decode.acc_seg: 91.5049, aux.loss_ce: 0.1028, aux.acc_seg: 89.5118, loss: 0.2985
2023-12-29 06:50:46,761 - mmseg - INFO - Iter [111450/160000]	lr: 1.821e-05, eta: 10:49:13, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1997, decode.acc_seg: 91.2934, aux.loss_ce: 0.1058, aux.acc_seg: 89.2314, loss: 0.3055
2023-12-29 06:51:29,088 - mmseg - INFO - Iter [111500/160000]	lr: 1.819e-05, eta: 10:48:34, time: 0.847, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.1138, aux.loss_ce: 0.1096, aux.acc_seg: 89.0870, loss: 0.3188
2023-12-29 06:52:10,468 - mmseg - INFO - Iter [111550/160000]	lr: 1.817e-05, eta: 10:47:55, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2148, decode.acc_seg: 91.0602, aux.loss_ce: 0.1106, aux.acc_seg: 89.1545, loss: 0.3253
2023-12-29 06:52:50,563 - mmseg - INFO - Iter [111600/160000]	lr: 1.815e-05, eta: 10:47:14, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2115, decode.acc_seg: 91.1624, aux.loss_ce: 0.1089, aux.acc_seg: 89.1192, loss: 0.3204
2023-12-29 06:53:31,610 - mmseg - INFO - Iter [111650/160000]	lr: 1.813e-05, eta: 10:46:35, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2009, decode.acc_seg: 91.5257, aux.loss_ce: 0.1050, aux.acc_seg: 89.4082, loss: 0.3058
2023-12-29 06:54:12,822 - mmseg - INFO - Iter [111700/160000]	lr: 1.811e-05, eta: 10:45:55, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2136, decode.acc_seg: 91.0924, aux.loss_ce: 0.1110, aux.acc_seg: 89.0061, loss: 0.3245
2023-12-29 06:54:52,479 - mmseg - INFO - Iter [111750/160000]	lr: 1.809e-05, eta: 10:45:15, time: 0.794, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2115, decode.acc_seg: 91.0128, aux.loss_ce: 0.1121, aux.acc_seg: 88.5954, loss: 0.3236
2023-12-29 06:55:32,784 - mmseg - INFO - Iter [111800/160000]	lr: 1.808e-05, eta: 10:44:35, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2122, decode.acc_seg: 91.0041, aux.loss_ce: 0.1108, aux.acc_seg: 88.9148, loss: 0.3230
2023-12-29 06:56:13,684 - mmseg - INFO - Iter [111850/160000]	lr: 1.806e-05, eta: 10:43:55, time: 0.818, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2075, decode.acc_seg: 91.2228, aux.loss_ce: 0.1073, aux.acc_seg: 89.2476, loss: 0.3148
2023-12-29 06:56:56,147 - mmseg - INFO - Iter [111900/160000]	lr: 1.804e-05, eta: 10:43:16, time: 0.849, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2170, decode.acc_seg: 90.7028, aux.loss_ce: 0.1133, aux.acc_seg: 88.5990, loss: 0.3304
2023-12-29 06:57:38,659 - mmseg - INFO - Iter [111950/160000]	lr: 1.802e-05, eta: 10:42:37, time: 0.850, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.5167, aux.loss_ce: 0.1053, aux.acc_seg: 89.5387, loss: 0.3081
2023-12-29 06:58:22,504 - mmseg - INFO - Saving checkpoint at 112000 iterations
2023-12-29 06:58:26,907 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 06:58:26,908 - mmseg - INFO - Iter [112000/160000]	lr: 1.800e-05, eta: 10:42:00, time: 0.966, data_time: 0.015, memory: 18256, decode.loss_ce: 0.2065, decode.acc_seg: 91.2549, aux.loss_ce: 0.1075, aux.acc_seg: 89.2345, loss: 0.3141
2023-12-29 07:00:00,888 - mmseg - INFO - per class results:
2023-12-29 07:00:00,901 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.24 | 87.35 |
|       building      | 82.33 | 90.74 |
|         sky         | 94.57 | 97.57 |
|        floor        | 80.92 | 89.79 |
|         tree        | 74.99 | 89.59 |
|       ceiling       | 83.11 | 91.27 |
|         road        |  82.9 | 90.21 |
|         bed         | 88.81 | 95.13 |
|      windowpane     | 62.75 | 79.17 |
|        grass        | 70.55 | 84.09 |
|       cabinet       | 61.27 | 73.15 |
|       sidewalk      | 65.85 | 79.77 |
|        person       | 80.65 | 93.69 |
|        earth        | 34.97 | 47.83 |
|         door        | 53.22 | 70.88 |
|        table        |  61.4 |  76.8 |
|       mountain      | 58.66 |  77.9 |
|        plant        |  49.6 | 61.04 |
|       curtain       | 75.17 | 88.29 |
|        chair        | 55.23 | 66.68 |
|         car         | 83.85 | 91.71 |
|        water        | 59.36 | 71.57 |
|       painting      | 72.02 | 88.22 |
|         sofa        | 65.63 | 83.18 |
|        shelf        | 46.94 | 63.36 |
|        house        | 52.58 | 73.65 |
|         sea         | 61.87 | 82.34 |
|        mirror       | 63.87 | 70.48 |
|         rug         | 65.54 | 77.09 |
|        field        |  41.1 |  60.9 |
|       armchair      | 40.01 | 57.42 |
|         seat        | 60.69 |  82.0 |
|        fence        | 50.48 |  68.3 |
|         desk        | 47.66 | 70.93 |
|         rock        |  39.4 | 64.27 |
|       wardrobe      | 48.34 |  68.6 |
|         lamp        | 64.76 | 77.21 |
|       bathtub       |  75.2 | 82.73 |
|       railing       | 36.22 | 49.53 |
|       cushion       | 62.05 | 74.99 |
|         base        | 33.68 | 46.11 |
|         box         | 24.91 | 32.78 |
|        column       | 45.03 |  58.0 |
|      signboard      | 37.13 | 50.04 |
|   chest of drawers  | 36.89 | 45.96 |
|       counter       |  37.5 | 50.97 |
|         sand        | 35.11 | 58.01 |
|         sink        | 69.45 | 76.92 |
|      skyscraper     | 46.85 | 58.09 |
|      fireplace      | 74.33 | 89.04 |
|     refrigerator    | 75.38 |  83.3 |
|      grandstand     | 37.41 | 73.44 |
|         path        | 25.97 | 35.64 |
|        stairs       | 32.33 | 37.72 |
|        runway       | 70.53 | 92.92 |
|         case        | 53.26 |  72.7 |
|      pool table     | 92.74 | 96.98 |
|        pillow       | 58.73 | 69.95 |
|     screen door     | 72.58 | 76.39 |
|       stairway      | 31.56 | 37.29 |
|        river        | 11.52 | 22.62 |
|        bridge       | 71.84 | 82.83 |
|       bookcase      | 36.71 | 57.75 |
|        blind        | 39.24 | 46.67 |
|     coffee table    | 57.77 | 80.89 |
|        toilet       | 83.37 | 91.94 |
|        flower       | 38.68 | 59.73 |
|         book        | 48.02 | 69.02 |
|         hill        |  3.47 |  5.14 |
|        bench        |  44.5 | 55.97 |
|      countertop     | 59.12 | 84.14 |
|        stove        |  76.9 | 83.73 |
|         palm        | 50.86 | 78.91 |
|    kitchen island   | 41.52 | 90.05 |
|       computer      | 73.71 | 90.74 |
|     swivel chair    | 40.74 | 73.21 |
|         boat        | 42.58 | 50.89 |
|         bar         | 41.28 | 51.73 |
|    arcade machine   | 81.61 | 88.91 |
|        hovel        | 57.93 | 71.18 |
|         bus         | 83.95 | 96.23 |
|        towel        | 61.58 | 76.58 |
|        light        | 54.14 | 60.51 |
|        truck        | 32.82 | 40.16 |
|        tower        | 22.68 | 39.42 |
|      chandelier     | 70.33 | 84.09 |
|        awning       | 27.33 | 36.76 |
|     streetlight     | 27.11 | 36.76 |
|        booth        | 54.36 | 65.74 |
| television receiver | 66.58 | 76.25 |
|       airplane      | 56.75 | 65.81 |
|      dirt track     | 31.22 | 45.89 |
|       apparel       | 46.12 | 61.69 |
|         pole        | 20.36 | 28.45 |
|         land        |  3.31 |  3.96 |
|      bannister      | 12.71 | 15.63 |
|      escalator      | 28.05 | 29.65 |
|       ottoman       | 40.63 | 60.84 |
|        bottle       |  34.9 | 48.29 |
|        buffet       | 41.92 | 45.19 |
|        poster       | 29.15 | 37.19 |
|        stage        | 17.94 | 32.48 |
|         van         | 40.66 | 58.77 |
|         ship        |  5.13 |  8.13 |
|       fountain      | 20.54 | 20.91 |
|    conveyer belt    | 77.67 |  91.2 |
|        canopy       | 11.72 | 18.52 |
|        washer       | 86.11 | 93.08 |
|      plaything      | 24.25 |  40.7 |
|    swimming pool    | 69.58 | 89.55 |
|        stool        | 34.29 | 50.63 |
|        barrel       | 38.89 | 64.74 |
|        basket       | 32.83 | 46.78 |
|      waterfall      | 66.54 | 91.79 |
|         tent        | 93.24 | 98.68 |
|         bag         | 15.02 | 19.94 |
|       minibike      | 70.93 | 86.25 |
|        cradle       | 75.89 | 98.55 |
|         oven        | 51.56 |  73.3 |
|         ball        | 46.85 | 68.74 |
|         food        | 51.44 | 62.46 |
|         step        |  6.78 |  9.72 |
|         tank        | 52.97 | 60.45 |
|      trade name     | 24.55 | 29.46 |
|      microwave      | 80.89 | 87.34 |
|         pot         | 48.23 | 56.55 |
|        animal       |  58.6 | 63.14 |
|       bicycle       | 53.07 | 71.17 |
|         lake        | 51.43 | 63.71 |
|      dishwasher     | 61.49 | 76.37 |
|        screen       | 66.07 | 90.67 |
|       blanket       | 13.02 | 15.19 |
|      sculpture      | 60.45 | 69.56 |
|         hood        | 61.13 | 72.31 |
|        sconce       | 44.58 | 53.51 |
|         vase        | 40.74 | 55.14 |
|    traffic light    |  27.7 | 42.38 |
|         tray        | 11.65 | 15.12 |
|        ashcan       | 40.91 | 55.76 |
|         fan         | 52.56 | 75.74 |
|         pier        |  42.7 | 77.24 |
|      crt screen     |  4.24 | 11.66 |
|        plate        | 52.88 | 73.73 |
|       monitor       |  9.47 | 10.06 |
|    bulletin board   | 49.32 | 66.47 |
|        shower       |  3.63 |  8.99 |
|       radiator      | 53.21 | 64.93 |
|        glass        | 15.25 | 17.16 |
|        clock        | 28.73 | 32.89 |
|         flag        | 49.81 | 56.02 |
+---------------------+-------+-------+
2023-12-29 07:00:00,902 - mmseg - INFO - Summary:
2023-12-29 07:00:00,902 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 83.18 | 49.78 | 62.8 |
+-------+-------+------+
2023-12-29 07:00:00,945 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 07:00:00,945 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8318, mIoU: 0.4978, mAcc: 0.6280, IoU.wall: 0.7724, IoU.building: 0.8233, IoU.sky: 0.9457, IoU.floor: 0.8092, IoU.tree: 0.7499, IoU.ceiling: 0.8311, IoU.road: 0.8290, IoU.bed : 0.8881, IoU.windowpane: 0.6275, IoU.grass: 0.7055, IoU.cabinet: 0.6127, IoU.sidewalk: 0.6585, IoU.person: 0.8065, IoU.earth: 0.3497, IoU.door: 0.5322, IoU.table: 0.6140, IoU.mountain: 0.5866, IoU.plant: 0.4960, IoU.curtain: 0.7517, IoU.chair: 0.5523, IoU.car: 0.8385, IoU.water: 0.5936, IoU.painting: 0.7202, IoU.sofa: 0.6563, IoU.shelf: 0.4694, IoU.house: 0.5258, IoU.sea: 0.6187, IoU.mirror: 0.6387, IoU.rug: 0.6554, IoU.field: 0.4110, IoU.armchair: 0.4001, IoU.seat: 0.6069, IoU.fence: 0.5048, IoU.desk: 0.4766, IoU.rock: 0.3940, IoU.wardrobe: 0.4834, IoU.lamp: 0.6476, IoU.bathtub: 0.7520, IoU.railing: 0.3622, IoU.cushion: 0.6205, IoU.base: 0.3368, IoU.box: 0.2491, IoU.column: 0.4503, IoU.signboard: 0.3713, IoU.chest of drawers: 0.3689, IoU.counter: 0.3750, IoU.sand: 0.3511, IoU.sink: 0.6945, IoU.skyscraper: 0.4685, IoU.fireplace: 0.7433, IoU.refrigerator: 0.7538, IoU.grandstand: 0.3741, IoU.path: 0.2597, IoU.stairs: 0.3233, IoU.runway: 0.7053, IoU.case: 0.5326, IoU.pool table: 0.9274, IoU.pillow: 0.5873, IoU.screen door: 0.7258, IoU.stairway: 0.3156, IoU.river: 0.1152, IoU.bridge: 0.7184, IoU.bookcase: 0.3671, IoU.blind: 0.3924, IoU.coffee table: 0.5777, IoU.toilet: 0.8337, IoU.flower: 0.3868, IoU.book: 0.4802, IoU.hill: 0.0347, IoU.bench: 0.4450, IoU.countertop: 0.5912, IoU.stove: 0.7690, IoU.palm: 0.5086, IoU.kitchen island: 0.4152, IoU.computer: 0.7371, IoU.swivel chair: 0.4074, IoU.boat: 0.4258, IoU.bar: 0.4128, IoU.arcade machine: 0.8161, IoU.hovel: 0.5793, IoU.bus: 0.8395, IoU.towel: 0.6158, IoU.light: 0.5414, IoU.truck: 0.3282, IoU.tower: 0.2268, IoU.chandelier: 0.7033, IoU.awning: 0.2733, IoU.streetlight: 0.2711, IoU.booth: 0.5436, IoU.television receiver: 0.6658, IoU.airplane: 0.5675, IoU.dirt track: 0.3122, IoU.apparel: 0.4612, IoU.pole: 0.2036, IoU.land: 0.0331, IoU.bannister: 0.1271, IoU.escalator: 0.2805, IoU.ottoman: 0.4063, IoU.bottle: 0.3490, IoU.buffet: 0.4192, IoU.poster: 0.2915, IoU.stage: 0.1794, IoU.van: 0.4066, IoU.ship: 0.0513, IoU.fountain: 0.2054, IoU.conveyer belt: 0.7767, IoU.canopy: 0.1172, IoU.washer: 0.8611, IoU.plaything: 0.2425, IoU.swimming pool: 0.6958, IoU.stool: 0.3429, IoU.barrel: 0.3889, IoU.basket: 0.3283, IoU.waterfall: 0.6654, IoU.tent: 0.9324, IoU.bag: 0.1502, IoU.minibike: 0.7093, IoU.cradle: 0.7589, IoU.oven: 0.5156, IoU.ball: 0.4685, IoU.food: 0.5144, IoU.step: 0.0678, IoU.tank: 0.5297, IoU.trade name: 0.2455, IoU.microwave: 0.8089, IoU.pot: 0.4823, IoU.animal: 0.5860, IoU.bicycle: 0.5307, IoU.lake: 0.5143, IoU.dishwasher: 0.6149, IoU.screen: 0.6607, IoU.blanket: 0.1302, IoU.sculpture: 0.6045, IoU.hood: 0.6113, IoU.sconce: 0.4458, IoU.vase: 0.4074, IoU.traffic light: 0.2770, IoU.tray: 0.1165, IoU.ashcan: 0.4091, IoU.fan: 0.5256, IoU.pier: 0.4270, IoU.crt screen: 0.0424, IoU.plate: 0.5288, IoU.monitor: 0.0947, IoU.bulletin board: 0.4932, IoU.shower: 0.0363, IoU.radiator: 0.5321, IoU.glass: 0.1525, IoU.clock: 0.2873, IoU.flag: 0.4981, Acc.wall: 0.8735, Acc.building: 0.9074, Acc.sky: 0.9757, Acc.floor: 0.8979, Acc.tree: 0.8959, Acc.ceiling: 0.9127, Acc.road: 0.9021, Acc.bed : 0.9513, Acc.windowpane: 0.7917, Acc.grass: 0.8409, Acc.cabinet: 0.7315, Acc.sidewalk: 0.7977, Acc.person: 0.9369, Acc.earth: 0.4783, Acc.door: 0.7088, Acc.table: 0.7680, Acc.mountain: 0.7790, Acc.plant: 0.6104, Acc.curtain: 0.8829, Acc.chair: 0.6668, Acc.car: 0.9171, Acc.water: 0.7157, Acc.painting: 0.8822, Acc.sofa: 0.8318, Acc.shelf: 0.6336, Acc.house: 0.7365, Acc.sea: 0.8234, Acc.mirror: 0.7048, Acc.rug: 0.7709, Acc.field: 0.6090, Acc.armchair: 0.5742, Acc.seat: 0.8200, Acc.fence: 0.6830, Acc.desk: 0.7093, Acc.rock: 0.6427, Acc.wardrobe: 0.6860, Acc.lamp: 0.7721, Acc.bathtub: 0.8273, Acc.railing: 0.4953, Acc.cushion: 0.7499, Acc.base: 0.4611, Acc.box: 0.3278, Acc.column: 0.5800, Acc.signboard: 0.5004, Acc.chest of drawers: 0.4596, Acc.counter: 0.5097, Acc.sand: 0.5801, Acc.sink: 0.7692, Acc.skyscraper: 0.5809, Acc.fireplace: 0.8904, Acc.refrigerator: 0.8330, Acc.grandstand: 0.7344, Acc.path: 0.3564, Acc.stairs: 0.3772, Acc.runway: 0.9292, Acc.case: 0.7270, Acc.pool table: 0.9698, Acc.pillow: 0.6995, Acc.screen door: 0.7639, Acc.stairway: 0.3729, Acc.river: 0.2262, Acc.bridge: 0.8283, Acc.bookcase: 0.5775, Acc.blind: 0.4667, Acc.coffee table: 0.8089, Acc.toilet: 0.9194, Acc.flower: 0.5973, Acc.book: 0.6902, Acc.hill: 0.0514, Acc.bench: 0.5597, Acc.countertop: 0.8414, Acc.stove: 0.8373, Acc.palm: 0.7891, Acc.kitchen island: 0.9005, Acc.computer: 0.9074, Acc.swivel chair: 0.7321, Acc.boat: 0.5089, Acc.bar: 0.5173, Acc.arcade machine: 0.8891, Acc.hovel: 0.7118, Acc.bus: 0.9623, Acc.towel: 0.7658, Acc.light: 0.6051, Acc.truck: 0.4016, Acc.tower: 0.3942, Acc.chandelier: 0.8409, Acc.awning: 0.3676, Acc.streetlight: 0.3676, Acc.booth: 0.6574, Acc.television receiver: 0.7625, Acc.airplane: 0.6581, Acc.dirt track: 0.4589, Acc.apparel: 0.6169, Acc.pole: 0.2845, Acc.land: 0.0396, Acc.bannister: 0.1563, Acc.escalator: 0.2965, Acc.ottoman: 0.6084, Acc.bottle: 0.4829, Acc.buffet: 0.4519, Acc.poster: 0.3719, Acc.stage: 0.3248, Acc.van: 0.5877, Acc.ship: 0.0813, Acc.fountain: 0.2091, Acc.conveyer belt: 0.9120, Acc.canopy: 0.1852, Acc.washer: 0.9308, Acc.plaything: 0.4070, Acc.swimming pool: 0.8955, Acc.stool: 0.5063, Acc.barrel: 0.6474, Acc.basket: 0.4678, Acc.waterfall: 0.9179, Acc.tent: 0.9868, Acc.bag: 0.1994, Acc.minibike: 0.8625, Acc.cradle: 0.9855, Acc.oven: 0.7330, Acc.ball: 0.6874, Acc.food: 0.6246, Acc.step: 0.0972, Acc.tank: 0.6045, Acc.trade name: 0.2946, Acc.microwave: 0.8734, Acc.pot: 0.5655, Acc.animal: 0.6314, Acc.bicycle: 0.7117, Acc.lake: 0.6371, Acc.dishwasher: 0.7637, Acc.screen: 0.9067, Acc.blanket: 0.1519, Acc.sculpture: 0.6956, Acc.hood: 0.7231, Acc.sconce: 0.5351, Acc.vase: 0.5514, Acc.traffic light: 0.4238, Acc.tray: 0.1512, Acc.ashcan: 0.5576, Acc.fan: 0.7574, Acc.pier: 0.7724, Acc.crt screen: 0.1166, Acc.plate: 0.7373, Acc.monitor: 0.1006, Acc.bulletin board: 0.6647, Acc.shower: 0.0899, Acc.radiator: 0.6493, Acc.glass: 0.1716, Acc.clock: 0.3289, Acc.flag: 0.5602
2023-12-29 07:00:42,108 - mmseg - INFO - Iter [112050/160000]	lr: 1.798e-05, eta: 10:42:01, time: 2.704, data_time: 1.893, memory: 18256, decode.loss_ce: 0.2162, decode.acc_seg: 90.8993, aux.loss_ce: 0.1117, aux.acc_seg: 88.7466, loss: 0.3279
2023-12-29 07:01:22,170 - mmseg - INFO - Iter [112100/160000]	lr: 1.796e-05, eta: 10:41:20, time: 0.800, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2171, decode.acc_seg: 90.9474, aux.loss_ce: 0.1129, aux.acc_seg: 88.6915, loss: 0.3300
2023-12-29 07:02:03,750 - mmseg - INFO - Iter [112150/160000]	lr: 1.794e-05, eta: 10:40:41, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2081, decode.acc_seg: 91.3469, aux.loss_ce: 0.1078, aux.acc_seg: 89.4009, loss: 0.3159
2023-12-29 07:02:45,175 - mmseg - INFO - Iter [112200/160000]	lr: 1.793e-05, eta: 10:40:01, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2083, decode.acc_seg: 91.0050, aux.loss_ce: 0.1105, aux.acc_seg: 88.7746, loss: 0.3188
2023-12-29 07:03:25,773 - mmseg - INFO - Iter [112250/160000]	lr: 1.791e-05, eta: 10:39:21, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2088, decode.acc_seg: 91.0877, aux.loss_ce: 0.1088, aux.acc_seg: 89.0547, loss: 0.3176
2023-12-29 07:04:05,123 - mmseg - INFO - Iter [112300/160000]	lr: 1.789e-05, eta: 10:38:41, time: 0.787, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2087, decode.acc_seg: 91.2997, aux.loss_ce: 0.1082, aux.acc_seg: 89.2497, loss: 0.3169
2023-12-29 07:04:46,039 - mmseg - INFO - Iter [112350/160000]	lr: 1.787e-05, eta: 10:38:01, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2078, decode.acc_seg: 91.3157, aux.loss_ce: 0.1090, aux.acc_seg: 89.0984, loss: 0.3169
2023-12-29 07:05:27,322 - mmseg - INFO - Iter [112400/160000]	lr: 1.785e-05, eta: 10:37:21, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2270, decode.acc_seg: 90.3196, aux.loss_ce: 0.1161, aux.acc_seg: 88.2508, loss: 0.3431
2023-12-29 07:06:09,949 - mmseg - INFO - Iter [112450/160000]	lr: 1.783e-05, eta: 10:36:42, time: 0.852, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1849, decode.acc_seg: 91.9821, aux.loss_ce: 0.0956, aux.acc_seg: 90.1655, loss: 0.2805
2023-12-29 07:06:50,550 - mmseg - INFO - Iter [112500/160000]	lr: 1.781e-05, eta: 10:36:02, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2081, decode.acc_seg: 91.1075, aux.loss_ce: 0.1075, aux.acc_seg: 89.2303, loss: 0.3156
2023-12-29 07:07:31,745 - mmseg - INFO - Iter [112550/160000]	lr: 1.779e-05, eta: 10:35:22, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2052, decode.acc_seg: 91.5442, aux.loss_ce: 0.1064, aux.acc_seg: 89.2923, loss: 0.3116
2023-12-29 07:08:10,396 - mmseg - INFO - Iter [112600/160000]	lr: 1.778e-05, eta: 10:34:42, time: 0.773, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2150, decode.acc_seg: 90.9180, aux.loss_ce: 0.1143, aux.acc_seg: 88.8036, loss: 0.3293
2023-12-29 07:08:51,431 - mmseg - INFO - Iter [112650/160000]	lr: 1.776e-05, eta: 10:34:02, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.1170, aux.loss_ce: 0.1095, aux.acc_seg: 88.9737, loss: 0.3187
2023-12-29 07:09:32,972 - mmseg - INFO - Iter [112700/160000]	lr: 1.774e-05, eta: 10:33:22, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2134, decode.acc_seg: 91.1480, aux.loss_ce: 0.1063, aux.acc_seg: 89.3854, loss: 0.3198
2023-12-29 07:10:13,784 - mmseg - INFO - Iter [112750/160000]	lr: 1.772e-05, eta: 10:32:42, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2054, decode.acc_seg: 91.4831, aux.loss_ce: 0.1078, aux.acc_seg: 89.6141, loss: 0.3133
2023-12-29 07:10:55,148 - mmseg - INFO - Iter [112800/160000]	lr: 1.770e-05, eta: 10:32:03, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2113, decode.acc_seg: 91.0934, aux.loss_ce: 0.1109, aux.acc_seg: 88.9034, loss: 0.3222
2023-12-29 07:11:33,506 - mmseg - INFO - Iter [112850/160000]	lr: 1.768e-05, eta: 10:31:22, time: 0.768, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2097, decode.acc_seg: 91.6477, aux.loss_ce: 0.1076, aux.acc_seg: 89.5179, loss: 0.3173
2023-12-29 07:12:13,949 - mmseg - INFO - Iter [112900/160000]	lr: 1.766e-05, eta: 10:30:42, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2175, decode.acc_seg: 90.7147, aux.loss_ce: 0.1120, aux.acc_seg: 88.7581, loss: 0.3295
2023-12-29 07:12:54,191 - mmseg - INFO - Iter [112950/160000]	lr: 1.764e-05, eta: 10:30:01, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2091, decode.acc_seg: 91.2064, aux.loss_ce: 0.1105, aux.acc_seg: 89.0912, loss: 0.3197
2023-12-29 07:13:33,293 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 07:13:33,294 - mmseg - INFO - Iter [113000/160000]	lr: 1.763e-05, eta: 10:29:21, time: 0.782, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2091, decode.acc_seg: 91.1911, aux.loss_ce: 0.1113, aux.acc_seg: 88.9270, loss: 0.3203
2023-12-29 07:14:14,760 - mmseg - INFO - Iter [113050/160000]	lr: 1.761e-05, eta: 10:28:41, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2142, decode.acc_seg: 90.9958, aux.loss_ce: 0.1082, aux.acc_seg: 89.1964, loss: 0.3224
2023-12-29 07:14:55,856 - mmseg - INFO - Iter [113100/160000]	lr: 1.759e-05, eta: 10:28:01, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2175, decode.acc_seg: 90.8373, aux.loss_ce: 0.1144, aux.acc_seg: 88.6553, loss: 0.3319
2023-12-29 07:15:36,825 - mmseg - INFO - Iter [113150/160000]	lr: 1.757e-05, eta: 10:27:22, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1979, decode.acc_seg: 91.8032, aux.loss_ce: 0.1013, aux.acc_seg: 89.9176, loss: 0.2992
2023-12-29 07:16:17,533 - mmseg - INFO - Iter [113200/160000]	lr: 1.755e-05, eta: 10:26:42, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2055, decode.acc_seg: 91.5583, aux.loss_ce: 0.1058, aux.acc_seg: 89.6959, loss: 0.3113
2023-12-29 07:16:58,285 - mmseg - INFO - Iter [113250/160000]	lr: 1.753e-05, eta: 10:26:02, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2015, decode.acc_seg: 91.5469, aux.loss_ce: 0.1047, aux.acc_seg: 89.4364, loss: 0.3061
2023-12-29 07:17:38,666 - mmseg - INFO - Iter [113300/160000]	lr: 1.751e-05, eta: 10:25:22, time: 0.807, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2154, decode.acc_seg: 90.9771, aux.loss_ce: 0.1112, aux.acc_seg: 88.9994, loss: 0.3266
2023-12-29 07:18:19,810 - mmseg - INFO - Iter [113350/160000]	lr: 1.749e-05, eta: 10:24:42, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2208, decode.acc_seg: 90.7197, aux.loss_ce: 0.1136, aux.acc_seg: 88.5858, loss: 0.3344
2023-12-29 07:19:00,140 - mmseg - INFO - Iter [113400/160000]	lr: 1.748e-05, eta: 10:24:02, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2105, decode.acc_seg: 90.7128, aux.loss_ce: 0.1125, aux.acc_seg: 88.4493, loss: 0.3230
2023-12-29 07:19:41,155 - mmseg - INFO - Iter [113450/160000]	lr: 1.746e-05, eta: 10:23:22, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2080, decode.acc_seg: 91.2606, aux.loss_ce: 0.1108, aux.acc_seg: 89.0560, loss: 0.3188
2023-12-29 07:20:21,771 - mmseg - INFO - Iter [113500/160000]	lr: 1.744e-05, eta: 10:22:42, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2075, decode.acc_seg: 91.1374, aux.loss_ce: 0.1067, aux.acc_seg: 89.1077, loss: 0.3142
2023-12-29 07:21:03,122 - mmseg - INFO - Iter [113550/160000]	lr: 1.742e-05, eta: 10:22:02, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2132, decode.acc_seg: 91.0810, aux.loss_ce: 0.1119, aux.acc_seg: 88.9658, loss: 0.3251
2023-12-29 07:21:43,916 - mmseg - INFO - Iter [113600/160000]	lr: 1.740e-05, eta: 10:21:22, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2066, decode.acc_seg: 91.4158, aux.loss_ce: 0.1082, aux.acc_seg: 89.4095, loss: 0.3148
2023-12-29 07:22:24,708 - mmseg - INFO - Iter [113650/160000]	lr: 1.738e-05, eta: 10:20:42, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2214, decode.acc_seg: 90.7678, aux.loss_ce: 0.1112, aux.acc_seg: 88.8128, loss: 0.3326
2023-12-29 07:23:06,768 - mmseg - INFO - Iter [113700/160000]	lr: 1.736e-05, eta: 10:20:03, time: 0.842, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2181, decode.acc_seg: 91.0875, aux.loss_ce: 0.1115, aux.acc_seg: 89.0016, loss: 0.3296
2023-12-29 07:23:48,255 - mmseg - INFO - Iter [113750/160000]	lr: 1.734e-05, eta: 10:19:23, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2103, decode.acc_seg: 91.3191, aux.loss_ce: 0.1112, aux.acc_seg: 89.1178, loss: 0.3215
2023-12-29 07:24:30,844 - mmseg - INFO - Iter [113800/160000]	lr: 1.733e-05, eta: 10:18:44, time: 0.851, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2123, decode.acc_seg: 91.2570, aux.loss_ce: 0.1087, aux.acc_seg: 89.3300, loss: 0.3210
2023-12-29 07:25:11,257 - mmseg - INFO - Iter [113850/160000]	lr: 1.731e-05, eta: 10:18:04, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2043, decode.acc_seg: 91.1519, aux.loss_ce: 0.1053, aux.acc_seg: 89.1939, loss: 0.3096
2023-12-29 07:25:48,521 - mmseg - INFO - Iter [113900/160000]	lr: 1.729e-05, eta: 10:17:23, time: 0.746, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2070, decode.acc_seg: 91.2659, aux.loss_ce: 0.1080, aux.acc_seg: 89.1100, loss: 0.3150
2023-12-29 07:26:28,034 - mmseg - INFO - Iter [113950/160000]	lr: 1.727e-05, eta: 10:16:42, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2082, decode.acc_seg: 91.1148, aux.loss_ce: 0.1077, aux.acc_seg: 89.0525, loss: 0.3159
2023-12-29 07:27:09,942 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 07:27:09,942 - mmseg - INFO - Iter [114000/160000]	lr: 1.725e-05, eta: 10:16:03, time: 0.838, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2133, decode.acc_seg: 91.0892, aux.loss_ce: 0.1135, aux.acc_seg: 88.6461, loss: 0.3267
2023-12-29 07:27:52,293 - mmseg - INFO - Iter [114050/160000]	lr: 1.723e-05, eta: 10:15:23, time: 0.847, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2134, decode.acc_seg: 91.1163, aux.loss_ce: 0.1102, aux.acc_seg: 88.9931, loss: 0.3235
2023-12-29 07:28:30,665 - mmseg - INFO - Iter [114100/160000]	lr: 1.721e-05, eta: 10:14:43, time: 0.768, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2061, decode.acc_seg: 91.0897, aux.loss_ce: 0.1076, aux.acc_seg: 88.8822, loss: 0.3137
2023-12-29 07:29:09,663 - mmseg - INFO - Iter [114150/160000]	lr: 1.719e-05, eta: 10:14:02, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2029, decode.acc_seg: 91.3962, aux.loss_ce: 0.1079, aux.acc_seg: 89.3412, loss: 0.3108
2023-12-29 07:29:50,152 - mmseg - INFO - Iter [114200/160000]	lr: 1.718e-05, eta: 10:13:22, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2084, decode.acc_seg: 91.1532, aux.loss_ce: 0.1067, aux.acc_seg: 89.2473, loss: 0.3151
2023-12-29 07:30:31,379 - mmseg - INFO - Iter [114250/160000]	lr: 1.716e-05, eta: 10:12:42, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2019, decode.acc_seg: 91.5807, aux.loss_ce: 0.1073, aux.acc_seg: 89.3048, loss: 0.3092
2023-12-29 07:31:11,257 - mmseg - INFO - Iter [114300/160000]	lr: 1.714e-05, eta: 10:12:02, time: 0.798, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1965, decode.acc_seg: 91.8133, aux.loss_ce: 0.1024, aux.acc_seg: 89.8139, loss: 0.2989
2023-12-29 07:31:50,301 - mmseg - INFO - Iter [114350/160000]	lr: 1.712e-05, eta: 10:11:21, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2245, decode.acc_seg: 90.6524, aux.loss_ce: 0.1188, aux.acc_seg: 88.4011, loss: 0.3433
2023-12-29 07:32:30,296 - mmseg - INFO - Iter [114400/160000]	lr: 1.710e-05, eta: 10:10:41, time: 0.799, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2189, decode.acc_seg: 90.9455, aux.loss_ce: 0.1132, aux.acc_seg: 88.9864, loss: 0.3322
2023-12-29 07:33:09,405 - mmseg - INFO - Iter [114450/160000]	lr: 1.708e-05, eta: 10:10:00, time: 0.783, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2041, decode.acc_seg: 91.0174, aux.loss_ce: 0.1084, aux.acc_seg: 88.7212, loss: 0.3124
2023-12-29 07:33:50,567 - mmseg - INFO - Iter [114500/160000]	lr: 1.706e-05, eta: 10:09:20, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2248, decode.acc_seg: 90.6296, aux.loss_ce: 0.1169, aux.acc_seg: 88.4502, loss: 0.3416
2023-12-29 07:34:31,049 - mmseg - INFO - Iter [114550/160000]	lr: 1.704e-05, eta: 10:08:40, time: 0.809, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2219, decode.acc_seg: 90.7424, aux.loss_ce: 0.1155, aux.acc_seg: 88.6332, loss: 0.3374
2023-12-29 07:35:11,858 - mmseg - INFO - Iter [114600/160000]	lr: 1.703e-05, eta: 10:08:00, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2132, decode.acc_seg: 91.0224, aux.loss_ce: 0.1094, aux.acc_seg: 89.3401, loss: 0.3226
2023-12-29 07:35:54,046 - mmseg - INFO - Iter [114650/160000]	lr: 1.701e-05, eta: 10:07:21, time: 0.843, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2183, decode.acc_seg: 90.9417, aux.loss_ce: 0.1147, aux.acc_seg: 88.6657, loss: 0.3330
2023-12-29 07:36:36,200 - mmseg - INFO - Iter [114700/160000]	lr: 1.699e-05, eta: 10:06:42, time: 0.844, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2037, decode.acc_seg: 91.3661, aux.loss_ce: 0.1076, aux.acc_seg: 89.2454, loss: 0.3113
2023-12-29 07:37:15,125 - mmseg - INFO - Iter [114750/160000]	lr: 1.697e-05, eta: 10:06:01, time: 0.778, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2070, decode.acc_seg: 91.1400, aux.loss_ce: 0.1067, aux.acc_seg: 89.1715, loss: 0.3137
2023-12-29 07:37:54,201 - mmseg - INFO - Iter [114800/160000]	lr: 1.695e-05, eta: 10:05:20, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2114, decode.acc_seg: 91.1230, aux.loss_ce: 0.1110, aux.acc_seg: 89.0126, loss: 0.3224
2023-12-29 07:38:35,464 - mmseg - INFO - Iter [114850/160000]	lr: 1.693e-05, eta: 10:04:41, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2062, decode.acc_seg: 91.3310, aux.loss_ce: 0.1060, aux.acc_seg: 89.4564, loss: 0.3122
2023-12-29 07:39:15,257 - mmseg - INFO - Iter [114900/160000]	lr: 1.691e-05, eta: 10:04:00, time: 0.797, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2058, decode.acc_seg: 91.6151, aux.loss_ce: 0.1080, aux.acc_seg: 89.5153, loss: 0.3138
2023-12-29 07:39:57,430 - mmseg - INFO - Iter [114950/160000]	lr: 1.689e-05, eta: 10:03:21, time: 0.843, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2209, decode.acc_seg: 90.3296, aux.loss_ce: 0.1151, aux.acc_seg: 88.2765, loss: 0.3359
2023-12-29 07:40:37,910 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 07:40:37,910 - mmseg - INFO - Iter [115000/160000]	lr: 1.688e-05, eta: 10:02:41, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2111, decode.acc_seg: 91.0182, aux.loss_ce: 0.1122, aux.acc_seg: 88.6174, loss: 0.3233
2023-12-29 07:41:18,943 - mmseg - INFO - Iter [115050/160000]	lr: 1.686e-05, eta: 10:02:01, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2104, decode.acc_seg: 91.3468, aux.loss_ce: 0.1118, aux.acc_seg: 89.0404, loss: 0.3222
2023-12-29 07:41:59,772 - mmseg - INFO - Iter [115100/160000]	lr: 1.684e-05, eta: 10:01:21, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2083, decode.acc_seg: 91.4360, aux.loss_ce: 0.1097, aux.acc_seg: 89.2485, loss: 0.3180
2023-12-29 07:42:40,158 - mmseg - INFO - Iter [115150/160000]	lr: 1.682e-05, eta: 10:00:41, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2067, decode.acc_seg: 91.2002, aux.loss_ce: 0.1051, aux.acc_seg: 89.4815, loss: 0.3118
2023-12-29 07:43:18,610 - mmseg - INFO - Iter [115200/160000]	lr: 1.680e-05, eta: 10:00:00, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2013, decode.acc_seg: 91.3847, aux.loss_ce: 0.1063, aux.acc_seg: 89.1038, loss: 0.3076
2023-12-29 07:43:58,120 - mmseg - INFO - Iter [115250/160000]	lr: 1.678e-05, eta: 9:59:20, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2157, decode.acc_seg: 91.0144, aux.loss_ce: 0.1113, aux.acc_seg: 88.9221, loss: 0.3271
2023-12-29 07:44:38,050 - mmseg - INFO - Iter [115300/160000]	lr: 1.676e-05, eta: 9:58:39, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2067, decode.acc_seg: 91.3028, aux.loss_ce: 0.1075, aux.acc_seg: 89.2300, loss: 0.3141
2023-12-29 07:45:19,232 - mmseg - INFO - Iter [115350/160000]	lr: 1.674e-05, eta: 9:58:00, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2138, decode.acc_seg: 90.9013, aux.loss_ce: 0.1128, aux.acc_seg: 88.7486, loss: 0.3267
2023-12-29 07:46:01,189 - mmseg - INFO - Iter [115400/160000]	lr: 1.673e-05, eta: 9:57:20, time: 0.839, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2033, decode.acc_seg: 91.3910, aux.loss_ce: 0.1078, aux.acc_seg: 89.1109, loss: 0.3111
2023-12-29 07:46:41,776 - mmseg - INFO - Iter [115450/160000]	lr: 1.671e-05, eta: 9:56:40, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2032, decode.acc_seg: 91.2654, aux.loss_ce: 0.1055, aux.acc_seg: 89.2205, loss: 0.3087
2023-12-29 07:47:22,276 - mmseg - INFO - Iter [115500/160000]	lr: 1.669e-05, eta: 9:56:00, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2154, decode.acc_seg: 90.8253, aux.loss_ce: 0.1106, aux.acc_seg: 88.7535, loss: 0.3260
2023-12-29 07:48:03,242 - mmseg - INFO - Iter [115550/160000]	lr: 1.667e-05, eta: 9:55:20, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2020, decode.acc_seg: 91.1904, aux.loss_ce: 0.1076, aux.acc_seg: 89.1308, loss: 0.3095
2023-12-29 07:48:44,229 - mmseg - INFO - Iter [115600/160000]	lr: 1.665e-05, eta: 9:54:40, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2076, decode.acc_seg: 91.0602, aux.loss_ce: 0.1089, aux.acc_seg: 88.9633, loss: 0.3165
2023-12-29 07:49:25,117 - mmseg - INFO - Iter [115650/160000]	lr: 1.663e-05, eta: 9:54:00, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2052, decode.acc_seg: 91.6205, aux.loss_ce: 0.1066, aux.acc_seg: 89.5939, loss: 0.3119
2023-12-29 07:50:05,240 - mmseg - INFO - Iter [115700/160000]	lr: 1.661e-05, eta: 9:53:20, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1964, decode.acc_seg: 91.6174, aux.loss_ce: 0.1028, aux.acc_seg: 89.6420, loss: 0.2992
2023-12-29 07:50:45,122 - mmseg - INFO - Iter [115750/160000]	lr: 1.659e-05, eta: 9:52:40, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2021, decode.acc_seg: 91.5987, aux.loss_ce: 0.1069, aux.acc_seg: 89.4037, loss: 0.3090
2023-12-29 07:51:25,854 - mmseg - INFO - Iter [115800/160000]	lr: 1.658e-05, eta: 9:52:00, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2075, decode.acc_seg: 91.2238, aux.loss_ce: 0.1087, aux.acc_seg: 89.1539, loss: 0.3162
2023-12-29 07:52:05,878 - mmseg - INFO - Iter [115850/160000]	lr: 1.656e-05, eta: 9:51:20, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1965, decode.acc_seg: 91.7529, aux.loss_ce: 0.1046, aux.acc_seg: 89.5626, loss: 0.3011
2023-12-29 07:52:45,119 - mmseg - INFO - Iter [115900/160000]	lr: 1.654e-05, eta: 9:50:39, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1998, decode.acc_seg: 91.5183, aux.loss_ce: 0.1038, aux.acc_seg: 89.6672, loss: 0.3036
2023-12-29 07:53:23,869 - mmseg - INFO - Iter [115950/160000]	lr: 1.652e-05, eta: 9:49:58, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2021, decode.acc_seg: 91.5940, aux.loss_ce: 0.1081, aux.acc_seg: 89.4225, loss: 0.3102
2023-12-29 07:54:05,288 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 07:54:05,289 - mmseg - INFO - Iter [116000/160000]	lr: 1.650e-05, eta: 9:49:19, time: 0.829, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2024, decode.acc_seg: 91.6035, aux.loss_ce: 0.1067, aux.acc_seg: 89.4608, loss: 0.3091
2023-12-29 07:54:45,648 - mmseg - INFO - Iter [116050/160000]	lr: 1.648e-05, eta: 9:48:39, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2082, decode.acc_seg: 91.2180, aux.loss_ce: 0.1094, aux.acc_seg: 89.3207, loss: 0.3176
2023-12-29 07:55:26,364 - mmseg - INFO - Iter [116100/160000]	lr: 1.646e-05, eta: 9:47:59, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2057, decode.acc_seg: 91.3735, aux.loss_ce: 0.1069, aux.acc_seg: 89.3012, loss: 0.3126
2023-12-29 07:56:07,588 - mmseg - INFO - Iter [116150/160000]	lr: 1.644e-05, eta: 9:47:19, time: 0.825, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2036, decode.acc_seg: 91.4284, aux.loss_ce: 0.1060, aux.acc_seg: 89.4234, loss: 0.3096
2023-12-29 07:56:48,033 - mmseg - INFO - Iter [116200/160000]	lr: 1.643e-05, eta: 9:46:39, time: 0.810, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2016, decode.acc_seg: 91.6595, aux.loss_ce: 0.1034, aux.acc_seg: 89.7084, loss: 0.3050
2023-12-29 07:57:28,415 - mmseg - INFO - Iter [116250/160000]	lr: 1.641e-05, eta: 9:45:59, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2122, decode.acc_seg: 91.1065, aux.loss_ce: 0.1125, aux.acc_seg: 88.8282, loss: 0.3247
2023-12-29 07:58:09,613 - mmseg - INFO - Iter [116300/160000]	lr: 1.639e-05, eta: 9:45:19, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2048, decode.acc_seg: 91.4380, aux.loss_ce: 0.1084, aux.acc_seg: 89.4070, loss: 0.3132
2023-12-29 07:58:48,483 - mmseg - INFO - Iter [116350/160000]	lr: 1.637e-05, eta: 9:44:38, time: 0.776, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2066, decode.acc_seg: 91.3096, aux.loss_ce: 0.1102, aux.acc_seg: 89.0531, loss: 0.3167
2023-12-29 07:59:29,823 - mmseg - INFO - Iter [116400/160000]	lr: 1.635e-05, eta: 9:43:58, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2016, decode.acc_seg: 91.4877, aux.loss_ce: 0.1047, aux.acc_seg: 89.3624, loss: 0.3064
2023-12-29 08:00:10,574 - mmseg - INFO - Iter [116450/160000]	lr: 1.633e-05, eta: 9:43:18, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1947, decode.acc_seg: 91.8678, aux.loss_ce: 0.1019, aux.acc_seg: 89.9378, loss: 0.2966
2023-12-29 08:00:52,107 - mmseg - INFO - Iter [116500/160000]	lr: 1.631e-05, eta: 9:42:39, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2123, decode.acc_seg: 91.0720, aux.loss_ce: 0.1101, aux.acc_seg: 89.0548, loss: 0.3224
2023-12-29 08:01:33,139 - mmseg - INFO - Iter [116550/160000]	lr: 1.629e-05, eta: 9:41:59, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2042, decode.acc_seg: 91.3496, aux.loss_ce: 0.1073, aux.acc_seg: 89.4236, loss: 0.3116
2023-12-29 08:02:13,418 - mmseg - INFO - Iter [116600/160000]	lr: 1.628e-05, eta: 9:41:19, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2067, decode.acc_seg: 91.3205, aux.loss_ce: 0.1077, aux.acc_seg: 89.2179, loss: 0.3144
2023-12-29 08:02:50,612 - mmseg - INFO - Iter [116650/160000]	lr: 1.626e-05, eta: 9:40:37, time: 0.744, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.2154, aux.loss_ce: 0.1046, aux.acc_seg: 89.2654, loss: 0.3074
2023-12-29 08:03:31,521 - mmseg - INFO - Iter [116700/160000]	lr: 1.624e-05, eta: 9:39:58, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1937, decode.acc_seg: 92.0091, aux.loss_ce: 0.1053, aux.acc_seg: 89.6864, loss: 0.2990
2023-12-29 08:04:12,988 - mmseg - INFO - Iter [116750/160000]	lr: 1.622e-05, eta: 9:39:18, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2078, decode.acc_seg: 91.1541, aux.loss_ce: 0.1099, aux.acc_seg: 88.9545, loss: 0.3177
2023-12-29 08:04:54,187 - mmseg - INFO - Iter [116800/160000]	lr: 1.620e-05, eta: 9:38:38, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2025, decode.acc_seg: 91.4507, aux.loss_ce: 0.1038, aux.acc_seg: 89.5448, loss: 0.3063
2023-12-29 08:05:32,719 - mmseg - INFO - Iter [116850/160000]	lr: 1.618e-05, eta: 9:37:57, time: 0.772, data_time: 0.015, memory: 18256, decode.loss_ce: 0.2002, decode.acc_seg: 91.6707, aux.loss_ce: 0.1037, aux.acc_seg: 89.7373, loss: 0.3039
2023-12-29 08:06:11,760 - mmseg - INFO - Iter [116900/160000]	lr: 1.616e-05, eta: 9:37:17, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1874, decode.acc_seg: 91.8990, aux.loss_ce: 0.0986, aux.acc_seg: 90.0327, loss: 0.2860
2023-12-29 08:06:50,752 - mmseg - INFO - Iter [116950/160000]	lr: 1.614e-05, eta: 9:36:36, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2069, decode.acc_seg: 91.1798, aux.loss_ce: 0.1086, aux.acc_seg: 89.0675, loss: 0.3155
2023-12-29 08:07:30,900 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 08:07:30,900 - mmseg - INFO - Iter [117000/160000]	lr: 1.613e-05, eta: 9:35:56, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2080, decode.acc_seg: 91.2141, aux.loss_ce: 0.1100, aux.acc_seg: 89.0181, loss: 0.3180
2023-12-29 08:08:12,697 - mmseg - INFO - Iter [117050/160000]	lr: 1.611e-05, eta: 9:35:16, time: 0.835, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2020, decode.acc_seg: 91.4421, aux.loss_ce: 0.1073, aux.acc_seg: 89.3465, loss: 0.3092
2023-12-29 08:08:53,305 - mmseg - INFO - Iter [117100/160000]	lr: 1.609e-05, eta: 9:34:36, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2143, decode.acc_seg: 91.0389, aux.loss_ce: 0.1086, aux.acc_seg: 89.2102, loss: 0.3229
2023-12-29 08:09:34,476 - mmseg - INFO - Iter [117150/160000]	lr: 1.607e-05, eta: 9:33:56, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2109, decode.acc_seg: 90.8688, aux.loss_ce: 0.1082, aux.acc_seg: 88.8973, loss: 0.3191
2023-12-29 08:10:14,046 - mmseg - INFO - Iter [117200/160000]	lr: 1.605e-05, eta: 9:33:16, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2070, decode.acc_seg: 91.3718, aux.loss_ce: 0.1057, aux.acc_seg: 89.2463, loss: 0.3127
2023-12-29 08:10:54,667 - mmseg - INFO - Iter [117250/160000]	lr: 1.603e-05, eta: 9:32:36, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2049, decode.acc_seg: 91.5461, aux.loss_ce: 0.1080, aux.acc_seg: 89.2077, loss: 0.3129
2023-12-29 08:11:36,262 - mmseg - INFO - Iter [117300/160000]	lr: 1.601e-05, eta: 9:31:56, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2030, decode.acc_seg: 91.1480, aux.loss_ce: 0.1075, aux.acc_seg: 88.9107, loss: 0.3105
2023-12-29 08:12:16,111 - mmseg - INFO - Iter [117350/160000]	lr: 1.599e-05, eta: 9:31:16, time: 0.798, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2019, decode.acc_seg: 91.4378, aux.loss_ce: 0.1055, aux.acc_seg: 89.3722, loss: 0.3075
2023-12-29 08:12:53,949 - mmseg - INFO - Iter [117400/160000]	lr: 1.598e-05, eta: 9:30:35, time: 0.757, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2126, decode.acc_seg: 90.9942, aux.loss_ce: 0.1112, aux.acc_seg: 88.9099, loss: 0.3238
2023-12-29 08:13:33,055 - mmseg - INFO - Iter [117450/160000]	lr: 1.596e-05, eta: 9:29:54, time: 0.781, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2108, decode.acc_seg: 91.3698, aux.loss_ce: 0.1131, aux.acc_seg: 88.8039, loss: 0.3238
2023-12-29 08:14:16,665 - mmseg - INFO - Iter [117500/160000]	lr: 1.594e-05, eta: 9:29:15, time: 0.872, data_time: 0.055, memory: 18256, decode.loss_ce: 0.2006, decode.acc_seg: 91.6391, aux.loss_ce: 0.1064, aux.acc_seg: 89.6159, loss: 0.3070
2023-12-29 08:14:56,008 - mmseg - INFO - Iter [117550/160000]	lr: 1.592e-05, eta: 9:28:35, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2021, decode.acc_seg: 91.4465, aux.loss_ce: 0.1089, aux.acc_seg: 89.0131, loss: 0.3110
2023-12-29 08:15:36,382 - mmseg - INFO - Iter [117600/160000]	lr: 1.590e-05, eta: 9:27:55, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1994, decode.acc_seg: 91.4694, aux.loss_ce: 0.1050, aux.acc_seg: 89.4534, loss: 0.3044
2023-12-29 08:16:16,530 - mmseg - INFO - Iter [117650/160000]	lr: 1.588e-05, eta: 9:27:15, time: 0.804, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1993, decode.acc_seg: 91.2868, aux.loss_ce: 0.1027, aux.acc_seg: 89.3236, loss: 0.3020
2023-12-29 08:16:58,301 - mmseg - INFO - Iter [117700/160000]	lr: 1.586e-05, eta: 9:26:35, time: 0.834, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1986, decode.acc_seg: 91.7515, aux.loss_ce: 0.1036, aux.acc_seg: 89.7158, loss: 0.3022
2023-12-29 08:17:38,483 - mmseg - INFO - Iter [117750/160000]	lr: 1.584e-05, eta: 9:25:55, time: 0.805, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2054, decode.acc_seg: 91.4863, aux.loss_ce: 0.1064, aux.acc_seg: 89.4899, loss: 0.3118
2023-12-29 08:18:20,396 - mmseg - INFO - Iter [117800/160000]	lr: 1.583e-05, eta: 9:25:15, time: 0.837, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2081, decode.acc_seg: 91.3832, aux.loss_ce: 0.1089, aux.acc_seg: 89.4091, loss: 0.3170
2023-12-29 08:19:01,166 - mmseg - INFO - Iter [117850/160000]	lr: 1.581e-05, eta: 9:24:35, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2113, decode.acc_seg: 91.3399, aux.loss_ce: 0.1113, aux.acc_seg: 89.2167, loss: 0.3225
2023-12-29 08:19:41,048 - mmseg - INFO - Iter [117900/160000]	lr: 1.579e-05, eta: 9:23:55, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2057, decode.acc_seg: 91.4813, aux.loss_ce: 0.1045, aux.acc_seg: 89.7802, loss: 0.3102
2023-12-29 08:20:22,087 - mmseg - INFO - Iter [117950/160000]	lr: 1.577e-05, eta: 9:23:15, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2050, decode.acc_seg: 91.3227, aux.loss_ce: 0.1071, aux.acc_seg: 89.2593, loss: 0.3122
2023-12-29 08:21:03,026 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 08:21:03,027 - mmseg - INFO - Iter [118000/160000]	lr: 1.575e-05, eta: 9:22:35, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2146, decode.acc_seg: 90.8538, aux.loss_ce: 0.1099, aux.acc_seg: 89.0961, loss: 0.3244
2023-12-29 08:21:43,285 - mmseg - INFO - Iter [118050/160000]	lr: 1.573e-05, eta: 9:21:55, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1896, decode.acc_seg: 91.9154, aux.loss_ce: 0.1000, aux.acc_seg: 89.7698, loss: 0.2897
2023-12-29 08:22:24,331 - mmseg - INFO - Iter [118100/160000]	lr: 1.571e-05, eta: 9:21:15, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2026, decode.acc_seg: 91.2431, aux.loss_ce: 0.1074, aux.acc_seg: 89.2011, loss: 0.3100
2023-12-29 08:23:05,011 - mmseg - INFO - Iter [118150/160000]	lr: 1.569e-05, eta: 9:20:35, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2091, decode.acc_seg: 91.0094, aux.loss_ce: 0.1085, aux.acc_seg: 89.0083, loss: 0.3175
2023-12-29 08:23:46,150 - mmseg - INFO - Iter [118200/160000]	lr: 1.568e-05, eta: 9:19:55, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2159, decode.acc_seg: 90.8867, aux.loss_ce: 0.1105, aux.acc_seg: 88.8987, loss: 0.3264
2023-12-29 08:24:29,908 - mmseg - INFO - Iter [118250/160000]	lr: 1.566e-05, eta: 9:19:16, time: 0.875, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1971, decode.acc_seg: 91.8179, aux.loss_ce: 0.1042, aux.acc_seg: 89.6735, loss: 0.3012
2023-12-29 08:25:13,385 - mmseg - INFO - Iter [118300/160000]	lr: 1.564e-05, eta: 9:18:37, time: 0.870, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1953, decode.acc_seg: 91.6028, aux.loss_ce: 0.1033, aux.acc_seg: 89.4816, loss: 0.2986
2023-12-29 08:25:54,581 - mmseg - INFO - Iter [118350/160000]	lr: 1.562e-05, eta: 9:17:58, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2077, decode.acc_seg: 91.3352, aux.loss_ce: 0.1090, aux.acc_seg: 89.2128, loss: 0.3168
2023-12-29 08:26:35,911 - mmseg - INFO - Iter [118400/160000]	lr: 1.560e-05, eta: 9:17:18, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2080, decode.acc_seg: 91.2543, aux.loss_ce: 0.1098, aux.acc_seg: 88.9497, loss: 0.3178
2023-12-29 08:27:17,111 - mmseg - INFO - Iter [118450/160000]	lr: 1.558e-05, eta: 9:16:38, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1937, decode.acc_seg: 91.8841, aux.loss_ce: 0.1016, aux.acc_seg: 89.8518, loss: 0.2953
2023-12-29 08:27:55,962 - mmseg - INFO - Iter [118500/160000]	lr: 1.556e-05, eta: 9:15:57, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2014, decode.acc_seg: 91.5210, aux.loss_ce: 0.1046, aux.acc_seg: 89.5839, loss: 0.3060
2023-12-29 08:28:35,924 - mmseg - INFO - Iter [118550/160000]	lr: 1.554e-05, eta: 9:15:17, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.4306, aux.loss_ce: 0.1068, aux.acc_seg: 89.3494, loss: 0.3095
2023-12-29 08:29:17,471 - mmseg - INFO - Iter [118600/160000]	lr: 1.553e-05, eta: 9:14:37, time: 0.831, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2216, decode.acc_seg: 90.7022, aux.loss_ce: 0.1141, aux.acc_seg: 88.6073, loss: 0.3357
2023-12-29 08:29:59,085 - mmseg - INFO - Iter [118650/160000]	lr: 1.551e-05, eta: 9:13:58, time: 0.833, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2095, decode.acc_seg: 91.3505, aux.loss_ce: 0.1090, aux.acc_seg: 89.2006, loss: 0.3184
2023-12-29 08:30:39,690 - mmseg - INFO - Iter [118700/160000]	lr: 1.549e-05, eta: 9:13:18, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2150, decode.acc_seg: 91.2172, aux.loss_ce: 0.1137, aux.acc_seg: 89.1126, loss: 0.3287
2023-12-29 08:31:21,864 - mmseg - INFO - Iter [118750/160000]	lr: 1.547e-05, eta: 9:12:38, time: 0.843, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2074, decode.acc_seg: 91.4461, aux.loss_ce: 0.1051, aux.acc_seg: 89.6570, loss: 0.3126
2023-12-29 08:32:02,997 - mmseg - INFO - Iter [118800/160000]	lr: 1.545e-05, eta: 9:11:58, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2017, decode.acc_seg: 91.5711, aux.loss_ce: 0.1073, aux.acc_seg: 89.0477, loss: 0.3091
2023-12-29 08:32:44,333 - mmseg - INFO - Iter [118850/160000]	lr: 1.543e-05, eta: 9:11:18, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1977, decode.acc_seg: 91.6003, aux.loss_ce: 0.1059, aux.acc_seg: 89.3895, loss: 0.3036
2023-12-29 08:33:25,581 - mmseg - INFO - Iter [118900/160000]	lr: 1.541e-05, eta: 9:10:39, time: 0.825, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.4068, aux.loss_ce: 0.1070, aux.acc_seg: 89.1416, loss: 0.3097
2023-12-29 08:34:06,650 - mmseg - INFO - Iter [118950/160000]	lr: 1.539e-05, eta: 9:09:59, time: 0.822, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1901, decode.acc_seg: 91.9407, aux.loss_ce: 0.1018, aux.acc_seg: 89.8518, loss: 0.2919
2023-12-29 08:34:46,754 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 08:34:46,754 - mmseg - INFO - Iter [119000/160000]	lr: 1.538e-05, eta: 9:09:18, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 91.4789, aux.loss_ce: 0.1033, aux.acc_seg: 89.3830, loss: 0.2998
2023-12-29 08:35:27,807 - mmseg - INFO - Iter [119050/160000]	lr: 1.536e-05, eta: 9:08:39, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1989, decode.acc_seg: 91.6450, aux.loss_ce: 0.1048, aux.acc_seg: 89.6091, loss: 0.3038
2023-12-29 08:36:08,500 - mmseg - INFO - Iter [119100/160000]	lr: 1.534e-05, eta: 9:07:58, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1995, decode.acc_seg: 91.4726, aux.loss_ce: 0.1058, aux.acc_seg: 89.4632, loss: 0.3054
2023-12-29 08:36:50,884 - mmseg - INFO - Iter [119150/160000]	lr: 1.532e-05, eta: 9:07:19, time: 0.847, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.3815, aux.loss_ce: 0.1085, aux.acc_seg: 89.1854, loss: 0.3112
2023-12-29 08:37:31,014 - mmseg - INFO - Iter [119200/160000]	lr: 1.530e-05, eta: 9:06:39, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2095, decode.acc_seg: 91.2385, aux.loss_ce: 0.1117, aux.acc_seg: 89.0624, loss: 0.3213
2023-12-29 08:38:12,152 - mmseg - INFO - Iter [119250/160000]	lr: 1.528e-05, eta: 9:05:59, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1904, decode.acc_seg: 91.9850, aux.loss_ce: 0.0994, aux.acc_seg: 90.1066, loss: 0.2899
2023-12-29 08:38:53,189 - mmseg - INFO - Iter [119300/160000]	lr: 1.526e-05, eta: 9:05:19, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2091, decode.acc_seg: 91.2368, aux.loss_ce: 0.1103, aux.acc_seg: 89.1133, loss: 0.3194
2023-12-29 08:39:31,079 - mmseg - INFO - Iter [119350/160000]	lr: 1.524e-05, eta: 9:04:38, time: 0.759, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2063, decode.acc_seg: 91.2635, aux.loss_ce: 0.1060, aux.acc_seg: 89.4262, loss: 0.3123
2023-12-29 08:40:09,157 - mmseg - INFO - Iter [119400/160000]	lr: 1.523e-05, eta: 9:03:57, time: 0.762, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2094, decode.acc_seg: 91.0798, aux.loss_ce: 0.1087, aux.acc_seg: 88.8053, loss: 0.3181
2023-12-29 08:40:49,438 - mmseg - INFO - Iter [119450/160000]	lr: 1.521e-05, eta: 9:03:17, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2038, decode.acc_seg: 91.4406, aux.loss_ce: 0.1061, aux.acc_seg: 89.2965, loss: 0.3100
2023-12-29 08:41:30,311 - mmseg - INFO - Iter [119500/160000]	lr: 1.519e-05, eta: 9:02:37, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 92.0591, aux.loss_ce: 0.0996, aux.acc_seg: 90.1607, loss: 0.2879
2023-12-29 08:42:10,516 - mmseg - INFO - Iter [119550/160000]	lr: 1.517e-05, eta: 9:01:57, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1972, decode.acc_seg: 91.5992, aux.loss_ce: 0.1058, aux.acc_seg: 89.1470, loss: 0.3030
2023-12-29 08:42:51,789 - mmseg - INFO - Iter [119600/160000]	lr: 1.515e-05, eta: 9:01:17, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2045, decode.acc_seg: 91.4134, aux.loss_ce: 0.1065, aux.acc_seg: 89.4673, loss: 0.3110
2023-12-29 08:43:32,983 - mmseg - INFO - Iter [119650/160000]	lr: 1.513e-05, eta: 9:00:37, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1984, decode.acc_seg: 91.4421, aux.loss_ce: 0.1051, aux.acc_seg: 89.2730, loss: 0.3034
2023-12-29 08:44:15,426 - mmseg - INFO - Iter [119700/160000]	lr: 1.511e-05, eta: 8:59:58, time: 0.849, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2063, decode.acc_seg: 91.3123, aux.loss_ce: 0.1098, aux.acc_seg: 89.0563, loss: 0.3161
2023-12-29 08:44:58,636 - mmseg - INFO - Iter [119750/160000]	lr: 1.509e-05, eta: 8:59:19, time: 0.864, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2053, decode.acc_seg: 91.5633, aux.loss_ce: 0.1072, aux.acc_seg: 89.6303, loss: 0.3125
2023-12-29 08:45:38,730 - mmseg - INFO - Iter [119800/160000]	lr: 1.508e-05, eta: 8:58:38, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2152, decode.acc_seg: 91.0471, aux.loss_ce: 0.1125, aux.acc_seg: 89.0011, loss: 0.3277
2023-12-29 08:46:18,230 - mmseg - INFO - Iter [119850/160000]	lr: 1.506e-05, eta: 8:57:58, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1960, decode.acc_seg: 91.6064, aux.loss_ce: 0.1036, aux.acc_seg: 89.4587, loss: 0.2995
2023-12-29 08:46:58,097 - mmseg - INFO - Iter [119900/160000]	lr: 1.504e-05, eta: 8:57:18, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2066, decode.acc_seg: 91.0587, aux.loss_ce: 0.1076, aux.acc_seg: 89.0948, loss: 0.3142
2023-12-29 08:47:38,581 - mmseg - INFO - Iter [119950/160000]	lr: 1.502e-05, eta: 8:56:37, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2186, decode.acc_seg: 90.8316, aux.loss_ce: 0.1158, aux.acc_seg: 88.4970, loss: 0.3344
2023-12-29 08:48:20,043 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 08:48:20,043 - mmseg - INFO - Iter [120000/160000]	lr: 1.500e-05, eta: 8:55:58, time: 0.828, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2110, decode.acc_seg: 91.3157, aux.loss_ce: 0.1089, aux.acc_seg: 89.3234, loss: 0.3199
2023-12-29 08:48:59,865 - mmseg - INFO - Iter [120050/160000]	lr: 1.498e-05, eta: 8:55:17, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2028, decode.acc_seg: 91.4239, aux.loss_ce: 0.1067, aux.acc_seg: 89.2455, loss: 0.3095
2023-12-29 08:49:41,344 - mmseg - INFO - Iter [120100/160000]	lr: 1.496e-05, eta: 8:54:38, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2071, decode.acc_seg: 91.3813, aux.loss_ce: 0.1097, aux.acc_seg: 89.1373, loss: 0.3168
2023-12-29 08:50:22,313 - mmseg - INFO - Iter [120150/160000]	lr: 1.494e-05, eta: 8:53:58, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2044, decode.acc_seg: 91.4669, aux.loss_ce: 0.1079, aux.acc_seg: 89.4625, loss: 0.3124
2023-12-29 08:51:02,959 - mmseg - INFO - Iter [120200/160000]	lr: 1.493e-05, eta: 8:53:18, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2049, decode.acc_seg: 91.3128, aux.loss_ce: 0.1059, aux.acc_seg: 89.2647, loss: 0.3108
2023-12-29 08:51:42,845 - mmseg - INFO - Iter [120250/160000]	lr: 1.491e-05, eta: 8:52:37, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1894, decode.acc_seg: 91.8255, aux.loss_ce: 0.0997, aux.acc_seg: 89.7139, loss: 0.2892
2023-12-29 08:52:23,412 - mmseg - INFO - Iter [120300/160000]	lr: 1.489e-05, eta: 8:51:57, time: 0.812, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1888, decode.acc_seg: 92.0488, aux.loss_ce: 0.0994, aux.acc_seg: 89.9894, loss: 0.2882
2023-12-29 08:53:04,097 - mmseg - INFO - Iter [120350/160000]	lr: 1.487e-05, eta: 8:51:17, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1913, decode.acc_seg: 92.0045, aux.loss_ce: 0.1011, aux.acc_seg: 89.9361, loss: 0.2923
2023-12-29 08:53:44,747 - mmseg - INFO - Iter [120400/160000]	lr: 1.485e-05, eta: 8:50:37, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2027, decode.acc_seg: 91.5789, aux.loss_ce: 0.1069, aux.acc_seg: 89.3417, loss: 0.3095
2023-12-29 08:54:25,877 - mmseg - INFO - Iter [120450/160000]	lr: 1.483e-05, eta: 8:49:57, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2208, decode.acc_seg: 90.8509, aux.loss_ce: 0.1125, aux.acc_seg: 88.7403, loss: 0.3332
2023-12-29 08:55:06,672 - mmseg - INFO - Iter [120500/160000]	lr: 1.481e-05, eta: 8:49:17, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2055, decode.acc_seg: 91.3923, aux.loss_ce: 0.1096, aux.acc_seg: 89.0772, loss: 0.3151
2023-12-29 08:55:46,710 - mmseg - INFO - Iter [120550/160000]	lr: 1.479e-05, eta: 8:48:37, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2031, decode.acc_seg: 91.6539, aux.loss_ce: 0.1040, aux.acc_seg: 89.6882, loss: 0.3071
2023-12-29 08:56:29,051 - mmseg - INFO - Iter [120600/160000]	lr: 1.478e-05, eta: 8:47:57, time: 0.847, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1951, decode.acc_seg: 91.5245, aux.loss_ce: 0.1032, aux.acc_seg: 89.2880, loss: 0.2984
2023-12-29 08:57:10,893 - mmseg - INFO - Iter [120650/160000]	lr: 1.476e-05, eta: 8:47:18, time: 0.838, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2033, decode.acc_seg: 91.4328, aux.loss_ce: 0.1079, aux.acc_seg: 89.3464, loss: 0.3112
2023-12-29 08:57:50,030 - mmseg - INFO - Iter [120700/160000]	lr: 1.474e-05, eta: 8:46:37, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2151, decode.acc_seg: 91.0312, aux.loss_ce: 0.1099, aux.acc_seg: 89.0720, loss: 0.3250
2023-12-29 08:58:31,095 - mmseg - INFO - Iter [120750/160000]	lr: 1.472e-05, eta: 8:45:57, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2064, decode.acc_seg: 91.4521, aux.loss_ce: 0.1066, aux.acc_seg: 89.3899, loss: 0.3131
2023-12-29 08:59:10,526 - mmseg - INFO - Iter [120800/160000]	lr: 1.470e-05, eta: 8:45:17, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2063, decode.acc_seg: 91.3214, aux.loss_ce: 0.1104, aux.acc_seg: 88.9235, loss: 0.3167
2023-12-29 08:59:52,084 - mmseg - INFO - Iter [120850/160000]	lr: 1.468e-05, eta: 8:44:37, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1987, decode.acc_seg: 91.8338, aux.loss_ce: 0.1057, aux.acc_seg: 89.7001, loss: 0.3045
2023-12-29 09:00:32,800 - mmseg - INFO - Iter [120900/160000]	lr: 1.466e-05, eta: 8:43:57, time: 0.814, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1982, decode.acc_seg: 91.5330, aux.loss_ce: 0.1060, aux.acc_seg: 89.2851, loss: 0.3043
2023-12-29 09:01:14,017 - mmseg - INFO - Iter [120950/160000]	lr: 1.464e-05, eta: 8:43:17, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1929, decode.acc_seg: 91.8316, aux.loss_ce: 0.1003, aux.acc_seg: 90.0416, loss: 0.2932
2023-12-29 09:01:54,534 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 09:01:54,535 - mmseg - INFO - Iter [121000/160000]	lr: 1.463e-05, eta: 8:42:37, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2081, decode.acc_seg: 91.1174, aux.loss_ce: 0.1113, aux.acc_seg: 88.7617, loss: 0.3194
2023-12-29 09:02:35,665 - mmseg - INFO - Iter [121050/160000]	lr: 1.461e-05, eta: 8:41:57, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2141, decode.acc_seg: 90.9236, aux.loss_ce: 0.1139, aux.acc_seg: 88.5914, loss: 0.3280
2023-12-29 09:03:14,495 - mmseg - INFO - Iter [121100/160000]	lr: 1.459e-05, eta: 8:41:17, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2117, decode.acc_seg: 90.8323, aux.loss_ce: 0.1095, aux.acc_seg: 88.7852, loss: 0.3212
2023-12-29 09:03:56,117 - mmseg - INFO - Iter [121150/160000]	lr: 1.457e-05, eta: 8:40:37, time: 0.832, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2018, decode.acc_seg: 91.1649, aux.loss_ce: 0.1062, aux.acc_seg: 89.2101, loss: 0.3080
2023-12-29 09:04:37,956 - mmseg - INFO - Iter [121200/160000]	lr: 1.455e-05, eta: 8:39:57, time: 0.835, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1999, decode.acc_seg: 91.2482, aux.loss_ce: 0.1058, aux.acc_seg: 89.2876, loss: 0.3057
2023-12-29 09:05:20,740 - mmseg - INFO - Iter [121250/160000]	lr: 1.453e-05, eta: 8:39:18, time: 0.856, data_time: 0.056, memory: 18256, decode.loss_ce: 0.1969, decode.acc_seg: 91.7553, aux.loss_ce: 0.1027, aux.acc_seg: 89.7480, loss: 0.2997
2023-12-29 09:06:04,035 - mmseg - INFO - Iter [121300/160000]	lr: 1.451e-05, eta: 8:38:39, time: 0.867, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2044, decode.acc_seg: 91.2838, aux.loss_ce: 0.1074, aux.acc_seg: 89.2100, loss: 0.3118
2023-12-29 09:06:45,480 - mmseg - INFO - Iter [121350/160000]	lr: 1.449e-05, eta: 8:37:59, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1971, decode.acc_seg: 91.6053, aux.loss_ce: 0.1039, aux.acc_seg: 89.3916, loss: 0.3010
2023-12-29 09:07:26,741 - mmseg - INFO - Iter [121400/160000]	lr: 1.448e-05, eta: 8:37:19, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2061, decode.acc_seg: 91.4564, aux.loss_ce: 0.1072, aux.acc_seg: 89.5380, loss: 0.3133
2023-12-29 09:08:07,790 - mmseg - INFO - Iter [121450/160000]	lr: 1.446e-05, eta: 8:36:39, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1963, decode.acc_seg: 91.5360, aux.loss_ce: 0.1029, aux.acc_seg: 89.5222, loss: 0.2992
2023-12-29 09:08:49,013 - mmseg - INFO - Iter [121500/160000]	lr: 1.444e-05, eta: 8:35:59, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2014, decode.acc_seg: 91.4658, aux.loss_ce: 0.1060, aux.acc_seg: 89.3384, loss: 0.3074
2023-12-29 09:09:30,591 - mmseg - INFO - Iter [121550/160000]	lr: 1.442e-05, eta: 8:35:19, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1993, decode.acc_seg: 91.7104, aux.loss_ce: 0.1051, aux.acc_seg: 89.5933, loss: 0.3044
2023-12-29 09:10:11,208 - mmseg - INFO - Iter [121600/160000]	lr: 1.440e-05, eta: 8:34:39, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1897, decode.acc_seg: 92.0236, aux.loss_ce: 0.0998, aux.acc_seg: 89.9909, loss: 0.2895
2023-12-29 09:10:51,875 - mmseg - INFO - Iter [121650/160000]	lr: 1.438e-05, eta: 8:33:59, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1988, decode.acc_seg: 91.7292, aux.loss_ce: 0.1033, aux.acc_seg: 89.6845, loss: 0.3021
2023-12-29 09:11:30,707 - mmseg - INFO - Iter [121700/160000]	lr: 1.436e-05, eta: 8:33:18, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1911, decode.acc_seg: 91.9470, aux.loss_ce: 0.1010, aux.acc_seg: 89.9457, loss: 0.2921
2023-12-29 09:12:12,386 - mmseg - INFO - Iter [121750/160000]	lr: 1.434e-05, eta: 8:32:39, time: 0.833, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1984, decode.acc_seg: 91.6483, aux.loss_ce: 0.1052, aux.acc_seg: 89.4874, loss: 0.3035
2023-12-29 09:12:53,611 - mmseg - INFO - Iter [121800/160000]	lr: 1.433e-05, eta: 8:31:59, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1970, decode.acc_seg: 91.5283, aux.loss_ce: 0.1036, aux.acc_seg: 89.5490, loss: 0.3006
2023-12-29 09:13:34,307 - mmseg - INFO - Iter [121850/160000]	lr: 1.431e-05, eta: 8:31:19, time: 0.813, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1964, decode.acc_seg: 91.8433, aux.loss_ce: 0.1074, aux.acc_seg: 89.3576, loss: 0.3038
2023-12-29 09:14:15,337 - mmseg - INFO - Iter [121900/160000]	lr: 1.429e-05, eta: 8:30:39, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2028, decode.acc_seg: 91.4336, aux.loss_ce: 0.1083, aux.acc_seg: 89.1303, loss: 0.3111
2023-12-29 09:14:55,369 - mmseg - INFO - Iter [121950/160000]	lr: 1.427e-05, eta: 8:29:59, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2058, decode.acc_seg: 91.3340, aux.loss_ce: 0.1080, aux.acc_seg: 89.1649, loss: 0.3138
2023-12-29 09:15:36,288 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 09:15:36,288 - mmseg - INFO - Iter [122000/160000]	lr: 1.425e-05, eta: 8:29:19, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1870, decode.acc_seg: 91.7949, aux.loss_ce: 0.1018, aux.acc_seg: 89.4925, loss: 0.2888
2023-12-29 09:16:16,149 - mmseg - INFO - Iter [122050/160000]	lr: 1.423e-05, eta: 8:28:38, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2007, decode.acc_seg: 91.6406, aux.loss_ce: 0.1068, aux.acc_seg: 89.4909, loss: 0.3075
2023-12-29 09:16:56,142 - mmseg - INFO - Iter [122100/160000]	lr: 1.421e-05, eta: 8:27:58, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1921, decode.acc_seg: 91.8098, aux.loss_ce: 0.1019, aux.acc_seg: 89.7066, loss: 0.2940
2023-12-29 09:17:36,879 - mmseg - INFO - Iter [122150/160000]	lr: 1.419e-05, eta: 8:27:18, time: 0.815, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 91.8871, aux.loss_ce: 0.1006, aux.acc_seg: 89.7192, loss: 0.2887
2023-12-29 09:18:18,227 - mmseg - INFO - Iter [122200/160000]	lr: 1.418e-05, eta: 8:26:38, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2078, decode.acc_seg: 91.5781, aux.loss_ce: 0.1108, aux.acc_seg: 89.2140, loss: 0.3186
2023-12-29 09:18:58,622 - mmseg - INFO - Iter [122250/160000]	lr: 1.416e-05, eta: 8:25:58, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1992, decode.acc_seg: 91.6077, aux.loss_ce: 0.1055, aux.acc_seg: 89.4705, loss: 0.3047
2023-12-29 09:19:38,679 - mmseg - INFO - Iter [122300/160000]	lr: 1.414e-05, eta: 8:25:18, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2059, decode.acc_seg: 91.4074, aux.loss_ce: 0.1060, aux.acc_seg: 89.5233, loss: 0.3119
2023-12-29 09:20:21,823 - mmseg - INFO - Iter [122350/160000]	lr: 1.412e-05, eta: 8:24:38, time: 0.863, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2108, decode.acc_seg: 91.1681, aux.loss_ce: 0.1117, aux.acc_seg: 89.0290, loss: 0.3226
2023-12-29 09:21:04,468 - mmseg - INFO - Iter [122400/160000]	lr: 1.410e-05, eta: 8:23:59, time: 0.853, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1928, decode.acc_seg: 91.7169, aux.loss_ce: 0.1024, aux.acc_seg: 89.5041, loss: 0.2953
2023-12-29 09:21:44,978 - mmseg - INFO - Iter [122450/160000]	lr: 1.408e-05, eta: 8:23:19, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2119, decode.acc_seg: 91.3227, aux.loss_ce: 0.1090, aux.acc_seg: 89.3054, loss: 0.3210
2023-12-29 09:22:25,841 - mmseg - INFO - Iter [122500/160000]	lr: 1.406e-05, eta: 8:22:39, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2035, decode.acc_seg: 91.3313, aux.loss_ce: 0.1040, aux.acc_seg: 89.3732, loss: 0.3075
2023-12-29 09:23:07,314 - mmseg - INFO - Iter [122550/160000]	lr: 1.404e-05, eta: 8:21:59, time: 0.829, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1957, decode.acc_seg: 91.8428, aux.loss_ce: 0.1067, aux.acc_seg: 89.2995, loss: 0.3024
2023-12-29 09:23:47,972 - mmseg - INFO - Iter [122600/160000]	lr: 1.403e-05, eta: 8:21:19, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1910, decode.acc_seg: 91.8783, aux.loss_ce: 0.0992, aux.acc_seg: 89.9489, loss: 0.2901
2023-12-29 09:24:28,919 - mmseg - INFO - Iter [122650/160000]	lr: 1.401e-05, eta: 8:20:39, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2060, decode.acc_seg: 91.3222, aux.loss_ce: 0.1077, aux.acc_seg: 89.2706, loss: 0.3137
2023-12-29 09:25:10,050 - mmseg - INFO - Iter [122700/160000]	lr: 1.399e-05, eta: 8:19:59, time: 0.821, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2037, decode.acc_seg: 91.5082, aux.loss_ce: 0.1055, aux.acc_seg: 89.5226, loss: 0.3093
2023-12-29 09:25:51,534 - mmseg - INFO - Iter [122750/160000]	lr: 1.397e-05, eta: 8:19:19, time: 0.830, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1964, decode.acc_seg: 91.7774, aux.loss_ce: 0.1036, aux.acc_seg: 89.5960, loss: 0.2999
2023-12-29 09:26:31,302 - mmseg - INFO - Iter [122800/160000]	lr: 1.395e-05, eta: 8:18:39, time: 0.795, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2057, decode.acc_seg: 91.5581, aux.loss_ce: 0.1081, aux.acc_seg: 89.4525, loss: 0.3137
2023-12-29 09:27:12,904 - mmseg - INFO - Iter [122850/160000]	lr: 1.393e-05, eta: 8:17:59, time: 0.832, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2093, decode.acc_seg: 91.0448, aux.loss_ce: 0.1090, aux.acc_seg: 89.0318, loss: 0.3183
2023-12-29 09:27:53,710 - mmseg - INFO - Iter [122900/160000]	lr: 1.391e-05, eta: 8:17:19, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1913, decode.acc_seg: 91.8713, aux.loss_ce: 0.1015, aux.acc_seg: 89.9314, loss: 0.2928
2023-12-29 09:28:32,960 - mmseg - INFO - Iter [122950/160000]	lr: 1.389e-05, eta: 8:16:38, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2007, decode.acc_seg: 91.4607, aux.loss_ce: 0.1049, aux.acc_seg: 89.4607, loss: 0.3056
2023-12-29 09:29:14,128 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 09:29:14,129 - mmseg - INFO - Iter [123000/160000]	lr: 1.388e-05, eta: 8:15:59, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1941, decode.acc_seg: 91.8821, aux.loss_ce: 0.1014, aux.acc_seg: 89.9158, loss: 0.2956
2023-12-29 09:29:55,385 - mmseg - INFO - Iter [123050/160000]	lr: 1.386e-05, eta: 8:15:19, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2039, decode.acc_seg: 91.4077, aux.loss_ce: 0.1073, aux.acc_seg: 89.2413, loss: 0.3112
2023-12-29 09:30:38,833 - mmseg - INFO - Iter [123100/160000]	lr: 1.384e-05, eta: 8:14:39, time: 0.869, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1975, decode.acc_seg: 91.4686, aux.loss_ce: 0.1025, aux.acc_seg: 89.7284, loss: 0.2999
2023-12-29 09:31:21,317 - mmseg - INFO - Iter [123150/160000]	lr: 1.382e-05, eta: 8:14:00, time: 0.850, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1934, decode.acc_seg: 91.8860, aux.loss_ce: 0.1030, aux.acc_seg: 89.7165, loss: 0.2964
2023-12-29 09:32:02,520 - mmseg - INFO - Iter [123200/160000]	lr: 1.380e-05, eta: 8:13:20, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1998, decode.acc_seg: 91.6668, aux.loss_ce: 0.1041, aux.acc_seg: 89.6593, loss: 0.3039
2023-12-29 09:32:44,736 - mmseg - INFO - Iter [123250/160000]	lr: 1.378e-05, eta: 8:12:40, time: 0.845, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2076, decode.acc_seg: 91.2644, aux.loss_ce: 0.1080, aux.acc_seg: 89.2965, loss: 0.3156
2023-12-29 09:33:26,563 - mmseg - INFO - Iter [123300/160000]	lr: 1.376e-05, eta: 8:12:01, time: 0.835, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1928, decode.acc_seg: 91.8537, aux.loss_ce: 0.1045, aux.acc_seg: 89.6847, loss: 0.2973
2023-12-29 09:34:07,247 - mmseg - INFO - Iter [123350/160000]	lr: 1.374e-05, eta: 8:11:20, time: 0.814, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2034, decode.acc_seg: 91.4170, aux.loss_ce: 0.1053, aux.acc_seg: 89.3594, loss: 0.3088
2023-12-29 09:34:45,412 - mmseg - INFO - Iter [123400/160000]	lr: 1.373e-05, eta: 8:10:40, time: 0.764, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2065, decode.acc_seg: 91.4364, aux.loss_ce: 0.1069, aux.acc_seg: 89.3574, loss: 0.3134
2023-12-29 09:35:26,217 - mmseg - INFO - Iter [123450/160000]	lr: 1.371e-05, eta: 8:10:00, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2011, decode.acc_seg: 91.5321, aux.loss_ce: 0.1077, aux.acc_seg: 89.1985, loss: 0.3088
2023-12-29 09:36:05,803 - mmseg - INFO - Iter [123500/160000]	lr: 1.369e-05, eta: 8:09:19, time: 0.792, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2083, decode.acc_seg: 91.2505, aux.loss_ce: 0.1075, aux.acc_seg: 89.3302, loss: 0.3157
2023-12-29 09:36:46,488 - mmseg - INFO - Iter [123550/160000]	lr: 1.367e-05, eta: 8:08:39, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1906, decode.acc_seg: 91.8956, aux.loss_ce: 0.1013, aux.acc_seg: 89.6838, loss: 0.2920
2023-12-29 09:37:25,326 - mmseg - INFO - Iter [123600/160000]	lr: 1.365e-05, eta: 8:07:58, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1947, decode.acc_seg: 91.5927, aux.loss_ce: 0.1052, aux.acc_seg: 89.2996, loss: 0.2999
2023-12-29 09:38:03,923 - mmseg - INFO - Iter [123650/160000]	lr: 1.363e-05, eta: 8:07:18, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2021, decode.acc_seg: 91.6904, aux.loss_ce: 0.1059, aux.acc_seg: 89.7721, loss: 0.3080
2023-12-29 09:38:42,783 - mmseg - INFO - Iter [123700/160000]	lr: 1.361e-05, eta: 8:06:37, time: 0.777, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1992, decode.acc_seg: 91.5694, aux.loss_ce: 0.1077, aux.acc_seg: 89.3714, loss: 0.3069
2023-12-29 09:39:23,472 - mmseg - INFO - Iter [123750/160000]	lr: 1.359e-05, eta: 8:05:57, time: 0.815, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2013, decode.acc_seg: 91.5043, aux.loss_ce: 0.1066, aux.acc_seg: 89.5737, loss: 0.3078
2023-12-29 09:40:05,259 - mmseg - INFO - Iter [123800/160000]	lr: 1.358e-05, eta: 8:05:17, time: 0.836, data_time: 0.053, memory: 18256, decode.loss_ce: 0.2038, decode.acc_seg: 91.3625, aux.loss_ce: 0.1068, aux.acc_seg: 89.2401, loss: 0.3106
2023-12-29 09:40:45,616 - mmseg - INFO - Iter [123850/160000]	lr: 1.356e-05, eta: 8:04:37, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1931, decode.acc_seg: 91.6917, aux.loss_ce: 0.1018, aux.acc_seg: 89.6762, loss: 0.2949
2023-12-29 09:41:27,003 - mmseg - INFO - Iter [123900/160000]	lr: 1.354e-05, eta: 8:03:57, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1997, decode.acc_seg: 91.5230, aux.loss_ce: 0.1064, aux.acc_seg: 89.2997, loss: 0.3062
2023-12-29 09:42:07,806 - mmseg - INFO - Iter [123950/160000]	lr: 1.352e-05, eta: 8:03:17, time: 0.815, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2029, decode.acc_seg: 91.4421, aux.loss_ce: 0.1073, aux.acc_seg: 89.3644, loss: 0.3102
2023-12-29 09:42:46,584 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 09:42:46,585 - mmseg - INFO - Iter [124000/160000]	lr: 1.350e-05, eta: 8:02:37, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1969, decode.acc_seg: 91.7654, aux.loss_ce: 0.1046, aux.acc_seg: 89.6705, loss: 0.3015
2023-12-29 09:43:27,977 - mmseg - INFO - Iter [124050/160000]	lr: 1.348e-05, eta: 8:01:57, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2101, decode.acc_seg: 91.0381, aux.loss_ce: 0.1096, aux.acc_seg: 89.0828, loss: 0.3197
2023-12-29 09:44:10,103 - mmseg - INFO - Iter [124100/160000]	lr: 1.346e-05, eta: 8:01:17, time: 0.842, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2010, decode.acc_seg: 91.6243, aux.loss_ce: 0.1085, aux.acc_seg: 89.5028, loss: 0.3095
2023-12-29 09:44:52,184 - mmseg - INFO - Iter [124150/160000]	lr: 1.344e-05, eta: 8:00:37, time: 0.843, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1957, decode.acc_seg: 91.8386, aux.loss_ce: 0.1035, aux.acc_seg: 89.7857, loss: 0.2992
2023-12-29 09:45:31,658 - mmseg - INFO - Iter [124200/160000]	lr: 1.343e-05, eta: 7:59:57, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1947, decode.acc_seg: 91.7092, aux.loss_ce: 0.1018, aux.acc_seg: 89.7086, loss: 0.2966
2023-12-29 09:46:13,122 - mmseg - INFO - Iter [124250/160000]	lr: 1.341e-05, eta: 7:59:17, time: 0.829, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1900, decode.acc_seg: 91.9093, aux.loss_ce: 0.1014, aux.acc_seg: 89.8119, loss: 0.2914
2023-12-29 09:46:54,310 - mmseg - INFO - Iter [124300/160000]	lr: 1.339e-05, eta: 7:58:37, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1944, decode.acc_seg: 91.6473, aux.loss_ce: 0.1043, aux.acc_seg: 89.4082, loss: 0.2987
2023-12-29 09:47:33,340 - mmseg - INFO - Iter [124350/160000]	lr: 1.337e-05, eta: 7:57:57, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1942, decode.acc_seg: 91.6670, aux.loss_ce: 0.1019, aux.acc_seg: 89.5993, loss: 0.2961
2023-12-29 09:48:15,516 - mmseg - INFO - Iter [124400/160000]	lr: 1.335e-05, eta: 7:57:17, time: 0.843, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1967, decode.acc_seg: 91.8310, aux.loss_ce: 0.1032, aux.acc_seg: 89.8189, loss: 0.2999
2023-12-29 09:48:57,053 - mmseg - INFO - Iter [124450/160000]	lr: 1.333e-05, eta: 7:56:37, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1946, decode.acc_seg: 91.8480, aux.loss_ce: 0.1043, aux.acc_seg: 89.7288, loss: 0.2989
2023-12-29 09:49:37,347 - mmseg - INFO - Iter [124500/160000]	lr: 1.331e-05, eta: 7:55:57, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1972, decode.acc_seg: 91.6191, aux.loss_ce: 0.1052, aux.acc_seg: 89.5693, loss: 0.3024
2023-12-29 09:50:18,526 - mmseg - INFO - Iter [124550/160000]	lr: 1.329e-05, eta: 7:55:17, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2012, decode.acc_seg: 91.4627, aux.loss_ce: 0.1055, aux.acc_seg: 89.4678, loss: 0.3067
2023-12-29 09:50:59,788 - mmseg - INFO - Iter [124600/160000]	lr: 1.328e-05, eta: 7:54:37, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1915, decode.acc_seg: 91.9275, aux.loss_ce: 0.1001, aux.acc_seg: 89.9097, loss: 0.2916
2023-12-29 09:51:39,661 - mmseg - INFO - Iter [124650/160000]	lr: 1.326e-05, eta: 7:53:57, time: 0.798, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1889, decode.acc_seg: 92.0444, aux.loss_ce: 0.0989, aux.acc_seg: 90.0580, loss: 0.2878
2023-12-29 09:52:20,723 - mmseg - INFO - Iter [124700/160000]	lr: 1.324e-05, eta: 7:53:17, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1836, decode.acc_seg: 92.1940, aux.loss_ce: 0.0993, aux.acc_seg: 89.8971, loss: 0.2829
2023-12-29 09:52:57,907 - mmseg - INFO - Iter [124750/160000]	lr: 1.322e-05, eta: 7:52:36, time: 0.744, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1893, decode.acc_seg: 91.9409, aux.loss_ce: 0.0997, aux.acc_seg: 90.0072, loss: 0.2889
2023-12-29 09:53:37,169 - mmseg - INFO - Iter [124800/160000]	lr: 1.320e-05, eta: 7:51:55, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 91.8333, aux.loss_ce: 0.1016, aux.acc_seg: 89.7351, loss: 0.2928
2023-12-29 09:54:16,796 - mmseg - INFO - Iter [124850/160000]	lr: 1.318e-05, eta: 7:51:15, time: 0.793, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2004, decode.acc_seg: 91.4899, aux.loss_ce: 0.1059, aux.acc_seg: 89.4815, loss: 0.3062
2023-12-29 09:54:57,366 - mmseg - INFO - Iter [124900/160000]	lr: 1.316e-05, eta: 7:50:35, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2020, decode.acc_seg: 91.3625, aux.loss_ce: 0.1056, aux.acc_seg: 89.6739, loss: 0.3077
2023-12-29 09:55:38,128 - mmseg - INFO - Iter [124950/160000]	lr: 1.314e-05, eta: 7:49:55, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2148, decode.acc_seg: 91.1149, aux.loss_ce: 0.1111, aux.acc_seg: 88.9968, loss: 0.3259
2023-12-29 09:56:18,798 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 09:56:18,799 - mmseg - INFO - Iter [125000/160000]	lr: 1.313e-05, eta: 7:49:14, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2018, decode.acc_seg: 91.4572, aux.loss_ce: 0.1067, aux.acc_seg: 89.2493, loss: 0.3086
2023-12-29 09:57:00,941 - mmseg - INFO - Iter [125050/160000]	lr: 1.311e-05, eta: 7:48:35, time: 0.842, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1946, decode.acc_seg: 91.7785, aux.loss_ce: 0.1012, aux.acc_seg: 90.0929, loss: 0.2958
2023-12-29 09:57:42,043 - mmseg - INFO - Iter [125100/160000]	lr: 1.309e-05, eta: 7:47:55, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2088, decode.acc_seg: 91.1363, aux.loss_ce: 0.1096, aux.acc_seg: 88.8973, loss: 0.3184
2023-12-29 09:58:21,143 - mmseg - INFO - Iter [125150/160000]	lr: 1.307e-05, eta: 7:47:14, time: 0.782, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2020, decode.acc_seg: 91.5513, aux.loss_ce: 0.1065, aux.acc_seg: 89.3393, loss: 0.3086
2023-12-29 09:59:01,887 - mmseg - INFO - Iter [125200/160000]	lr: 1.305e-05, eta: 7:46:34, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1982, decode.acc_seg: 91.6198, aux.loss_ce: 0.1034, aux.acc_seg: 89.6056, loss: 0.3016
2023-12-29 09:59:40,035 - mmseg - INFO - Iter [125250/160000]	lr: 1.303e-05, eta: 7:45:53, time: 0.763, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1918, decode.acc_seg: 91.8980, aux.loss_ce: 0.1033, aux.acc_seg: 89.6308, loss: 0.2951
2023-12-29 10:00:21,046 - mmseg - INFO - Iter [125300/160000]	lr: 1.301e-05, eta: 7:45:13, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2017, decode.acc_seg: 91.5458, aux.loss_ce: 0.1056, aux.acc_seg: 89.5352, loss: 0.3072
2023-12-29 10:01:01,866 - mmseg - INFO - Iter [125350/160000]	lr: 1.299e-05, eta: 7:44:33, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1982, decode.acc_seg: 91.4754, aux.loss_ce: 0.1047, aux.acc_seg: 89.4517, loss: 0.3029
2023-12-29 10:01:42,937 - mmseg - INFO - Iter [125400/160000]	lr: 1.298e-05, eta: 7:43:53, time: 0.822, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1935, decode.acc_seg: 91.8136, aux.loss_ce: 0.1026, aux.acc_seg: 89.6623, loss: 0.2960
2023-12-29 10:02:22,342 - mmseg - INFO - Iter [125450/160000]	lr: 1.296e-05, eta: 7:43:13, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2050, decode.acc_seg: 91.4037, aux.loss_ce: 0.1067, aux.acc_seg: 89.3747, loss: 0.3117
2023-12-29 10:03:03,258 - mmseg - INFO - Iter [125500/160000]	lr: 1.294e-05, eta: 7:42:33, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2032, decode.acc_seg: 91.6460, aux.loss_ce: 0.1067, aux.acc_seg: 89.3298, loss: 0.3098
2023-12-29 10:03:44,334 - mmseg - INFO - Iter [125550/160000]	lr: 1.292e-05, eta: 7:41:53, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2036, decode.acc_seg: 91.5566, aux.loss_ce: 0.1079, aux.acc_seg: 89.5294, loss: 0.3115
2023-12-29 10:04:23,186 - mmseg - INFO - Iter [125600/160000]	lr: 1.290e-05, eta: 7:41:12, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1994, decode.acc_seg: 91.6366, aux.loss_ce: 0.1070, aux.acc_seg: 89.4492, loss: 0.3065
2023-12-29 10:05:02,629 - mmseg - INFO - Iter [125650/160000]	lr: 1.288e-05, eta: 7:40:32, time: 0.789, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2096, decode.acc_seg: 91.2584, aux.loss_ce: 0.1095, aux.acc_seg: 89.2208, loss: 0.3191
2023-12-29 10:05:42,593 - mmseg - INFO - Iter [125700/160000]	lr: 1.286e-05, eta: 7:39:52, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 91.7508, aux.loss_ce: 0.1025, aux.acc_seg: 89.6118, loss: 0.2937
2023-12-29 10:06:23,029 - mmseg - INFO - Iter [125750/160000]	lr: 1.284e-05, eta: 7:39:11, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2039, decode.acc_seg: 91.3398, aux.loss_ce: 0.1067, aux.acc_seg: 89.1878, loss: 0.3106
2023-12-29 10:07:04,611 - mmseg - INFO - Iter [125800/160000]	lr: 1.283e-05, eta: 7:38:31, time: 0.832, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1990, decode.acc_seg: 91.7151, aux.loss_ce: 0.1066, aux.acc_seg: 89.4124, loss: 0.3057
2023-12-29 10:07:46,101 - mmseg - INFO - Iter [125850/160000]	lr: 1.281e-05, eta: 7:37:52, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1893, decode.acc_seg: 91.7632, aux.loss_ce: 0.1000, aux.acc_seg: 89.7176, loss: 0.2893
2023-12-29 10:08:27,676 - mmseg - INFO - Iter [125900/160000]	lr: 1.279e-05, eta: 7:37:12, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1879, decode.acc_seg: 92.0272, aux.loss_ce: 0.1005, aux.acc_seg: 89.9228, loss: 0.2884
2023-12-29 10:09:08,377 - mmseg - INFO - Iter [125950/160000]	lr: 1.277e-05, eta: 7:36:32, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1873, decode.acc_seg: 91.9659, aux.loss_ce: 0.0969, aux.acc_seg: 90.2381, loss: 0.2842
2023-12-29 10:09:49,462 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 10:09:49,463 - mmseg - INFO - Iter [126000/160000]	lr: 1.275e-05, eta: 7:35:52, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1990, decode.acc_seg: 91.2341, aux.loss_ce: 0.1044, aux.acc_seg: 89.1211, loss: 0.3034
2023-12-29 10:10:30,073 - mmseg - INFO - Iter [126050/160000]	lr: 1.273e-05, eta: 7:35:12, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1998, decode.acc_seg: 91.5522, aux.loss_ce: 0.1069, aux.acc_seg: 89.3818, loss: 0.3067
2023-12-29 10:11:11,710 - mmseg - INFO - Iter [126100/160000]	lr: 1.271e-05, eta: 7:34:32, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1963, decode.acc_seg: 91.8303, aux.loss_ce: 0.1029, aux.acc_seg: 89.9281, loss: 0.2992
2023-12-29 10:11:49,336 - mmseg - INFO - Iter [126150/160000]	lr: 1.269e-05, eta: 7:33:51, time: 0.754, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1995, decode.acc_seg: 91.5512, aux.loss_ce: 0.1059, aux.acc_seg: 89.3824, loss: 0.3054
2023-12-29 10:12:27,028 - mmseg - INFO - Iter [126200/160000]	lr: 1.268e-05, eta: 7:33:10, time: 0.752, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2066, decode.acc_seg: 91.6912, aux.loss_ce: 0.1076, aux.acc_seg: 89.5215, loss: 0.3142
2023-12-29 10:13:07,296 - mmseg - INFO - Iter [126250/160000]	lr: 1.266e-05, eta: 7:32:30, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1869, decode.acc_seg: 91.7954, aux.loss_ce: 0.1024, aux.acc_seg: 89.5387, loss: 0.2893
2023-12-29 10:13:46,080 - mmseg - INFO - Iter [126300/160000]	lr: 1.264e-05, eta: 7:31:49, time: 0.776, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2080, decode.acc_seg: 91.1846, aux.loss_ce: 0.1107, aux.acc_seg: 89.0280, loss: 0.3187
2023-12-29 10:14:29,654 - mmseg - INFO - Iter [126350/160000]	lr: 1.262e-05, eta: 7:31:10, time: 0.872, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1957, decode.acc_seg: 91.9034, aux.loss_ce: 0.1061, aux.acc_seg: 89.4185, loss: 0.3018
2023-12-29 10:15:10,834 - mmseg - INFO - Iter [126400/160000]	lr: 1.260e-05, eta: 7:30:30, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1988, decode.acc_seg: 91.4355, aux.loss_ce: 0.1064, aux.acc_seg: 89.0361, loss: 0.3052
2023-12-29 10:15:48,687 - mmseg - INFO - Iter [126450/160000]	lr: 1.258e-05, eta: 7:29:49, time: 0.756, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2054, decode.acc_seg: 91.7542, aux.loss_ce: 0.1080, aux.acc_seg: 89.5471, loss: 0.3134
2023-12-29 10:16:29,320 - mmseg - INFO - Iter [126500/160000]	lr: 1.256e-05, eta: 7:29:09, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1773, decode.acc_seg: 92.3351, aux.loss_ce: 0.0952, aux.acc_seg: 90.3476, loss: 0.2725
2023-12-29 10:17:10,133 - mmseg - INFO - Iter [126550/160000]	lr: 1.254e-05, eta: 7:28:29, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2002, decode.acc_seg: 91.5198, aux.loss_ce: 0.1053, aux.acc_seg: 89.4180, loss: 0.3056
2023-12-29 10:17:51,024 - mmseg - INFO - Iter [126600/160000]	lr: 1.253e-05, eta: 7:27:49, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1943, decode.acc_seg: 91.8333, aux.loss_ce: 0.1046, aux.acc_seg: 89.5650, loss: 0.2989
2023-12-29 10:18:32,319 - mmseg - INFO - Iter [126650/160000]	lr: 1.251e-05, eta: 7:27:09, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1879, decode.acc_seg: 92.1004, aux.loss_ce: 0.0979, aux.acc_seg: 90.1474, loss: 0.2858
2023-12-29 10:19:12,863 - mmseg - INFO - Iter [126700/160000]	lr: 1.249e-05, eta: 7:26:29, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2013, decode.acc_seg: 91.6756, aux.loss_ce: 0.1064, aux.acc_seg: 89.6440, loss: 0.3077
2023-12-29 10:19:52,758 - mmseg - INFO - Iter [126750/160000]	lr: 1.247e-05, eta: 7:25:48, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1950, decode.acc_seg: 91.6426, aux.loss_ce: 0.1034, aux.acc_seg: 89.4494, loss: 0.2985
2023-12-29 10:20:33,994 - mmseg - INFO - Iter [126800/160000]	lr: 1.245e-05, eta: 7:25:08, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1951, decode.acc_seg: 91.7099, aux.loss_ce: 0.1035, aux.acc_seg: 89.7087, loss: 0.2986
2023-12-29 10:21:15,784 - mmseg - INFO - Iter [126850/160000]	lr: 1.243e-05, eta: 7:24:29, time: 0.834, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2082, decode.acc_seg: 91.4126, aux.loss_ce: 0.1079, aux.acc_seg: 89.3115, loss: 0.3161
2023-12-29 10:21:56,586 - mmseg - INFO - Iter [126900/160000]	lr: 1.241e-05, eta: 7:23:48, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1934, decode.acc_seg: 91.7144, aux.loss_ce: 0.1012, aux.acc_seg: 89.7024, loss: 0.2946
2023-12-29 10:22:36,449 - mmseg - INFO - Iter [126950/160000]	lr: 1.239e-05, eta: 7:23:08, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1999, decode.acc_seg: 91.6677, aux.loss_ce: 0.1069, aux.acc_seg: 89.4167, loss: 0.3069
2023-12-29 10:23:17,499 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 10:23:17,500 - mmseg - INFO - Iter [127000/160000]	lr: 1.238e-05, eta: 7:22:28, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1913, decode.acc_seg: 91.8180, aux.loss_ce: 0.1001, aux.acc_seg: 89.9345, loss: 0.2913
2023-12-29 10:23:59,156 - mmseg - INFO - Iter [127050/160000]	lr: 1.236e-05, eta: 7:21:48, time: 0.833, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2080, decode.acc_seg: 91.3067, aux.loss_ce: 0.1107, aux.acc_seg: 88.9911, loss: 0.3186
2023-12-29 10:24:41,013 - mmseg - INFO - Iter [127100/160000]	lr: 1.234e-05, eta: 7:21:08, time: 0.837, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1999, decode.acc_seg: 91.5192, aux.loss_ce: 0.1058, aux.acc_seg: 89.4543, loss: 0.3057
2023-12-29 10:25:22,632 - mmseg - INFO - Iter [127150/160000]	lr: 1.232e-05, eta: 7:20:29, time: 0.832, data_time: 0.015, memory: 18256, decode.loss_ce: 0.2070, decode.acc_seg: 91.2872, aux.loss_ce: 0.1102, aux.acc_seg: 89.0129, loss: 0.3172
2023-12-29 10:26:04,422 - mmseg - INFO - Iter [127200/160000]	lr: 1.230e-05, eta: 7:19:49, time: 0.836, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1977, decode.acc_seg: 91.3984, aux.loss_ce: 0.1020, aux.acc_seg: 89.4856, loss: 0.2998
2023-12-29 10:26:45,847 - mmseg - INFO - Iter [127250/160000]	lr: 1.228e-05, eta: 7:19:09, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1993, decode.acc_seg: 91.4637, aux.loss_ce: 0.1066, aux.acc_seg: 89.2934, loss: 0.3059
2023-12-29 10:27:26,357 - mmseg - INFO - Iter [127300/160000]	lr: 1.226e-05, eta: 7:18:29, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1930, decode.acc_seg: 91.8056, aux.loss_ce: 0.1026, aux.acc_seg: 89.8006, loss: 0.2956
2023-12-29 10:28:07,834 - mmseg - INFO - Iter [127350/160000]	lr: 1.224e-05, eta: 7:17:49, time: 0.830, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1918, decode.acc_seg: 91.8792, aux.loss_ce: 0.1018, aux.acc_seg: 89.8113, loss: 0.2935
2023-12-29 10:28:47,568 - mmseg - INFO - Iter [127400/160000]	lr: 1.223e-05, eta: 7:17:08, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2109, decode.acc_seg: 91.2499, aux.loss_ce: 0.1098, aux.acc_seg: 89.2154, loss: 0.3207
2023-12-29 10:29:28,313 - mmseg - INFO - Iter [127450/160000]	lr: 1.221e-05, eta: 7:16:28, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1927, decode.acc_seg: 91.7814, aux.loss_ce: 0.1015, aux.acc_seg: 89.6670, loss: 0.2942
2023-12-29 10:30:08,281 - mmseg - INFO - Iter [127500/160000]	lr: 1.219e-05, eta: 7:15:48, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1997, decode.acc_seg: 91.6853, aux.loss_ce: 0.1047, aux.acc_seg: 89.5308, loss: 0.3044
2023-12-29 10:30:48,302 - mmseg - INFO - Iter [127550/160000]	lr: 1.217e-05, eta: 7:15:08, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1970, decode.acc_seg: 91.8027, aux.loss_ce: 0.1031, aux.acc_seg: 89.9061, loss: 0.3001
2023-12-29 10:31:32,302 - mmseg - INFO - Iter [127600/160000]	lr: 1.215e-05, eta: 7:14:28, time: 0.879, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2012, decode.acc_seg: 91.6752, aux.loss_ce: 0.1061, aux.acc_seg: 89.6730, loss: 0.3073
2023-12-29 10:32:14,748 - mmseg - INFO - Iter [127650/160000]	lr: 1.213e-05, eta: 7:13:49, time: 0.849, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1900, decode.acc_seg: 91.9899, aux.loss_ce: 0.1020, aux.acc_seg: 89.8249, loss: 0.2920
2023-12-29 10:32:55,757 - mmseg - INFO - Iter [127700/160000]	lr: 1.211e-05, eta: 7:13:09, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1961, decode.acc_seg: 91.8324, aux.loss_ce: 0.1056, aux.acc_seg: 89.6206, loss: 0.3017
2023-12-29 10:33:36,788 - mmseg - INFO - Iter [127750/160000]	lr: 1.209e-05, eta: 7:12:29, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1978, decode.acc_seg: 91.8501, aux.loss_ce: 0.1032, aux.acc_seg: 90.0061, loss: 0.3010
2023-12-29 10:34:14,851 - mmseg - INFO - Iter [127800/160000]	lr: 1.208e-05, eta: 7:11:48, time: 0.762, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1967, decode.acc_seg: 91.5005, aux.loss_ce: 0.1031, aux.acc_seg: 89.4433, loss: 0.2997
2023-12-29 10:34:54,732 - mmseg - INFO - Iter [127850/160000]	lr: 1.206e-05, eta: 7:11:08, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2006, decode.acc_seg: 91.6955, aux.loss_ce: 0.1065, aux.acc_seg: 89.5083, loss: 0.3072
2023-12-29 10:35:36,497 - mmseg - INFO - Iter [127900/160000]	lr: 1.204e-05, eta: 7:10:28, time: 0.836, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2078, decode.acc_seg: 91.5638, aux.loss_ce: 0.1083, aux.acc_seg: 89.6456, loss: 0.3161
2023-12-29 10:36:17,421 - mmseg - INFO - Iter [127950/160000]	lr: 1.202e-05, eta: 7:09:48, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1890, decode.acc_seg: 92.0432, aux.loss_ce: 0.0998, aux.acc_seg: 89.8905, loss: 0.2887
2023-12-29 10:36:57,487 - mmseg - INFO - Saving checkpoint at 128000 iterations
2023-12-29 10:37:02,429 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 10:37:02,429 - mmseg - INFO - Iter [128000/160000]	lr: 1.200e-05, eta: 7:09:09, time: 0.900, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2049, decode.acc_seg: 91.1961, aux.loss_ce: 0.1079, aux.acc_seg: 89.0343, loss: 0.3128
2023-12-29 10:39:06,060 - mmseg - INFO - per class results:
2023-12-29 10:39:06,073 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  77.2 |  87.7 |
|       building      | 82.71 | 91.92 |
|         sky         | 94.41 | 97.42 |
|        floor        | 81.57 | 90.53 |
|         tree        | 74.67 | 87.09 |
|       ceiling       | 83.62 | 91.54 |
|         road        | 83.03 | 89.02 |
|         bed         | 89.14 | 96.01 |
|      windowpane     | 62.62 | 80.83 |
|        grass        |  66.8 | 81.74 |
|       cabinet       | 59.81 | 71.99 |
|       sidewalk      | 67.16 | 82.79 |
|        person       | 81.69 | 93.37 |
|        earth        | 33.73 | 44.45 |
|         door        |  51.7 | 65.62 |
|        table        | 60.53 | 75.68 |
|       mountain      | 58.07 | 78.96 |
|        plant        |  51.9 |  65.4 |
|       curtain       | 75.61 | 88.13 |
|        chair        |  55.5 | 67.51 |
|         car         | 83.85 | 90.84 |
|        water        | 60.74 | 75.51 |
|       painting      | 72.99 | 88.28 |
|         sofa        | 64.12 | 84.99 |
|        shelf        | 43.15 | 56.31 |
|        house        | 55.75 | 75.18 |
|         sea         | 55.07 | 73.89 |
|        mirror       |  66.7 | 74.39 |
|         rug         | 63.76 | 74.89 |
|        field        | 33.12 | 56.73 |
|       armchair      |  38.8 | 53.72 |
|         seat        | 62.18 | 83.44 |
|        fence        | 47.96 | 65.95 |
|         desk        | 49.19 |  71.8 |
|         rock        |  36.0 | 57.33 |
|       wardrobe      | 49.16 | 68.57 |
|         lamp        | 64.72 | 77.49 |
|       bathtub       | 77.65 | 83.01 |
|       railing       | 34.15 | 47.18 |
|       cushion       | 60.83 | 74.23 |
|         base        | 34.67 | 47.94 |
|         box         | 26.25 | 32.33 |
|        column       | 45.74 | 56.46 |
|      signboard      |  38.7 | 52.52 |
|   chest of drawers  | 38.61 | 50.02 |
|       counter       | 30.72 | 38.83 |
|         sand        | 40.43 | 76.07 |
|         sink        |  69.6 | 78.64 |
|      skyscraper     | 38.32 | 47.41 |
|      fireplace      | 70.75 | 90.27 |
|     refrigerator    | 72.78 | 79.53 |
|      grandstand     | 41.57 | 72.53 |
|         path        | 20.92 | 29.32 |
|        stairs       | 32.19 | 38.12 |
|        runway       |  70.0 | 92.01 |
|         case        |  51.8 | 76.14 |
|      pool table     | 93.17 |  97.0 |
|        pillow       | 59.04 | 71.89 |
|     screen door     | 74.96 | 77.37 |
|       stairway      | 32.32 | 38.61 |
|        river        |  9.79 | 18.92 |
|        bridge       |  71.5 | 81.56 |
|       bookcase      | 36.43 | 59.76 |
|        blind        | 39.94 | 45.31 |
|     coffee table    | 56.01 |  82.8 |
|        toilet       |  83.9 | 89.56 |
|        flower       | 39.68 | 53.96 |
|         book        |  45.1 | 64.62 |
|         hill        |  3.12 |  5.31 |
|        bench        | 44.68 | 52.88 |
|      countertop     | 62.87 | 84.64 |
|        stove        | 81.09 | 88.87 |
|         palm        | 49.13 | 77.87 |
|    kitchen island   | 34.44 | 64.58 |
|       computer      | 68.94 | 80.12 |
|     swivel chair    | 40.32 | 70.68 |
|         boat        | 35.55 | 48.13 |
|         bar         | 44.66 | 61.25 |
|    arcade machine   | 76.76 | 82.97 |
|        hovel        | 52.16 | 59.91 |
|         bus         | 84.24 | 95.78 |
|        towel        |  62.3 | 73.34 |
|        light        | 53.26 | 58.46 |
|        truck        | 34.87 | 47.98 |
|        tower        | 11.29 | 18.58 |
|      chandelier     |  71.2 |  82.9 |
|        awning       |  25.5 | 35.19 |
|     streetlight     | 25.44 | 33.09 |
|        booth        | 69.53 | 78.75 |
| television receiver | 65.89 | 76.82 |
|       airplane      | 57.23 | 66.74 |
|      dirt track     | 26.87 | 50.68 |
|       apparel       | 40.76 |  57.3 |
|         pole        | 22.42 | 31.05 |
|         land        |  4.52 |  6.18 |
|      bannister      | 14.34 | 20.27 |
|      escalator      | 26.36 | 28.46 |
|       ottoman       | 41.34 |  58.4 |
|        bottle       | 35.63 |  62.8 |
|        buffet       | 42.63 | 45.97 |
|        poster       | 28.77 | 34.24 |
|        stage        | 22.51 | 31.64 |
|         van         |  43.3 | 59.19 |
|         ship        |  56.0 | 95.29 |
|       fountain      | 20.89 | 21.31 |
|    conveyer belt    | 76.62 | 91.12 |
|        canopy       | 17.52 | 24.49 |
|        washer       | 88.74 | 90.55 |
|      plaything      | 23.68 | 39.36 |
|    swimming pool    | 54.23 | 88.79 |
|        stool        | 33.11 | 50.33 |
|        barrel       | 43.86 | 66.34 |
|        basket       |  33.0 |  49.3 |
|      waterfall      | 65.35 | 91.11 |
|         tent        | 94.28 | 98.57 |
|         bag         | 14.99 | 18.69 |
|       minibike      | 72.79 | 86.71 |
|        cradle       | 75.08 | 96.92 |
|         oven        | 57.09 | 72.21 |
|         ball        | 40.12 | 69.09 |
|         food        | 53.14 | 63.36 |
|         step        |  11.1 | 13.51 |
|         tank        | 55.32 |  58.0 |
|      trade name     | 24.65 | 29.92 |
|      microwave      | 82.66 | 89.93 |
|         pot         | 45.25 |  52.9 |
|        animal       | 53.55 | 57.81 |
|       bicycle       | 54.59 | 74.69 |
|         lake        | 56.17 | 63.72 |
|      dishwasher     | 66.47 | 75.53 |
|        screen       | 65.04 | 89.61 |
|       blanket       |  9.78 | 11.37 |
|      sculpture      | 59.25 |  72.7 |
|         hood        | 62.34 | 66.68 |
|        sconce       | 43.53 | 51.52 |
|         vase        | 39.84 | 53.26 |
|    traffic light    | 27.99 | 42.55 |
|         tray        | 10.57 | 12.05 |
|        ashcan       | 42.96 |  54.5 |
|         fan         | 55.37 | 76.08 |
|         pier        | 44.84 | 83.49 |
|      crt screen     |  4.07 | 11.41 |
|        plate        | 53.12 | 72.88 |
|       monitor       |  8.97 | 12.53 |
|    bulletin board   |  48.2 | 57.91 |
|        shower       |  3.7  |  3.71 |
|       radiator      | 57.17 | 64.69 |
|        glass        | 14.76 |  16.1 |
|        clock        | 30.93 | 36.41 |
|         flag        | 43.22 | 46.83 |
+---------------------+-------+-------+
2023-12-29 10:39:06,073 - mmseg - INFO - Summary:
2023-12-29 10:39:06,074 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.11 | 49.84 | 62.65 |
+-------+-------+-------+
2023-12-29 10:39:06,114 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 10:39:06,115 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8311, mIoU: 0.4984, mAcc: 0.6265, IoU.wall: 0.7720, IoU.building: 0.8271, IoU.sky: 0.9441, IoU.floor: 0.8157, IoU.tree: 0.7467, IoU.ceiling: 0.8362, IoU.road: 0.8303, IoU.bed : 0.8914, IoU.windowpane: 0.6262, IoU.grass: 0.6680, IoU.cabinet: 0.5981, IoU.sidewalk: 0.6716, IoU.person: 0.8169, IoU.earth: 0.3373, IoU.door: 0.5170, IoU.table: 0.6053, IoU.mountain: 0.5807, IoU.plant: 0.5190, IoU.curtain: 0.7561, IoU.chair: 0.5550, IoU.car: 0.8385, IoU.water: 0.6074, IoU.painting: 0.7299, IoU.sofa: 0.6412, IoU.shelf: 0.4315, IoU.house: 0.5575, IoU.sea: 0.5507, IoU.mirror: 0.6670, IoU.rug: 0.6376, IoU.field: 0.3312, IoU.armchair: 0.3880, IoU.seat: 0.6218, IoU.fence: 0.4796, IoU.desk: 0.4919, IoU.rock: 0.3600, IoU.wardrobe: 0.4916, IoU.lamp: 0.6472, IoU.bathtub: 0.7765, IoU.railing: 0.3415, IoU.cushion: 0.6083, IoU.base: 0.3467, IoU.box: 0.2625, IoU.column: 0.4574, IoU.signboard: 0.3870, IoU.chest of drawers: 0.3861, IoU.counter: 0.3072, IoU.sand: 0.4043, IoU.sink: 0.6960, IoU.skyscraper: 0.3832, IoU.fireplace: 0.7075, IoU.refrigerator: 0.7278, IoU.grandstand: 0.4157, IoU.path: 0.2092, IoU.stairs: 0.3219, IoU.runway: 0.7000, IoU.case: 0.5180, IoU.pool table: 0.9317, IoU.pillow: 0.5904, IoU.screen door: 0.7496, IoU.stairway: 0.3232, IoU.river: 0.0979, IoU.bridge: 0.7150, IoU.bookcase: 0.3643, IoU.blind: 0.3994, IoU.coffee table: 0.5601, IoU.toilet: 0.8390, IoU.flower: 0.3968, IoU.book: 0.4510, IoU.hill: 0.0312, IoU.bench: 0.4468, IoU.countertop: 0.6287, IoU.stove: 0.8109, IoU.palm: 0.4913, IoU.kitchen island: 0.3444, IoU.computer: 0.6894, IoU.swivel chair: 0.4032, IoU.boat: 0.3555, IoU.bar: 0.4466, IoU.arcade machine: 0.7676, IoU.hovel: 0.5216, IoU.bus: 0.8424, IoU.towel: 0.6230, IoU.light: 0.5326, IoU.truck: 0.3487, IoU.tower: 0.1129, IoU.chandelier: 0.7120, IoU.awning: 0.2550, IoU.streetlight: 0.2544, IoU.booth: 0.6953, IoU.television receiver: 0.6589, IoU.airplane: 0.5723, IoU.dirt track: 0.2687, IoU.apparel: 0.4076, IoU.pole: 0.2242, IoU.land: 0.0452, IoU.bannister: 0.1434, IoU.escalator: 0.2636, IoU.ottoman: 0.4134, IoU.bottle: 0.3563, IoU.buffet: 0.4263, IoU.poster: 0.2877, IoU.stage: 0.2251, IoU.van: 0.4330, IoU.ship: 0.5600, IoU.fountain: 0.2089, IoU.conveyer belt: 0.7662, IoU.canopy: 0.1752, IoU.washer: 0.8874, IoU.plaything: 0.2368, IoU.swimming pool: 0.5423, IoU.stool: 0.3311, IoU.barrel: 0.4386, IoU.basket: 0.3300, IoU.waterfall: 0.6535, IoU.tent: 0.9428, IoU.bag: 0.1499, IoU.minibike: 0.7279, IoU.cradle: 0.7508, IoU.oven: 0.5709, IoU.ball: 0.4012, IoU.food: 0.5314, IoU.step: 0.1110, IoU.tank: 0.5532, IoU.trade name: 0.2465, IoU.microwave: 0.8266, IoU.pot: 0.4525, IoU.animal: 0.5355, IoU.bicycle: 0.5459, IoU.lake: 0.5617, IoU.dishwasher: 0.6647, IoU.screen: 0.6504, IoU.blanket: 0.0978, IoU.sculpture: 0.5925, IoU.hood: 0.6234, IoU.sconce: 0.4353, IoU.vase: 0.3984, IoU.traffic light: 0.2799, IoU.tray: 0.1057, IoU.ashcan: 0.4296, IoU.fan: 0.5537, IoU.pier: 0.4484, IoU.crt screen: 0.0407, IoU.plate: 0.5312, IoU.monitor: 0.0897, IoU.bulletin board: 0.4820, IoU.shower: 0.0370, IoU.radiator: 0.5717, IoU.glass: 0.1476, IoU.clock: 0.3093, IoU.flag: 0.4322, Acc.wall: 0.8770, Acc.building: 0.9192, Acc.sky: 0.9742, Acc.floor: 0.9053, Acc.tree: 0.8709, Acc.ceiling: 0.9154, Acc.road: 0.8902, Acc.bed : 0.9601, Acc.windowpane: 0.8083, Acc.grass: 0.8174, Acc.cabinet: 0.7199, Acc.sidewalk: 0.8279, Acc.person: 0.9337, Acc.earth: 0.4445, Acc.door: 0.6562, Acc.table: 0.7568, Acc.mountain: 0.7896, Acc.plant: 0.6540, Acc.curtain: 0.8813, Acc.chair: 0.6751, Acc.car: 0.9084, Acc.water: 0.7551, Acc.painting: 0.8828, Acc.sofa: 0.8499, Acc.shelf: 0.5631, Acc.house: 0.7518, Acc.sea: 0.7389, Acc.mirror: 0.7439, Acc.rug: 0.7489, Acc.field: 0.5673, Acc.armchair: 0.5372, Acc.seat: 0.8344, Acc.fence: 0.6595, Acc.desk: 0.7180, Acc.rock: 0.5733, Acc.wardrobe: 0.6857, Acc.lamp: 0.7749, Acc.bathtub: 0.8301, Acc.railing: 0.4718, Acc.cushion: 0.7423, Acc.base: 0.4794, Acc.box: 0.3233, Acc.column: 0.5646, Acc.signboard: 0.5252, Acc.chest of drawers: 0.5002, Acc.counter: 0.3883, Acc.sand: 0.7607, Acc.sink: 0.7864, Acc.skyscraper: 0.4741, Acc.fireplace: 0.9027, Acc.refrigerator: 0.7953, Acc.grandstand: 0.7253, Acc.path: 0.2932, Acc.stairs: 0.3812, Acc.runway: 0.9201, Acc.case: 0.7614, Acc.pool table: 0.9700, Acc.pillow: 0.7189, Acc.screen door: 0.7737, Acc.stairway: 0.3861, Acc.river: 0.1892, Acc.bridge: 0.8156, Acc.bookcase: 0.5976, Acc.blind: 0.4531, Acc.coffee table: 0.8280, Acc.toilet: 0.8956, Acc.flower: 0.5396, Acc.book: 0.6462, Acc.hill: 0.0531, Acc.bench: 0.5288, Acc.countertop: 0.8464, Acc.stove: 0.8887, Acc.palm: 0.7787, Acc.kitchen island: 0.6458, Acc.computer: 0.8012, Acc.swivel chair: 0.7068, Acc.boat: 0.4813, Acc.bar: 0.6125, Acc.arcade machine: 0.8297, Acc.hovel: 0.5991, Acc.bus: 0.9578, Acc.towel: 0.7334, Acc.light: 0.5846, Acc.truck: 0.4798, Acc.tower: 0.1858, Acc.chandelier: 0.8290, Acc.awning: 0.3519, Acc.streetlight: 0.3309, Acc.booth: 0.7875, Acc.television receiver: 0.7682, Acc.airplane: 0.6674, Acc.dirt track: 0.5068, Acc.apparel: 0.5730, Acc.pole: 0.3105, Acc.land: 0.0618, Acc.bannister: 0.2027, Acc.escalator: 0.2846, Acc.ottoman: 0.5840, Acc.bottle: 0.6280, Acc.buffet: 0.4597, Acc.poster: 0.3424, Acc.stage: 0.3164, Acc.van: 0.5919, Acc.ship: 0.9529, Acc.fountain: 0.2131, Acc.conveyer belt: 0.9112, Acc.canopy: 0.2449, Acc.washer: 0.9055, Acc.plaything: 0.3936, Acc.swimming pool: 0.8879, Acc.stool: 0.5033, Acc.barrel: 0.6634, Acc.basket: 0.4930, Acc.waterfall: 0.9111, Acc.tent: 0.9857, Acc.bag: 0.1869, Acc.minibike: 0.8671, Acc.cradle: 0.9692, Acc.oven: 0.7221, Acc.ball: 0.6909, Acc.food: 0.6336, Acc.step: 0.1351, Acc.tank: 0.5800, Acc.trade name: 0.2992, Acc.microwave: 0.8993, Acc.pot: 0.5290, Acc.animal: 0.5781, Acc.bicycle: 0.7469, Acc.lake: 0.6372, Acc.dishwasher: 0.7553, Acc.screen: 0.8961, Acc.blanket: 0.1137, Acc.sculpture: 0.7270, Acc.hood: 0.6668, Acc.sconce: 0.5152, Acc.vase: 0.5326, Acc.traffic light: 0.4255, Acc.tray: 0.1205, Acc.ashcan: 0.5450, Acc.fan: 0.7608, Acc.pier: 0.8349, Acc.crt screen: 0.1141, Acc.plate: 0.7288, Acc.monitor: 0.1253, Acc.bulletin board: 0.5791, Acc.shower: 0.0371, Acc.radiator: 0.6469, Acc.glass: 0.1610, Acc.clock: 0.3641, Acc.flag: 0.4683
2023-12-29 10:39:45,550 - mmseg - INFO - Iter [128050/160000]	lr: 1.198e-05, eta: 7:08:59, time: 3.262, data_time: 2.484, memory: 18256, decode.loss_ce: 0.1806, decode.acc_seg: 92.0990, aux.loss_ce: 0.0965, aux.acc_seg: 90.0026, loss: 0.2772
2023-12-29 10:40:22,871 - mmseg - INFO - Iter [128100/160000]	lr: 1.196e-05, eta: 7:08:18, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1832, decode.acc_seg: 91.9306, aux.loss_ce: 0.0975, aux.acc_seg: 89.8898, loss: 0.2808
2023-12-29 10:41:02,663 - mmseg - INFO - Iter [128150/160000]	lr: 1.194e-05, eta: 7:07:38, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1885, decode.acc_seg: 92.1068, aux.loss_ce: 0.1005, aux.acc_seg: 90.0403, loss: 0.2890
2023-12-29 10:41:43,771 - mmseg - INFO - Iter [128200/160000]	lr: 1.193e-05, eta: 7:06:58, time: 0.821, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1873, decode.acc_seg: 91.9665, aux.loss_ce: 0.1000, aux.acc_seg: 89.8946, loss: 0.2873
2023-12-29 10:42:21,754 - mmseg - INFO - Iter [128250/160000]	lr: 1.191e-05, eta: 7:06:17, time: 0.760, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2008, decode.acc_seg: 91.5944, aux.loss_ce: 0.1054, aux.acc_seg: 89.5944, loss: 0.3062
2023-12-29 10:43:01,260 - mmseg - INFO - Iter [128300/160000]	lr: 1.189e-05, eta: 7:05:36, time: 0.791, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1939, decode.acc_seg: 92.0067, aux.loss_ce: 0.1057, aux.acc_seg: 89.6585, loss: 0.2996
2023-12-29 10:43:41,737 - mmseg - INFO - Iter [128350/160000]	lr: 1.187e-05, eta: 7:04:56, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.7226, aux.loss_ce: 0.1032, aux.acc_seg: 89.4122, loss: 0.2956
2023-12-29 10:44:22,163 - mmseg - INFO - Iter [128400/160000]	lr: 1.185e-05, eta: 7:04:16, time: 0.808, data_time: 0.010, memory: 18256, decode.loss_ce: 0.1869, decode.acc_seg: 91.9180, aux.loss_ce: 0.1014, aux.acc_seg: 89.8164, loss: 0.2883
2023-12-29 10:45:01,842 - mmseg - INFO - Iter [128450/160000]	lr: 1.183e-05, eta: 7:03:35, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2101, decode.acc_seg: 91.1316, aux.loss_ce: 0.1121, aux.acc_seg: 88.9654, loss: 0.3222
2023-12-29 10:45:42,442 - mmseg - INFO - Iter [128500/160000]	lr: 1.181e-05, eta: 7:02:55, time: 0.811, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2006, decode.acc_seg: 91.5215, aux.loss_ce: 0.1033, aux.acc_seg: 89.6868, loss: 0.3038
2023-12-29 10:46:22,952 - mmseg - INFO - Iter [128550/160000]	lr: 1.179e-05, eta: 7:02:15, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1890, decode.acc_seg: 92.1141, aux.loss_ce: 0.1013, aux.acc_seg: 89.9112, loss: 0.2903
2023-12-29 10:47:01,473 - mmseg - INFO - Iter [128600/160000]	lr: 1.178e-05, eta: 7:01:34, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2058, decode.acc_seg: 91.1947, aux.loss_ce: 0.1106, aux.acc_seg: 89.0047, loss: 0.3164
2023-12-29 10:47:40,728 - mmseg - INFO - Iter [128650/160000]	lr: 1.176e-05, eta: 7:00:54, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1886, decode.acc_seg: 92.0137, aux.loss_ce: 0.0992, aux.acc_seg: 89.9786, loss: 0.2878
2023-12-29 10:48:19,944 - mmseg - INFO - Iter [128700/160000]	lr: 1.174e-05, eta: 7:00:13, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2058, decode.acc_seg: 91.3138, aux.loss_ce: 0.1047, aux.acc_seg: 89.3099, loss: 0.3105
2023-12-29 10:48:58,582 - mmseg - INFO - Iter [128750/160000]	lr: 1.172e-05, eta: 6:59:33, time: 0.773, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2066, decode.acc_seg: 91.1013, aux.loss_ce: 0.1108, aux.acc_seg: 88.8766, loss: 0.3174
2023-12-29 10:49:36,152 - mmseg - INFO - Iter [128800/160000]	lr: 1.170e-05, eta: 6:58:52, time: 0.751, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2100, decode.acc_seg: 91.1591, aux.loss_ce: 0.1094, aux.acc_seg: 89.0793, loss: 0.3194
2023-12-29 10:50:17,820 - mmseg - INFO - Iter [128850/160000]	lr: 1.168e-05, eta: 6:58:12, time: 0.834, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1971, decode.acc_seg: 91.7218, aux.loss_ce: 0.1054, aux.acc_seg: 89.5648, loss: 0.3025
2023-12-29 10:50:56,573 - mmseg - INFO - Iter [128900/160000]	lr: 1.166e-05, eta: 6:57:31, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1807, decode.acc_seg: 92.2784, aux.loss_ce: 0.0965, aux.acc_seg: 90.2082, loss: 0.2772
2023-12-29 10:51:35,777 - mmseg - INFO - Iter [128950/160000]	lr: 1.164e-05, eta: 6:56:51, time: 0.783, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1986, decode.acc_seg: 91.5410, aux.loss_ce: 0.1060, aux.acc_seg: 89.3203, loss: 0.3046
2023-12-29 10:52:14,978 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 10:52:14,979 - mmseg - INFO - Iter [129000/160000]	lr: 1.163e-05, eta: 6:56:10, time: 0.785, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1898, decode.acc_seg: 92.2412, aux.loss_ce: 0.0997, aux.acc_seg: 90.2528, loss: 0.2895
2023-12-29 10:52:54,086 - mmseg - INFO - Iter [129050/160000]	lr: 1.161e-05, eta: 6:55:29, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1839, decode.acc_seg: 92.1553, aux.loss_ce: 0.1002, aux.acc_seg: 89.9376, loss: 0.2841
2023-12-29 10:53:34,502 - mmseg - INFO - Iter [129100/160000]	lr: 1.159e-05, eta: 6:54:49, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1967, decode.acc_seg: 91.4996, aux.loss_ce: 0.1048, aux.acc_seg: 89.4479, loss: 0.3015
2023-12-29 10:54:17,036 - mmseg - INFO - Iter [129150/160000]	lr: 1.157e-05, eta: 6:54:09, time: 0.851, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1865, decode.acc_seg: 92.1313, aux.loss_ce: 0.1010, aux.acc_seg: 89.7894, loss: 0.2876
2023-12-29 10:54:56,595 - mmseg - INFO - Iter [129200/160000]	lr: 1.155e-05, eta: 6:53:29, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1917, decode.acc_seg: 91.8832, aux.loss_ce: 0.1023, aux.acc_seg: 89.6488, loss: 0.2940
2023-12-29 10:55:36,805 - mmseg - INFO - Iter [129250/160000]	lr: 1.153e-05, eta: 6:52:49, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 92.2376, aux.loss_ce: 0.1009, aux.acc_seg: 90.0297, loss: 0.2889
2023-12-29 10:56:16,451 - mmseg - INFO - Iter [129300/160000]	lr: 1.151e-05, eta: 6:52:08, time: 0.794, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1951, decode.acc_seg: 91.8310, aux.loss_ce: 0.1019, aux.acc_seg: 89.8536, loss: 0.2970
2023-12-29 10:56:55,704 - mmseg - INFO - Iter [129350/160000]	lr: 1.149e-05, eta: 6:51:28, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1956, decode.acc_seg: 91.6569, aux.loss_ce: 0.1043, aux.acc_seg: 89.4932, loss: 0.2999
2023-12-29 10:57:35,438 - mmseg - INFO - Iter [129400/160000]	lr: 1.148e-05, eta: 6:50:47, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1968, decode.acc_seg: 91.6309, aux.loss_ce: 0.1047, aux.acc_seg: 89.5070, loss: 0.3015
2023-12-29 10:58:13,810 - mmseg - INFO - Iter [129450/160000]	lr: 1.146e-05, eta: 6:50:07, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1970, decode.acc_seg: 91.6888, aux.loss_ce: 0.1031, aux.acc_seg: 89.7947, loss: 0.3001
2023-12-29 10:58:53,471 - mmseg - INFO - Iter [129500/160000]	lr: 1.144e-05, eta: 6:49:26, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 91.9338, aux.loss_ce: 0.1009, aux.acc_seg: 89.9088, loss: 0.2908
2023-12-29 10:59:32,078 - mmseg - INFO - Iter [129550/160000]	lr: 1.142e-05, eta: 6:48:46, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2006, decode.acc_seg: 91.5259, aux.loss_ce: 0.1028, aux.acc_seg: 89.6511, loss: 0.3034
2023-12-29 11:00:11,899 - mmseg - INFO - Iter [129600/160000]	lr: 1.140e-05, eta: 6:48:05, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1927, decode.acc_seg: 91.8887, aux.loss_ce: 0.1025, aux.acc_seg: 89.8261, loss: 0.2952
2023-12-29 11:00:52,218 - mmseg - INFO - Iter [129650/160000]	lr: 1.138e-05, eta: 6:47:25, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1903, decode.acc_seg: 91.7661, aux.loss_ce: 0.1037, aux.acc_seg: 89.5431, loss: 0.2940
2023-12-29 11:01:32,383 - mmseg - INFO - Iter [129700/160000]	lr: 1.136e-05, eta: 6:46:45, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1896, decode.acc_seg: 91.7887, aux.loss_ce: 0.1007, aux.acc_seg: 89.7400, loss: 0.2904
2023-12-29 11:02:12,118 - mmseg - INFO - Iter [129750/160000]	lr: 1.134e-05, eta: 6:46:04, time: 0.795, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1965, decode.acc_seg: 91.5782, aux.loss_ce: 0.1030, aux.acc_seg: 89.6394, loss: 0.2995
2023-12-29 11:02:51,325 - mmseg - INFO - Iter [129800/160000]	lr: 1.133e-05, eta: 6:45:24, time: 0.783, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2078, decode.acc_seg: 91.1401, aux.loss_ce: 0.1060, aux.acc_seg: 89.0954, loss: 0.3138
2023-12-29 11:03:32,268 - mmseg - INFO - Iter [129850/160000]	lr: 1.131e-05, eta: 6:44:44, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1811, decode.acc_seg: 92.2428, aux.loss_ce: 0.0971, aux.acc_seg: 90.2402, loss: 0.2782
2023-12-29 11:04:13,925 - mmseg - INFO - Iter [129900/160000]	lr: 1.129e-05, eta: 6:44:04, time: 0.833, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1971, decode.acc_seg: 91.6711, aux.loss_ce: 0.1043, aux.acc_seg: 89.5381, loss: 0.3014
2023-12-29 11:04:52,395 - mmseg - INFO - Iter [129950/160000]	lr: 1.127e-05, eta: 6:43:23, time: 0.771, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 91.8469, aux.loss_ce: 0.0987, aux.acc_seg: 89.9643, loss: 0.2868
2023-12-29 11:05:32,580 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 11:05:32,580 - mmseg - INFO - Iter [130000/160000]	lr: 1.125e-05, eta: 6:42:43, time: 0.803, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2092, decode.acc_seg: 91.1648, aux.loss_ce: 0.1094, aux.acc_seg: 89.0379, loss: 0.3186
2023-12-29 11:06:14,294 - mmseg - INFO - Iter [130050/160000]	lr: 1.123e-05, eta: 6:42:03, time: 0.834, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2024, decode.acc_seg: 91.5699, aux.loss_ce: 0.1064, aux.acc_seg: 89.4787, loss: 0.3087
2023-12-29 11:06:57,549 - mmseg - INFO - Iter [130100/160000]	lr: 1.121e-05, eta: 6:41:23, time: 0.865, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2003, decode.acc_seg: 91.6293, aux.loss_ce: 0.1057, aux.acc_seg: 89.5608, loss: 0.3060
2023-12-29 11:07:35,736 - mmseg - INFO - Iter [130150/160000]	lr: 1.119e-05, eta: 6:40:42, time: 0.765, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1875, decode.acc_seg: 91.9900, aux.loss_ce: 0.0996, aux.acc_seg: 89.9556, loss: 0.2872
2023-12-29 11:08:16,731 - mmseg - INFO - Iter [130200/160000]	lr: 1.118e-05, eta: 6:40:02, time: 0.820, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 92.0074, aux.loss_ce: 0.0979, aux.acc_seg: 90.3116, loss: 0.2878
2023-12-29 11:08:57,494 - mmseg - INFO - Iter [130250/160000]	lr: 1.116e-05, eta: 6:39:22, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1878, decode.acc_seg: 91.9351, aux.loss_ce: 0.0987, aux.acc_seg: 90.0854, loss: 0.2865
2023-12-29 11:09:37,339 - mmseg - INFO - Iter [130300/160000]	lr: 1.114e-05, eta: 6:38:42, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2036, decode.acc_seg: 91.5112, aux.loss_ce: 0.1059, aux.acc_seg: 89.5710, loss: 0.3095
2023-12-29 11:10:16,717 - mmseg - INFO - Iter [130350/160000]	lr: 1.112e-05, eta: 6:38:01, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1929, decode.acc_seg: 91.7900, aux.loss_ce: 0.1007, aux.acc_seg: 89.9198, loss: 0.2936
2023-12-29 11:10:56,781 - mmseg - INFO - Iter [130400/160000]	lr: 1.110e-05, eta: 6:37:21, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2028, decode.acc_seg: 91.3552, aux.loss_ce: 0.1067, aux.acc_seg: 89.1904, loss: 0.3095
2023-12-29 11:11:35,175 - mmseg - INFO - Iter [130450/160000]	lr: 1.108e-05, eta: 6:36:40, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1879, decode.acc_seg: 92.1013, aux.loss_ce: 0.0995, aux.acc_seg: 89.9886, loss: 0.2874
2023-12-29 11:12:12,775 - mmseg - INFO - Iter [130500/160000]	lr: 1.106e-05, eta: 6:35:59, time: 0.752, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1949, decode.acc_seg: 91.6730, aux.loss_ce: 0.1051, aux.acc_seg: 89.4801, loss: 0.3000
2023-12-29 11:12:51,652 - mmseg - INFO - Iter [130550/160000]	lr: 1.104e-05, eta: 6:35:19, time: 0.777, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2072, decode.acc_seg: 91.4187, aux.loss_ce: 0.1066, aux.acc_seg: 89.4538, loss: 0.3137
2023-12-29 11:13:32,223 - mmseg - INFO - Iter [130600/160000]	lr: 1.103e-05, eta: 6:34:39, time: 0.811, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1991, decode.acc_seg: 91.6913, aux.loss_ce: 0.1051, aux.acc_seg: 89.6182, loss: 0.3042
2023-12-29 11:14:12,503 - mmseg - INFO - Iter [130650/160000]	lr: 1.101e-05, eta: 6:33:58, time: 0.807, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2052, decode.acc_seg: 91.5522, aux.loss_ce: 0.1063, aux.acc_seg: 89.6854, loss: 0.3115
2023-12-29 11:14:52,963 - mmseg - INFO - Iter [130700/160000]	lr: 1.099e-05, eta: 6:33:18, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 91.9226, aux.loss_ce: 0.1025, aux.acc_seg: 89.7427, loss: 0.2924
2023-12-29 11:15:31,401 - mmseg - INFO - Iter [130750/160000]	lr: 1.097e-05, eta: 6:32:37, time: 0.768, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1886, decode.acc_seg: 92.0305, aux.loss_ce: 0.1004, aux.acc_seg: 89.9795, loss: 0.2890
2023-12-29 11:16:10,880 - mmseg - INFO - Iter [130800/160000]	lr: 1.095e-05, eta: 6:31:57, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1978, decode.acc_seg: 91.7917, aux.loss_ce: 0.1033, aux.acc_seg: 89.7103, loss: 0.3011
2023-12-29 11:16:51,590 - mmseg - INFO - Iter [130850/160000]	lr: 1.093e-05, eta: 6:31:17, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1861, decode.acc_seg: 91.9996, aux.loss_ce: 0.0987, aux.acc_seg: 90.0309, loss: 0.2848
2023-12-29 11:17:30,006 - mmseg - INFO - Iter [130900/160000]	lr: 1.091e-05, eta: 6:30:36, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1933, decode.acc_seg: 91.7277, aux.loss_ce: 0.1023, aux.acc_seg: 89.7522, loss: 0.2956
2023-12-29 11:18:08,427 - mmseg - INFO - Iter [130950/160000]	lr: 1.089e-05, eta: 6:29:55, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.1130, aux.loss_ce: 0.0975, aux.acc_seg: 89.7888, loss: 0.2804
2023-12-29 11:18:49,193 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 11:18:49,193 - mmseg - INFO - Iter [131000/160000]	lr: 1.088e-05, eta: 6:29:15, time: 0.814, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1982, decode.acc_seg: 92.0188, aux.loss_ce: 0.1042, aux.acc_seg: 89.9544, loss: 0.3023
2023-12-29 11:19:27,818 - mmseg - INFO - Iter [131050/160000]	lr: 1.086e-05, eta: 6:28:35, time: 0.774, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1927, decode.acc_seg: 91.8356, aux.loss_ce: 0.1021, aux.acc_seg: 89.6522, loss: 0.2948
2023-12-29 11:20:05,359 - mmseg - INFO - Iter [131100/160000]	lr: 1.084e-05, eta: 6:27:54, time: 0.751, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 91.9142, aux.loss_ce: 0.0996, aux.acc_seg: 89.9791, loss: 0.2878
2023-12-29 11:20:45,755 - mmseg - INFO - Iter [131150/160000]	lr: 1.082e-05, eta: 6:27:14, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.2001, decode.acc_seg: 91.3598, aux.loss_ce: 0.1049, aux.acc_seg: 89.3128, loss: 0.3050
2023-12-29 11:21:23,257 - mmseg - INFO - Iter [131200/160000]	lr: 1.080e-05, eta: 6:26:33, time: 0.751, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1861, decode.acc_seg: 91.9348, aux.loss_ce: 0.1003, aux.acc_seg: 89.6766, loss: 0.2864
2023-12-29 11:22:03,735 - mmseg - INFO - Iter [131250/160000]	lr: 1.078e-05, eta: 6:25:52, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1969, decode.acc_seg: 91.7637, aux.loss_ce: 0.1020, aux.acc_seg: 89.7014, loss: 0.2989
2023-12-29 11:22:44,668 - mmseg - INFO - Iter [131300/160000]	lr: 1.076e-05, eta: 6:25:12, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1937, decode.acc_seg: 91.8857, aux.loss_ce: 0.1036, aux.acc_seg: 89.6230, loss: 0.2973
2023-12-29 11:23:26,519 - mmseg - INFO - Iter [131350/160000]	lr: 1.074e-05, eta: 6:24:32, time: 0.836, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 91.7621, aux.loss_ce: 0.1013, aux.acc_seg: 89.3346, loss: 0.2894
2023-12-29 11:24:11,495 - mmseg - INFO - Iter [131400/160000]	lr: 1.073e-05, eta: 6:23:53, time: 0.900, data_time: 0.056, memory: 18256, decode.loss_ce: 0.1904, decode.acc_seg: 91.9294, aux.loss_ce: 0.1010, aux.acc_seg: 89.8668, loss: 0.2914
2023-12-29 11:24:49,263 - mmseg - INFO - Iter [131450/160000]	lr: 1.071e-05, eta: 6:23:12, time: 0.755, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1907, decode.acc_seg: 92.0514, aux.loss_ce: 0.1064, aux.acc_seg: 89.7113, loss: 0.2972
2023-12-29 11:25:28,475 - mmseg - INFO - Iter [131500/160000]	lr: 1.069e-05, eta: 6:22:32, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 92.1392, aux.loss_ce: 0.0998, aux.acc_seg: 89.9177, loss: 0.2879
2023-12-29 11:26:08,543 - mmseg - INFO - Iter [131550/160000]	lr: 1.067e-05, eta: 6:21:52, time: 0.800, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1889, decode.acc_seg: 91.8523, aux.loss_ce: 0.0988, aux.acc_seg: 90.0956, loss: 0.2877
2023-12-29 11:26:49,174 - mmseg - INFO - Iter [131600/160000]	lr: 1.065e-05, eta: 6:21:11, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1949, decode.acc_seg: 91.5035, aux.loss_ce: 0.1043, aux.acc_seg: 89.4440, loss: 0.2992
2023-12-29 11:27:29,898 - mmseg - INFO - Iter [131650/160000]	lr: 1.063e-05, eta: 6:20:31, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1894, decode.acc_seg: 92.1913, aux.loss_ce: 0.0999, aux.acc_seg: 90.3053, loss: 0.2893
2023-12-29 11:28:10,329 - mmseg - INFO - Iter [131700/160000]	lr: 1.061e-05, eta: 6:19:51, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2022, decode.acc_seg: 91.4598, aux.loss_ce: 0.1052, aux.acc_seg: 89.3043, loss: 0.3074
2023-12-29 11:28:51,583 - mmseg - INFO - Iter [131750/160000]	lr: 1.059e-05, eta: 6:19:11, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1950, decode.acc_seg: 91.6948, aux.loss_ce: 0.1050, aux.acc_seg: 89.6175, loss: 0.2999
2023-12-29 11:29:29,953 - mmseg - INFO - Iter [131800/160000]	lr: 1.058e-05, eta: 6:18:30, time: 0.767, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1900, decode.acc_seg: 92.0681, aux.loss_ce: 0.1011, aux.acc_seg: 89.8494, loss: 0.2912
2023-12-29 11:30:10,698 - mmseg - INFO - Iter [131850/160000]	lr: 1.056e-05, eta: 6:17:50, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1842, decode.acc_seg: 91.9718, aux.loss_ce: 0.0995, aux.acc_seg: 89.7196, loss: 0.2837
2023-12-29 11:30:49,514 - mmseg - INFO - Iter [131900/160000]	lr: 1.054e-05, eta: 6:17:09, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1853, decode.acc_seg: 92.0518, aux.loss_ce: 0.0979, aux.acc_seg: 90.1620, loss: 0.2832
2023-12-29 11:31:30,640 - mmseg - INFO - Iter [131950/160000]	lr: 1.052e-05, eta: 6:16:29, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1875, decode.acc_seg: 92.0727, aux.loss_ce: 0.1024, aux.acc_seg: 89.8055, loss: 0.2899
2023-12-29 11:32:11,814 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 11:32:11,815 - mmseg - INFO - Iter [132000/160000]	lr: 1.050e-05, eta: 6:15:49, time: 0.822, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 91.7585, aux.loss_ce: 0.1002, aux.acc_seg: 89.7197, loss: 0.2902
2023-12-29 11:32:50,871 - mmseg - INFO - Iter [132050/160000]	lr: 1.048e-05, eta: 6:15:09, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1890, decode.acc_seg: 91.9893, aux.loss_ce: 0.0998, aux.acc_seg: 89.9470, loss: 0.2889
2023-12-29 11:33:31,335 - mmseg - INFO - Iter [132100/160000]	lr: 1.046e-05, eta: 6:14:29, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1974, decode.acc_seg: 91.6566, aux.loss_ce: 0.1047, aux.acc_seg: 89.6690, loss: 0.3021
2023-12-29 11:34:11,738 - mmseg - INFO - Iter [132150/160000]	lr: 1.044e-05, eta: 6:13:48, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1948, decode.acc_seg: 91.9507, aux.loss_ce: 0.1014, aux.acc_seg: 90.0288, loss: 0.2962
2023-12-29 11:34:50,391 - mmseg - INFO - Iter [132200/160000]	lr: 1.043e-05, eta: 6:13:08, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1925, decode.acc_seg: 91.8365, aux.loss_ce: 0.0999, aux.acc_seg: 89.8258, loss: 0.2924
2023-12-29 11:35:30,113 - mmseg - INFO - Iter [132250/160000]	lr: 1.041e-05, eta: 6:12:27, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1883, decode.acc_seg: 92.0326, aux.loss_ce: 0.1029, aux.acc_seg: 89.7322, loss: 0.2912
2023-12-29 11:36:10,331 - mmseg - INFO - Iter [132300/160000]	lr: 1.039e-05, eta: 6:11:47, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1959, decode.acc_seg: 91.8324, aux.loss_ce: 0.1064, aux.acc_seg: 89.3672, loss: 0.3023
2023-12-29 11:36:49,723 - mmseg - INFO - Iter [132350/160000]	lr: 1.037e-05, eta: 6:11:07, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1872, decode.acc_seg: 91.6180, aux.loss_ce: 0.0990, aux.acc_seg: 89.5592, loss: 0.2862
2023-12-29 11:37:29,576 - mmseg - INFO - Iter [132400/160000]	lr: 1.035e-05, eta: 6:10:26, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1969, decode.acc_seg: 91.5111, aux.loss_ce: 0.1048, aux.acc_seg: 89.2359, loss: 0.3017
2023-12-29 11:38:09,278 - mmseg - INFO - Iter [132450/160000]	lr: 1.033e-05, eta: 6:09:46, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2058, decode.acc_seg: 91.6625, aux.loss_ce: 0.1076, aux.acc_seg: 89.5890, loss: 0.3134
2023-12-29 11:38:48,574 - mmseg - INFO - Iter [132500/160000]	lr: 1.031e-05, eta: 6:09:05, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1892, decode.acc_seg: 91.8492, aux.loss_ce: 0.1013, aux.acc_seg: 89.6272, loss: 0.2904
2023-12-29 11:39:28,144 - mmseg - INFO - Iter [132550/160000]	lr: 1.029e-05, eta: 6:08:25, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1984, decode.acc_seg: 91.6119, aux.loss_ce: 0.1042, aux.acc_seg: 89.5326, loss: 0.3026
2023-12-29 11:40:09,132 - mmseg - INFO - Iter [132600/160000]	lr: 1.028e-05, eta: 6:07:45, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1971, decode.acc_seg: 91.6548, aux.loss_ce: 0.1050, aux.acc_seg: 89.4224, loss: 0.3021
2023-12-29 11:40:51,196 - mmseg - INFO - Iter [132650/160000]	lr: 1.026e-05, eta: 6:07:05, time: 0.841, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1843, decode.acc_seg: 92.1642, aux.loss_ce: 0.0959, aux.acc_seg: 90.4247, loss: 0.2802
2023-12-29 11:41:31,088 - mmseg - INFO - Iter [132700/160000]	lr: 1.024e-05, eta: 6:06:25, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1918, decode.acc_seg: 91.8684, aux.loss_ce: 0.1027, aux.acc_seg: 89.8890, loss: 0.2945
2023-12-29 11:42:10,998 - mmseg - INFO - Iter [132750/160000]	lr: 1.022e-05, eta: 6:05:44, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 91.9392, aux.loss_ce: 0.0994, aux.acc_seg: 89.9339, loss: 0.2871
2023-12-29 11:42:50,026 - mmseg - INFO - Iter [132800/160000]	lr: 1.020e-05, eta: 6:05:04, time: 0.780, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2008, decode.acc_seg: 91.8254, aux.loss_ce: 0.1062, aux.acc_seg: 89.7574, loss: 0.3069
2023-12-29 11:43:29,969 - mmseg - INFO - Iter [132850/160000]	lr: 1.018e-05, eta: 6:04:23, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 91.9525, aux.loss_ce: 0.0984, aux.acc_seg: 89.9115, loss: 0.2861
2023-12-29 11:44:10,093 - mmseg - INFO - Iter [132900/160000]	lr: 1.016e-05, eta: 6:03:43, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1873, decode.acc_seg: 92.0449, aux.loss_ce: 0.0999, aux.acc_seg: 89.8865, loss: 0.2873
2023-12-29 11:44:52,584 - mmseg - INFO - Iter [132950/160000]	lr: 1.014e-05, eta: 6:03:03, time: 0.850, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1880, decode.acc_seg: 92.1694, aux.loss_ce: 0.1001, aux.acc_seg: 90.0429, loss: 0.2881
2023-12-29 11:45:34,385 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 11:45:34,385 - mmseg - INFO - Iter [133000/160000]	lr: 1.013e-05, eta: 6:02:23, time: 0.836, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1814, decode.acc_seg: 92.5243, aux.loss_ce: 0.0955, aux.acc_seg: 90.7849, loss: 0.2769
2023-12-29 11:46:15,522 - mmseg - INFO - Iter [133050/160000]	lr: 1.011e-05, eta: 6:01:43, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1883, decode.acc_seg: 91.7646, aux.loss_ce: 0.1007, aux.acc_seg: 89.8593, loss: 0.2891
2023-12-29 11:46:55,855 - mmseg - INFO - Iter [133100/160000]	lr: 1.009e-05, eta: 6:01:03, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1852, decode.acc_seg: 91.9849, aux.loss_ce: 0.1020, aux.acc_seg: 89.6546, loss: 0.2872
2023-12-29 11:47:34,769 - mmseg - INFO - Iter [133150/160000]	lr: 1.007e-05, eta: 6:00:22, time: 0.778, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1919, decode.acc_seg: 91.9311, aux.loss_ce: 0.1027, aux.acc_seg: 89.9295, loss: 0.2946
2023-12-29 11:48:16,502 - mmseg - INFO - Iter [133200/160000]	lr: 1.005e-05, eta: 5:59:43, time: 0.835, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1964, decode.acc_seg: 91.5335, aux.loss_ce: 0.1055, aux.acc_seg: 89.3249, loss: 0.3018
2023-12-29 11:48:57,640 - mmseg - INFO - Iter [133250/160000]	lr: 1.003e-05, eta: 5:59:02, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1936, decode.acc_seg: 91.8900, aux.loss_ce: 0.1019, aux.acc_seg: 89.9731, loss: 0.2955
2023-12-29 11:49:38,511 - mmseg - INFO - Iter [133300/160000]	lr: 1.001e-05, eta: 5:58:22, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1845, decode.acc_seg: 92.1604, aux.loss_ce: 0.0981, aux.acc_seg: 90.1002, loss: 0.2826
2023-12-29 11:50:18,359 - mmseg - INFO - Iter [133350/160000]	lr: 9.994e-06, eta: 5:57:42, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1855, decode.acc_seg: 92.0636, aux.loss_ce: 0.0979, aux.acc_seg: 90.1243, loss: 0.2834
2023-12-29 11:50:59,296 - mmseg - INFO - Iter [133400/160000]	lr: 9.975e-06, eta: 5:57:02, time: 0.818, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1959, decode.acc_seg: 91.6632, aux.loss_ce: 0.1038, aux.acc_seg: 89.5887, loss: 0.2997
2023-12-29 11:51:40,103 - mmseg - INFO - Iter [133450/160000]	lr: 9.957e-06, eta: 5:56:22, time: 0.817, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1859, decode.acc_seg: 92.0311, aux.loss_ce: 0.0986, aux.acc_seg: 90.0323, loss: 0.2846
2023-12-29 11:52:19,739 - mmseg - INFO - Iter [133500/160000]	lr: 9.938e-06, eta: 5:55:41, time: 0.792, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1917, decode.acc_seg: 91.7936, aux.loss_ce: 0.1019, aux.acc_seg: 89.6694, loss: 0.2936
2023-12-29 11:52:56,966 - mmseg - INFO - Iter [133550/160000]	lr: 9.919e-06, eta: 5:55:00, time: 0.744, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1935, decode.acc_seg: 91.6581, aux.loss_ce: 0.1022, aux.acc_seg: 89.6989, loss: 0.2958
2023-12-29 11:53:37,478 - mmseg - INFO - Iter [133600/160000]	lr: 9.900e-06, eta: 5:54:20, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1887, decode.acc_seg: 91.8661, aux.loss_ce: 0.0993, aux.acc_seg: 90.0794, loss: 0.2880
2023-12-29 11:54:17,956 - mmseg - INFO - Iter [133650/160000]	lr: 9.882e-06, eta: 5:53:40, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1962, decode.acc_seg: 91.5928, aux.loss_ce: 0.1047, aux.acc_seg: 89.4712, loss: 0.3009
2023-12-29 11:54:58,974 - mmseg - INFO - Iter [133700/160000]	lr: 9.863e-06, eta: 5:53:00, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1935, decode.acc_seg: 92.1012, aux.loss_ce: 0.1029, aux.acc_seg: 90.0324, loss: 0.2964
2023-12-29 11:55:38,763 - mmseg - INFO - Iter [133750/160000]	lr: 9.844e-06, eta: 5:52:19, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 92.0284, aux.loss_ce: 0.1029, aux.acc_seg: 90.0098, loss: 0.2995
2023-12-29 11:56:19,382 - mmseg - INFO - Iter [133800/160000]	lr: 9.825e-06, eta: 5:51:39, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1921, decode.acc_seg: 91.7607, aux.loss_ce: 0.0992, aux.acc_seg: 89.7892, loss: 0.2914
2023-12-29 11:57:00,346 - mmseg - INFO - Iter [133850/160000]	lr: 9.807e-06, eta: 5:50:59, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1986, decode.acc_seg: 91.6880, aux.loss_ce: 0.1042, aux.acc_seg: 89.4543, loss: 0.3027
2023-12-29 11:57:41,490 - mmseg - INFO - Iter [133900/160000]	lr: 9.788e-06, eta: 5:50:19, time: 0.822, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1904, decode.acc_seg: 92.0377, aux.loss_ce: 0.1006, aux.acc_seg: 89.9372, loss: 0.2910
2023-12-29 11:58:22,033 - mmseg - INFO - Iter [133950/160000]	lr: 9.769e-06, eta: 5:49:39, time: 0.811, data_time: 0.015, memory: 18256, decode.loss_ce: 0.1857, decode.acc_seg: 92.1085, aux.loss_ce: 0.0991, aux.acc_seg: 90.0186, loss: 0.2848
2023-12-29 11:59:02,146 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 11:59:02,146 - mmseg - INFO - Iter [134000/160000]	lr: 9.750e-06, eta: 5:48:59, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 92.0746, aux.loss_ce: 0.1004, aux.acc_seg: 89.9738, loss: 0.2872
2023-12-29 11:59:44,978 - mmseg - INFO - Iter [134050/160000]	lr: 9.732e-06, eta: 5:48:19, time: 0.856, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1956, decode.acc_seg: 91.5563, aux.loss_ce: 0.1061, aux.acc_seg: 89.3455, loss: 0.3018
2023-12-29 12:00:25,885 - mmseg - INFO - Iter [134100/160000]	lr: 9.713e-06, eta: 5:47:39, time: 0.819, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1941, decode.acc_seg: 91.8765, aux.loss_ce: 0.1009, aux.acc_seg: 89.9893, loss: 0.2951
2023-12-29 12:01:06,540 - mmseg - INFO - Iter [134150/160000]	lr: 9.694e-06, eta: 5:46:58, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1954, decode.acc_seg: 91.6951, aux.loss_ce: 0.1052, aux.acc_seg: 89.4286, loss: 0.3006
2023-12-29 12:01:46,334 - mmseg - INFO - Iter [134200/160000]	lr: 9.675e-06, eta: 5:46:18, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1842, decode.acc_seg: 92.1538, aux.loss_ce: 0.0965, aux.acc_seg: 90.2064, loss: 0.2808
2023-12-29 12:02:25,638 - mmseg - INFO - Iter [134250/160000]	lr: 9.657e-06, eta: 5:45:38, time: 0.786, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1821, decode.acc_seg: 92.1998, aux.loss_ce: 0.0974, aux.acc_seg: 90.1345, loss: 0.2795
2023-12-29 12:03:05,038 - mmseg - INFO - Iter [134300/160000]	lr: 9.638e-06, eta: 5:44:57, time: 0.789, data_time: 0.013, memory: 18256, decode.loss_ce: 0.2005, decode.acc_seg: 91.7587, aux.loss_ce: 0.1067, aux.acc_seg: 89.8210, loss: 0.3072
2023-12-29 12:03:45,507 - mmseg - INFO - Iter [134350/160000]	lr: 9.619e-06, eta: 5:44:17, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1935, decode.acc_seg: 91.8695, aux.loss_ce: 0.1010, aux.acc_seg: 89.9398, loss: 0.2945
2023-12-29 12:04:25,100 - mmseg - INFO - Iter [134400/160000]	lr: 9.600e-06, eta: 5:43:37, time: 0.792, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1775, decode.acc_seg: 92.3580, aux.loss_ce: 0.0968, aux.acc_seg: 90.2893, loss: 0.2743
2023-12-29 12:05:06,423 - mmseg - INFO - Iter [134450/160000]	lr: 9.582e-06, eta: 5:42:56, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1814, decode.acc_seg: 92.2939, aux.loss_ce: 0.0965, aux.acc_seg: 90.2348, loss: 0.2779
2023-12-29 12:05:45,474 - mmseg - INFO - Iter [134500/160000]	lr: 9.563e-06, eta: 5:42:16, time: 0.782, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1865, decode.acc_seg: 92.1338, aux.loss_ce: 0.0995, aux.acc_seg: 90.0350, loss: 0.2860
2023-12-29 12:06:25,168 - mmseg - INFO - Iter [134550/160000]	lr: 9.544e-06, eta: 5:41:36, time: 0.794, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1961, decode.acc_seg: 91.6020, aux.loss_ce: 0.1019, aux.acc_seg: 89.5940, loss: 0.2980
2023-12-29 12:07:03,149 - mmseg - INFO - Iter [134600/160000]	lr: 9.525e-06, eta: 5:40:55, time: 0.759, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 91.9677, aux.loss_ce: 0.1054, aux.acc_seg: 89.8566, loss: 0.3019
2023-12-29 12:07:43,798 - mmseg - INFO - Iter [134650/160000]	lr: 9.507e-06, eta: 5:40:15, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1860, decode.acc_seg: 91.9082, aux.loss_ce: 0.0994, aux.acc_seg: 89.9578, loss: 0.2854
2023-12-29 12:08:24,795 - mmseg - INFO - Iter [134700/160000]	lr: 9.488e-06, eta: 5:39:35, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1854, decode.acc_seg: 92.1289, aux.loss_ce: 0.1001, aux.acc_seg: 90.0367, loss: 0.2855
2023-12-29 12:09:06,505 - mmseg - INFO - Iter [134750/160000]	lr: 9.469e-06, eta: 5:38:55, time: 0.834, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1878, decode.acc_seg: 91.9755, aux.loss_ce: 0.0992, aux.acc_seg: 89.8741, loss: 0.2870
2023-12-29 12:09:47,005 - mmseg - INFO - Iter [134800/160000]	lr: 9.450e-06, eta: 5:38:14, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1989, decode.acc_seg: 91.6250, aux.loss_ce: 0.1063, aux.acc_seg: 89.5856, loss: 0.3053
2023-12-29 12:10:27,786 - mmseg - INFO - Iter [134850/160000]	lr: 9.432e-06, eta: 5:37:34, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1972, decode.acc_seg: 91.4636, aux.loss_ce: 0.1028, aux.acc_seg: 89.4713, loss: 0.3000
2023-12-29 12:11:05,987 - mmseg - INFO - Iter [134900/160000]	lr: 9.413e-06, eta: 5:36:54, time: 0.764, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1953, decode.acc_seg: 91.6287, aux.loss_ce: 0.1034, aux.acc_seg: 89.6808, loss: 0.2988
2023-12-29 12:11:45,734 - mmseg - INFO - Iter [134950/160000]	lr: 9.394e-06, eta: 5:36:13, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1931, decode.acc_seg: 91.9099, aux.loss_ce: 0.1021, aux.acc_seg: 89.8727, loss: 0.2952
2023-12-29 12:12:26,566 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 12:12:26,566 - mmseg - INFO - Iter [135000/160000]	lr: 9.375e-06, eta: 5:35:33, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1909, decode.acc_seg: 91.8256, aux.loss_ce: 0.1018, aux.acc_seg: 89.7165, loss: 0.2927
2023-12-29 12:13:07,489 - mmseg - INFO - Iter [135050/160000]	lr: 9.357e-06, eta: 5:34:53, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1875, decode.acc_seg: 92.0345, aux.loss_ce: 0.0987, aux.acc_seg: 90.0524, loss: 0.2862
2023-12-29 12:13:46,337 - mmseg - INFO - Iter [135100/160000]	lr: 9.338e-06, eta: 5:34:12, time: 0.777, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 91.7108, aux.loss_ce: 0.1046, aux.acc_seg: 89.6715, loss: 0.3012
2023-12-29 12:14:28,868 - mmseg - INFO - Iter [135150/160000]	lr: 9.319e-06, eta: 5:33:32, time: 0.850, data_time: 0.054, memory: 18256, decode.loss_ce: 0.2062, decode.acc_seg: 91.4633, aux.loss_ce: 0.1072, aux.acc_seg: 89.6299, loss: 0.3134
2023-12-29 12:15:10,370 - mmseg - INFO - Iter [135200/160000]	lr: 9.300e-06, eta: 5:32:52, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.2007, decode.acc_seg: 91.4997, aux.loss_ce: 0.1062, aux.acc_seg: 89.3971, loss: 0.3069
2023-12-29 12:15:51,501 - mmseg - INFO - Iter [135250/160000]	lr: 9.282e-06, eta: 5:32:12, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.3523, aux.loss_ce: 0.0993, aux.acc_seg: 90.2028, loss: 0.2816
2023-12-29 12:16:32,784 - mmseg - INFO - Iter [135300/160000]	lr: 9.263e-06, eta: 5:31:32, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 91.8087, aux.loss_ce: 0.0991, aux.acc_seg: 89.8366, loss: 0.2904
2023-12-29 12:17:13,933 - mmseg - INFO - Iter [135350/160000]	lr: 9.244e-06, eta: 5:30:52, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1825, decode.acc_seg: 92.2221, aux.loss_ce: 0.0970, aux.acc_seg: 90.1529, loss: 0.2795
2023-12-29 12:17:55,054 - mmseg - INFO - Iter [135400/160000]	lr: 9.225e-06, eta: 5:30:12, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1793, decode.acc_seg: 92.4800, aux.loss_ce: 0.0959, aux.acc_seg: 90.5479, loss: 0.2752
2023-12-29 12:18:36,397 - mmseg - INFO - Iter [135450/160000]	lr: 9.207e-06, eta: 5:29:32, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 91.9173, aux.loss_ce: 0.0985, aux.acc_seg: 89.8006, loss: 0.2853
2023-12-29 12:19:19,627 - mmseg - INFO - Iter [135500/160000]	lr: 9.188e-06, eta: 5:28:52, time: 0.865, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1884, decode.acc_seg: 91.7762, aux.loss_ce: 0.0993, aux.acc_seg: 89.9327, loss: 0.2876
2023-12-29 12:20:01,084 - mmseg - INFO - Iter [135550/160000]	lr: 9.169e-06, eta: 5:28:12, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1811, decode.acc_seg: 92.1933, aux.loss_ce: 0.0978, aux.acc_seg: 90.0473, loss: 0.2789
2023-12-29 12:20:41,461 - mmseg - INFO - Iter [135600/160000]	lr: 9.150e-06, eta: 5:27:32, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1795, decode.acc_seg: 92.4907, aux.loss_ce: 0.0966, aux.acc_seg: 90.3557, loss: 0.2761
2023-12-29 12:21:22,497 - mmseg - INFO - Iter [135650/160000]	lr: 9.132e-06, eta: 5:26:52, time: 0.822, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1941, decode.acc_seg: 91.5791, aux.loss_ce: 0.1038, aux.acc_seg: 89.3851, loss: 0.2978
2023-12-29 12:22:03,343 - mmseg - INFO - Iter [135700/160000]	lr: 9.113e-06, eta: 5:26:12, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1934, decode.acc_seg: 91.6789, aux.loss_ce: 0.1050, aux.acc_seg: 89.3562, loss: 0.2984
2023-12-29 12:22:43,556 - mmseg - INFO - Iter [135750/160000]	lr: 9.094e-06, eta: 5:25:31, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1919, decode.acc_seg: 91.9158, aux.loss_ce: 0.1018, aux.acc_seg: 89.7844, loss: 0.2937
2023-12-29 12:23:23,887 - mmseg - INFO - Iter [135800/160000]	lr: 9.075e-06, eta: 5:24:51, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1979, decode.acc_seg: 91.6666, aux.loss_ce: 0.1046, aux.acc_seg: 89.6146, loss: 0.3025
2023-12-29 12:24:04,955 - mmseg - INFO - Iter [135850/160000]	lr: 9.057e-06, eta: 5:24:11, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 91.9236, aux.loss_ce: 0.1001, aux.acc_seg: 89.9586, loss: 0.2878
2023-12-29 12:24:46,465 - mmseg - INFO - Iter [135900/160000]	lr: 9.038e-06, eta: 5:23:31, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1943, decode.acc_seg: 91.8848, aux.loss_ce: 0.1024, aux.acc_seg: 89.9074, loss: 0.2967
2023-12-29 12:25:27,864 - mmseg - INFO - Iter [135950/160000]	lr: 9.019e-06, eta: 5:22:51, time: 0.828, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1892, decode.acc_seg: 91.8693, aux.loss_ce: 0.0966, aux.acc_seg: 90.1559, loss: 0.2858
2023-12-29 12:26:09,709 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 12:26:09,709 - mmseg - INFO - Iter [136000/160000]	lr: 9.000e-06, eta: 5:22:11, time: 0.837, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1947, decode.acc_seg: 91.6787, aux.loss_ce: 0.1040, aux.acc_seg: 89.6364, loss: 0.2987
2023-12-29 12:26:50,171 - mmseg - INFO - Iter [136050/160000]	lr: 8.982e-06, eta: 5:21:31, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1909, decode.acc_seg: 92.0133, aux.loss_ce: 0.1022, aux.acc_seg: 89.9915, loss: 0.2931
2023-12-29 12:27:30,504 - mmseg - INFO - Iter [136100/160000]	lr: 8.963e-06, eta: 5:20:50, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1940, decode.acc_seg: 91.9471, aux.loss_ce: 0.1043, aux.acc_seg: 89.7495, loss: 0.2983
2023-12-29 12:28:12,048 - mmseg - INFO - Iter [136150/160000]	lr: 8.944e-06, eta: 5:20:10, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 92.0543, aux.loss_ce: 0.1008, aux.acc_seg: 90.1264, loss: 0.2920
2023-12-29 12:28:53,426 - mmseg - INFO - Iter [136200/160000]	lr: 8.925e-06, eta: 5:19:30, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1839, decode.acc_seg: 92.2575, aux.loss_ce: 0.0985, aux.acc_seg: 90.0794, loss: 0.2824
2023-12-29 12:29:34,516 - mmseg - INFO - Iter [136250/160000]	lr: 8.907e-06, eta: 5:18:50, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1880, decode.acc_seg: 91.8589, aux.loss_ce: 0.1000, aux.acc_seg: 89.7761, loss: 0.2880
2023-12-29 12:30:15,890 - mmseg - INFO - Iter [136300/160000]	lr: 8.888e-06, eta: 5:18:10, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1843, decode.acc_seg: 92.0596, aux.loss_ce: 0.0991, aux.acc_seg: 89.9100, loss: 0.2834
2023-12-29 12:30:56,619 - mmseg - INFO - Iter [136350/160000]	lr: 8.869e-06, eta: 5:17:30, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 91.8506, aux.loss_ce: 0.0977, aux.acc_seg: 89.8340, loss: 0.2846
2023-12-29 12:31:37,884 - mmseg - INFO - Iter [136400/160000]	lr: 8.850e-06, eta: 5:16:50, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1947, decode.acc_seg: 91.7298, aux.loss_ce: 0.1040, aux.acc_seg: 89.7517, loss: 0.2987
2023-12-29 12:32:21,114 - mmseg - INFO - Iter [136450/160000]	lr: 8.832e-06, eta: 5:16:10, time: 0.864, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.1092, aux.loss_ce: 0.1001, aux.acc_seg: 89.7435, loss: 0.2825
2023-12-29 12:33:02,462 - mmseg - INFO - Iter [136500/160000]	lr: 8.813e-06, eta: 5:15:30, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1889, decode.acc_seg: 91.9995, aux.loss_ce: 0.1040, aux.acc_seg: 89.9117, loss: 0.2930
2023-12-29 12:33:43,272 - mmseg - INFO - Iter [136550/160000]	lr: 8.794e-06, eta: 5:14:50, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1913, decode.acc_seg: 91.7709, aux.loss_ce: 0.1009, aux.acc_seg: 89.7049, loss: 0.2922
2023-12-29 12:34:24,617 - mmseg - INFO - Iter [136600/160000]	lr: 8.775e-06, eta: 5:14:10, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.3658, aux.loss_ce: 0.0975, aux.acc_seg: 90.1802, loss: 0.2765
2023-12-29 12:35:05,807 - mmseg - INFO - Iter [136650/160000]	lr: 8.757e-06, eta: 5:13:29, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1798, decode.acc_seg: 92.3267, aux.loss_ce: 0.0970, aux.acc_seg: 90.2480, loss: 0.2768
2023-12-29 12:35:47,184 - mmseg - INFO - Iter [136700/160000]	lr: 8.738e-06, eta: 5:12:49, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1811, decode.acc_seg: 92.0689, aux.loss_ce: 0.0965, aux.acc_seg: 89.9700, loss: 0.2776
2023-12-29 12:36:28,508 - mmseg - INFO - Iter [136750/160000]	lr: 8.719e-06, eta: 5:12:09, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1803, decode.acc_seg: 92.1221, aux.loss_ce: 0.0978, aux.acc_seg: 90.0517, loss: 0.2781
2023-12-29 12:37:08,940 - mmseg - INFO - Iter [136800/160000]	lr: 8.700e-06, eta: 5:11:29, time: 0.809, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1864, decode.acc_seg: 92.0531, aux.loss_ce: 0.0971, aux.acc_seg: 90.1503, loss: 0.2835
2023-12-29 12:37:49,059 - mmseg - INFO - Iter [136850/160000]	lr: 8.682e-06, eta: 5:10:49, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1806, decode.acc_seg: 92.1342, aux.loss_ce: 0.0988, aux.acc_seg: 89.9710, loss: 0.2794
2023-12-29 12:38:30,412 - mmseg - INFO - Iter [136900/160000]	lr: 8.663e-06, eta: 5:10:09, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1965, decode.acc_seg: 91.8508, aux.loss_ce: 0.1031, aux.acc_seg: 89.7728, loss: 0.2995
2023-12-29 12:39:11,652 - mmseg - INFO - Iter [136950/160000]	lr: 8.644e-06, eta: 5:09:28, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1901, decode.acc_seg: 92.0114, aux.loss_ce: 0.1007, aux.acc_seg: 90.0257, loss: 0.2908
2023-12-29 12:39:52,202 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 12:39:52,203 - mmseg - INFO - Iter [137000/160000]	lr: 8.625e-06, eta: 5:08:48, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1839, decode.acc_seg: 92.1606, aux.loss_ce: 0.1001, aux.acc_seg: 90.2012, loss: 0.2840
2023-12-29 12:40:33,544 - mmseg - INFO - Iter [137050/160000]	lr: 8.607e-06, eta: 5:08:08, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1937, decode.acc_seg: 91.8909, aux.loss_ce: 0.1023, aux.acc_seg: 89.8102, loss: 0.2960
2023-12-29 12:41:14,398 - mmseg - INFO - Iter [137100/160000]	lr: 8.588e-06, eta: 5:07:28, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1840, decode.acc_seg: 92.1068, aux.loss_ce: 0.0956, aux.acc_seg: 90.2399, loss: 0.2796
2023-12-29 12:41:54,966 - mmseg - INFO - Iter [137150/160000]	lr: 8.569e-06, eta: 5:06:48, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1801, decode.acc_seg: 92.0177, aux.loss_ce: 0.0955, aux.acc_seg: 90.0184, loss: 0.2756
2023-12-29 12:42:35,487 - mmseg - INFO - Iter [137200/160000]	lr: 8.550e-06, eta: 5:06:07, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1883, decode.acc_seg: 91.9339, aux.loss_ce: 0.1005, aux.acc_seg: 89.8413, loss: 0.2888
2023-12-29 12:43:16,227 - mmseg - INFO - Iter [137250/160000]	lr: 8.532e-06, eta: 5:05:27, time: 0.813, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 92.0603, aux.loss_ce: 0.0984, aux.acc_seg: 90.2448, loss: 0.2842
2023-12-29 12:43:57,381 - mmseg - INFO - Iter [137300/160000]	lr: 8.513e-06, eta: 5:04:47, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1799, decode.acc_seg: 92.3467, aux.loss_ce: 0.0961, aux.acc_seg: 90.3362, loss: 0.2760
2023-12-29 12:44:38,671 - mmseg - INFO - Iter [137350/160000]	lr: 8.494e-06, eta: 5:04:07, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1991, decode.acc_seg: 91.4392, aux.loss_ce: 0.1047, aux.acc_seg: 89.5685, loss: 0.3039
2023-12-29 12:45:20,006 - mmseg - INFO - Iter [137400/160000]	lr: 8.475e-06, eta: 5:03:27, time: 0.827, data_time: 0.014, memory: 18256, decode.loss_ce: 0.2022, decode.acc_seg: 91.6621, aux.loss_ce: 0.1087, aux.acc_seg: 89.6265, loss: 0.3109
2023-12-29 12:45:59,187 - mmseg - INFO - Iter [137450/160000]	lr: 8.457e-06, eta: 5:02:46, time: 0.783, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1972, decode.acc_seg: 91.5089, aux.loss_ce: 0.1060, aux.acc_seg: 89.1943, loss: 0.3033
2023-12-29 12:46:39,705 - mmseg - INFO - Iter [137500/160000]	lr: 8.438e-06, eta: 5:02:06, time: 0.811, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1943, decode.acc_seg: 91.7148, aux.loss_ce: 0.1033, aux.acc_seg: 89.5617, loss: 0.2975
2023-12-29 12:47:18,448 - mmseg - INFO - Iter [137550/160000]	lr: 8.419e-06, eta: 5:01:26, time: 0.775, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1945, decode.acc_seg: 91.8845, aux.loss_ce: 0.1015, aux.acc_seg: 89.9546, loss: 0.2959
2023-12-29 12:48:00,104 - mmseg - INFO - Iter [137600/160000]	lr: 8.400e-06, eta: 5:00:46, time: 0.833, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1734, decode.acc_seg: 92.4903, aux.loss_ce: 0.0932, aux.acc_seg: 90.5622, loss: 0.2667
2023-12-29 12:48:37,419 - mmseg - INFO - Iter [137650/160000]	lr: 8.382e-06, eta: 5:00:05, time: 0.747, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1915, decode.acc_seg: 91.9319, aux.loss_ce: 0.1017, aux.acc_seg: 89.7526, loss: 0.2932
2023-12-29 12:49:16,571 - mmseg - INFO - Iter [137700/160000]	lr: 8.363e-06, eta: 4:59:24, time: 0.782, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.2419, aux.loss_ce: 0.0957, aux.acc_seg: 90.2570, loss: 0.2780
2023-12-29 12:49:58,003 - mmseg - INFO - Iter [137750/160000]	lr: 8.344e-06, eta: 4:58:44, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1871, decode.acc_seg: 91.8497, aux.loss_ce: 0.0989, aux.acc_seg: 89.9065, loss: 0.2860
2023-12-29 12:50:39,405 - mmseg - INFO - Iter [137800/160000]	lr: 8.325e-06, eta: 4:58:04, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1872, decode.acc_seg: 91.8403, aux.loss_ce: 0.1002, aux.acc_seg: 89.7668, loss: 0.2874
2023-12-29 12:51:22,053 - mmseg - INFO - Iter [137850/160000]	lr: 8.307e-06, eta: 4:57:24, time: 0.852, data_time: 0.024, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.1774, aux.loss_ce: 0.0983, aux.acc_seg: 90.1096, loss: 0.2812
2023-12-29 12:52:03,379 - mmseg - INFO - Iter [137900/160000]	lr: 8.288e-06, eta: 4:56:44, time: 0.828, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1972, decode.acc_seg: 91.7774, aux.loss_ce: 0.1047, aux.acc_seg: 89.7644, loss: 0.3020
2023-12-29 12:52:45,673 - mmseg - INFO - Iter [137950/160000]	lr: 8.269e-06, eta: 4:56:04, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1921, decode.acc_seg: 92.0197, aux.loss_ce: 0.1008, aux.acc_seg: 90.0328, loss: 0.2929
2023-12-29 12:53:24,672 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 12:53:24,673 - mmseg - INFO - Iter [138000/160000]	lr: 8.250e-06, eta: 4:55:24, time: 0.779, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1808, decode.acc_seg: 92.4533, aux.loss_ce: 0.0961, aux.acc_seg: 90.4571, loss: 0.2769
2023-12-29 12:54:04,732 - mmseg - INFO - Iter [138050/160000]	lr: 8.232e-06, eta: 4:54:43, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1906, decode.acc_seg: 91.7871, aux.loss_ce: 0.1021, aux.acc_seg: 89.6426, loss: 0.2928
2023-12-29 12:54:43,051 - mmseg - INFO - Iter [138100/160000]	lr: 8.213e-06, eta: 4:54:03, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1964, decode.acc_seg: 91.7440, aux.loss_ce: 0.1052, aux.acc_seg: 89.4861, loss: 0.3016
2023-12-29 12:55:24,639 - mmseg - INFO - Iter [138150/160000]	lr: 8.194e-06, eta: 4:53:23, time: 0.833, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1910, decode.acc_seg: 91.8936, aux.loss_ce: 0.1005, aux.acc_seg: 89.9121, loss: 0.2915
2023-12-29 12:56:04,052 - mmseg - INFO - Iter [138200/160000]	lr: 8.175e-06, eta: 4:52:42, time: 0.787, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1853, decode.acc_seg: 92.1630, aux.loss_ce: 0.0988, aux.acc_seg: 90.1426, loss: 0.2841
2023-12-29 12:56:45,415 - mmseg - INFO - Iter [138250/160000]	lr: 8.157e-06, eta: 4:52:02, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1843, decode.acc_seg: 92.2176, aux.loss_ce: 0.0986, aux.acc_seg: 90.2725, loss: 0.2829
2023-12-29 12:57:25,869 - mmseg - INFO - Iter [138300/160000]	lr: 8.138e-06, eta: 4:51:22, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1831, decode.acc_seg: 92.1892, aux.loss_ce: 0.1003, aux.acc_seg: 89.8841, loss: 0.2835
2023-12-29 12:58:07,162 - mmseg - INFO - Iter [138350/160000]	lr: 8.119e-06, eta: 4:50:42, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1898, decode.acc_seg: 91.7947, aux.loss_ce: 0.1030, aux.acc_seg: 89.6533, loss: 0.2929
2023-12-29 12:58:47,917 - mmseg - INFO - Iter [138400/160000]	lr: 8.100e-06, eta: 4:50:02, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1843, decode.acc_seg: 91.9653, aux.loss_ce: 0.0981, aux.acc_seg: 89.8976, loss: 0.2824
2023-12-29 12:59:28,506 - mmseg - INFO - Iter [138450/160000]	lr: 8.082e-06, eta: 4:49:21, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.9950, aux.loss_ce: 0.1039, aux.acc_seg: 89.8579, loss: 0.2963
2023-12-29 13:00:09,696 - mmseg - INFO - Iter [138500/160000]	lr: 8.063e-06, eta: 4:48:41, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 92.1241, aux.loss_ce: 0.0991, aux.acc_seg: 90.0127, loss: 0.2849
2023-12-29 13:00:50,798 - mmseg - INFO - Iter [138550/160000]	lr: 8.044e-06, eta: 4:48:01, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1889, decode.acc_seg: 91.9937, aux.loss_ce: 0.1011, aux.acc_seg: 89.9058, loss: 0.2900
2023-12-29 13:01:31,862 - mmseg - INFO - Iter [138600/160000]	lr: 8.025e-06, eta: 4:47:21, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1840, decode.acc_seg: 92.1511, aux.loss_ce: 0.1005, aux.acc_seg: 89.8814, loss: 0.2845
2023-12-29 13:02:11,869 - mmseg - INFO - Iter [138650/160000]	lr: 8.007e-06, eta: 4:46:41, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1845, decode.acc_seg: 92.0989, aux.loss_ce: 0.0976, aux.acc_seg: 90.0394, loss: 0.2820
2023-12-29 13:02:52,342 - mmseg - INFO - Iter [138700/160000]	lr: 7.988e-06, eta: 4:46:00, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1959, decode.acc_seg: 91.6268, aux.loss_ce: 0.1010, aux.acc_seg: 89.7214, loss: 0.2969
2023-12-29 13:03:33,571 - mmseg - INFO - Iter [138750/160000]	lr: 7.969e-06, eta: 4:45:20, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 91.7964, aux.loss_ce: 0.1027, aux.acc_seg: 89.7871, loss: 0.2939
2023-12-29 13:04:14,710 - mmseg - INFO - Iter [138800/160000]	lr: 7.950e-06, eta: 4:44:40, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1831, decode.acc_seg: 92.2369, aux.loss_ce: 0.0974, aux.acc_seg: 90.1938, loss: 0.2805
2023-12-29 13:04:55,809 - mmseg - INFO - Iter [138850/160000]	lr: 7.932e-06, eta: 4:44:00, time: 0.823, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1775, decode.acc_seg: 92.4166, aux.loss_ce: 0.0948, aux.acc_seg: 90.4346, loss: 0.2723
2023-12-29 13:05:36,391 - mmseg - INFO - Iter [138900/160000]	lr: 7.913e-06, eta: 4:43:20, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1825, decode.acc_seg: 92.0001, aux.loss_ce: 0.0979, aux.acc_seg: 89.9615, loss: 0.2804
2023-12-29 13:06:19,300 - mmseg - INFO - Iter [138950/160000]	lr: 7.894e-06, eta: 4:42:40, time: 0.859, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1843, decode.acc_seg: 92.2444, aux.loss_ce: 0.0987, aux.acc_seg: 90.2596, loss: 0.2830
2023-12-29 13:07:00,623 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 13:07:00,624 - mmseg - INFO - Iter [139000/160000]	lr: 7.875e-06, eta: 4:42:00, time: 0.825, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 92.0532, aux.loss_ce: 0.0999, aux.acc_seg: 89.9702, loss: 0.2856
2023-12-29 13:07:41,603 - mmseg - INFO - Iter [139050/160000]	lr: 7.857e-06, eta: 4:41:19, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1903, decode.acc_seg: 91.9693, aux.loss_ce: 0.1021, aux.acc_seg: 89.8361, loss: 0.2924
2023-12-29 13:08:23,582 - mmseg - INFO - Iter [139100/160000]	lr: 7.838e-06, eta: 4:40:39, time: 0.839, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.5966, aux.loss_ce: 0.1021, aux.acc_seg: 89.5404, loss: 0.2945
2023-12-29 13:09:04,485 - mmseg - INFO - Iter [139150/160000]	lr: 7.819e-06, eta: 4:39:59, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1918, decode.acc_seg: 91.7364, aux.loss_ce: 0.1022, aux.acc_seg: 89.6664, loss: 0.2940
2023-12-29 13:09:44,316 - mmseg - INFO - Iter [139200/160000]	lr: 7.800e-06, eta: 4:39:19, time: 0.797, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 91.8810, aux.loss_ce: 0.0998, aux.acc_seg: 90.0447, loss: 0.2898
2023-12-29 13:10:24,783 - mmseg - INFO - Iter [139250/160000]	lr: 7.782e-06, eta: 4:38:39, time: 0.809, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1819, decode.acc_seg: 92.2294, aux.loss_ce: 0.0987, aux.acc_seg: 90.2689, loss: 0.2807
2023-12-29 13:11:05,427 - mmseg - INFO - Iter [139300/160000]	lr: 7.763e-06, eta: 4:37:58, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1880, decode.acc_seg: 91.9460, aux.loss_ce: 0.0991, aux.acc_seg: 90.0078, loss: 0.2871
2023-12-29 13:11:47,369 - mmseg - INFO - Iter [139350/160000]	lr: 7.744e-06, eta: 4:37:18, time: 0.839, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1857, decode.acc_seg: 92.1121, aux.loss_ce: 0.0980, aux.acc_seg: 90.2495, loss: 0.2837
2023-12-29 13:12:28,977 - mmseg - INFO - Iter [139400/160000]	lr: 7.725e-06, eta: 4:36:38, time: 0.832, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1820, decode.acc_seg: 92.4002, aux.loss_ce: 0.0979, aux.acc_seg: 90.2395, loss: 0.2800
2023-12-29 13:13:09,187 - mmseg - INFO - Iter [139450/160000]	lr: 7.707e-06, eta: 4:35:58, time: 0.806, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.3752, aux.loss_ce: 0.0976, aux.acc_seg: 90.4358, loss: 0.2798
2023-12-29 13:13:49,973 - mmseg - INFO - Iter [139500/160000]	lr: 7.688e-06, eta: 4:35:18, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1791, decode.acc_seg: 92.2002, aux.loss_ce: 0.0970, aux.acc_seg: 89.9740, loss: 0.2761
2023-12-29 13:14:30,276 - mmseg - INFO - Iter [139550/160000]	lr: 7.669e-06, eta: 4:34:37, time: 0.807, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1819, decode.acc_seg: 92.3896, aux.loss_ce: 0.0959, aux.acc_seg: 90.4700, loss: 0.2778
2023-12-29 13:15:11,568 - mmseg - INFO - Iter [139600/160000]	lr: 7.650e-06, eta: 4:33:57, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 91.9358, aux.loss_ce: 0.0983, aux.acc_seg: 89.8765, loss: 0.2850
2023-12-29 13:15:51,917 - mmseg - INFO - Iter [139650/160000]	lr: 7.632e-06, eta: 4:33:17, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1913, decode.acc_seg: 91.9811, aux.loss_ce: 0.0999, aux.acc_seg: 90.0318, loss: 0.2912
2023-12-29 13:16:32,453 - mmseg - INFO - Iter [139700/160000]	lr: 7.613e-06, eta: 4:32:37, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1901, decode.acc_seg: 91.9942, aux.loss_ce: 0.1007, aux.acc_seg: 89.9650, loss: 0.2908
2023-12-29 13:17:11,330 - mmseg - INFO - Iter [139750/160000]	lr: 7.594e-06, eta: 4:31:56, time: 0.779, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1891, decode.acc_seg: 92.0840, aux.loss_ce: 0.1025, aux.acc_seg: 89.9054, loss: 0.2916
2023-12-29 13:17:52,280 - mmseg - INFO - Iter [139800/160000]	lr: 7.575e-06, eta: 4:31:16, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1914, decode.acc_seg: 92.1233, aux.loss_ce: 0.1007, aux.acc_seg: 90.1517, loss: 0.2922
2023-12-29 13:18:31,183 - mmseg - INFO - Iter [139850/160000]	lr: 7.557e-06, eta: 4:30:36, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1959, decode.acc_seg: 91.5749, aux.loss_ce: 0.1056, aux.acc_seg: 89.6326, loss: 0.3014
2023-12-29 13:19:11,866 - mmseg - INFO - Iter [139900/160000]	lr: 7.538e-06, eta: 4:29:55, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 92.0081, aux.loss_ce: 0.1009, aux.acc_seg: 89.9645, loss: 0.2886
2023-12-29 13:19:53,260 - mmseg - INFO - Iter [139950/160000]	lr: 7.519e-06, eta: 4:29:15, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1954, decode.acc_seg: 91.7985, aux.loss_ce: 0.1024, aux.acc_seg: 89.9024, loss: 0.2978
2023-12-29 13:20:34,689 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 13:20:34,689 - mmseg - INFO - Iter [140000/160000]	lr: 7.500e-06, eta: 4:28:35, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1848, decode.acc_seg: 92.1517, aux.loss_ce: 0.0984, aux.acc_seg: 89.9893, loss: 0.2832
2023-12-29 13:21:16,951 - mmseg - INFO - Iter [140050/160000]	lr: 7.482e-06, eta: 4:27:55, time: 0.845, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1888, decode.acc_seg: 92.0125, aux.loss_ce: 0.1019, aux.acc_seg: 89.8140, loss: 0.2908
2023-12-29 13:21:58,004 - mmseg - INFO - Iter [140100/160000]	lr: 7.463e-06, eta: 4:27:15, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1914, decode.acc_seg: 91.9788, aux.loss_ce: 0.1008, aux.acc_seg: 89.8964, loss: 0.2922
2023-12-29 13:22:38,847 - mmseg - INFO - Iter [140150/160000]	lr: 7.444e-06, eta: 4:26:35, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1898, decode.acc_seg: 91.8491, aux.loss_ce: 0.1022, aux.acc_seg: 89.6347, loss: 0.2920
2023-12-29 13:23:22,118 - mmseg - INFO - Iter [140200/160000]	lr: 7.425e-06, eta: 4:25:55, time: 0.867, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 92.2370, aux.loss_ce: 0.0999, aux.acc_seg: 89.9388, loss: 0.2848
2023-12-29 13:24:03,287 - mmseg - INFO - Iter [140250/160000]	lr: 7.407e-06, eta: 4:25:15, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1880, decode.acc_seg: 91.8931, aux.loss_ce: 0.1021, aux.acc_seg: 89.5415, loss: 0.2901
2023-12-29 13:24:43,531 - mmseg - INFO - Iter [140300/160000]	lr: 7.388e-06, eta: 4:24:34, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1903, decode.acc_seg: 91.9650, aux.loss_ce: 0.0967, aux.acc_seg: 90.2868, loss: 0.2871
2023-12-29 13:25:23,842 - mmseg - INFO - Iter [140350/160000]	lr: 7.369e-06, eta: 4:23:54, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1851, decode.acc_seg: 92.1036, aux.loss_ce: 0.0968, aux.acc_seg: 90.1677, loss: 0.2820
2023-12-29 13:26:05,248 - mmseg - INFO - Iter [140400/160000]	lr: 7.350e-06, eta: 4:23:14, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1841, decode.acc_seg: 92.1546, aux.loss_ce: 0.0973, aux.acc_seg: 90.1492, loss: 0.2815
2023-12-29 13:26:45,847 - mmseg - INFO - Iter [140450/160000]	lr: 7.332e-06, eta: 4:22:34, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1838, decode.acc_seg: 92.1925, aux.loss_ce: 0.0986, aux.acc_seg: 90.1439, loss: 0.2824
2023-12-29 13:27:25,636 - mmseg - INFO - Iter [140500/160000]	lr: 7.313e-06, eta: 4:21:53, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1860, decode.acc_seg: 91.9780, aux.loss_ce: 0.0986, aux.acc_seg: 90.0863, loss: 0.2846
2023-12-29 13:28:06,410 - mmseg - INFO - Iter [140550/160000]	lr: 7.294e-06, eta: 4:21:13, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1798, decode.acc_seg: 92.3498, aux.loss_ce: 0.0982, aux.acc_seg: 90.2134, loss: 0.2780
2023-12-29 13:28:49,146 - mmseg - INFO - Iter [140600/160000]	lr: 7.275e-06, eta: 4:20:33, time: 0.854, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1804, decode.acc_seg: 92.2363, aux.loss_ce: 0.0961, aux.acc_seg: 90.2035, loss: 0.2765
2023-12-29 13:29:30,016 - mmseg - INFO - Iter [140650/160000]	lr: 7.257e-06, eta: 4:19:53, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1968, decode.acc_seg: 91.8442, aux.loss_ce: 0.1046, aux.acc_seg: 89.5310, loss: 0.3013
2023-12-29 13:30:10,590 - mmseg - INFO - Iter [140700/160000]	lr: 7.238e-06, eta: 4:19:13, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 91.7270, aux.loss_ce: 0.1032, aux.acc_seg: 89.9381, loss: 0.2998
2023-12-29 13:30:51,671 - mmseg - INFO - Iter [140750/160000]	lr: 7.219e-06, eta: 4:18:32, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1867, decode.acc_seg: 92.1151, aux.loss_ce: 0.1000, aux.acc_seg: 90.0822, loss: 0.2867
2023-12-29 13:31:33,292 - mmseg - INFO - Iter [140800/160000]	lr: 7.200e-06, eta: 4:17:52, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 91.9442, aux.loss_ce: 0.0964, aux.acc_seg: 89.9080, loss: 0.2814
2023-12-29 13:32:14,880 - mmseg - INFO - Iter [140850/160000]	lr: 7.182e-06, eta: 4:17:12, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1837, decode.acc_seg: 92.1120, aux.loss_ce: 0.0984, aux.acc_seg: 89.9808, loss: 0.2822
2023-12-29 13:32:55,445 - mmseg - INFO - Iter [140900/160000]	lr: 7.163e-06, eta: 4:16:32, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1824, decode.acc_seg: 92.1425, aux.loss_ce: 0.0957, aux.acc_seg: 90.2635, loss: 0.2781
2023-12-29 13:33:37,881 - mmseg - INFO - Iter [140950/160000]	lr: 7.144e-06, eta: 4:15:52, time: 0.849, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1840, decode.acc_seg: 92.1730, aux.loss_ce: 0.0996, aux.acc_seg: 90.0470, loss: 0.2836
2023-12-29 13:34:18,671 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 13:34:18,672 - mmseg - INFO - Iter [141000/160000]	lr: 7.125e-06, eta: 4:15:12, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.3943, aux.loss_ce: 0.0960, aux.acc_seg: 90.3906, loss: 0.2750
2023-12-29 13:34:59,875 - mmseg - INFO - Iter [141050/160000]	lr: 7.107e-06, eta: 4:14:32, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1832, decode.acc_seg: 92.2113, aux.loss_ce: 0.1002, aux.acc_seg: 90.0063, loss: 0.2834
2023-12-29 13:35:41,397 - mmseg - INFO - Iter [141100/160000]	lr: 7.088e-06, eta: 4:13:51, time: 0.829, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1871, decode.acc_seg: 91.9133, aux.loss_ce: 0.0995, aux.acc_seg: 89.8928, loss: 0.2866
2023-12-29 13:36:22,051 - mmseg - INFO - Iter [141150/160000]	lr: 7.069e-06, eta: 4:13:11, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1826, decode.acc_seg: 92.2003, aux.loss_ce: 0.0992, aux.acc_seg: 90.0542, loss: 0.2818
2023-12-29 13:37:03,281 - mmseg - INFO - Iter [141200/160000]	lr: 7.050e-06, eta: 4:12:31, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1941, decode.acc_seg: 91.5592, aux.loss_ce: 0.1053, aux.acc_seg: 89.1464, loss: 0.2994
2023-12-29 13:37:43,794 - mmseg - INFO - Iter [141250/160000]	lr: 7.032e-06, eta: 4:11:51, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.3679, aux.loss_ce: 0.0963, aux.acc_seg: 90.3830, loss: 0.2753
2023-12-29 13:38:24,341 - mmseg - INFO - Iter [141300/160000]	lr: 7.013e-06, eta: 4:11:10, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1768, decode.acc_seg: 92.5267, aux.loss_ce: 0.0941, aux.acc_seg: 90.4550, loss: 0.2709
2023-12-29 13:39:04,516 - mmseg - INFO - Iter [141350/160000]	lr: 6.994e-06, eta: 4:10:30, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1900, decode.acc_seg: 92.0785, aux.loss_ce: 0.1029, aux.acc_seg: 89.9183, loss: 0.2929
2023-12-29 13:39:45,034 - mmseg - INFO - Iter [141400/160000]	lr: 6.975e-06, eta: 4:09:50, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1828, decode.acc_seg: 92.1095, aux.loss_ce: 0.0983, aux.acc_seg: 90.0779, loss: 0.2810
2023-12-29 13:40:25,382 - mmseg - INFO - Iter [141450/160000]	lr: 6.957e-06, eta: 4:09:10, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.1411, aux.loss_ce: 0.0985, aux.acc_seg: 90.0634, loss: 0.2814
2023-12-29 13:41:08,326 - mmseg - INFO - Iter [141500/160000]	lr: 6.938e-06, eta: 4:08:30, time: 0.858, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1817, decode.acc_seg: 92.3857, aux.loss_ce: 0.0978, aux.acc_seg: 90.2756, loss: 0.2795
2023-12-29 13:41:47,367 - mmseg - INFO - Iter [141550/160000]	lr: 6.919e-06, eta: 4:07:49, time: 0.782, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1844, decode.acc_seg: 92.3672, aux.loss_ce: 0.1005, aux.acc_seg: 90.1709, loss: 0.2850
2023-12-29 13:42:28,238 - mmseg - INFO - Iter [141600/160000]	lr: 6.900e-06, eta: 4:07:09, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1751, decode.acc_seg: 92.3593, aux.loss_ce: 0.0946, aux.acc_seg: 90.2961, loss: 0.2697
2023-12-29 13:43:09,411 - mmseg - INFO - Iter [141650/160000]	lr: 6.882e-06, eta: 4:06:29, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 92.2173, aux.loss_ce: 0.1007, aux.acc_seg: 90.1720, loss: 0.2875
2023-12-29 13:43:48,609 - mmseg - INFO - Iter [141700/160000]	lr: 6.863e-06, eta: 4:05:48, time: 0.784, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1876, decode.acc_seg: 92.0682, aux.loss_ce: 0.0999, aux.acc_seg: 90.0498, loss: 0.2875
2023-12-29 13:44:29,497 - mmseg - INFO - Iter [141750/160000]	lr: 6.844e-06, eta: 4:05:08, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1965, decode.acc_seg: 91.8917, aux.loss_ce: 0.1060, aux.acc_seg: 89.6042, loss: 0.3025
2023-12-29 13:45:09,897 - mmseg - INFO - Iter [141800/160000]	lr: 6.825e-06, eta: 4:04:28, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1948, decode.acc_seg: 91.7227, aux.loss_ce: 0.1043, aux.acc_seg: 89.4076, loss: 0.2991
2023-12-29 13:45:50,811 - mmseg - INFO - Iter [141850/160000]	lr: 6.807e-06, eta: 4:03:48, time: 0.817, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1896, decode.acc_seg: 91.8850, aux.loss_ce: 0.1014, aux.acc_seg: 89.6197, loss: 0.2910
2023-12-29 13:46:31,761 - mmseg - INFO - Iter [141900/160000]	lr: 6.788e-06, eta: 4:03:07, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1770, decode.acc_seg: 92.5329, aux.loss_ce: 0.0952, aux.acc_seg: 90.5819, loss: 0.2721
2023-12-29 13:47:13,123 - mmseg - INFO - Iter [141950/160000]	lr: 6.769e-06, eta: 4:02:27, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1906, decode.acc_seg: 91.6354, aux.loss_ce: 0.1031, aux.acc_seg: 89.6444, loss: 0.2937
2023-12-29 13:47:52,685 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 13:47:52,685 - mmseg - INFO - Iter [142000/160000]	lr: 6.750e-06, eta: 4:01:47, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1873, decode.acc_seg: 92.2184, aux.loss_ce: 0.1015, aux.acc_seg: 89.9908, loss: 0.2888
2023-12-29 13:48:30,860 - mmseg - INFO - Iter [142050/160000]	lr: 6.732e-06, eta: 4:01:06, time: 0.764, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1822, decode.acc_seg: 92.0298, aux.loss_ce: 0.0952, aux.acc_seg: 90.0491, loss: 0.2774
2023-12-29 13:49:08,227 - mmseg - INFO - Iter [142100/160000]	lr: 6.713e-06, eta: 4:00:26, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1919, decode.acc_seg: 91.7648, aux.loss_ce: 0.1021, aux.acc_seg: 89.9048, loss: 0.2941
2023-12-29 13:49:47,080 - mmseg - INFO - Iter [142150/160000]	lr: 6.694e-06, eta: 3:59:45, time: 0.776, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.3144, aux.loss_ce: 0.0966, aux.acc_seg: 90.2233, loss: 0.2789
2023-12-29 13:50:26,942 - mmseg - INFO - Iter [142200/160000]	lr: 6.675e-06, eta: 3:59:05, time: 0.798, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1922, decode.acc_seg: 92.0610, aux.loss_ce: 0.1046, aux.acc_seg: 89.8453, loss: 0.2969
2023-12-29 13:51:07,176 - mmseg - INFO - Iter [142250/160000]	lr: 6.657e-06, eta: 3:58:24, time: 0.804, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1804, decode.acc_seg: 92.2463, aux.loss_ce: 0.0958, aux.acc_seg: 90.2917, loss: 0.2762
2023-12-29 13:51:48,557 - mmseg - INFO - Iter [142300/160000]	lr: 6.638e-06, eta: 3:57:44, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1878, decode.acc_seg: 92.0250, aux.loss_ce: 0.0998, aux.acc_seg: 90.0081, loss: 0.2876
2023-12-29 13:52:27,065 - mmseg - INFO - Iter [142350/160000]	lr: 6.619e-06, eta: 3:57:04, time: 0.769, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.2416, aux.loss_ce: 0.0949, aux.acc_seg: 90.3574, loss: 0.2738
2023-12-29 13:53:08,452 - mmseg - INFO - Iter [142400/160000]	lr: 6.600e-06, eta: 3:56:24, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1806, decode.acc_seg: 92.2640, aux.loss_ce: 0.0966, aux.acc_seg: 90.2655, loss: 0.2772
2023-12-29 13:53:48,610 - mmseg - INFO - Iter [142450/160000]	lr: 6.582e-06, eta: 3:55:43, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1900, decode.acc_seg: 91.9715, aux.loss_ce: 0.1035, aux.acc_seg: 89.7636, loss: 0.2935
2023-12-29 13:54:29,563 - mmseg - INFO - Iter [142500/160000]	lr: 6.563e-06, eta: 3:55:03, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1822, decode.acc_seg: 92.2080, aux.loss_ce: 0.0973, aux.acc_seg: 90.2462, loss: 0.2795
2023-12-29 13:55:10,132 - mmseg - INFO - Iter [142550/160000]	lr: 6.544e-06, eta: 3:54:23, time: 0.811, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1874, decode.acc_seg: 92.0323, aux.loss_ce: 0.1016, aux.acc_seg: 89.7707, loss: 0.2890
2023-12-29 13:55:50,826 - mmseg - INFO - Iter [142600/160000]	lr: 6.525e-06, eta: 3:53:43, time: 0.813, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1887, decode.acc_seg: 91.8906, aux.loss_ce: 0.0994, aux.acc_seg: 89.9733, loss: 0.2881
2023-12-29 13:56:32,933 - mmseg - INFO - Iter [142650/160000]	lr: 6.507e-06, eta: 3:53:03, time: 0.844, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1857, decode.acc_seg: 92.0836, aux.loss_ce: 0.0977, aux.acc_seg: 90.0245, loss: 0.2834
2023-12-29 13:57:13,964 - mmseg - INFO - Iter [142700/160000]	lr: 6.488e-06, eta: 3:52:22, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1831, decode.acc_seg: 92.1846, aux.loss_ce: 0.0987, aux.acc_seg: 90.0719, loss: 0.2817
2023-12-29 13:57:56,871 - mmseg - INFO - Iter [142750/160000]	lr: 6.469e-06, eta: 3:51:42, time: 0.858, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1733, decode.acc_seg: 92.5630, aux.loss_ce: 0.0921, aux.acc_seg: 90.6509, loss: 0.2653
2023-12-29 13:58:38,039 - mmseg - INFO - Iter [142800/160000]	lr: 6.450e-06, eta: 3:51:02, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1826, decode.acc_seg: 92.2433, aux.loss_ce: 0.0963, aux.acc_seg: 90.3697, loss: 0.2789
2023-12-29 13:59:19,060 - mmseg - INFO - Iter [142850/160000]	lr: 6.432e-06, eta: 3:50:22, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 92.0786, aux.loss_ce: 0.0979, aux.acc_seg: 90.0630, loss: 0.2861
2023-12-29 14:00:00,584 - mmseg - INFO - Iter [142900/160000]	lr: 6.413e-06, eta: 3:49:42, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1780, decode.acc_seg: 92.4592, aux.loss_ce: 0.0978, aux.acc_seg: 90.0998, loss: 0.2758
2023-12-29 14:00:41,890 - mmseg - INFO - Iter [142950/160000]	lr: 6.394e-06, eta: 3:49:02, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1860, decode.acc_seg: 92.0864, aux.loss_ce: 0.0989, aux.acc_seg: 90.1458, loss: 0.2849
2023-12-29 14:01:23,280 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:01:23,281 - mmseg - INFO - Iter [143000/160000]	lr: 6.375e-06, eta: 3:48:21, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1834, decode.acc_seg: 92.1333, aux.loss_ce: 0.0991, aux.acc_seg: 89.9230, loss: 0.2826
2023-12-29 14:02:03,311 - mmseg - INFO - Iter [143050/160000]	lr: 6.357e-06, eta: 3:47:41, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.9390, aux.loss_ce: 0.1031, aux.acc_seg: 89.8142, loss: 0.2955
2023-12-29 14:02:44,288 - mmseg - INFO - Iter [143100/160000]	lr: 6.338e-06, eta: 3:47:01, time: 0.820, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1826, decode.acc_seg: 92.1928, aux.loss_ce: 0.0982, aux.acc_seg: 89.9622, loss: 0.2808
2023-12-29 14:03:26,909 - mmseg - INFO - Iter [143150/160000]	lr: 6.319e-06, eta: 3:46:21, time: 0.852, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1777, decode.acc_seg: 92.5063, aux.loss_ce: 0.0974, aux.acc_seg: 90.4223, loss: 0.2751
2023-12-29 14:04:08,357 - mmseg - INFO - Iter [143200/160000]	lr: 6.300e-06, eta: 3:45:41, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1798, decode.acc_seg: 92.2804, aux.loss_ce: 0.0944, aux.acc_seg: 90.3548, loss: 0.2742
2023-12-29 14:04:46,660 - mmseg - INFO - Iter [143250/160000]	lr: 6.282e-06, eta: 3:45:00, time: 0.765, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1739, decode.acc_seg: 92.6863, aux.loss_ce: 0.0930, aux.acc_seg: 90.6067, loss: 0.2669
2023-12-29 14:05:26,959 - mmseg - INFO - Iter [143300/160000]	lr: 6.263e-06, eta: 3:44:20, time: 0.806, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1802, decode.acc_seg: 92.2469, aux.loss_ce: 0.0956, aux.acc_seg: 90.2714, loss: 0.2758
2023-12-29 14:06:07,542 - mmseg - INFO - Iter [143350/160000]	lr: 6.244e-06, eta: 3:43:40, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 91.9944, aux.loss_ce: 0.1029, aux.acc_seg: 89.5549, loss: 0.2911
2023-12-29 14:06:49,266 - mmseg - INFO - Iter [143400/160000]	lr: 6.225e-06, eta: 3:42:59, time: 0.834, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1855, decode.acc_seg: 92.0632, aux.loss_ce: 0.0987, aux.acc_seg: 90.1364, loss: 0.2843
2023-12-29 14:07:28,576 - mmseg - INFO - Iter [143450/160000]	lr: 6.207e-06, eta: 3:42:19, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1705, decode.acc_seg: 92.4228, aux.loss_ce: 0.0933, aux.acc_seg: 90.2784, loss: 0.2638
2023-12-29 14:08:07,292 - mmseg - INFO - Iter [143500/160000]	lr: 6.188e-06, eta: 3:41:39, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1921, decode.acc_seg: 91.9001, aux.loss_ce: 0.1019, aux.acc_seg: 89.7299, loss: 0.2940
2023-12-29 14:08:46,767 - mmseg - INFO - Iter [143550/160000]	lr: 6.169e-06, eta: 3:40:58, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1736, decode.acc_seg: 92.6643, aux.loss_ce: 0.0899, aux.acc_seg: 90.9770, loss: 0.2635
2023-12-29 14:09:28,983 - mmseg - INFO - Iter [143600/160000]	lr: 6.150e-06, eta: 3:40:18, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1969, decode.acc_seg: 91.6234, aux.loss_ce: 0.1037, aux.acc_seg: 89.6967, loss: 0.3006
2023-12-29 14:10:10,859 - mmseg - INFO - Iter [143650/160000]	lr: 6.132e-06, eta: 3:39:38, time: 0.836, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1863, decode.acc_seg: 92.0917, aux.loss_ce: 0.0993, aux.acc_seg: 90.1637, loss: 0.2856
2023-12-29 14:10:52,352 - mmseg - INFO - Iter [143700/160000]	lr: 6.113e-06, eta: 3:38:58, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1813, decode.acc_seg: 92.1189, aux.loss_ce: 0.0956, aux.acc_seg: 90.2150, loss: 0.2769
2023-12-29 14:11:33,019 - mmseg - INFO - Iter [143750/160000]	lr: 6.094e-06, eta: 3:38:18, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1865, decode.acc_seg: 92.0495, aux.loss_ce: 0.1001, aux.acc_seg: 89.9131, loss: 0.2866
2023-12-29 14:12:14,499 - mmseg - INFO - Iter [143800/160000]	lr: 6.075e-06, eta: 3:37:37, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1760, decode.acc_seg: 92.4877, aux.loss_ce: 0.0949, aux.acc_seg: 90.5019, loss: 0.2709
2023-12-29 14:12:56,053 - mmseg - INFO - Iter [143850/160000]	lr: 6.057e-06, eta: 3:36:57, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1865, decode.acc_seg: 92.3328, aux.loss_ce: 0.1017, aux.acc_seg: 90.2895, loss: 0.2882
2023-12-29 14:13:36,737 - mmseg - INFO - Iter [143900/160000]	lr: 6.038e-06, eta: 3:36:17, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1910, decode.acc_seg: 91.9629, aux.loss_ce: 0.1007, aux.acc_seg: 89.9458, loss: 0.2916
2023-12-29 14:14:19,382 - mmseg - INFO - Iter [143950/160000]	lr: 6.019e-06, eta: 3:35:37, time: 0.853, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 92.0532, aux.loss_ce: 0.1003, aux.acc_seg: 89.9617, loss: 0.2884
2023-12-29 14:15:02,459 - mmseg - INFO - Saving checkpoint at 144000 iterations
2023-12-29 14:15:06,784 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:15:06,784 - mmseg - INFO - Iter [144000/160000]	lr: 6.000e-06, eta: 3:34:57, time: 0.949, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1842, decode.acc_seg: 92.1947, aux.loss_ce: 0.0991, aux.acc_seg: 90.1165, loss: 0.2832
2023-12-29 14:16:42,573 - mmseg - INFO - per class results:
2023-12-29 14:16:42,587 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.79 |  88.2 |
|       building      | 82.94 |  90.9 |
|         sky         | 94.48 | 97.31 |
|        floor        | 81.56 | 90.41 |
|         tree        | 75.44 | 88.57 |
|       ceiling       | 83.51 | 91.69 |
|         road        | 83.25 |  89.8 |
|         bed         | 88.23 | 95.76 |
|      windowpane     | 63.84 | 78.89 |
|        grass        | 68.21 | 83.34 |
|       cabinet       | 60.35 | 72.82 |
|       sidewalk      | 67.93 | 81.83 |
|        person       | 81.58 | 93.71 |
|        earth        | 36.34 | 48.77 |
|         door        |  54.0 | 69.24 |
|        table        | 61.34 | 77.85 |
|       mountain      | 58.55 |  77.8 |
|        plant        | 51.67 | 62.56 |
|       curtain       | 75.34 | 87.68 |
|        chair        | 56.57 | 68.62 |
|         car         | 83.65 | 90.89 |
|        water        | 57.71 | 71.19 |
|       painting      | 71.45 | 89.36 |
|         sofa        | 66.14 | 84.12 |
|        shelf        | 41.37 |  54.2 |
|        house        | 52.36 | 76.27 |
|         sea         | 55.79 | 75.44 |
|        mirror       | 67.48 | 74.49 |
|         rug         |  64.2 | 74.71 |
|        field        | 34.81 | 60.04 |
|       armchair      | 41.77 | 57.22 |
|         seat        | 59.96 | 81.94 |
|        fence        | 48.96 | 68.34 |
|         desk        | 49.19 | 72.92 |
|         rock        | 42.94 | 66.32 |
|       wardrobe      | 47.83 | 67.34 |
|         lamp        | 64.36 | 76.76 |
|       bathtub       | 76.84 | 83.12 |
|       railing       | 35.37 | 47.68 |
|       cushion       | 61.21 | 73.61 |
|         base        | 35.24 | 49.54 |
|         box         | 26.12 | 33.49 |
|        column       | 46.61 | 56.42 |
|      signboard      | 37.44 | 50.69 |
|   chest of drawers  | 39.13 | 50.43 |
|       counter       | 25.51 | 31.99 |
|         sand        | 42.99 | 71.78 |
|         sink        | 69.71 | 79.33 |
|      skyscraper     |  45.6 | 55.25 |
|      fireplace      | 71.12 |  90.3 |
|     refrigerator    | 72.11 | 79.99 |
|      grandstand     | 34.68 | 72.06 |
|         path        | 20.47 | 29.58 |
|        stairs       | 32.18 |  37.9 |
|        runway       |  69.7 | 91.33 |
|         case        | 52.58 | 70.96 |
|      pool table     | 92.98 | 97.35 |
|        pillow       | 58.87 | 70.22 |
|     screen door     | 69.82 |  80.4 |
|       stairway      | 31.58 | 37.31 |
|        river        |  9.23 | 20.27 |
|        bridge       | 73.33 |  82.6 |
|       bookcase      | 35.31 | 59.22 |
|        blind        | 40.01 | 46.93 |
|     coffee table    | 58.82 | 77.07 |
|        toilet       |  83.9 | 90.85 |
|        flower       | 40.29 |  58.7 |
|         book        | 46.51 | 70.23 |
|         hill        |  4.14 |  7.15 |
|        bench        | 44.04 | 53.14 |
|      countertop     | 63.52 | 84.28 |
|        stove        | 79.05 | 87.85 |
|         palm        | 48.23 | 70.11 |
|    kitchen island   | 42.11 | 83.37 |
|       computer      | 71.86 | 83.85 |
|     swivel chair    |  39.7 | 66.99 |
|         boat        |  42.3 | 50.37 |
|         bar         |  42.7 | 63.34 |
|    arcade machine   | 81.55 | 89.28 |
|        hovel        | 41.32 | 49.44 |
|         bus         | 79.91 | 96.49 |
|        towel        | 62.91 |  73.7 |
|        light        | 56.63 | 65.55 |
|        truck        | 28.72 | 36.97 |
|        tower        | 27.91 | 46.69 |
|      chandelier     | 69.69 | 87.05 |
|        awning       | 24.82 | 36.05 |
|     streetlight     | 26.77 | 34.65 |
|        booth        | 57.97 | 63.51 |
| television receiver | 63.77 | 80.14 |
|       airplane      | 56.83 | 66.91 |
|      dirt track     | 28.62 | 53.53 |
|       apparel       | 42.02 | 56.95 |
|         pole        | 24.03 | 33.01 |
|         land        |  3.8  |  4.9  |
|      bannister      | 13.29 | 16.91 |
|      escalator      |  28.2 | 30.36 |
|       ottoman       | 39.73 | 61.23 |
|        bottle       |  32.8 | 55.01 |
|        buffet       | 42.18 | 46.33 |
|        poster       | 27.88 | 33.48 |
|        stage        | 21.21 | 32.88 |
|         van         | 42.27 | 59.83 |
|         ship        | 51.66 | 83.72 |
|       fountain      | 20.44 | 20.53 |
|    conveyer belt    | 78.38 | 89.83 |
|        canopy       | 18.32 | 25.04 |
|        washer       | 88.43 | 94.47 |
|      plaything      |  23.9 | 43.52 |
|    swimming pool    | 61.11 | 90.31 |
|        stool        | 34.87 | 51.41 |
|        barrel       | 14.41 | 68.44 |
|        basket       | 33.46 | 47.47 |
|      waterfall      | 69.13 | 77.86 |
|         tent        | 95.09 | 98.57 |
|         bag         | 13.14 | 17.21 |
|       minibike      | 74.11 | 84.15 |
|        cradle       | 75.85 | 97.68 |
|         oven        | 53.43 |  72.9 |
|         ball        | 45.26 | 70.56 |
|         food        | 51.48 | 62.75 |
|         step        | 10.32 | 12.47 |
|         tank        | 58.06 |  62.8 |
|      trade name     | 23.43 | 27.03 |
|      microwave      | 79.46 | 86.45 |
|         pot         | 46.77 |  55.3 |
|        animal       | 49.04 | 56.31 |
|       bicycle       | 54.28 | 76.68 |
|         lake        | 58.17 | 63.66 |
|      dishwasher     | 62.82 | 71.09 |
|        screen       | 63.78 | 90.33 |
|       blanket       | 11.35 | 12.86 |
|      sculpture      | 61.61 | 72.03 |
|         hood        | 59.58 | 71.46 |
|        sconce       | 44.77 | 53.44 |
|         vase        | 40.78 | 53.66 |
|    traffic light    |  29.3 | 46.09 |
|         tray        | 13.42 | 17.96 |
|        ashcan       | 43.27 | 53.46 |
|         fan         | 55.21 | 74.84 |
|         pier        |  32.0 | 57.43 |
|      crt screen     |  4.22 | 11.25 |
|        plate        | 52.63 | 76.59 |
|       monitor       |  9.32 | 11.75 |
|    bulletin board   | 49.64 | 60.73 |
|        shower       |  4.45 |  5.58 |
|       radiator      | 57.75 | 66.12 |
|        glass        |  15.8 | 17.84 |
|        clock        |  31.0 | 34.95 |
|         flag        | 48.73 |  55.1 |
+---------------------+-------+-------+
2023-12-29 14:16:42,587 - mmseg - INFO - Summary:
2023-12-29 14:16:42,587 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.32 | 49.76 | 62.91 |
+-------+-------+-------+
2023-12-29 14:16:42,618 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:16:42,619 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8332, mIoU: 0.4976, mAcc: 0.6291, IoU.wall: 0.7779, IoU.building: 0.8294, IoU.sky: 0.9448, IoU.floor: 0.8156, IoU.tree: 0.7544, IoU.ceiling: 0.8351, IoU.road: 0.8325, IoU.bed : 0.8823, IoU.windowpane: 0.6384, IoU.grass: 0.6821, IoU.cabinet: 0.6035, IoU.sidewalk: 0.6793, IoU.person: 0.8158, IoU.earth: 0.3634, IoU.door: 0.5400, IoU.table: 0.6134, IoU.mountain: 0.5855, IoU.plant: 0.5167, IoU.curtain: 0.7534, IoU.chair: 0.5657, IoU.car: 0.8365, IoU.water: 0.5771, IoU.painting: 0.7145, IoU.sofa: 0.6614, IoU.shelf: 0.4137, IoU.house: 0.5236, IoU.sea: 0.5579, IoU.mirror: 0.6748, IoU.rug: 0.6420, IoU.field: 0.3481, IoU.armchair: 0.4177, IoU.seat: 0.5996, IoU.fence: 0.4896, IoU.desk: 0.4919, IoU.rock: 0.4294, IoU.wardrobe: 0.4783, IoU.lamp: 0.6436, IoU.bathtub: 0.7684, IoU.railing: 0.3537, IoU.cushion: 0.6121, IoU.base: 0.3524, IoU.box: 0.2612, IoU.column: 0.4661, IoU.signboard: 0.3744, IoU.chest of drawers: 0.3913, IoU.counter: 0.2551, IoU.sand: 0.4299, IoU.sink: 0.6971, IoU.skyscraper: 0.4560, IoU.fireplace: 0.7112, IoU.refrigerator: 0.7211, IoU.grandstand: 0.3468, IoU.path: 0.2047, IoU.stairs: 0.3218, IoU.runway: 0.6970, IoU.case: 0.5258, IoU.pool table: 0.9298, IoU.pillow: 0.5887, IoU.screen door: 0.6982, IoU.stairway: 0.3158, IoU.river: 0.0923, IoU.bridge: 0.7333, IoU.bookcase: 0.3531, IoU.blind: 0.4001, IoU.coffee table: 0.5882, IoU.toilet: 0.8390, IoU.flower: 0.4029, IoU.book: 0.4651, IoU.hill: 0.0414, IoU.bench: 0.4404, IoU.countertop: 0.6352, IoU.stove: 0.7905, IoU.palm: 0.4823, IoU.kitchen island: 0.4211, IoU.computer: 0.7186, IoU.swivel chair: 0.3970, IoU.boat: 0.4230, IoU.bar: 0.4270, IoU.arcade machine: 0.8155, IoU.hovel: 0.4132, IoU.bus: 0.7991, IoU.towel: 0.6291, IoU.light: 0.5663, IoU.truck: 0.2872, IoU.tower: 0.2791, IoU.chandelier: 0.6969, IoU.awning: 0.2482, IoU.streetlight: 0.2677, IoU.booth: 0.5797, IoU.television receiver: 0.6377, IoU.airplane: 0.5683, IoU.dirt track: 0.2862, IoU.apparel: 0.4202, IoU.pole: 0.2403, IoU.land: 0.0380, IoU.bannister: 0.1329, IoU.escalator: 0.2820, IoU.ottoman: 0.3973, IoU.bottle: 0.3280, IoU.buffet: 0.4218, IoU.poster: 0.2788, IoU.stage: 0.2121, IoU.van: 0.4227, IoU.ship: 0.5166, IoU.fountain: 0.2044, IoU.conveyer belt: 0.7838, IoU.canopy: 0.1832, IoU.washer: 0.8843, IoU.plaything: 0.2390, IoU.swimming pool: 0.6111, IoU.stool: 0.3487, IoU.barrel: 0.1441, IoU.basket: 0.3346, IoU.waterfall: 0.6913, IoU.tent: 0.9509, IoU.bag: 0.1314, IoU.minibike: 0.7411, IoU.cradle: 0.7585, IoU.oven: 0.5343, IoU.ball: 0.4526, IoU.food: 0.5148, IoU.step: 0.1032, IoU.tank: 0.5806, IoU.trade name: 0.2343, IoU.microwave: 0.7946, IoU.pot: 0.4677, IoU.animal: 0.4904, IoU.bicycle: 0.5428, IoU.lake: 0.5817, IoU.dishwasher: 0.6282, IoU.screen: 0.6378, IoU.blanket: 0.1135, IoU.sculpture: 0.6161, IoU.hood: 0.5958, IoU.sconce: 0.4477, IoU.vase: 0.4078, IoU.traffic light: 0.2930, IoU.tray: 0.1342, IoU.ashcan: 0.4327, IoU.fan: 0.5521, IoU.pier: 0.3200, IoU.crt screen: 0.0422, IoU.plate: 0.5263, IoU.monitor: 0.0932, IoU.bulletin board: 0.4964, IoU.shower: 0.0445, IoU.radiator: 0.5775, IoU.glass: 0.1580, IoU.clock: 0.3100, IoU.flag: 0.4873, Acc.wall: 0.8820, Acc.building: 0.9090, Acc.sky: 0.9731, Acc.floor: 0.9041, Acc.tree: 0.8857, Acc.ceiling: 0.9169, Acc.road: 0.8980, Acc.bed : 0.9576, Acc.windowpane: 0.7889, Acc.grass: 0.8334, Acc.cabinet: 0.7282, Acc.sidewalk: 0.8183, Acc.person: 0.9371, Acc.earth: 0.4877, Acc.door: 0.6924, Acc.table: 0.7785, Acc.mountain: 0.7780, Acc.plant: 0.6256, Acc.curtain: 0.8768, Acc.chair: 0.6862, Acc.car: 0.9089, Acc.water: 0.7119, Acc.painting: 0.8936, Acc.sofa: 0.8412, Acc.shelf: 0.5420, Acc.house: 0.7627, Acc.sea: 0.7544, Acc.mirror: 0.7449, Acc.rug: 0.7471, Acc.field: 0.6004, Acc.armchair: 0.5722, Acc.seat: 0.8194, Acc.fence: 0.6834, Acc.desk: 0.7292, Acc.rock: 0.6632, Acc.wardrobe: 0.6734, Acc.lamp: 0.7676, Acc.bathtub: 0.8312, Acc.railing: 0.4768, Acc.cushion: 0.7361, Acc.base: 0.4954, Acc.box: 0.3349, Acc.column: 0.5642, Acc.signboard: 0.5069, Acc.chest of drawers: 0.5043, Acc.counter: 0.3199, Acc.sand: 0.7178, Acc.sink: 0.7933, Acc.skyscraper: 0.5525, Acc.fireplace: 0.9030, Acc.refrigerator: 0.7999, Acc.grandstand: 0.7206, Acc.path: 0.2958, Acc.stairs: 0.3790, Acc.runway: 0.9133, Acc.case: 0.7096, Acc.pool table: 0.9735, Acc.pillow: 0.7022, Acc.screen door: 0.8040, Acc.stairway: 0.3731, Acc.river: 0.2027, Acc.bridge: 0.8260, Acc.bookcase: 0.5922, Acc.blind: 0.4693, Acc.coffee table: 0.7707, Acc.toilet: 0.9085, Acc.flower: 0.5870, Acc.book: 0.7023, Acc.hill: 0.0715, Acc.bench: 0.5314, Acc.countertop: 0.8428, Acc.stove: 0.8785, Acc.palm: 0.7011, Acc.kitchen island: 0.8337, Acc.computer: 0.8385, Acc.swivel chair: 0.6699, Acc.boat: 0.5037, Acc.bar: 0.6334, Acc.arcade machine: 0.8928, Acc.hovel: 0.4944, Acc.bus: 0.9649, Acc.towel: 0.7370, Acc.light: 0.6555, Acc.truck: 0.3697, Acc.tower: 0.4669, Acc.chandelier: 0.8705, Acc.awning: 0.3605, Acc.streetlight: 0.3465, Acc.booth: 0.6351, Acc.television receiver: 0.8014, Acc.airplane: 0.6691, Acc.dirt track: 0.5353, Acc.apparel: 0.5695, Acc.pole: 0.3301, Acc.land: 0.0490, Acc.bannister: 0.1691, Acc.escalator: 0.3036, Acc.ottoman: 0.6123, Acc.bottle: 0.5501, Acc.buffet: 0.4633, Acc.poster: 0.3348, Acc.stage: 0.3288, Acc.van: 0.5983, Acc.ship: 0.8372, Acc.fountain: 0.2053, Acc.conveyer belt: 0.8983, Acc.canopy: 0.2504, Acc.washer: 0.9447, Acc.plaything: 0.4352, Acc.swimming pool: 0.9031, Acc.stool: 0.5141, Acc.barrel: 0.6844, Acc.basket: 0.4747, Acc.waterfall: 0.7786, Acc.tent: 0.9857, Acc.bag: 0.1721, Acc.minibike: 0.8415, Acc.cradle: 0.9768, Acc.oven: 0.7290, Acc.ball: 0.7056, Acc.food: 0.6275, Acc.step: 0.1247, Acc.tank: 0.6280, Acc.trade name: 0.2703, Acc.microwave: 0.8645, Acc.pot: 0.5530, Acc.animal: 0.5631, Acc.bicycle: 0.7668, Acc.lake: 0.6366, Acc.dishwasher: 0.7109, Acc.screen: 0.9033, Acc.blanket: 0.1286, Acc.sculpture: 0.7203, Acc.hood: 0.7146, Acc.sconce: 0.5344, Acc.vase: 0.5366, Acc.traffic light: 0.4609, Acc.tray: 0.1796, Acc.ashcan: 0.5346, Acc.fan: 0.7484, Acc.pier: 0.5743, Acc.crt screen: 0.1125, Acc.plate: 0.7659, Acc.monitor: 0.1175, Acc.bulletin board: 0.6073, Acc.shower: 0.0558, Acc.radiator: 0.6612, Acc.glass: 0.1784, Acc.clock: 0.3495, Acc.flag: 0.5510
2023-12-29 14:17:20,684 - mmseg - INFO - Iter [144050/160000]	lr: 5.982e-06, eta: 3:34:27, time: 2.678, data_time: 1.928, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.2403, aux.loss_ce: 0.1004, aux.acc_seg: 89.9937, loss: 0.2833
2023-12-29 14:17:59,415 - mmseg - INFO - Iter [144100/160000]	lr: 5.963e-06, eta: 3:33:47, time: 0.774, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1830, decode.acc_seg: 92.3988, aux.loss_ce: 0.0968, aux.acc_seg: 90.1775, loss: 0.2798
2023-12-29 14:18:40,079 - mmseg - INFO - Iter [144150/160000]	lr: 5.944e-06, eta: 3:33:07, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1805, decode.acc_seg: 92.3177, aux.loss_ce: 0.0973, aux.acc_seg: 90.2796, loss: 0.2778
2023-12-29 14:19:18,960 - mmseg - INFO - Iter [144200/160000]	lr: 5.925e-06, eta: 3:32:26, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1840, decode.acc_seg: 92.1881, aux.loss_ce: 0.0996, aux.acc_seg: 89.9755, loss: 0.2836
2023-12-29 14:19:59,283 - mmseg - INFO - Iter [144250/160000]	lr: 5.907e-06, eta: 3:31:46, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1787, decode.acc_seg: 92.3089, aux.loss_ce: 0.0966, aux.acc_seg: 90.3292, loss: 0.2753
2023-12-29 14:20:39,379 - mmseg - INFO - Iter [144300/160000]	lr: 5.888e-06, eta: 3:31:05, time: 0.803, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1736, decode.acc_seg: 92.4210, aux.loss_ce: 0.0918, aux.acc_seg: 90.6722, loss: 0.2654
2023-12-29 14:21:19,479 - mmseg - INFO - Iter [144350/160000]	lr: 5.869e-06, eta: 3:30:25, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1749, decode.acc_seg: 92.3452, aux.loss_ce: 0.0935, aux.acc_seg: 90.3818, loss: 0.2684
2023-12-29 14:21:58,715 - mmseg - INFO - Iter [144400/160000]	lr: 5.850e-06, eta: 3:29:45, time: 0.786, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1799, decode.acc_seg: 92.2221, aux.loss_ce: 0.0985, aux.acc_seg: 89.9781, loss: 0.2783
2023-12-29 14:22:38,639 - mmseg - INFO - Iter [144450/160000]	lr: 5.832e-06, eta: 3:29:04, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.3780, aux.loss_ce: 0.0985, aux.acc_seg: 90.1384, loss: 0.2775
2023-12-29 14:23:16,741 - mmseg - INFO - Iter [144500/160000]	lr: 5.813e-06, eta: 3:28:24, time: 0.763, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1769, decode.acc_seg: 92.2959, aux.loss_ce: 0.0952, aux.acc_seg: 90.2103, loss: 0.2722
2023-12-29 14:23:56,977 - mmseg - INFO - Iter [144550/160000]	lr: 5.794e-06, eta: 3:27:43, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1651, decode.acc_seg: 92.9749, aux.loss_ce: 0.0879, aux.acc_seg: 91.1329, loss: 0.2530
2023-12-29 14:24:33,655 - mmseg - INFO - Iter [144600/160000]	lr: 5.775e-06, eta: 3:27:03, time: 0.734, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1872, decode.acc_seg: 91.7074, aux.loss_ce: 0.0988, aux.acc_seg: 89.7275, loss: 0.2860
2023-12-29 14:25:12,336 - mmseg - INFO - Iter [144650/160000]	lr: 5.757e-06, eta: 3:26:22, time: 0.772, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1889, decode.acc_seg: 92.1323, aux.loss_ce: 0.0998, aux.acc_seg: 90.1554, loss: 0.2887
2023-12-29 14:25:52,638 - mmseg - INFO - Iter [144700/160000]	lr: 5.738e-06, eta: 3:25:42, time: 0.806, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1825, decode.acc_seg: 92.1094, aux.loss_ce: 0.0987, aux.acc_seg: 89.9946, loss: 0.2812
2023-12-29 14:26:32,977 - mmseg - INFO - Iter [144750/160000]	lr: 5.719e-06, eta: 3:25:01, time: 0.807, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1949, decode.acc_seg: 91.9949, aux.loss_ce: 0.1034, aux.acc_seg: 89.8844, loss: 0.2983
2023-12-29 14:27:11,052 - mmseg - INFO - Iter [144800/160000]	lr: 5.700e-06, eta: 3:24:21, time: 0.762, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1867, decode.acc_seg: 92.2088, aux.loss_ce: 0.1013, aux.acc_seg: 90.2208, loss: 0.2880
2023-12-29 14:27:50,106 - mmseg - INFO - Iter [144850/160000]	lr: 5.682e-06, eta: 3:23:40, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1982, decode.acc_seg: 91.8816, aux.loss_ce: 0.1055, aux.acc_seg: 89.8510, loss: 0.3038
2023-12-29 14:28:30,191 - mmseg - INFO - Iter [144900/160000]	lr: 5.663e-06, eta: 3:23:00, time: 0.803, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1830, decode.acc_seg: 92.0056, aux.loss_ce: 0.0949, aux.acc_seg: 90.1395, loss: 0.2779
2023-12-29 14:29:09,622 - mmseg - INFO - Iter [144950/160000]	lr: 5.644e-06, eta: 3:22:20, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1914, decode.acc_seg: 91.9940, aux.loss_ce: 0.0997, aux.acc_seg: 90.2160, loss: 0.2911
2023-12-29 14:29:49,568 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:29:49,568 - mmseg - INFO - Iter [145000/160000]	lr: 5.625e-06, eta: 3:21:39, time: 0.799, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1937, decode.acc_seg: 91.8814, aux.loss_ce: 0.1040, aux.acc_seg: 89.7343, loss: 0.2977
2023-12-29 14:30:28,598 - mmseg - INFO - Iter [145050/160000]	lr: 5.607e-06, eta: 3:20:59, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1876, decode.acc_seg: 92.0120, aux.loss_ce: 0.1010, aux.acc_seg: 89.9423, loss: 0.2886
2023-12-29 14:31:06,865 - mmseg - INFO - Iter [145100/160000]	lr: 5.588e-06, eta: 3:20:18, time: 0.765, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1917, decode.acc_seg: 92.1020, aux.loss_ce: 0.1000, aux.acc_seg: 90.2345, loss: 0.2916
2023-12-29 14:31:44,208 - mmseg - INFO - Iter [145150/160000]	lr: 5.569e-06, eta: 3:19:38, time: 0.747, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1878, decode.acc_seg: 92.0552, aux.loss_ce: 0.1007, aux.acc_seg: 89.9689, loss: 0.2885
2023-12-29 14:32:23,492 - mmseg - INFO - Iter [145200/160000]	lr: 5.550e-06, eta: 3:18:57, time: 0.785, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1855, decode.acc_seg: 92.1758, aux.loss_ce: 0.1014, aux.acc_seg: 89.8773, loss: 0.2869
2023-12-29 14:33:05,088 - mmseg - INFO - Iter [145250/160000]	lr: 5.532e-06, eta: 3:18:17, time: 0.833, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1868, decode.acc_seg: 92.0966, aux.loss_ce: 0.0996, aux.acc_seg: 89.9675, loss: 0.2865
2023-12-29 14:33:42,135 - mmseg - INFO - Iter [145300/160000]	lr: 5.513e-06, eta: 3:17:36, time: 0.741, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1835, decode.acc_seg: 92.2932, aux.loss_ce: 0.0987, aux.acc_seg: 90.2540, loss: 0.2821
2023-12-29 14:34:21,465 - mmseg - INFO - Iter [145350/160000]	lr: 5.494e-06, eta: 3:16:56, time: 0.787, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1756, decode.acc_seg: 92.3788, aux.loss_ce: 0.0925, aux.acc_seg: 90.4808, loss: 0.2682
2023-12-29 14:35:00,165 - mmseg - INFO - Iter [145400/160000]	lr: 5.475e-06, eta: 3:16:15, time: 0.774, data_time: 0.010, memory: 18256, decode.loss_ce: 0.1763, decode.acc_seg: 92.4738, aux.loss_ce: 0.0926, aux.acc_seg: 90.5010, loss: 0.2689
2023-12-29 14:35:39,887 - mmseg - INFO - Iter [145450/160000]	lr: 5.457e-06, eta: 3:15:35, time: 0.793, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1826, decode.acc_seg: 92.2645, aux.loss_ce: 0.0991, aux.acc_seg: 90.0582, loss: 0.2817
2023-12-29 14:36:20,175 - mmseg - INFO - Iter [145500/160000]	lr: 5.438e-06, eta: 3:14:55, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1852, decode.acc_seg: 92.0677, aux.loss_ce: 0.0989, aux.acc_seg: 90.0990, loss: 0.2841
2023-12-29 14:37:00,429 - mmseg - INFO - Iter [145550/160000]	lr: 5.419e-06, eta: 3:14:14, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1925, decode.acc_seg: 91.8760, aux.loss_ce: 0.1014, aux.acc_seg: 89.8736, loss: 0.2939
2023-12-29 14:37:40,660 - mmseg - INFO - Iter [145600/160000]	lr: 5.400e-06, eta: 3:13:34, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1810, decode.acc_seg: 92.2176, aux.loss_ce: 0.0990, aux.acc_seg: 90.0298, loss: 0.2800
2023-12-29 14:38:20,451 - mmseg - INFO - Iter [145650/160000]	lr: 5.382e-06, eta: 3:12:54, time: 0.796, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1833, decode.acc_seg: 92.2274, aux.loss_ce: 0.0989, aux.acc_seg: 90.0855, loss: 0.2821
2023-12-29 14:38:59,358 - mmseg - INFO - Iter [145700/160000]	lr: 5.363e-06, eta: 3:12:13, time: 0.779, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1761, decode.acc_seg: 92.3797, aux.loss_ce: 0.0944, aux.acc_seg: 90.2884, loss: 0.2705
2023-12-29 14:39:36,649 - mmseg - INFO - Iter [145750/160000]	lr: 5.344e-06, eta: 3:11:32, time: 0.745, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1837, decode.acc_seg: 92.0699, aux.loss_ce: 0.0999, aux.acc_seg: 89.9300, loss: 0.2836
2023-12-29 14:40:16,721 - mmseg - INFO - Iter [145800/160000]	lr: 5.325e-06, eta: 3:10:52, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1866, decode.acc_seg: 92.0532, aux.loss_ce: 0.1016, aux.acc_seg: 89.6431, loss: 0.2881
2023-12-29 14:40:56,627 - mmseg - INFO - Iter [145850/160000]	lr: 5.307e-06, eta: 3:10:12, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1812, decode.acc_seg: 92.3232, aux.loss_ce: 0.0991, aux.acc_seg: 90.1584, loss: 0.2803
2023-12-29 14:41:35,059 - mmseg - INFO - Iter [145900/160000]	lr: 5.288e-06, eta: 3:09:31, time: 0.769, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1818, decode.acc_seg: 92.1108, aux.loss_ce: 0.0956, aux.acc_seg: 90.2092, loss: 0.2774
2023-12-29 14:42:13,054 - mmseg - INFO - Iter [145950/160000]	lr: 5.269e-06, eta: 3:08:51, time: 0.759, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1778, decode.acc_seg: 92.4086, aux.loss_ce: 0.0937, aux.acc_seg: 90.5451, loss: 0.2715
2023-12-29 14:42:53,268 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:42:53,268 - mmseg - INFO - Iter [146000/160000]	lr: 5.250e-06, eta: 3:08:10, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1738, decode.acc_seg: 92.5720, aux.loss_ce: 0.0967, aux.acc_seg: 90.2389, loss: 0.2705
2023-12-29 14:43:31,361 - mmseg - INFO - Iter [146050/160000]	lr: 5.232e-06, eta: 3:07:30, time: 0.760, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1896, decode.acc_seg: 92.0338, aux.loss_ce: 0.1003, aux.acc_seg: 89.9201, loss: 0.2898
2023-12-29 14:44:10,247 - mmseg - INFO - Iter [146100/160000]	lr: 5.213e-06, eta: 3:06:49, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1788, decode.acc_seg: 92.5547, aux.loss_ce: 0.0951, aux.acc_seg: 90.4835, loss: 0.2739
2023-12-29 14:44:50,750 - mmseg - INFO - Iter [146150/160000]	lr: 5.194e-06, eta: 3:06:09, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1721, decode.acc_seg: 92.7894, aux.loss_ce: 0.0923, aux.acc_seg: 90.8987, loss: 0.2644
2023-12-29 14:45:31,008 - mmseg - INFO - Iter [146200/160000]	lr: 5.175e-06, eta: 3:05:29, time: 0.805, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 91.9652, aux.loss_ce: 0.0990, aux.acc_seg: 89.8951, loss: 0.2849
2023-12-29 14:46:08,821 - mmseg - INFO - Iter [146250/160000]	lr: 5.157e-06, eta: 3:04:48, time: 0.755, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1876, decode.acc_seg: 91.8032, aux.loss_ce: 0.1003, aux.acc_seg: 89.7877, loss: 0.2879
2023-12-29 14:46:48,897 - mmseg - INFO - Iter [146300/160000]	lr: 5.138e-06, eta: 3:04:08, time: 0.801, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1828, decode.acc_seg: 92.0427, aux.loss_ce: 0.0989, aux.acc_seg: 89.9937, loss: 0.2816
2023-12-29 14:47:29,334 - mmseg - INFO - Iter [146350/160000]	lr: 5.119e-06, eta: 3:03:28, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1865, decode.acc_seg: 92.0843, aux.loss_ce: 0.0994, aux.acc_seg: 90.0824, loss: 0.2860
2023-12-29 14:48:08,502 - mmseg - INFO - Iter [146400/160000]	lr: 5.100e-06, eta: 3:02:47, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1770, decode.acc_seg: 92.4303, aux.loss_ce: 0.0954, aux.acc_seg: 90.3104, loss: 0.2723
2023-12-29 14:48:45,564 - mmseg - INFO - Iter [146450/160000]	lr: 5.082e-06, eta: 3:02:06, time: 0.741, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1789, decode.acc_seg: 92.3141, aux.loss_ce: 0.0960, aux.acc_seg: 90.3954, loss: 0.2749
2023-12-29 14:49:22,716 - mmseg - INFO - Iter [146500/160000]	lr: 5.063e-06, eta: 3:01:26, time: 0.743, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1909, decode.acc_seg: 91.9837, aux.loss_ce: 0.1012, aux.acc_seg: 90.0177, loss: 0.2921
2023-12-29 14:50:04,170 - mmseg - INFO - Iter [146550/160000]	lr: 5.044e-06, eta: 3:00:46, time: 0.829, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1688, decode.acc_seg: 92.6778, aux.loss_ce: 0.0911, aux.acc_seg: 90.7228, loss: 0.2599
2023-12-29 14:50:45,784 - mmseg - INFO - Iter [146600/160000]	lr: 5.025e-06, eta: 3:00:05, time: 0.831, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1827, decode.acc_seg: 92.1885, aux.loss_ce: 0.0993, aux.acc_seg: 89.9343, loss: 0.2821
2023-12-29 14:51:23,943 - mmseg - INFO - Iter [146650/160000]	lr: 5.007e-06, eta: 2:59:25, time: 0.764, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1729, decode.acc_seg: 92.6234, aux.loss_ce: 0.0942, aux.acc_seg: 90.5776, loss: 0.2671
2023-12-29 14:52:03,439 - mmseg - INFO - Iter [146700/160000]	lr: 4.988e-06, eta: 2:58:45, time: 0.790, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1854, decode.acc_seg: 92.1437, aux.loss_ce: 0.0996, aux.acc_seg: 90.1260, loss: 0.2850
2023-12-29 14:52:40,555 - mmseg - INFO - Iter [146750/160000]	lr: 4.969e-06, eta: 2:58:04, time: 0.743, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1864, decode.acc_seg: 91.9439, aux.loss_ce: 0.0991, aux.acc_seg: 89.8361, loss: 0.2856
2023-12-29 14:53:19,423 - mmseg - INFO - Iter [146800/160000]	lr: 4.950e-06, eta: 2:57:23, time: 0.778, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1787, decode.acc_seg: 92.4208, aux.loss_ce: 0.0965, aux.acc_seg: 90.3450, loss: 0.2752
2023-12-29 14:53:58,948 - mmseg - INFO - Iter [146850/160000]	lr: 4.932e-06, eta: 2:56:43, time: 0.789, data_time: 0.010, memory: 18256, decode.loss_ce: 0.1842, decode.acc_seg: 92.3283, aux.loss_ce: 0.1004, aux.acc_seg: 90.0429, loss: 0.2846
2023-12-29 14:54:39,254 - mmseg - INFO - Iter [146900/160000]	lr: 4.913e-06, eta: 2:56:03, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1791, decode.acc_seg: 92.2869, aux.loss_ce: 0.0973, aux.acc_seg: 90.0914, loss: 0.2764
2023-12-29 14:55:18,327 - mmseg - INFO - Iter [146950/160000]	lr: 4.894e-06, eta: 2:55:22, time: 0.783, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.9497, aux.loss_ce: 0.1020, aux.acc_seg: 89.9235, loss: 0.2944
2023-12-29 14:55:57,281 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 14:55:57,282 - mmseg - INFO - Iter [147000/160000]	lr: 4.875e-06, eta: 2:54:42, time: 0.779, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1740, decode.acc_seg: 92.6221, aux.loss_ce: 0.0950, aux.acc_seg: 90.2997, loss: 0.2690
2023-12-29 14:56:38,241 - mmseg - INFO - Iter [147050/160000]	lr: 4.857e-06, eta: 2:54:02, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1770, decode.acc_seg: 92.3718, aux.loss_ce: 0.0953, aux.acc_seg: 90.4178, loss: 0.2723
2023-12-29 14:57:17,912 - mmseg - INFO - Iter [147100/160000]	lr: 4.838e-06, eta: 2:53:21, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1810, decode.acc_seg: 92.2631, aux.loss_ce: 0.0963, aux.acc_seg: 90.3006, loss: 0.2773
2023-12-29 14:57:55,880 - mmseg - INFO - Iter [147150/160000]	lr: 4.819e-06, eta: 2:52:41, time: 0.758, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1805, decode.acc_seg: 92.3251, aux.loss_ce: 0.0984, aux.acc_seg: 90.1980, loss: 0.2788
2023-12-29 14:58:35,783 - mmseg - INFO - Iter [147200/160000]	lr: 4.800e-06, eta: 2:52:00, time: 0.799, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1744, decode.acc_seg: 92.5112, aux.loss_ce: 0.0933, aux.acc_seg: 90.5729, loss: 0.2676
2023-12-29 14:59:16,097 - mmseg - INFO - Iter [147250/160000]	lr: 4.782e-06, eta: 2:51:20, time: 0.805, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1786, decode.acc_seg: 92.3128, aux.loss_ce: 0.0961, aux.acc_seg: 90.1184, loss: 0.2747
2023-12-29 14:59:55,776 - mmseg - INFO - Iter [147300/160000]	lr: 4.763e-06, eta: 2:50:40, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1698, decode.acc_seg: 92.5953, aux.loss_ce: 0.0929, aux.acc_seg: 90.6162, loss: 0.2628
2023-12-29 15:00:35,376 - mmseg - INFO - Iter [147350/160000]	lr: 4.744e-06, eta: 2:49:59, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1783, decode.acc_seg: 92.4388, aux.loss_ce: 0.0953, aux.acc_seg: 90.3821, loss: 0.2736
2023-12-29 15:01:13,941 - mmseg - INFO - Iter [147400/160000]	lr: 4.725e-06, eta: 2:49:19, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1794, decode.acc_seg: 92.2761, aux.loss_ce: 0.0976, aux.acc_seg: 90.0683, loss: 0.2771
2023-12-29 15:01:52,587 - mmseg - INFO - Iter [147450/160000]	lr: 4.707e-06, eta: 2:48:38, time: 0.773, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1879, decode.acc_seg: 91.9380, aux.loss_ce: 0.1025, aux.acc_seg: 89.6034, loss: 0.2904
2023-12-29 15:02:31,235 - mmseg - INFO - Iter [147500/160000]	lr: 4.688e-06, eta: 2:47:58, time: 0.772, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1834, decode.acc_seg: 92.0696, aux.loss_ce: 0.0997, aux.acc_seg: 90.0331, loss: 0.2831
2023-12-29 15:03:11,270 - mmseg - INFO - Iter [147550/160000]	lr: 4.669e-06, eta: 2:47:18, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1771, decode.acc_seg: 92.2967, aux.loss_ce: 0.0970, aux.acc_seg: 90.2010, loss: 0.2741
2023-12-29 15:03:49,747 - mmseg - INFO - Iter [147600/160000]	lr: 4.650e-06, eta: 2:46:37, time: 0.769, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1845, decode.acc_seg: 92.0293, aux.loss_ce: 0.0987, aux.acc_seg: 89.9877, loss: 0.2832
2023-12-29 15:04:28,224 - mmseg - INFO - Iter [147650/160000]	lr: 4.632e-06, eta: 2:45:57, time: 0.770, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1800, decode.acc_seg: 92.3100, aux.loss_ce: 0.0990, aux.acc_seg: 90.0354, loss: 0.2790
2023-12-29 15:05:09,597 - mmseg - INFO - Iter [147700/160000]	lr: 4.613e-06, eta: 2:45:16, time: 0.826, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1911, decode.acc_seg: 91.8045, aux.loss_ce: 0.1042, aux.acc_seg: 89.6145, loss: 0.2953
2023-12-29 15:05:49,819 - mmseg - INFO - Iter [147750/160000]	lr: 4.594e-06, eta: 2:44:36, time: 0.804, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1943, decode.acc_seg: 91.9443, aux.loss_ce: 0.1048, aux.acc_seg: 89.7799, loss: 0.2991
2023-12-29 15:06:31,538 - mmseg - INFO - Iter [147800/160000]	lr: 4.575e-06, eta: 2:43:56, time: 0.835, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1819, decode.acc_seg: 92.1215, aux.loss_ce: 0.0974, aux.acc_seg: 89.9609, loss: 0.2792
2023-12-29 15:07:12,522 - mmseg - INFO - Iter [147850/160000]	lr: 4.557e-06, eta: 2:43:16, time: 0.819, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1838, decode.acc_seg: 92.4179, aux.loss_ce: 0.0966, aux.acc_seg: 90.4534, loss: 0.2804
2023-12-29 15:07:53,220 - mmseg - INFO - Iter [147900/160000]	lr: 4.538e-06, eta: 2:42:35, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1871, decode.acc_seg: 92.0989, aux.loss_ce: 0.0975, aux.acc_seg: 90.3323, loss: 0.2846
2023-12-29 15:08:33,970 - mmseg - INFO - Iter [147950/160000]	lr: 4.519e-06, eta: 2:41:55, time: 0.816, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1750, decode.acc_seg: 92.3660, aux.loss_ce: 0.0944, aux.acc_seg: 90.4145, loss: 0.2694
2023-12-29 15:09:13,495 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 15:09:13,496 - mmseg - INFO - Iter [148000/160000]	lr: 4.500e-06, eta: 2:41:15, time: 0.789, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1924, decode.acc_seg: 91.8318, aux.loss_ce: 0.1035, aux.acc_seg: 89.7865, loss: 0.2959
2023-12-29 15:09:54,701 - mmseg - INFO - Iter [148050/160000]	lr: 4.482e-06, eta: 2:40:34, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1797, decode.acc_seg: 92.3279, aux.loss_ce: 0.0956, aux.acc_seg: 90.4368, loss: 0.2753
2023-12-29 15:10:35,176 - mmseg - INFO - Iter [148100/160000]	lr: 4.463e-06, eta: 2:39:54, time: 0.811, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1882, decode.acc_seg: 92.1838, aux.loss_ce: 0.0991, aux.acc_seg: 90.2722, loss: 0.2872
2023-12-29 15:11:12,846 - mmseg - INFO - Iter [148150/160000]	lr: 4.444e-06, eta: 2:39:14, time: 0.753, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1645, decode.acc_seg: 92.8334, aux.loss_ce: 0.0884, aux.acc_seg: 90.8906, loss: 0.2528
2023-12-29 15:11:50,807 - mmseg - INFO - Iter [148200/160000]	lr: 4.425e-06, eta: 2:38:33, time: 0.759, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1724, decode.acc_seg: 92.5797, aux.loss_ce: 0.0945, aux.acc_seg: 90.4990, loss: 0.2669
2023-12-29 15:12:29,936 - mmseg - INFO - Iter [148250/160000]	lr: 4.407e-06, eta: 2:37:53, time: 0.782, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1911, decode.acc_seg: 91.7683, aux.loss_ce: 0.1014, aux.acc_seg: 89.6681, loss: 0.2925
2023-12-29 15:13:10,989 - mmseg - INFO - Iter [148300/160000]	lr: 4.388e-06, eta: 2:37:12, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1867, decode.acc_seg: 92.0664, aux.loss_ce: 0.0974, aux.acc_seg: 90.0396, loss: 0.2841
2023-12-29 15:13:51,410 - mmseg - INFO - Iter [148350/160000]	lr: 4.369e-06, eta: 2:36:32, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1842, decode.acc_seg: 92.0992, aux.loss_ce: 0.0980, aux.acc_seg: 90.1031, loss: 0.2822
2023-12-29 15:14:32,518 - mmseg - INFO - Iter [148400/160000]	lr: 4.350e-06, eta: 2:35:52, time: 0.823, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1830, decode.acc_seg: 92.1638, aux.loss_ce: 0.0961, aux.acc_seg: 90.1618, loss: 0.2792
2023-12-29 15:15:12,312 - mmseg - INFO - Iter [148450/160000]	lr: 4.332e-06, eta: 2:35:12, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1728, decode.acc_seg: 92.6949, aux.loss_ce: 0.0945, aux.acc_seg: 90.6293, loss: 0.2672
2023-12-29 15:15:50,449 - mmseg - INFO - Iter [148500/160000]	lr: 4.313e-06, eta: 2:34:31, time: 0.763, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1794, decode.acc_seg: 92.3320, aux.loss_ce: 0.0971, aux.acc_seg: 90.2910, loss: 0.2765
2023-12-29 15:16:29,838 - mmseg - INFO - Iter [148550/160000]	lr: 4.294e-06, eta: 2:33:51, time: 0.788, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1847, decode.acc_seg: 92.1599, aux.loss_ce: 0.1000, aux.acc_seg: 90.3140, loss: 0.2847
2023-12-29 15:17:09,803 - mmseg - INFO - Iter [148600/160000]	lr: 4.275e-06, eta: 2:33:10, time: 0.798, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1836, decode.acc_seg: 92.3203, aux.loss_ce: 0.0968, aux.acc_seg: 90.3970, loss: 0.2805
2023-12-29 15:17:50,441 - mmseg - INFO - Iter [148650/160000]	lr: 4.257e-06, eta: 2:32:30, time: 0.813, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1783, decode.acc_seg: 92.2787, aux.loss_ce: 0.0964, aux.acc_seg: 90.2499, loss: 0.2748
2023-12-29 15:18:31,162 - mmseg - INFO - Iter [148700/160000]	lr: 4.238e-06, eta: 2:31:50, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1825, decode.acc_seg: 91.9430, aux.loss_ce: 0.0990, aux.acc_seg: 89.7289, loss: 0.2815
2023-12-29 15:19:12,379 - mmseg - INFO - Iter [148750/160000]	lr: 4.219e-06, eta: 2:31:10, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1746, decode.acc_seg: 92.6046, aux.loss_ce: 0.0954, aux.acc_seg: 90.4171, loss: 0.2700
2023-12-29 15:19:53,739 - mmseg - INFO - Iter [148800/160000]	lr: 4.200e-06, eta: 2:30:29, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1820, decode.acc_seg: 92.3456, aux.loss_ce: 0.0978, aux.acc_seg: 90.3707, loss: 0.2798
2023-12-29 15:20:33,381 - mmseg - INFO - Iter [148850/160000]	lr: 4.182e-06, eta: 2:29:49, time: 0.793, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1899, decode.acc_seg: 91.8206, aux.loss_ce: 0.1012, aux.acc_seg: 89.7896, loss: 0.2911
2023-12-29 15:21:14,674 - mmseg - INFO - Iter [148900/160000]	lr: 4.163e-06, eta: 2:29:09, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1908, decode.acc_seg: 91.8294, aux.loss_ce: 0.1021, aux.acc_seg: 89.5960, loss: 0.2930
2023-12-29 15:21:55,682 - mmseg - INFO - Iter [148950/160000]	lr: 4.144e-06, eta: 2:28:28, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1835, decode.acc_seg: 92.2579, aux.loss_ce: 0.0986, aux.acc_seg: 89.9200, loss: 0.2822
2023-12-29 15:22:36,198 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 15:22:36,198 - mmseg - INFO - Iter [149000/160000]	lr: 4.125e-06, eta: 2:27:48, time: 0.810, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1763, decode.acc_seg: 92.4402, aux.loss_ce: 0.0929, aux.acc_seg: 90.5729, loss: 0.2691
2023-12-29 15:23:22,352 - mmseg - INFO - Iter [149050/160000]	lr: 4.107e-06, eta: 2:27:08, time: 0.923, data_time: 0.055, memory: 18256, decode.loss_ce: 0.1643, decode.acc_seg: 92.7937, aux.loss_ce: 0.0897, aux.acc_seg: 90.7016, loss: 0.2540
2023-12-29 15:24:06,179 - mmseg - INFO - Iter [149100/160000]	lr: 4.088e-06, eta: 2:26:28, time: 0.878, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1844, decode.acc_seg: 92.3694, aux.loss_ce: 0.1006, aux.acc_seg: 90.3194, loss: 0.2850
2023-12-29 15:24:47,191 - mmseg - INFO - Iter [149150/160000]	lr: 4.069e-06, eta: 2:25:48, time: 0.819, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1835, decode.acc_seg: 92.0237, aux.loss_ce: 0.0985, aux.acc_seg: 90.0166, loss: 0.2820
2023-12-29 15:25:28,473 - mmseg - INFO - Iter [149200/160000]	lr: 4.050e-06, eta: 2:25:08, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1792, decode.acc_seg: 92.3289, aux.loss_ce: 0.0961, aux.acc_seg: 90.2882, loss: 0.2752
2023-12-29 15:26:09,391 - mmseg - INFO - Iter [149250/160000]	lr: 4.032e-06, eta: 2:24:27, time: 0.817, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1785, decode.acc_seg: 92.3891, aux.loss_ce: 0.0950, aux.acc_seg: 90.3835, loss: 0.2735
2023-12-29 15:26:51,578 - mmseg - INFO - Iter [149300/160000]	lr: 4.013e-06, eta: 2:23:47, time: 0.844, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1831, decode.acc_seg: 92.2616, aux.loss_ce: 0.0993, aux.acc_seg: 90.1945, loss: 0.2824
2023-12-29 15:27:33,837 - mmseg - INFO - Iter [149350/160000]	lr: 3.994e-06, eta: 2:23:07, time: 0.845, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1863, decode.acc_seg: 92.1753, aux.loss_ce: 0.0995, aux.acc_seg: 90.2277, loss: 0.2858
2023-12-29 15:28:16,105 - mmseg - INFO - Iter [149400/160000]	lr: 3.975e-06, eta: 2:22:27, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1748, decode.acc_seg: 92.3784, aux.loss_ce: 0.0960, aux.acc_seg: 90.2348, loss: 0.2708
2023-12-29 15:28:55,285 - mmseg - INFO - Iter [149450/160000]	lr: 3.957e-06, eta: 2:21:47, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1774, decode.acc_seg: 92.3378, aux.loss_ce: 0.0964, aux.acc_seg: 90.1567, loss: 0.2737
2023-12-29 15:29:35,854 - mmseg - INFO - Iter [149500/160000]	lr: 3.938e-06, eta: 2:21:06, time: 0.810, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1862, decode.acc_seg: 91.9602, aux.loss_ce: 0.0999, aux.acc_seg: 89.8135, loss: 0.2862
2023-12-29 15:30:18,193 - mmseg - INFO - Iter [149550/160000]	lr: 3.919e-06, eta: 2:20:26, time: 0.847, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.1293, aux.loss_ce: 0.0955, aux.acc_seg: 90.0523, loss: 0.2744
2023-12-29 15:30:59,636 - mmseg - INFO - Iter [149600/160000]	lr: 3.900e-06, eta: 2:19:46, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1809, decode.acc_seg: 92.3138, aux.loss_ce: 0.0969, aux.acc_seg: 90.2294, loss: 0.2777
2023-12-29 15:31:39,681 - mmseg - INFO - Iter [149650/160000]	lr: 3.882e-06, eta: 2:19:05, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1804, decode.acc_seg: 92.2651, aux.loss_ce: 0.0964, aux.acc_seg: 90.2315, loss: 0.2767
2023-12-29 15:32:20,404 - mmseg - INFO - Iter [149700/160000]	lr: 3.863e-06, eta: 2:18:25, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1884, decode.acc_seg: 92.1526, aux.loss_ce: 0.1022, aux.acc_seg: 90.0506, loss: 0.2907
2023-12-29 15:33:00,781 - mmseg - INFO - Iter [149750/160000]	lr: 3.844e-06, eta: 2:17:45, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.1889, aux.loss_ce: 0.0946, aux.acc_seg: 90.1558, loss: 0.2770
2023-12-29 15:33:41,749 - mmseg - INFO - Iter [149800/160000]	lr: 3.825e-06, eta: 2:17:05, time: 0.820, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1840, decode.acc_seg: 92.0769, aux.loss_ce: 0.0997, aux.acc_seg: 89.9314, loss: 0.2838
2023-12-29 15:34:22,938 - mmseg - INFO - Iter [149850/160000]	lr: 3.807e-06, eta: 2:16:24, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1745, decode.acc_seg: 92.6707, aux.loss_ce: 0.0938, aux.acc_seg: 90.6103, loss: 0.2683
2023-12-29 15:35:03,814 - mmseg - INFO - Iter [149900/160000]	lr: 3.788e-06, eta: 2:15:44, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1708, decode.acc_seg: 92.6339, aux.loss_ce: 0.0929, aux.acc_seg: 90.6910, loss: 0.2636
2023-12-29 15:35:44,544 - mmseg - INFO - Iter [149950/160000]	lr: 3.769e-06, eta: 2:15:04, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1795, decode.acc_seg: 92.0706, aux.loss_ce: 0.0967, aux.acc_seg: 89.9852, loss: 0.2762
2023-12-29 15:36:24,094 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 15:36:24,094 - mmseg - INFO - Iter [150000/160000]	lr: 3.750e-06, eta: 2:14:23, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1759, decode.acc_seg: 92.3934, aux.loss_ce: 0.0958, aux.acc_seg: 90.3424, loss: 0.2717
2023-12-29 15:37:04,249 - mmseg - INFO - Iter [150050/160000]	lr: 3.732e-06, eta: 2:13:43, time: 0.802, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 92.0874, aux.loss_ce: 0.1042, aux.acc_seg: 89.7655, loss: 0.2919
2023-12-29 15:37:45,795 - mmseg - INFO - Iter [150100/160000]	lr: 3.713e-06, eta: 2:13:03, time: 0.831, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1966, decode.acc_seg: 91.7517, aux.loss_ce: 0.1031, aux.acc_seg: 89.7880, loss: 0.2996
2023-12-29 15:38:25,441 - mmseg - INFO - Iter [150150/160000]	lr: 3.694e-06, eta: 2:12:22, time: 0.793, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1796, decode.acc_seg: 92.2194, aux.loss_ce: 0.0969, aux.acc_seg: 90.1093, loss: 0.2765
2023-12-29 15:39:04,831 - mmseg - INFO - Iter [150200/160000]	lr: 3.675e-06, eta: 2:11:42, time: 0.788, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1922, decode.acc_seg: 91.7615, aux.loss_ce: 0.1035, aux.acc_seg: 89.6661, loss: 0.2956
2023-12-29 15:39:45,798 - mmseg - INFO - Iter [150250/160000]	lr: 3.657e-06, eta: 2:11:02, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1828, decode.acc_seg: 92.0964, aux.loss_ce: 0.1015, aux.acc_seg: 90.0149, loss: 0.2842
2023-12-29 15:40:30,787 - mmseg - INFO - Iter [150300/160000]	lr: 3.638e-06, eta: 2:10:22, time: 0.898, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1834, decode.acc_seg: 92.3417, aux.loss_ce: 0.0984, aux.acc_seg: 90.2214, loss: 0.2818
2023-12-29 15:41:11,503 - mmseg - INFO - Iter [150350/160000]	lr: 3.619e-06, eta: 2:09:41, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1736, decode.acc_seg: 92.6403, aux.loss_ce: 0.0930, aux.acc_seg: 90.8255, loss: 0.2666
2023-12-29 15:41:49,495 - mmseg - INFO - Iter [150400/160000]	lr: 3.600e-06, eta: 2:09:01, time: 0.759, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1773, decode.acc_seg: 92.3355, aux.loss_ce: 0.0939, aux.acc_seg: 90.3451, loss: 0.2712
2023-12-29 15:42:30,650 - mmseg - INFO - Iter [150450/160000]	lr: 3.582e-06, eta: 2:08:21, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1714, decode.acc_seg: 92.6828, aux.loss_ce: 0.0914, aux.acc_seg: 90.7870, loss: 0.2628
2023-12-29 15:43:12,063 - mmseg - INFO - Iter [150500/160000]	lr: 3.563e-06, eta: 2:07:40, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1827, decode.acc_seg: 92.1132, aux.loss_ce: 0.0983, aux.acc_seg: 90.1247, loss: 0.2810
2023-12-29 15:43:53,190 - mmseg - INFO - Iter [150550/160000]	lr: 3.544e-06, eta: 2:07:00, time: 0.823, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1769, decode.acc_seg: 92.3170, aux.loss_ce: 0.0962, aux.acc_seg: 90.1519, loss: 0.2731
2023-12-29 15:44:34,393 - mmseg - INFO - Iter [150600/160000]	lr: 3.525e-06, eta: 2:06:20, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1803, decode.acc_seg: 92.3356, aux.loss_ce: 0.0951, aux.acc_seg: 90.3912, loss: 0.2754
2023-12-29 15:45:14,733 - mmseg - INFO - Iter [150650/160000]	lr: 3.507e-06, eta: 2:05:40, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1802, decode.acc_seg: 92.3300, aux.loss_ce: 0.0981, aux.acc_seg: 90.1578, loss: 0.2783
2023-12-29 15:45:53,721 - mmseg - INFO - Iter [150700/160000]	lr: 3.488e-06, eta: 2:04:59, time: 0.780, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1763, decode.acc_seg: 92.2210, aux.loss_ce: 0.0966, aux.acc_seg: 90.0280, loss: 0.2729
2023-12-29 15:46:31,833 - mmseg - INFO - Iter [150750/160000]	lr: 3.469e-06, eta: 2:04:19, time: 0.762, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1897, decode.acc_seg: 92.0188, aux.loss_ce: 0.1019, aux.acc_seg: 89.8933, loss: 0.2916
2023-12-29 15:47:10,411 - mmseg - INFO - Iter [150800/160000]	lr: 3.450e-06, eta: 2:03:38, time: 0.770, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1809, decode.acc_seg: 92.2621, aux.loss_ce: 0.0960, aux.acc_seg: 90.3516, loss: 0.2769
2023-12-29 15:47:52,964 - mmseg - INFO - Iter [150850/160000]	lr: 3.432e-06, eta: 2:02:58, time: 0.851, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1973, decode.acc_seg: 91.5855, aux.loss_ce: 0.1050, aux.acc_seg: 89.5261, loss: 0.3023
2023-12-29 15:48:31,586 - mmseg - INFO - Iter [150900/160000]	lr: 3.413e-06, eta: 2:02:18, time: 0.774, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1884, decode.acc_seg: 92.0594, aux.loss_ce: 0.1012, aux.acc_seg: 89.9419, loss: 0.2896
2023-12-29 15:49:09,333 - mmseg - INFO - Iter [150950/160000]	lr: 3.394e-06, eta: 2:01:37, time: 0.755, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1746, decode.acc_seg: 92.5244, aux.loss_ce: 0.0917, aux.acc_seg: 90.6360, loss: 0.2663
2023-12-29 15:49:47,203 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 15:49:47,203 - mmseg - INFO - Iter [151000/160000]	lr: 3.375e-06, eta: 2:00:57, time: 0.757, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1799, decode.acc_seg: 92.4537, aux.loss_ce: 0.0976, aux.acc_seg: 90.2294, loss: 0.2775
2023-12-29 15:50:25,882 - mmseg - INFO - Iter [151050/160000]	lr: 3.357e-06, eta: 2:00:16, time: 0.774, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1718, decode.acc_seg: 92.8260, aux.loss_ce: 0.0918, aux.acc_seg: 91.0738, loss: 0.2636
2023-12-29 15:51:06,340 - mmseg - INFO - Iter [151100/160000]	lr: 3.338e-06, eta: 1:59:36, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1698, decode.acc_seg: 92.7680, aux.loss_ce: 0.0920, aux.acc_seg: 90.7918, loss: 0.2618
2023-12-29 15:51:47,605 - mmseg - INFO - Iter [151150/160000]	lr: 3.319e-06, eta: 1:58:56, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1800, decode.acc_seg: 92.2555, aux.loss_ce: 0.0969, aux.acc_seg: 90.2391, loss: 0.2769
2023-12-29 15:52:27,451 - mmseg - INFO - Iter [151200/160000]	lr: 3.300e-06, eta: 1:58:15, time: 0.796, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.3009, aux.loss_ce: 0.0982, aux.acc_seg: 90.3574, loss: 0.2811
2023-12-29 15:53:08,796 - mmseg - INFO - Iter [151250/160000]	lr: 3.282e-06, eta: 1:57:35, time: 0.828, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1669, decode.acc_seg: 92.8258, aux.loss_ce: 0.0907, aux.acc_seg: 90.7602, loss: 0.2576
2023-12-29 15:53:49,869 - mmseg - INFO - Iter [151300/160000]	lr: 3.263e-06, eta: 1:56:55, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1730, decode.acc_seg: 92.7422, aux.loss_ce: 0.0946, aux.acc_seg: 90.5708, loss: 0.2676
2023-12-29 15:54:29,919 - mmseg - INFO - Iter [151350/160000]	lr: 3.244e-06, eta: 1:56:15, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1761, decode.acc_seg: 92.3451, aux.loss_ce: 0.0961, aux.acc_seg: 90.1104, loss: 0.2722
2023-12-29 15:55:09,604 - mmseg - INFO - Iter [151400/160000]	lr: 3.225e-06, eta: 1:55:34, time: 0.794, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1838, decode.acc_seg: 92.2800, aux.loss_ce: 0.1007, aux.acc_seg: 89.9038, loss: 0.2845
2023-12-29 15:55:49,303 - mmseg - INFO - Iter [151450/160000]	lr: 3.207e-06, eta: 1:54:54, time: 0.792, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1838, decode.acc_seg: 92.1028, aux.loss_ce: 0.0987, aux.acc_seg: 90.1122, loss: 0.2825
2023-12-29 15:56:30,692 - mmseg - INFO - Iter [151500/160000]	lr: 3.188e-06, eta: 1:54:14, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1800, decode.acc_seg: 92.4464, aux.loss_ce: 0.0953, aux.acc_seg: 90.5480, loss: 0.2753
2023-12-29 15:57:10,699 - mmseg - INFO - Iter [151550/160000]	lr: 3.169e-06, eta: 1:53:33, time: 0.801, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1849, decode.acc_seg: 91.9891, aux.loss_ce: 0.1007, aux.acc_seg: 89.9772, loss: 0.2855
2023-12-29 15:57:52,350 - mmseg - INFO - Iter [151600/160000]	lr: 3.150e-06, eta: 1:52:53, time: 0.833, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1885, decode.acc_seg: 91.8459, aux.loss_ce: 0.1034, aux.acc_seg: 89.3749, loss: 0.2918
2023-12-29 15:58:33,022 - mmseg - INFO - Iter [151650/160000]	lr: 3.132e-06, eta: 1:52:13, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1857, decode.acc_seg: 91.9585, aux.loss_ce: 0.0994, aux.acc_seg: 89.7998, loss: 0.2851
2023-12-29 15:59:11,467 - mmseg - INFO - Iter [151700/160000]	lr: 3.113e-06, eta: 1:51:32, time: 0.768, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 92.0522, aux.loss_ce: 0.0991, aux.acc_seg: 89.9252, loss: 0.2841
2023-12-29 15:59:52,144 - mmseg - INFO - Iter [151750/160000]	lr: 3.094e-06, eta: 1:50:52, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1818, decode.acc_seg: 92.2512, aux.loss_ce: 0.0991, aux.acc_seg: 90.1396, loss: 0.2809
2023-12-29 16:00:31,381 - mmseg - INFO - Iter [151800/160000]	lr: 3.075e-06, eta: 1:50:12, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1877, decode.acc_seg: 92.0785, aux.loss_ce: 0.1005, aux.acc_seg: 89.8317, loss: 0.2882
2023-12-29 16:01:13,481 - mmseg - INFO - Iter [151850/160000]	lr: 3.057e-06, eta: 1:49:31, time: 0.842, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1888, decode.acc_seg: 92.0339, aux.loss_ce: 0.1008, aux.acc_seg: 89.7795, loss: 0.2896
2023-12-29 16:01:56,106 - mmseg - INFO - Iter [151900/160000]	lr: 3.038e-06, eta: 1:48:51, time: 0.853, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1793, decode.acc_seg: 92.4585, aux.loss_ce: 0.0950, aux.acc_seg: 90.4610, loss: 0.2743
2023-12-29 16:02:36,553 - mmseg - INFO - Iter [151950/160000]	lr: 3.019e-06, eta: 1:48:11, time: 0.809, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1849, decode.acc_seg: 92.0660, aux.loss_ce: 0.0986, aux.acc_seg: 90.0449, loss: 0.2834
2023-12-29 16:03:16,933 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 16:03:16,934 - mmseg - INFO - Iter [152000/160000]	lr: 3.000e-06, eta: 1:47:31, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.4675, aux.loss_ce: 0.0962, aux.acc_seg: 90.3219, loss: 0.2752
2023-12-29 16:03:56,720 - mmseg - INFO - Iter [152050/160000]	lr: 2.982e-06, eta: 1:46:50, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1787, decode.acc_seg: 92.4360, aux.loss_ce: 0.0992, aux.acc_seg: 90.1034, loss: 0.2779
2023-12-29 16:04:38,201 - mmseg - INFO - Iter [152100/160000]	lr: 2.963e-06, eta: 1:46:10, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1764, decode.acc_seg: 92.4604, aux.loss_ce: 0.0948, aux.acc_seg: 90.2262, loss: 0.2712
2023-12-29 16:05:19,509 - mmseg - INFO - Iter [152150/160000]	lr: 2.944e-06, eta: 1:45:30, time: 0.826, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1755, decode.acc_seg: 92.3740, aux.loss_ce: 0.0954, aux.acc_seg: 90.2638, loss: 0.2709
2023-12-29 16:05:59,112 - mmseg - INFO - Iter [152200/160000]	lr: 2.925e-06, eta: 1:44:49, time: 0.793, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1918, decode.acc_seg: 91.8507, aux.loss_ce: 0.1022, aux.acc_seg: 89.6545, loss: 0.2941
2023-12-29 16:06:38,628 - mmseg - INFO - Iter [152250/160000]	lr: 2.907e-06, eta: 1:44:09, time: 0.790, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1756, decode.acc_seg: 92.7013, aux.loss_ce: 0.0951, aux.acc_seg: 90.5896, loss: 0.2707
2023-12-29 16:07:19,578 - mmseg - INFO - Iter [152300/160000]	lr: 2.888e-06, eta: 1:43:29, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1846, decode.acc_seg: 92.1564, aux.loss_ce: 0.0973, aux.acc_seg: 90.1658, loss: 0.2819
2023-12-29 16:08:00,347 - mmseg - INFO - Iter [152350/160000]	lr: 2.869e-06, eta: 1:42:48, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1876, decode.acc_seg: 91.9315, aux.loss_ce: 0.0992, aux.acc_seg: 90.0797, loss: 0.2868
2023-12-29 16:08:40,694 - mmseg - INFO - Iter [152400/160000]	lr: 2.850e-06, eta: 1:42:08, time: 0.807, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1789, decode.acc_seg: 92.2738, aux.loss_ce: 0.0968, aux.acc_seg: 90.2125, loss: 0.2757
2023-12-29 16:09:21,273 - mmseg - INFO - Iter [152450/160000]	lr: 2.832e-06, eta: 1:41:28, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1766, decode.acc_seg: 92.5127, aux.loss_ce: 0.0963, aux.acc_seg: 90.4398, loss: 0.2729
2023-12-29 16:10:01,171 - mmseg - INFO - Iter [152500/160000]	lr: 2.813e-06, eta: 1:40:47, time: 0.797, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1887, decode.acc_seg: 92.0327, aux.loss_ce: 0.1016, aux.acc_seg: 90.0562, loss: 0.2903
2023-12-29 16:10:41,096 - mmseg - INFO - Iter [152550/160000]	lr: 2.794e-06, eta: 1:40:07, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1845, decode.acc_seg: 92.4025, aux.loss_ce: 0.1001, aux.acc_seg: 90.2072, loss: 0.2847
2023-12-29 16:11:20,370 - mmseg - INFO - Iter [152600/160000]	lr: 2.775e-06, eta: 1:39:27, time: 0.785, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1659, decode.acc_seg: 92.8635, aux.loss_ce: 0.0913, aux.acc_seg: 90.7062, loss: 0.2572
2023-12-29 16:12:01,121 - mmseg - INFO - Iter [152650/160000]	lr: 2.757e-06, eta: 1:38:46, time: 0.815, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.4023, aux.loss_ce: 0.0975, aux.acc_seg: 90.4144, loss: 0.2797
2023-12-29 16:12:41,175 - mmseg - INFO - Iter [152700/160000]	lr: 2.738e-06, eta: 1:38:06, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1822, decode.acc_seg: 92.2329, aux.loss_ce: 0.0973, aux.acc_seg: 90.1341, loss: 0.2795
2023-12-29 16:13:24,481 - mmseg - INFO - Iter [152750/160000]	lr: 2.719e-06, eta: 1:37:26, time: 0.865, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1944, decode.acc_seg: 91.8147, aux.loss_ce: 0.1044, aux.acc_seg: 89.5780, loss: 0.2989
2023-12-29 16:14:09,146 - mmseg - INFO - Iter [152800/160000]	lr: 2.700e-06, eta: 1:36:46, time: 0.893, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1785, decode.acc_seg: 92.2230, aux.loss_ce: 0.0968, aux.acc_seg: 90.1170, loss: 0.2753
2023-12-29 16:14:52,700 - mmseg - INFO - Iter [152850/160000]	lr: 2.682e-06, eta: 1:36:06, time: 0.873, data_time: 0.056, memory: 18256, decode.loss_ce: 0.1932, decode.acc_seg: 91.9832, aux.loss_ce: 0.1031, aux.acc_seg: 89.8676, loss: 0.2962
2023-12-29 16:15:33,649 - mmseg - INFO - Iter [152900/160000]	lr: 2.663e-06, eta: 1:35:25, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1800, decode.acc_seg: 92.2829, aux.loss_ce: 0.0989, aux.acc_seg: 90.0042, loss: 0.2790
2023-12-29 16:16:13,760 - mmseg - INFO - Iter [152950/160000]	lr: 2.644e-06, eta: 1:34:45, time: 0.801, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1770, decode.acc_seg: 92.4243, aux.loss_ce: 0.0959, aux.acc_seg: 90.2647, loss: 0.2729
2023-12-29 16:16:54,541 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 16:16:54,542 - mmseg - INFO - Iter [153000/160000]	lr: 2.625e-06, eta: 1:34:05, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1804, decode.acc_seg: 92.4159, aux.loss_ce: 0.0970, aux.acc_seg: 90.3297, loss: 0.2774
2023-12-29 16:17:35,186 - mmseg - INFO - Iter [153050/160000]	lr: 2.607e-06, eta: 1:33:24, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1837, decode.acc_seg: 92.1825, aux.loss_ce: 0.0995, aux.acc_seg: 90.0183, loss: 0.2832
2023-12-29 16:18:14,770 - mmseg - INFO - Iter [153100/160000]	lr: 2.588e-06, eta: 1:32:44, time: 0.792, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.0546, aux.loss_ce: 0.0954, aux.acc_seg: 90.2166, loss: 0.2783
2023-12-29 16:18:55,227 - mmseg - INFO - Iter [153150/160000]	lr: 2.569e-06, eta: 1:32:04, time: 0.808, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1743, decode.acc_seg: 92.4236, aux.loss_ce: 0.0939, aux.acc_seg: 90.3148, loss: 0.2682
2023-12-29 16:19:35,828 - mmseg - INFO - Iter [153200/160000]	lr: 2.550e-06, eta: 1:31:23, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1866, decode.acc_seg: 92.1250, aux.loss_ce: 0.0996, aux.acc_seg: 90.0077, loss: 0.2862
2023-12-29 16:20:16,851 - mmseg - INFO - Iter [153250/160000]	lr: 2.532e-06, eta: 1:30:43, time: 0.820, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1809, decode.acc_seg: 92.5122, aux.loss_ce: 0.0955, aux.acc_seg: 90.7018, loss: 0.2764
2023-12-29 16:20:58,260 - mmseg - INFO - Iter [153300/160000]	lr: 2.513e-06, eta: 1:30:03, time: 0.828, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1733, decode.acc_seg: 92.6192, aux.loss_ce: 0.0916, aux.acc_seg: 90.8260, loss: 0.2649
2023-12-29 16:21:38,789 - mmseg - INFO - Iter [153350/160000]	lr: 2.494e-06, eta: 1:29:23, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1736, decode.acc_seg: 92.5767, aux.loss_ce: 0.0940, aux.acc_seg: 90.5928, loss: 0.2676
2023-12-29 16:22:18,003 - mmseg - INFO - Iter [153400/160000]	lr: 2.475e-06, eta: 1:28:42, time: 0.784, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1796, decode.acc_seg: 92.3167, aux.loss_ce: 0.0966, aux.acc_seg: 90.3931, loss: 0.2762
2023-12-29 16:22:57,725 - mmseg - INFO - Iter [153450/160000]	lr: 2.457e-06, eta: 1:28:02, time: 0.794, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1863, decode.acc_seg: 91.9022, aux.loss_ce: 0.0993, aux.acc_seg: 89.8465, loss: 0.2856
2023-12-29 16:23:40,055 - mmseg - INFO - Iter [153500/160000]	lr: 2.438e-06, eta: 1:27:22, time: 0.846, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1785, decode.acc_seg: 92.4219, aux.loss_ce: 0.0956, aux.acc_seg: 90.6140, loss: 0.2741
2023-12-29 16:24:22,010 - mmseg - INFO - Iter [153550/160000]	lr: 2.419e-06, eta: 1:26:41, time: 0.840, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1754, decode.acc_seg: 92.4040, aux.loss_ce: 0.0953, aux.acc_seg: 90.2492, loss: 0.2707
2023-12-29 16:25:01,519 - mmseg - INFO - Iter [153600/160000]	lr: 2.400e-06, eta: 1:26:01, time: 0.791, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1718, decode.acc_seg: 92.5419, aux.loss_ce: 0.0932, aux.acc_seg: 90.5543, loss: 0.2650
2023-12-29 16:25:43,061 - mmseg - INFO - Iter [153650/160000]	lr: 2.382e-06, eta: 1:25:21, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1921, decode.acc_seg: 91.9608, aux.loss_ce: 0.1040, aux.acc_seg: 89.7735, loss: 0.2961
2023-12-29 16:26:22,072 - mmseg - INFO - Iter [153700/160000]	lr: 2.363e-06, eta: 1:24:40, time: 0.780, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1789, decode.acc_seg: 92.0934, aux.loss_ce: 0.0946, aux.acc_seg: 90.1897, loss: 0.2735
2023-12-29 16:27:03,263 - mmseg - INFO - Iter [153750/160000]	lr: 2.344e-06, eta: 1:24:00, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1814, decode.acc_seg: 92.3055, aux.loss_ce: 0.0979, aux.acc_seg: 90.1572, loss: 0.2793
2023-12-29 16:27:44,216 - mmseg - INFO - Iter [153800/160000]	lr: 2.325e-06, eta: 1:23:20, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1706, decode.acc_seg: 92.5847, aux.loss_ce: 0.0913, aux.acc_seg: 90.5701, loss: 0.2619
2023-12-29 16:28:25,072 - mmseg - INFO - Iter [153850/160000]	lr: 2.307e-06, eta: 1:22:39, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1795, decode.acc_seg: 92.1270, aux.loss_ce: 0.0979, aux.acc_seg: 89.8816, loss: 0.2774
2023-12-29 16:29:05,952 - mmseg - INFO - Iter [153900/160000]	lr: 2.288e-06, eta: 1:21:59, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1709, decode.acc_seg: 92.5933, aux.loss_ce: 0.0941, aux.acc_seg: 90.2944, loss: 0.2650
2023-12-29 16:29:47,535 - mmseg - INFO - Iter [153950/160000]	lr: 2.269e-06, eta: 1:21:19, time: 0.833, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1785, decode.acc_seg: 92.4093, aux.loss_ce: 0.0974, aux.acc_seg: 90.1635, loss: 0.2759
2023-12-29 16:30:28,009 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 16:30:28,010 - mmseg - INFO - Iter [154000/160000]	lr: 2.250e-06, eta: 1:20:39, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1810, decode.acc_seg: 92.2300, aux.loss_ce: 0.0962, aux.acc_seg: 90.1960, loss: 0.2772
2023-12-29 16:31:08,961 - mmseg - INFO - Iter [154050/160000]	lr: 2.232e-06, eta: 1:19:58, time: 0.820, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1855, decode.acc_seg: 91.9804, aux.loss_ce: 0.1004, aux.acc_seg: 89.8123, loss: 0.2859
2023-12-29 16:31:50,543 - mmseg - INFO - Iter [154100/160000]	lr: 2.213e-06, eta: 1:19:18, time: 0.832, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1782, decode.acc_seg: 92.4794, aux.loss_ce: 0.0943, aux.acc_seg: 90.5562, loss: 0.2725
2023-12-29 16:32:30,198 - mmseg - INFO - Iter [154150/160000]	lr: 2.194e-06, eta: 1:18:38, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1935, decode.acc_seg: 91.7603, aux.loss_ce: 0.1048, aux.acc_seg: 89.5268, loss: 0.2983
2023-12-29 16:33:11,273 - mmseg - INFO - Iter [154200/160000]	lr: 2.175e-06, eta: 1:17:57, time: 0.821, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1844, decode.acc_seg: 91.9666, aux.loss_ce: 0.0994, aux.acc_seg: 89.8412, loss: 0.2838
2023-12-29 16:33:52,543 - mmseg - INFO - Iter [154250/160000]	lr: 2.157e-06, eta: 1:17:17, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 91.9971, aux.loss_ce: 0.1012, aux.acc_seg: 89.8115, loss: 0.2861
2023-12-29 16:34:32,963 - mmseg - INFO - Iter [154300/160000]	lr: 2.138e-06, eta: 1:16:37, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1911, decode.acc_seg: 92.1164, aux.loss_ce: 0.1017, aux.acc_seg: 89.8981, loss: 0.2928
2023-12-29 16:35:12,557 - mmseg - INFO - Iter [154350/160000]	lr: 2.119e-06, eta: 1:15:56, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1733, decode.acc_seg: 92.4079, aux.loss_ce: 0.0936, aux.acc_seg: 90.4045, loss: 0.2669
2023-12-29 16:35:53,629 - mmseg - INFO - Iter [154400/160000]	lr: 2.100e-06, eta: 1:15:16, time: 0.822, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1772, decode.acc_seg: 92.4090, aux.loss_ce: 0.0956, aux.acc_seg: 90.1897, loss: 0.2728
2023-12-29 16:36:35,008 - mmseg - INFO - Iter [154450/160000]	lr: 2.082e-06, eta: 1:14:36, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1744, decode.acc_seg: 92.5213, aux.loss_ce: 0.0952, aux.acc_seg: 90.2525, loss: 0.2696
2023-12-29 16:37:14,611 - mmseg - INFO - Iter [154500/160000]	lr: 2.063e-06, eta: 1:13:55, time: 0.793, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 92.0193, aux.loss_ce: 0.1016, aux.acc_seg: 89.7860, loss: 0.2896
2023-12-29 16:37:55,704 - mmseg - INFO - Iter [154550/160000]	lr: 2.044e-06, eta: 1:13:15, time: 0.823, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1739, decode.acc_seg: 92.4776, aux.loss_ce: 0.0936, aux.acc_seg: 90.4680, loss: 0.2675
2023-12-29 16:38:36,355 - mmseg - INFO - Iter [154600/160000]	lr: 2.025e-06, eta: 1:12:35, time: 0.812, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1862, decode.acc_seg: 92.1837, aux.loss_ce: 0.1011, aux.acc_seg: 89.8589, loss: 0.2874
2023-12-29 16:39:16,780 - mmseg - INFO - Iter [154650/160000]	lr: 2.007e-06, eta: 1:11:54, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1775, decode.acc_seg: 92.2916, aux.loss_ce: 0.0959, aux.acc_seg: 90.2326, loss: 0.2735
2023-12-29 16:39:55,649 - mmseg - INFO - Iter [154700/160000]	lr: 1.988e-06, eta: 1:11:14, time: 0.777, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1766, decode.acc_seg: 92.3341, aux.loss_ce: 0.0934, aux.acc_seg: 90.5231, loss: 0.2700
2023-12-29 16:40:36,387 - mmseg - INFO - Iter [154750/160000]	lr: 1.969e-06, eta: 1:10:34, time: 0.815, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1771, decode.acc_seg: 92.5499, aux.loss_ce: 0.0967, aux.acc_seg: 90.3839, loss: 0.2738
2023-12-29 16:41:15,497 - mmseg - INFO - Iter [154800/160000]	lr: 1.950e-06, eta: 1:09:53, time: 0.783, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1833, decode.acc_seg: 92.1843, aux.loss_ce: 0.1003, aux.acc_seg: 89.8420, loss: 0.2836
2023-12-29 16:41:56,491 - mmseg - INFO - Iter [154850/160000]	lr: 1.932e-06, eta: 1:09:13, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1771, decode.acc_seg: 92.5285, aux.loss_ce: 0.0951, aux.acc_seg: 90.4114, loss: 0.2722
2023-12-29 16:42:39,105 - mmseg - INFO - Iter [154900/160000]	lr: 1.913e-06, eta: 1:08:33, time: 0.854, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1816, decode.acc_seg: 92.2234, aux.loss_ce: 0.0977, aux.acc_seg: 90.2274, loss: 0.2792
2023-12-29 16:43:19,504 - mmseg - INFO - Iter [154950/160000]	lr: 1.894e-06, eta: 1:07:53, time: 0.808, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1743, decode.acc_seg: 92.6891, aux.loss_ce: 0.0947, aux.acc_seg: 90.6296, loss: 0.2690
2023-12-29 16:44:02,769 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 16:44:02,770 - mmseg - INFO - Iter [155000/160000]	lr: 1.875e-06, eta: 1:07:12, time: 0.864, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 92.2005, aux.loss_ce: 0.0963, aux.acc_seg: 90.2837, loss: 0.2813
2023-12-29 16:44:43,649 - mmseg - INFO - Iter [155050/160000]	lr: 1.857e-06, eta: 1:06:32, time: 0.818, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1850, decode.acc_seg: 92.1322, aux.loss_ce: 0.0987, aux.acc_seg: 90.0306, loss: 0.2836
2023-12-29 16:45:24,691 - mmseg - INFO - Iter [155100/160000]	lr: 1.838e-06, eta: 1:05:52, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1869, decode.acc_seg: 91.9098, aux.loss_ce: 0.1002, aux.acc_seg: 89.7656, loss: 0.2871
2023-12-29 16:46:06,300 - mmseg - INFO - Iter [155150/160000]	lr: 1.819e-06, eta: 1:05:11, time: 0.832, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1791, decode.acc_seg: 92.2086, aux.loss_ce: 0.0951, aux.acc_seg: 90.2187, loss: 0.2741
2023-12-29 16:46:47,236 - mmseg - INFO - Iter [155200/160000]	lr: 1.800e-06, eta: 1:04:31, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1731, decode.acc_seg: 92.7132, aux.loss_ce: 0.0948, aux.acc_seg: 90.5927, loss: 0.2679
2023-12-29 16:47:27,036 - mmseg - INFO - Iter [155250/160000]	lr: 1.782e-06, eta: 1:03:51, time: 0.796, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1884, decode.acc_seg: 92.1656, aux.loss_ce: 0.1020, aux.acc_seg: 90.0875, loss: 0.2904
2023-12-29 16:48:07,346 - mmseg - INFO - Iter [155300/160000]	lr: 1.763e-06, eta: 1:03:10, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1797, decode.acc_seg: 92.3133, aux.loss_ce: 0.0963, aux.acc_seg: 90.2359, loss: 0.2761
2023-12-29 16:48:50,142 - mmseg - INFO - Iter [155350/160000]	lr: 1.744e-06, eta: 1:02:30, time: 0.856, data_time: 0.053, memory: 18256, decode.loss_ce: 0.1814, decode.acc_seg: 92.3442, aux.loss_ce: 0.0953, aux.acc_seg: 90.4164, loss: 0.2767
2023-12-29 16:49:30,720 - mmseg - INFO - Iter [155400/160000]	lr: 1.725e-06, eta: 1:01:50, time: 0.812, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1775, decode.acc_seg: 92.6220, aux.loss_ce: 0.0947, aux.acc_seg: 90.6816, loss: 0.2722
2023-12-29 16:50:10,920 - mmseg - INFO - Iter [155450/160000]	lr: 1.707e-06, eta: 1:01:10, time: 0.804, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1822, decode.acc_seg: 92.3030, aux.loss_ce: 0.0986, aux.acc_seg: 90.1398, loss: 0.2808
2023-12-29 16:50:52,806 - mmseg - INFO - Iter [155500/160000]	lr: 1.688e-06, eta: 1:00:29, time: 0.836, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1702, decode.acc_seg: 92.7135, aux.loss_ce: 0.0936, aux.acc_seg: 90.6463, loss: 0.2639
2023-12-29 16:51:34,339 - mmseg - INFO - Iter [155550/160000]	lr: 1.669e-06, eta: 0:59:49, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1912, decode.acc_seg: 91.9986, aux.loss_ce: 0.1023, aux.acc_seg: 89.8074, loss: 0.2935
2023-12-29 16:52:15,268 - mmseg - INFO - Iter [155600/160000]	lr: 1.650e-06, eta: 0:59:09, time: 0.819, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1829, decode.acc_seg: 92.2147, aux.loss_ce: 0.0966, aux.acc_seg: 90.2148, loss: 0.2795
2023-12-29 16:52:57,068 - mmseg - INFO - Iter [155650/160000]	lr: 1.632e-06, eta: 0:58:28, time: 0.836, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1802, decode.acc_seg: 92.3736, aux.loss_ce: 0.0972, aux.acc_seg: 90.1264, loss: 0.2774
2023-12-29 16:53:37,773 - mmseg - INFO - Iter [155700/160000]	lr: 1.613e-06, eta: 0:57:48, time: 0.814, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1786, decode.acc_seg: 92.3030, aux.loss_ce: 0.0960, aux.acc_seg: 90.2560, loss: 0.2746
2023-12-29 16:54:18,580 - mmseg - INFO - Iter [155750/160000]	lr: 1.594e-06, eta: 0:57:08, time: 0.816, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1892, decode.acc_seg: 92.0423, aux.loss_ce: 0.1022, aux.acc_seg: 89.8570, loss: 0.2915
2023-12-29 16:54:59,267 - mmseg - INFO - Iter [155800/160000]	lr: 1.575e-06, eta: 0:56:27, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1737, decode.acc_seg: 92.5851, aux.loss_ce: 0.0937, aux.acc_seg: 90.5414, loss: 0.2674
2023-12-29 16:55:41,125 - mmseg - INFO - Iter [155850/160000]	lr: 1.557e-06, eta: 0:55:47, time: 0.837, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1762, decode.acc_seg: 92.5042, aux.loss_ce: 0.0966, aux.acc_seg: 90.2621, loss: 0.2728
2023-12-29 16:56:23,352 - mmseg - INFO - Iter [155900/160000]	lr: 1.538e-06, eta: 0:55:07, time: 0.844, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1705, decode.acc_seg: 92.4533, aux.loss_ce: 0.0934, aux.acc_seg: 90.1939, loss: 0.2640
2023-12-29 16:57:04,828 - mmseg - INFO - Iter [155950/160000]	lr: 1.519e-06, eta: 0:54:26, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1745, decode.acc_seg: 92.3113, aux.loss_ce: 0.0937, aux.acc_seg: 90.3864, loss: 0.2682
2023-12-29 16:57:44,501 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 16:57:44,502 - mmseg - INFO - Iter [156000/160000]	lr: 1.500e-06, eta: 0:53:46, time: 0.794, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 92.2228, aux.loss_ce: 0.1020, aux.acc_seg: 89.8864, loss: 0.2878
2023-12-29 16:58:25,980 - mmseg - INFO - Iter [156050/160000]	lr: 1.482e-06, eta: 0:53:06, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1691, decode.acc_seg: 92.7444, aux.loss_ce: 0.0942, aux.acc_seg: 90.5343, loss: 0.2633
2023-12-29 16:59:06,505 - mmseg - INFO - Iter [156100/160000]	lr: 1.463e-06, eta: 0:52:25, time: 0.811, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1846, decode.acc_seg: 92.3268, aux.loss_ce: 0.0993, aux.acc_seg: 90.1907, loss: 0.2839
2023-12-29 16:59:47,202 - mmseg - INFO - Iter [156150/160000]	lr: 1.444e-06, eta: 0:51:45, time: 0.814, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1874, decode.acc_seg: 92.0680, aux.loss_ce: 0.0993, aux.acc_seg: 90.1525, loss: 0.2867
2023-12-29 17:00:28,570 - mmseg - INFO - Iter [156200/160000]	lr: 1.425e-06, eta: 0:51:05, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1747, decode.acc_seg: 92.4135, aux.loss_ce: 0.0953, aux.acc_seg: 90.3562, loss: 0.2700
2023-12-29 17:01:10,283 - mmseg - INFO - Iter [156250/160000]	lr: 1.407e-06, eta: 0:50:25, time: 0.835, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1805, decode.acc_seg: 92.3490, aux.loss_ce: 0.0993, aux.acc_seg: 89.9942, loss: 0.2798
2023-12-29 17:01:50,759 - mmseg - INFO - Iter [156300/160000]	lr: 1.388e-06, eta: 0:49:44, time: 0.810, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1688, decode.acc_seg: 92.5600, aux.loss_ce: 0.0898, aux.acc_seg: 90.6066, loss: 0.2586
2023-12-29 17:02:31,368 - mmseg - INFO - Iter [156350/160000]	lr: 1.369e-06, eta: 0:49:04, time: 0.811, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1837, decode.acc_seg: 92.1714, aux.loss_ce: 0.0987, aux.acc_seg: 90.0709, loss: 0.2824
2023-12-29 17:03:12,440 - mmseg - INFO - Iter [156400/160000]	lr: 1.350e-06, eta: 0:48:24, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1923, decode.acc_seg: 91.8802, aux.loss_ce: 0.1032, aux.acc_seg: 89.7963, loss: 0.2955
2023-12-29 17:03:53,613 - mmseg - INFO - Iter [156450/160000]	lr: 1.332e-06, eta: 0:47:43, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1688, decode.acc_seg: 92.8008, aux.loss_ce: 0.0890, aux.acc_seg: 91.0641, loss: 0.2577
2023-12-29 17:04:35,023 - mmseg - INFO - Iter [156500/160000]	lr: 1.313e-06, eta: 0:47:03, time: 0.829, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1739, decode.acc_seg: 92.6516, aux.loss_ce: 0.0962, aux.acc_seg: 90.3223, loss: 0.2701
2023-12-29 17:05:16,573 - mmseg - INFO - Iter [156550/160000]	lr: 1.294e-06, eta: 0:46:23, time: 0.830, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1703, decode.acc_seg: 92.7570, aux.loss_ce: 0.0927, aux.acc_seg: 90.7311, loss: 0.2630
2023-12-29 17:05:57,142 - mmseg - INFO - Iter [156600/160000]	lr: 1.275e-06, eta: 0:45:42, time: 0.812, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1657, decode.acc_seg: 92.6870, aux.loss_ce: 0.0905, aux.acc_seg: 90.6453, loss: 0.2561
2023-12-29 17:06:39,019 - mmseg - INFO - Iter [156650/160000]	lr: 1.257e-06, eta: 0:45:02, time: 0.836, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1835, decode.acc_seg: 91.9582, aux.loss_ce: 0.0993, aux.acc_seg: 89.8420, loss: 0.2828
2023-12-29 17:07:20,283 - mmseg - INFO - Iter [156700/160000]	lr: 1.238e-06, eta: 0:44:22, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1769, decode.acc_seg: 92.5776, aux.loss_ce: 0.0970, aux.acc_seg: 90.4111, loss: 0.2739
2023-12-29 17:08:01,243 - mmseg - INFO - Iter [156750/160000]	lr: 1.219e-06, eta: 0:43:41, time: 0.821, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1763, decode.acc_seg: 92.5786, aux.loss_ce: 0.0949, aux.acc_seg: 90.5020, loss: 0.2711
2023-12-29 17:08:42,426 - mmseg - INFO - Iter [156800/160000]	lr: 1.200e-06, eta: 0:43:01, time: 0.824, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1793, decode.acc_seg: 92.3646, aux.loss_ce: 0.0959, aux.acc_seg: 90.3005, loss: 0.2752
2023-12-29 17:09:21,847 - mmseg - INFO - Iter [156850/160000]	lr: 1.182e-06, eta: 0:42:21, time: 0.788, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1748, decode.acc_seg: 92.4901, aux.loss_ce: 0.0931, aux.acc_seg: 90.7256, loss: 0.2679
2023-12-29 17:10:03,689 - mmseg - INFO - Iter [156900/160000]	lr: 1.163e-06, eta: 0:41:40, time: 0.836, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1740, decode.acc_seg: 92.3977, aux.loss_ce: 0.0961, aux.acc_seg: 90.0801, loss: 0.2701
2023-12-29 17:10:46,308 - mmseg - INFO - Iter [156950/160000]	lr: 1.144e-06, eta: 0:41:00, time: 0.854, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1780, decode.acc_seg: 92.5085, aux.loss_ce: 0.0961, aux.acc_seg: 90.3418, loss: 0.2741
2023-12-29 17:11:25,942 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 17:11:25,942 - mmseg - INFO - Iter [157000/160000]	lr: 1.125e-06, eta: 0:40:20, time: 0.791, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1831, decode.acc_seg: 92.2395, aux.loss_ce: 0.0974, aux.acc_seg: 90.1610, loss: 0.2805
2023-12-29 17:12:06,855 - mmseg - INFO - Iter [157050/160000]	lr: 1.107e-06, eta: 0:39:39, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1766, decode.acc_seg: 92.2398, aux.loss_ce: 0.0955, aux.acc_seg: 90.0476, loss: 0.2721
2023-12-29 17:12:45,869 - mmseg - INFO - Iter [157100/160000]	lr: 1.088e-06, eta: 0:38:59, time: 0.780, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1799, decode.acc_seg: 92.3595, aux.loss_ce: 0.0978, aux.acc_seg: 90.1974, loss: 0.2776
2023-12-29 17:13:27,830 - mmseg - INFO - Iter [157150/160000]	lr: 1.069e-06, eta: 0:38:19, time: 0.839, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1685, decode.acc_seg: 92.7027, aux.loss_ce: 0.0909, aux.acc_seg: 90.7843, loss: 0.2595
2023-12-29 17:14:09,467 - mmseg - INFO - Iter [157200/160000]	lr: 1.050e-06, eta: 0:37:38, time: 0.834, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1813, decode.acc_seg: 92.0305, aux.loss_ce: 0.0972, aux.acc_seg: 90.0481, loss: 0.2784
2023-12-29 17:14:48,251 - mmseg - INFO - Iter [157250/160000]	lr: 1.032e-06, eta: 0:36:58, time: 0.775, data_time: 0.011, memory: 18256, decode.loss_ce: 0.1739, decode.acc_seg: 92.5727, aux.loss_ce: 0.0958, aux.acc_seg: 90.4735, loss: 0.2697
2023-12-29 17:15:29,576 - mmseg - INFO - Iter [157300/160000]	lr: 1.013e-06, eta: 0:36:18, time: 0.826, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1725, decode.acc_seg: 92.5970, aux.loss_ce: 0.0930, aux.acc_seg: 90.5634, loss: 0.2654
2023-12-29 17:16:11,778 - mmseg - INFO - Iter [157350/160000]	lr: 9.941e-07, eta: 0:35:37, time: 0.844, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1737, decode.acc_seg: 92.5671, aux.loss_ce: 0.0937, aux.acc_seg: 90.5383, loss: 0.2674
2023-12-29 17:16:51,760 - mmseg - INFO - Iter [157400/160000]	lr: 9.754e-07, eta: 0:34:57, time: 0.800, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1923, decode.acc_seg: 91.8400, aux.loss_ce: 0.1026, aux.acc_seg: 89.7713, loss: 0.2949
2023-12-29 17:17:31,613 - mmseg - INFO - Iter [157450/160000]	lr: 9.566e-07, eta: 0:34:17, time: 0.797, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1801, decode.acc_seg: 92.2695, aux.loss_ce: 0.0967, aux.acc_seg: 90.0374, loss: 0.2768
2023-12-29 17:18:11,642 - mmseg - INFO - Iter [157500/160000]	lr: 9.379e-07, eta: 0:33:36, time: 0.802, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1830, decode.acc_seg: 92.3719, aux.loss_ce: 0.0982, aux.acc_seg: 90.2129, loss: 0.2812
2023-12-29 17:18:51,994 - mmseg - INFO - Iter [157550/160000]	lr: 9.191e-07, eta: 0:32:56, time: 0.806, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1763, decode.acc_seg: 92.4589, aux.loss_ce: 0.0951, aux.acc_seg: 90.4771, loss: 0.2715
2023-12-29 17:19:32,628 - mmseg - INFO - Iter [157600/160000]	lr: 9.004e-07, eta: 0:32:16, time: 0.813, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1764, decode.acc_seg: 92.5438, aux.loss_ce: 0.0942, aux.acc_seg: 90.5851, loss: 0.2707
2023-12-29 17:20:13,555 - mmseg - INFO - Iter [157650/160000]	lr: 8.816e-07, eta: 0:31:35, time: 0.819, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1812, decode.acc_seg: 92.3256, aux.loss_ce: 0.0975, aux.acc_seg: 90.2289, loss: 0.2787
2023-12-29 17:20:54,357 - mmseg - INFO - Iter [157700/160000]	lr: 8.629e-07, eta: 0:30:55, time: 0.816, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1756, decode.acc_seg: 92.5339, aux.loss_ce: 0.0936, aux.acc_seg: 90.7373, loss: 0.2692
2023-12-29 17:21:32,886 - mmseg - INFO - Iter [157750/160000]	lr: 8.441e-07, eta: 0:30:15, time: 0.771, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1801, decode.acc_seg: 92.3064, aux.loss_ce: 0.0958, aux.acc_seg: 90.4501, loss: 0.2759
2023-12-29 17:22:13,768 - mmseg - INFO - Iter [157800/160000]	lr: 8.254e-07, eta: 0:29:34, time: 0.818, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1772, decode.acc_seg: 92.5167, aux.loss_ce: 0.0949, aux.acc_seg: 90.3235, loss: 0.2722
2023-12-29 17:22:55,000 - mmseg - INFO - Iter [157850/160000]	lr: 8.066e-07, eta: 0:28:54, time: 0.825, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1826, decode.acc_seg: 92.2591, aux.loss_ce: 0.1001, aux.acc_seg: 89.9755, loss: 0.2827
2023-12-29 17:23:37,052 - mmseg - INFO - Iter [157900/160000]	lr: 7.879e-07, eta: 0:28:14, time: 0.842, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1743, decode.acc_seg: 92.5501, aux.loss_ce: 0.0949, aux.acc_seg: 90.5237, loss: 0.2692
2023-12-29 17:24:16,492 - mmseg - INFO - Iter [157950/160000]	lr: 7.691e-07, eta: 0:27:33, time: 0.789, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1782, decode.acc_seg: 92.3024, aux.loss_ce: 0.0960, aux.acc_seg: 90.2525, loss: 0.2742
2023-12-29 17:24:55,597 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 17:24:55,597 - mmseg - INFO - Iter [158000/160000]	lr: 7.504e-07, eta: 0:26:53, time: 0.781, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1686, decode.acc_seg: 92.6452, aux.loss_ce: 0.0908, aux.acc_seg: 90.6411, loss: 0.2595
2023-12-29 17:25:37,155 - mmseg - INFO - Iter [158050/160000]	lr: 7.316e-07, eta: 0:26:13, time: 0.831, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1766, decode.acc_seg: 92.2791, aux.loss_ce: 0.0925, aux.acc_seg: 90.4608, loss: 0.2691
2023-12-29 17:26:18,715 - mmseg - INFO - Iter [158100/160000]	lr: 7.129e-07, eta: 0:25:32, time: 0.830, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1790, decode.acc_seg: 92.4694, aux.loss_ce: 0.0949, aux.acc_seg: 90.7037, loss: 0.2739
2023-12-29 17:26:59,936 - mmseg - INFO - Iter [158150/160000]	lr: 6.941e-07, eta: 0:24:52, time: 0.825, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1881, decode.acc_seg: 92.1441, aux.loss_ce: 0.1030, aux.acc_seg: 89.8658, loss: 0.2911
2023-12-29 17:27:38,683 - mmseg - INFO - Iter [158200/160000]	lr: 6.754e-07, eta: 0:24:12, time: 0.775, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1771, decode.acc_seg: 92.6339, aux.loss_ce: 0.0969, aux.acc_seg: 90.4014, loss: 0.2740
2023-12-29 17:28:19,951 - mmseg - INFO - Iter [158250/160000]	lr: 6.566e-07, eta: 0:23:31, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1747, decode.acc_seg: 92.6346, aux.loss_ce: 0.0934, aux.acc_seg: 90.7184, loss: 0.2681
2023-12-29 17:29:01,273 - mmseg - INFO - Iter [158300/160000]	lr: 6.379e-07, eta: 0:22:51, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1760, decode.acc_seg: 92.6206, aux.loss_ce: 0.0940, aux.acc_seg: 90.6049, loss: 0.2700
2023-12-29 17:29:42,614 - mmseg - INFO - Iter [158350/160000]	lr: 6.191e-07, eta: 0:22:11, time: 0.827, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1641, decode.acc_seg: 92.9424, aux.loss_ce: 0.0888, aux.acc_seg: 90.9038, loss: 0.2529
2023-12-29 17:30:23,327 - mmseg - INFO - Iter [158400/160000]	lr: 6.004e-07, eta: 0:21:30, time: 0.814, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1815, decode.acc_seg: 92.3358, aux.loss_ce: 0.0975, aux.acc_seg: 90.2808, loss: 0.2790
2023-12-29 17:31:03,603 - mmseg - INFO - Iter [158450/160000]	lr: 5.816e-07, eta: 0:20:50, time: 0.805, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1734, decode.acc_seg: 92.5895, aux.loss_ce: 0.0925, aux.acc_seg: 90.7352, loss: 0.2659
2023-12-29 17:31:46,146 - mmseg - INFO - Iter [158500/160000]	lr: 5.629e-07, eta: 0:20:10, time: 0.851, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1866, decode.acc_seg: 92.1001, aux.loss_ce: 0.1006, aux.acc_seg: 89.7718, loss: 0.2872
2023-12-29 17:32:28,373 - mmseg - INFO - Iter [158550/160000]	lr: 5.441e-07, eta: 0:19:29, time: 0.845, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1819, decode.acc_seg: 92.3764, aux.loss_ce: 0.0969, aux.acc_seg: 90.3621, loss: 0.2787
2023-12-29 17:33:09,253 - mmseg - INFO - Iter [158600/160000]	lr: 5.254e-07, eta: 0:18:49, time: 0.818, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1799, decode.acc_seg: 92.2226, aux.loss_ce: 0.0974, aux.acc_seg: 90.2615, loss: 0.2773
2023-12-29 17:33:49,606 - mmseg - INFO - Iter [158650/160000]	lr: 5.066e-07, eta: 0:18:09, time: 0.807, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1823, decode.acc_seg: 92.0590, aux.loss_ce: 0.0991, aux.acc_seg: 89.8365, loss: 0.2814
2023-12-29 17:34:30,879 - mmseg - INFO - Iter [158700/160000]	lr: 4.879e-07, eta: 0:17:28, time: 0.825, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1769, decode.acc_seg: 92.4113, aux.loss_ce: 0.0967, aux.acc_seg: 90.2148, loss: 0.2735
2023-12-29 17:35:10,854 - mmseg - INFO - Iter [158750/160000]	lr: 4.691e-07, eta: 0:16:48, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1764, decode.acc_seg: 92.4613, aux.loss_ce: 0.0958, aux.acc_seg: 90.3243, loss: 0.2722
2023-12-29 17:35:52,182 - mmseg - INFO - Iter [158800/160000]	lr: 4.504e-07, eta: 0:16:08, time: 0.827, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1749, decode.acc_seg: 92.4447, aux.loss_ce: 0.0940, aux.acc_seg: 90.3594, loss: 0.2690
2023-12-29 17:36:32,638 - mmseg - INFO - Iter [158850/160000]	lr: 4.316e-07, eta: 0:15:27, time: 0.809, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1721, decode.acc_seg: 92.5151, aux.loss_ce: 0.0937, aux.acc_seg: 90.2520, loss: 0.2658
2023-12-29 17:37:12,273 - mmseg - INFO - Iter [158900/160000]	lr: 4.129e-07, eta: 0:14:47, time: 0.793, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1753, decode.acc_seg: 92.6028, aux.loss_ce: 0.0938, aux.acc_seg: 90.6478, loss: 0.2691
2023-12-29 17:37:52,339 - mmseg - INFO - Iter [158950/160000]	lr: 3.941e-07, eta: 0:14:07, time: 0.800, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1715, decode.acc_seg: 92.7274, aux.loss_ce: 0.0924, aux.acc_seg: 90.7152, loss: 0.2639
2023-12-29 17:38:33,613 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 17:38:33,613 - mmseg - INFO - Iter [159000/160000]	lr: 3.754e-07, eta: 0:13:26, time: 0.826, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1872, decode.acc_seg: 92.2211, aux.loss_ce: 0.0999, aux.acc_seg: 90.1422, loss: 0.2871
2023-12-29 17:39:14,495 - mmseg - INFO - Iter [159050/160000]	lr: 3.566e-07, eta: 0:12:46, time: 0.817, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1721, decode.acc_seg: 92.5822, aux.loss_ce: 0.0926, aux.acc_seg: 90.5896, loss: 0.2647
2023-12-29 17:39:55,094 - mmseg - INFO - Iter [159100/160000]	lr: 3.379e-07, eta: 0:12:06, time: 0.813, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1729, decode.acc_seg: 92.5024, aux.loss_ce: 0.0928, aux.acc_seg: 90.4652, loss: 0.2657
2023-12-29 17:40:37,414 - mmseg - INFO - Iter [159150/160000]	lr: 3.191e-07, eta: 0:11:25, time: 0.846, data_time: 0.054, memory: 18256, decode.loss_ce: 0.1740, decode.acc_seg: 92.5518, aux.loss_ce: 0.0925, aux.acc_seg: 90.4691, loss: 0.2665
2023-12-29 17:41:17,395 - mmseg - INFO - Iter [159200/160000]	lr: 3.004e-07, eta: 0:10:45, time: 0.799, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1795, decode.acc_seg: 92.3359, aux.loss_ce: 0.0967, aux.acc_seg: 90.3007, loss: 0.2761
2023-12-29 17:41:58,568 - mmseg - INFO - Iter [159250/160000]	lr: 2.816e-07, eta: 0:10:05, time: 0.824, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1770, decode.acc_seg: 92.1484, aux.loss_ce: 0.0960, aux.acc_seg: 89.9851, loss: 0.2729
2023-12-29 17:42:38,167 - mmseg - INFO - Iter [159300/160000]	lr: 2.629e-07, eta: 0:09:24, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1792, decode.acc_seg: 92.3313, aux.loss_ce: 0.0972, aux.acc_seg: 90.2109, loss: 0.2764
2023-12-29 17:43:18,768 - mmseg - INFO - Iter [159350/160000]	lr: 2.441e-07, eta: 0:08:44, time: 0.811, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1728, decode.acc_seg: 92.6014, aux.loss_ce: 0.0935, aux.acc_seg: 90.5022, loss: 0.2663
2023-12-29 17:43:58,779 - mmseg - INFO - Iter [159400/160000]	lr: 2.254e-07, eta: 0:08:04, time: 0.801, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1800, decode.acc_seg: 92.1548, aux.loss_ce: 0.0975, aux.acc_seg: 90.0967, loss: 0.2775
2023-12-29 17:44:38,147 - mmseg - INFO - Iter [159450/160000]	lr: 2.066e-07, eta: 0:07:23, time: 0.787, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1736, decode.acc_seg: 92.5174, aux.loss_ce: 0.0930, aux.acc_seg: 90.6753, loss: 0.2666
2023-12-29 17:45:17,496 - mmseg - INFO - Iter [159500/160000]	lr: 1.879e-07, eta: 0:06:43, time: 0.786, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1771, decode.acc_seg: 92.4634, aux.loss_ce: 0.0976, aux.acc_seg: 90.2455, loss: 0.2747
2023-12-29 17:45:58,613 - mmseg - INFO - Iter [159550/160000]	lr: 1.691e-07, eta: 0:06:03, time: 0.822, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1802, decode.acc_seg: 92.4234, aux.loss_ce: 0.0979, aux.acc_seg: 90.3039, loss: 0.2780
2023-12-29 17:46:41,930 - mmseg - INFO - Iter [159600/160000]	lr: 1.504e-07, eta: 0:05:22, time: 0.866, data_time: 0.015, memory: 18256, decode.loss_ce: 0.1673, decode.acc_seg: 92.7445, aux.loss_ce: 0.0917, aux.acc_seg: 90.6760, loss: 0.2590
2023-12-29 17:47:23,838 - mmseg - INFO - Iter [159650/160000]	lr: 1.316e-07, eta: 0:04:42, time: 0.838, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1726, decode.acc_seg: 92.6446, aux.loss_ce: 0.0923, aux.acc_seg: 90.7728, loss: 0.2649
2023-12-29 17:48:03,650 - mmseg - INFO - Iter [159700/160000]	lr: 1.129e-07, eta: 0:04:02, time: 0.797, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1812, decode.acc_seg: 92.2170, aux.loss_ce: 0.0988, aux.acc_seg: 90.1214, loss: 0.2801
2023-12-29 17:48:43,302 - mmseg - INFO - Iter [159750/160000]	lr: 9.413e-08, eta: 0:03:21, time: 0.792, data_time: 0.012, memory: 18256, decode.loss_ce: 0.1858, decode.acc_seg: 92.4000, aux.loss_ce: 0.1014, aux.acc_seg: 90.1138, loss: 0.2872
2023-12-29 17:49:23,817 - mmseg - INFO - Iter [159800/160000]	lr: 7.537e-08, eta: 0:02:41, time: 0.810, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1878, decode.acc_seg: 92.0800, aux.loss_ce: 0.1008, aux.acc_seg: 89.9177, loss: 0.2887
2023-12-29 17:50:06,146 - mmseg - INFO - Iter [159850/160000]	lr: 5.663e-08, eta: 0:02:01, time: 0.847, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1692, decode.acc_seg: 92.7406, aux.loss_ce: 0.0921, aux.acc_seg: 90.7325, loss: 0.2613
2023-12-29 17:50:46,499 - mmseg - INFO - Iter [159900/160000]	lr: 3.787e-08, eta: 0:01:20, time: 0.808, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1764, decode.acc_seg: 92.5096, aux.loss_ce: 0.0960, aux.acc_seg: 90.3991, loss: 0.2725
2023-12-29 17:51:27,468 - mmseg - INFO - Iter [159950/160000]	lr: 1.913e-08, eta: 0:00:40, time: 0.818, data_time: 0.014, memory: 18256, decode.loss_ce: 0.1690, decode.acc_seg: 92.9485, aux.loss_ce: 0.0899, aux.acc_seg: 91.0230, loss: 0.2589
2023-12-29 17:52:09,303 - mmseg - INFO - Saving checkpoint at 160000 iterations
2023-12-29 17:52:15,946 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 17:52:15,947 - mmseg - INFO - Iter [160000/160000]	lr: 3.750e-10, eta: 0:00:00, time: 0.971, data_time: 0.013, memory: 18256, decode.loss_ce: 0.1757, decode.acc_seg: 92.3399, aux.loss_ce: 0.0927, aux.acc_seg: 90.4972, loss: 0.2684
2023-12-29 17:54:15,068 - mmseg - INFO - per class results:
2023-12-29 17:54:15,079 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.78 | 88.38 |
|       building      | 82.52 | 91.06 |
|         sky         | 94.45 | 97.38 |
|        floor        | 81.72 | 90.82 |
|         tree        | 75.18 | 88.33 |
|       ceiling       |  83.9 | 91.46 |
|         road        | 83.19 | 90.38 |
|         bed         |  89.5 | 95.55 |
|      windowpane     |  63.9 | 79.55 |
|        grass        | 69.31 | 84.19 |
|       cabinet       | 59.84 | 71.91 |
|       sidewalk      | 66.73 | 79.46 |
|        person       | 81.75 |  93.5 |
|        earth        | 38.05 | 51.52 |
|         door        | 53.83 | 69.19 |
|        table        | 61.56 |  76.7 |
|       mountain      |  59.2 | 76.67 |
|        plant        | 52.03 | 63.76 |
|       curtain       | 75.62 |  88.4 |
|        chair        | 56.09 | 67.85 |
|         car         | 84.16 |  91.6 |
|        water        | 55.56 | 66.19 |
|       painting      | 72.18 | 88.85 |
|         sofa        | 65.69 | 83.27 |
|        shelf        | 43.13 | 57.33 |
|        house        | 52.38 | 75.91 |
|         sea         | 59.53 | 81.98 |
|        mirror       | 66.79 | 74.36 |
|         rug         | 63.17 | 73.32 |
|        field        | 36.88 | 57.81 |
|       armchair      |  41.9 | 59.88 |
|         seat        | 60.91 | 84.06 |
|        fence        | 46.57 | 64.46 |
|         desk        | 51.22 | 71.43 |
|         rock        | 41.67 | 66.22 |
|       wardrobe      | 48.71 | 70.08 |
|         lamp        | 64.61 | 76.11 |
|       bathtub       | 76.92 | 83.19 |
|       railing       | 34.62 | 47.27 |
|       cushion       | 61.33 | 74.91 |
|         base        | 35.46 | 48.13 |
|         box         | 25.99 | 33.54 |
|        column       |  46.7 | 56.52 |
|      signboard      | 37.55 | 51.48 |
|   chest of drawers  | 38.47 | 50.48 |
|       counter       | 34.78 |  45.5 |
|         sand        | 39.75 | 63.46 |
|         sink        | 69.85 | 79.68 |
|      skyscraper     | 36.63 |  44.5 |
|      fireplace      |  74.8 | 88.53 |
|     refrigerator    | 73.22 | 80.39 |
|      grandstand     | 37.17 | 72.07 |
|         path        | 20.91 | 30.77 |
|        stairs       | 31.62 | 38.37 |
|        runway       | 70.77 | 92.27 |
|         case        | 54.42 |  73.1 |
|      pool table     | 93.14 | 97.26 |
|        pillow       |  59.5 | 71.36 |
|     screen door     | 71.81 | 77.72 |
|       stairway      | 32.38 |  38.1 |
|        river        | 12.26 | 30.38 |
|        bridge       | 72.34 | 81.61 |
|       bookcase      | 36.16 | 59.88 |
|        blind        |  39.9 | 45.43 |
|     coffee table    | 57.14 | 79.88 |
|        toilet       | 84.36 | 90.11 |
|        flower       | 39.81 | 57.72 |
|         book        | 46.22 | 65.39 |
|         hill        |  4.09 |  6.57 |
|        bench        | 43.52 | 54.32 |
|      countertop     | 62.64 | 83.65 |
|        stove        | 79.61 | 88.21 |
|         palm        | 47.95 | 70.94 |
|    kitchen island   | 37.22 | 74.18 |
|       computer      | 71.03 | 85.19 |
|     swivel chair    | 40.86 | 68.88 |
|         boat        | 41.77 |  51.2 |
|         bar         | 43.81 |  62.8 |
|    arcade machine   | 78.82 | 85.18 |
|        hovel        | 45.04 | 54.13 |
|         bus         | 80.76 | 96.28 |
|        towel        |  63.9 | 76.08 |
|        light        | 56.17 | 63.96 |
|        truck        | 32.71 | 40.95 |
|        tower        | 26.37 | 43.68 |
|      chandelier     | 70.38 | 85.72 |
|        awning       | 27.39 | 37.44 |
|     streetlight     | 26.16 | 33.69 |
|        booth        | 58.51 | 67.74 |
| television receiver | 66.31 | 79.59 |
|       airplane      | 57.93 | 68.45 |
|      dirt track     |  24.6 |  50.1 |
|       apparel       | 42.79 | 58.17 |
|         pole        | 23.37 |  31.8 |
|         land        |  3.85 |  4.88 |
|      bannister      | 12.84 | 16.03 |
|      escalator      | 27.91 | 30.21 |
|       ottoman       | 36.29 |  54.4 |
|        bottle       | 33.68 | 55.93 |
|        buffet       | 39.56 | 44.45 |
|        poster       | 29.13 | 34.94 |
|        stage        | 22.17 | 33.92 |
|         van         | 41.53 | 59.69 |
|         ship        | 48.23 | 74.84 |
|       fountain      | 20.94 | 21.12 |
|    conveyer belt    | 77.76 | 89.33 |
|        canopy       | 25.02 | 35.23 |
|        washer       | 89.06 | 92.64 |
|      plaything      | 24.92 | 43.43 |
|    swimming pool    | 52.52 | 90.83 |
|        stool        | 32.81 | 49.21 |
|        barrel       | 26.85 | 66.42 |
|        basket       | 33.07 | 47.17 |
|      waterfall      |  68.4 | 80.34 |
|         tent        | 94.92 | 98.56 |
|         bag         | 12.52 | 15.48 |
|       minibike      |  74.2 | 85.47 |
|        cradle       | 76.59 | 97.69 |
|         oven        | 51.32 | 72.25 |
|         ball        | 49.41 | 69.25 |
|         food        | 50.45 | 60.88 |
|         step        | 13.41 | 16.49 |
|         tank        | 59.82 | 62.27 |
|      trade name     | 23.96 | 28.32 |
|      microwave      |  77.5 | 84.45 |
|         pot         | 47.54 | 56.93 |
|        animal       | 51.53 | 55.63 |
|       bicycle       | 55.67 | 78.05 |
|         lake        | 53.62 | 63.72 |
|      dishwasher     | 63.94 | 76.54 |
|        screen       |  63.8 | 88.85 |
|       blanket       | 11.31 | 13.42 |
|      sculpture      | 65.61 | 75.84 |
|         hood        |  58.1 | 70.33 |
|        sconce       | 45.11 | 53.36 |
|         vase        | 41.64 | 53.85 |
|    traffic light    | 30.34 | 47.33 |
|         tray        | 13.93 | 17.09 |
|        ashcan       | 41.91 | 53.13 |
|         fan         | 55.44 | 75.94 |
|         pier        |  39.9 | 71.99 |
|      crt screen     |  3.98 | 10.53 |
|        plate        | 53.15 | 75.92 |
|       monitor       |  9.63 | 11.83 |
|    bulletin board   | 49.39 | 63.05 |
|        shower       |  3.15 |  5.0  |
|       radiator      | 58.08 | 66.43 |
|        glass        | 15.89 | 17.67 |
|        clock        |  30.1 | 34.17 |
|         flag        | 46.47 | 51.04 |
+---------------------+-------+-------+
2023-12-29 17:54:15,079 - mmseg - INFO - Summary:
2023-12-29 17:54:15,080 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 83.39 | 50.01 | 63.0 |
+-------+-------+------+
2023-12-29 17:54:15,118 - mmseg - INFO - Exp name: upernet_512_debi_small_160k.py
2023-12-29 17:54:15,118 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8339, mIoU: 0.5001, mAcc: 0.6300, IoU.wall: 0.7778, IoU.building: 0.8252, IoU.sky: 0.9445, IoU.floor: 0.8172, IoU.tree: 0.7518, IoU.ceiling: 0.8390, IoU.road: 0.8319, IoU.bed : 0.8950, IoU.windowpane: 0.6390, IoU.grass: 0.6931, IoU.cabinet: 0.5984, IoU.sidewalk: 0.6673, IoU.person: 0.8175, IoU.earth: 0.3805, IoU.door: 0.5383, IoU.table: 0.6156, IoU.mountain: 0.5920, IoU.plant: 0.5203, IoU.curtain: 0.7562, IoU.chair: 0.5609, IoU.car: 0.8416, IoU.water: 0.5556, IoU.painting: 0.7218, IoU.sofa: 0.6569, IoU.shelf: 0.4313, IoU.house: 0.5238, IoU.sea: 0.5953, IoU.mirror: 0.6679, IoU.rug: 0.6317, IoU.field: 0.3688, IoU.armchair: 0.4190, IoU.seat: 0.6091, IoU.fence: 0.4657, IoU.desk: 0.5122, IoU.rock: 0.4167, IoU.wardrobe: 0.4871, IoU.lamp: 0.6461, IoU.bathtub: 0.7692, IoU.railing: 0.3462, IoU.cushion: 0.6133, IoU.base: 0.3546, IoU.box: 0.2599, IoU.column: 0.4670, IoU.signboard: 0.3755, IoU.chest of drawers: 0.3847, IoU.counter: 0.3478, IoU.sand: 0.3975, IoU.sink: 0.6985, IoU.skyscraper: 0.3663, IoU.fireplace: 0.7480, IoU.refrigerator: 0.7322, IoU.grandstand: 0.3717, IoU.path: 0.2091, IoU.stairs: 0.3162, IoU.runway: 0.7077, IoU.case: 0.5442, IoU.pool table: 0.9314, IoU.pillow: 0.5950, IoU.screen door: 0.7181, IoU.stairway: 0.3238, IoU.river: 0.1226, IoU.bridge: 0.7234, IoU.bookcase: 0.3616, IoU.blind: 0.3990, IoU.coffee table: 0.5714, IoU.toilet: 0.8436, IoU.flower: 0.3981, IoU.book: 0.4622, IoU.hill: 0.0409, IoU.bench: 0.4352, IoU.countertop: 0.6264, IoU.stove: 0.7961, IoU.palm: 0.4795, IoU.kitchen island: 0.3722, IoU.computer: 0.7103, IoU.swivel chair: 0.4086, IoU.boat: 0.4177, IoU.bar: 0.4381, IoU.arcade machine: 0.7882, IoU.hovel: 0.4504, IoU.bus: 0.8076, IoU.towel: 0.6390, IoU.light: 0.5617, IoU.truck: 0.3271, IoU.tower: 0.2637, IoU.chandelier: 0.7038, IoU.awning: 0.2739, IoU.streetlight: 0.2616, IoU.booth: 0.5851, IoU.television receiver: 0.6631, IoU.airplane: 0.5793, IoU.dirt track: 0.2460, IoU.apparel: 0.4279, IoU.pole: 0.2337, IoU.land: 0.0385, IoU.bannister: 0.1284, IoU.escalator: 0.2791, IoU.ottoman: 0.3629, IoU.bottle: 0.3368, IoU.buffet: 0.3956, IoU.poster: 0.2913, IoU.stage: 0.2217, IoU.van: 0.4153, IoU.ship: 0.4823, IoU.fountain: 0.2094, IoU.conveyer belt: 0.7776, IoU.canopy: 0.2502, IoU.washer: 0.8906, IoU.plaything: 0.2492, IoU.swimming pool: 0.5252, IoU.stool: 0.3281, IoU.barrel: 0.2685, IoU.basket: 0.3307, IoU.waterfall: 0.6840, IoU.tent: 0.9492, IoU.bag: 0.1252, IoU.minibike: 0.7420, IoU.cradle: 0.7659, IoU.oven: 0.5132, IoU.ball: 0.4941, IoU.food: 0.5045, IoU.step: 0.1341, IoU.tank: 0.5982, IoU.trade name: 0.2396, IoU.microwave: 0.7750, IoU.pot: 0.4754, IoU.animal: 0.5153, IoU.bicycle: 0.5567, IoU.lake: 0.5362, IoU.dishwasher: 0.6394, IoU.screen: 0.6380, IoU.blanket: 0.1131, IoU.sculpture: 0.6561, IoU.hood: 0.5810, IoU.sconce: 0.4511, IoU.vase: 0.4164, IoU.traffic light: 0.3034, IoU.tray: 0.1393, IoU.ashcan: 0.4191, IoU.fan: 0.5544, IoU.pier: 0.3990, IoU.crt screen: 0.0398, IoU.plate: 0.5315, IoU.monitor: 0.0963, IoU.bulletin board: 0.4939, IoU.shower: 0.0315, IoU.radiator: 0.5808, IoU.glass: 0.1589, IoU.clock: 0.3010, IoU.flag: 0.4647, Acc.wall: 0.8838, Acc.building: 0.9106, Acc.sky: 0.9738, Acc.floor: 0.9082, Acc.tree: 0.8833, Acc.ceiling: 0.9146, Acc.road: 0.9038, Acc.bed : 0.9555, Acc.windowpane: 0.7955, Acc.grass: 0.8419, Acc.cabinet: 0.7191, Acc.sidewalk: 0.7946, Acc.person: 0.9350, Acc.earth: 0.5152, Acc.door: 0.6919, Acc.table: 0.7670, Acc.mountain: 0.7667, Acc.plant: 0.6376, Acc.curtain: 0.8840, Acc.chair: 0.6785, Acc.car: 0.9160, Acc.water: 0.6619, Acc.painting: 0.8885, Acc.sofa: 0.8327, Acc.shelf: 0.5733, Acc.house: 0.7591, Acc.sea: 0.8198, Acc.mirror: 0.7436, Acc.rug: 0.7332, Acc.field: 0.5781, Acc.armchair: 0.5988, Acc.seat: 0.8406, Acc.fence: 0.6446, Acc.desk: 0.7143, Acc.rock: 0.6622, Acc.wardrobe: 0.7008, Acc.lamp: 0.7611, Acc.bathtub: 0.8319, Acc.railing: 0.4727, Acc.cushion: 0.7491, Acc.base: 0.4813, Acc.box: 0.3354, Acc.column: 0.5652, Acc.signboard: 0.5148, Acc.chest of drawers: 0.5048, Acc.counter: 0.4550, Acc.sand: 0.6346, Acc.sink: 0.7968, Acc.skyscraper: 0.4450, Acc.fireplace: 0.8853, Acc.refrigerator: 0.8039, Acc.grandstand: 0.7207, Acc.path: 0.3077, Acc.stairs: 0.3837, Acc.runway: 0.9227, Acc.case: 0.7310, Acc.pool table: 0.9726, Acc.pillow: 0.7136, Acc.screen door: 0.7772, Acc.stairway: 0.3810, Acc.river: 0.3038, Acc.bridge: 0.8161, Acc.bookcase: 0.5988, Acc.blind: 0.4543, Acc.coffee table: 0.7988, Acc.toilet: 0.9011, Acc.flower: 0.5772, Acc.book: 0.6539, Acc.hill: 0.0657, Acc.bench: 0.5432, Acc.countertop: 0.8365, Acc.stove: 0.8821, Acc.palm: 0.7094, Acc.kitchen island: 0.7418, Acc.computer: 0.8519, Acc.swivel chair: 0.6888, Acc.boat: 0.5120, Acc.bar: 0.6280, Acc.arcade machine: 0.8518, Acc.hovel: 0.5413, Acc.bus: 0.9628, Acc.towel: 0.7608, Acc.light: 0.6396, Acc.truck: 0.4095, Acc.tower: 0.4368, Acc.chandelier: 0.8572, Acc.awning: 0.3744, Acc.streetlight: 0.3369, Acc.booth: 0.6774, Acc.television receiver: 0.7959, Acc.airplane: 0.6845, Acc.dirt track: 0.5010, Acc.apparel: 0.5817, Acc.pole: 0.3180, Acc.land: 0.0488, Acc.bannister: 0.1603, Acc.escalator: 0.3021, Acc.ottoman: 0.5440, Acc.bottle: 0.5593, Acc.buffet: 0.4445, Acc.poster: 0.3494, Acc.stage: 0.3392, Acc.van: 0.5969, Acc.ship: 0.7484, Acc.fountain: 0.2112, Acc.conveyer belt: 0.8933, Acc.canopy: 0.3523, Acc.washer: 0.9264, Acc.plaything: 0.4343, Acc.swimming pool: 0.9083, Acc.stool: 0.4921, Acc.barrel: 0.6642, Acc.basket: 0.4717, Acc.waterfall: 0.8034, Acc.tent: 0.9856, Acc.bag: 0.1548, Acc.minibike: 0.8547, Acc.cradle: 0.9769, Acc.oven: 0.7225, Acc.ball: 0.6925, Acc.food: 0.6088, Acc.step: 0.1649, Acc.tank: 0.6227, Acc.trade name: 0.2832, Acc.microwave: 0.8445, Acc.pot: 0.5693, Acc.animal: 0.5563, Acc.bicycle: 0.7805, Acc.lake: 0.6372, Acc.dishwasher: 0.7654, Acc.screen: 0.8885, Acc.blanket: 0.1342, Acc.sculpture: 0.7584, Acc.hood: 0.7033, Acc.sconce: 0.5336, Acc.vase: 0.5385, Acc.traffic light: 0.4733, Acc.tray: 0.1709, Acc.ashcan: 0.5313, Acc.fan: 0.7594, Acc.pier: 0.7199, Acc.crt screen: 0.1053, Acc.plate: 0.7592, Acc.monitor: 0.1183, Acc.bulletin board: 0.6305, Acc.shower: 0.0500, Acc.radiator: 0.6643, Acc.glass: 0.1767, Acc.clock: 0.3417, Acc.flag: 0.5104
