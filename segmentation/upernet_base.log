2023-11-26 13:45:10,637 - mmseg - INFO - Multi-processing start method is `None`
2023-11-26 13:45:10,637 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>
2023-11-26 13:45:10,637 - mmseg - INFO - OMP num threads is 1
2023-11-26 13:45:10,677 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-32GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.3, V11.3.109
GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.2.0
MMCV: 1.5.0
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.3
MMSegmentation: 0.23.0+922e771
------------------------------------------------------------

2023-11-26 13:45:10,678 - mmseg - INFO - Distributed training: True
2023-11-26 13:45:11,159 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='debi_base',
        resume='/data/Next-ViT/nextvit_cls_exp/1013_012125/checkpoint_best.pth'
    ),
    decode_head=dict(
        type='UPerHead',
        in_channels=[96, 192, 384, 768],
        in_index=[0, 1, 2, 3],
        pool_scales=(1, 2, 3, 6),
        channels=512,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=384,
        in_index=2,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = '/data/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='AlignResize', keep_ratio=True, size_divisor=32),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='AlignResize', keep_ratio=True, size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='/data/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='AlignResize', keep_ratio=True, size_divisor=32),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
find_unused_parameters = False
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            rpe_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(
    grad_clip=None,
    type='Fp16OptimizerHook',
    coalesce=True,
    bucket_size_mb=-1,
    loss_scale='dynamic',
    distributed=True)
fp16 = None
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=3000,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/upernet_512_debi_base_160k'
gpu_ids = range(0, 8)
auto_resume = False

2023-11-26 13:45:18,349 - mmseg - INFO - Set random seed to 845413785, deterministic: False
2023-11-26 13:45:21,151 - mmseg - INFO - initialize UPerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2023-11-26 13:45:21,355 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.downsample_layers.0.0.weight - torch.Size([48, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.0.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.3.weight - torch.Size([96, 48, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.3.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.4.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.4.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.weight - torch.Size([192, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.weight - torch.Size([384, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.weight - torch.Size([768, 384, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed1.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed2.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pos_embed2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.lepe.weight - torch.Size([96, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.lepe.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.qkv.qkv.weight - torch.Size([288, 96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.qkv.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.wo.weight - torch.Size([96, 96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn1.wo.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.rpe_table - torch.Size([3, 111, 111]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.lepe1.weight - torch.Size([96, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.lepe1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.qkv_conv.qkv.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.qkv_conv.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_q.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_q.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_k.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_k.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_v.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_v.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_out.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.proj_out.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.unifyheads1.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.unifyheads1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.0.weight - torch.Size([96, 1, 9, 9]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.1.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.1.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.conv_offset_q.3.weight - torch.Size([1, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.attn2.mlp.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp1.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm3.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm3.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm4.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm4.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.mlp2.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed1.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed2.weight - torch.Size([96, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pos_embed2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.lepe.weight - torch.Size([96, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.lepe.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.qkv.qkv.weight - torch.Size([288, 96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.qkv.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.wo.weight - torch.Size([96, 96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn1.wo.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.rpe_table - torch.Size([3, 111, 111]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.lepe1.weight - torch.Size([96, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.lepe1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.qkv_conv.qkv.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.qkv_conv.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_q.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_q.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_k.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_k.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_v.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_v.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_out.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.proj_out.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.unifyheads1.weight - torch.Size([96, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.unifyheads1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.0.weight - torch.Size([96, 1, 9, 9]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.1.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.1.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.conv_offset_q.3.weight - torch.Size([1, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.attn2.mlp.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp1.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm3.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm3.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm4.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm4.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear1.0.weight - torch.Size([288, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear1.0.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear2.0.weight - torch.Size([96, 288, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.linear2.0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.dwc.weight - torch.Size([288, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.mlp2.dwc.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed1.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed2.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pos_embed2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.lepe.weight - torch.Size([192, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.lepe.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.qkv.qkv.weight - torch.Size([576, 192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.qkv.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.wo.weight - torch.Size([192, 192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn1.wo.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.rpe_table - torch.Size([6, 55, 55]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.lepe1.weight - torch.Size([192, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.lepe1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.qkv_conv.qkv.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.qkv_conv.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_q.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_q.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_k.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_k.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_v.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_v.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_out.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.proj_out.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.unifyheads1.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.unifyheads1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.0.weight - torch.Size([96, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.1.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.1.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.conv_offset_q.3.weight - torch.Size([1, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.attn2.mlp.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp1.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm3.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm3.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm4.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm4.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.mlp2.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed1.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed2.weight - torch.Size([192, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pos_embed2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.lepe.weight - torch.Size([192, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.lepe.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.qkv.qkv.weight - torch.Size([576, 192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.qkv.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.wo.weight - torch.Size([192, 192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn1.wo.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.rpe_table - torch.Size([6, 55, 55]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.lepe1.weight - torch.Size([192, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.lepe1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.qkv_conv.qkv.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.qkv_conv.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_q.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_q.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_k.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_k.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_v.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_v.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_out.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.proj_out.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.unifyheads1.weight - torch.Size([192, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.unifyheads1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.0.weight - torch.Size([96, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.1.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.1.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.conv_offset_q.3.weight - torch.Size([1, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.attn2.mlp.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp1.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm3.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm3.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm4.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm4.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear1.0.weight - torch.Size([576, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear1.0.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear2.0.weight - torch.Size([192, 576, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.linear2.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.dwc.weight - torch.Size([576, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.mlp2.dwc.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed1.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed2.weight - torch.Size([384, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pos_embed2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.lepe.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.lepe.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.qkv.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.qkv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.wo.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn1.wo.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.rpe_table - torch.Size([12, 27, 27]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.lepe1.weight - torch.Size([384, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.lepe1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.qkv_conv.qkv.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.qkv_conv.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_q.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_q.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_k.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_k.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_v.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_v.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_out.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.proj_out.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.unifyheads1.weight - torch.Size([384, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.unifyheads1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.attn2.mlp.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp1.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm3.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm3.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm4.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm4.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear1.0.weight - torch.Size([1152, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear1.0.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear2.0.weight - torch.Size([384, 1152, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.linear2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.dwc.weight - torch.Size([1152, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.mlp2.dwc.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed1.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed2.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pos_embed2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.rpe_table - torch.Size([24, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.lepe1.weight - torch.Size([768, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.lepe1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.qkv_conv.qkv.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.qkv_conv.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_q.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_q.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_k.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_k.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_v.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_v.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_out.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.proj_out.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.unifyheads1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.unifyheads1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.0.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn1.mlp.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.rpe_table - torch.Size([24, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.lepe1.weight - torch.Size([768, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.lepe1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.qkv_conv.qkv.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.qkv_conv.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_q.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_q.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_k.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_k.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_v.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_v.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_out.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.proj_out.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.unifyheads1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.unifyheads1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.attn2.mlp.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp1.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm4.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm4.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.mlp2.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed1.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed2.weight - torch.Size([768, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pos_embed2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.rpe_table - torch.Size([24, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.lepe1.weight - torch.Size([768, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.lepe1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.qkv_conv.qkv.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.qkv_conv.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_q.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_q.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_k.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_k.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_v.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_v.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_out.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.proj_out.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.unifyheads1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.unifyheads1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.0.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn1.mlp.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.rpe_table - torch.Size([24, 13, 13]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.lepe1.weight - torch.Size([768, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.lepe1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.qkv_conv.qkv.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.qkv_conv.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_q.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_q.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_k.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_k.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_v.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_v.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_out.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.proj_out.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.unifyheads1.weight - torch.Size([768, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.unifyheads1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.0.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.1.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.1.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.conv_offset_q.3.weight - torch.Size([1, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.attn2.mlp.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp1.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm4.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm4.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear1.0.weight - torch.Size([2304, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear1.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear2.0.weight - torch.Size([768, 2304, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.linear2.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.dwc.weight - torch.Size([2304, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.mlp2.dwc.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.0.ln.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.0.ln.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.1.ln.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.1.ln.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.2.ln.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.2.ln.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.3.ln.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.extra_norms.3.ln.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 512, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 768, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([512, 2816, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.conv.weight - torch.Size([512, 96, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.conv.weight - torch.Size([512, 192, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.conv.weight - torch.Size([512, 384, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.conv.weight - torch.Size([512, 2048, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.fpn_bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 384, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023-11-26 13:45:21,372 - mmseg - INFO - EncoderDecoder(
  (backbone): debi_base(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): GELU()
        (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Sequential(
        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Sequential(
        (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
          (pos_embed2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
            )
            (wo): Linear(in_features=96, out_features=96, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(96, 96, kernel_size=(5, 5), stride=(8, 8), padding=(2, 2), groups=96)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(96, 96, kernel_size=(9, 9), stride=(8, 8), padding=(4, 4), groups=96, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
            )
          )
          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
          )
          (drop_path1): Identity()
          (drop_path2): Identity()
          (norm3): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
          (pos_embed2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)
          (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
            )
            (wo): Linear(in_features=96, out_features=96, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(96, 96, kernel_size=(5, 5), stride=(8, 8), padding=(2, 2), groups=96)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(96, 96, kernel_size=(9, 9), stride=(8, 8), padding=(4, 4), groups=96, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
            )
          )
          (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288)
          )
        )
      )
      (1): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          (pos_embed2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
            )
            (wo): Linear(in_features=192, out_features=192, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(192, 192, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), groups=192)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=96, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
            )
          )
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          (pos_embed2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)
          (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
            )
            (wo): Linear(in_features=192, out_features=192, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(192, 192, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2), groups=192)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=96, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
            )
          )
          (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)
          )
        )
      )
      (2): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (2): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (3): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (4): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (5): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (6): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (7): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
        (8): Block(
          (pos_embed1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (pos_embed2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)
          (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (attn1): BiLevelRoutingAttention(
            (lepe): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv): QKVLinear(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
            )
            (wo): Linear(in_features=384, out_features=384, bias=True)
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(384, 384, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=384)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
            )
          )
          (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152)
          )
        )
      )
      (3): Sequential(
        (0): Block(
          (pos_embed1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          (pos_embed2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn1): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
            )
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
            )
          )
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
          )
        )
        (1): Block(
          (pos_embed1): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          (pos_embed2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn1): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
            )
          )
          (attn2): DeBiLevelRoutingAttention(
            (lepe1): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768)
            (router): TopkRouting(
              (emb): Identity()
              (routing_act): Softmax(dim=-1)
            )
            (kv_gather): KVGather()
            (qkv_conv): QKVConv(
              (qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (kv_down): Identity()
            (attn_act): Softmax(dim=-1)
            (proj_q): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_k): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_v): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (proj_out): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (unifyheads1): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
            (conv_offset_q): Sequential(
              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
              (1): LayerNormProxy(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (2): GELU()
              (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): TransformerMLPWithConv(
              (linear1): Sequential(
                (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop1): Dropout(p=0.0, inplace=True)
              (act): GELU()
              (linear2): Sequential(
                (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
              )
              (drop2): Dropout(p=0.0, inplace=True)
              (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
            )
          )
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp1): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
          )
          (drop_path1): DropPath()
          (drop_path2): DropPath()
          (norm3): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (norm4): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp2): TransformerMLPWithConv(
            (linear1): Sequential(
              (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop1): Dropout(p=0.0, inplace=True)
            (act): GELU()
            (linear2): Sequential(
              (0): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
            )
            (drop2): Dropout(p=0.0, inplace=True)
            (dwc): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304)
          )
        )
      )
    )
    (pre_logits): Identity()
    (extra_norms): ModuleList(
      (0): LayerNorm2d(
        (ln): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      )
      (1): LayerNorm2d(
        (ln): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
      (2): LayerNorm2d(
        (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
      (3): LayerNorm2d(
        (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decode_head): UPerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (0): Sequential(
        (0): AdaptiveAvgPool2d(output_size=1)
        (1): ConvModule(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): AdaptiveAvgPool2d(output_size=2)
        (1): ConvModule(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): AdaptiveAvgPool2d(output_size=3)
        (1): ConvModule(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (3): Sequential(
        (0): AdaptiveAvgPool2d(output_size=6)
        (1): ConvModule(
          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(2816, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)
    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2023-11-26 13:45:21,893 - mmseg - INFO - Loaded 20210 images
2023-11-26 13:45:23,625 - mmseg - INFO - Loaded 2000 images
2023-11-26 13:45:23,626 - mmseg - INFO - Start running, host: cuda11py3.9@1082ba884f56, work_dir: /data/Next-ViT/segmentation/work_dirs/upernet_512_debi_base_160k
2023-11-26 13:45:23,626 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-11-26 13:45:23,626 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2023-11-26 13:45:23,633 - mmseg - INFO - Checkpoints will be saved to /data/Next-ViT/segmentation/work_dirs/upernet_512_debi_base_160k by HardDiskBackend.
2023-11-26 13:46:26,870 - mmseg - INFO - Iter [50/160000]	lr: 9.798e-07, eta: 1 day, 20:37:27, time: 1.004, data_time: 0.012, memory: 18766, decode.loss_ce: 4.0588, decode.acc_seg: 0.5353, aux.loss_ce: 1.6165, aux.acc_seg: 1.0796, loss: 5.6752
2023-11-26 13:47:07,417 - mmseg - INFO - Iter [100/160000]	lr: 1.979e-06, eta: 1 day, 16:18:50, time: 0.811, data_time: 0.011, memory: 18766, decode.loss_ce: 4.0215, decode.acc_seg: 1.0084, aux.loss_ce: 1.6107, aux.acc_seg: 1.0894, loss: 5.6322
2023-11-26 13:47:47,108 - mmseg - INFO - Iter [150/160000]	lr: 2.977e-06, eta: 1 day, 14:37:33, time: 0.794, data_time: 0.011, memory: 18766, decode.loss_ce: 3.9528, decode.acc_seg: 4.0788, aux.loss_ce: 1.5991, aux.acc_seg: 1.8044, loss: 5.5519
2023-11-26 13:48:28,153 - mmseg - INFO - Iter [200/160000]	lr: 3.975e-06, eta: 1 day, 14:03:42, time: 0.820, data_time: 0.010, memory: 18766, decode.loss_ce: 3.8852, decode.acc_seg: 17.7619, aux.loss_ce: 1.6050, aux.acc_seg: 3.1539, loss: 5.4902
2023-11-26 13:49:09,254 - mmseg - INFO - Iter [250/160000]	lr: 4.972e-06, eta: 1 day, 13:44:07, time: 0.822, data_time: 0.011, memory: 18766, decode.loss_ce: 3.7581, decode.acc_seg: 35.2938, aux.loss_ce: 1.6138, aux.acc_seg: 6.5337, loss: 5.3720
2023-11-26 13:49:49,852 - mmseg - INFO - Iter [300/160000]	lr: 5.969e-06, eta: 1 day, 13:26:21, time: 0.812, data_time: 0.012, memory: 18766, decode.loss_ce: 3.4446, decode.acc_seg: 40.6731, aux.loss_ce: 1.5642, aux.acc_seg: 15.5753, loss: 5.0088
2023-11-26 13:50:29,950 - mmseg - INFO - Iter [350/160000]	lr: 6.965e-06, eta: 1 day, 13:09:42, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 3.1498, decode.acc_seg: 47.1856, aux.loss_ce: 1.5343, aux.acc_seg: 32.8850, loss: 4.6841
2023-11-26 13:51:09,539 - mmseg - INFO - Iter [400/160000]	lr: 7.960e-06, eta: 1 day, 12:53:46, time: 0.792, data_time: 0.011, memory: 18766, decode.loss_ce: 3.0011, decode.acc_seg: 48.5415, aux.loss_ce: 1.5190, aux.acc_seg: 42.8153, loss: 4.5202
2023-11-26 13:51:49,018 - mmseg - INFO - Iter [450/160000]	lr: 8.955e-06, eta: 1 day, 12:40:18, time: 0.789, data_time: 0.010, memory: 18766, decode.loss_ce: 2.7748, decode.acc_seg: 49.9378, aux.loss_ce: 1.4453, aux.acc_seg: 46.9944, loss: 4.2200
2023-11-26 13:52:28,952 - mmseg - INFO - Iter [500/160000]	lr: 9.949e-06, eta: 1 day, 12:31:56, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 2.6145, decode.acc_seg: 53.0535, aux.loss_ce: 1.3970, aux.acc_seg: 49.1487, loss: 4.0114
2023-11-26 13:53:09,170 - mmseg - INFO - Iter [550/160000]	lr: 1.094e-05, eta: 1 day, 12:26:25, time: 0.805, data_time: 0.010, memory: 18766, decode.loss_ce: 2.4896, decode.acc_seg: 51.7786, aux.loss_ce: 1.3361, aux.acc_seg: 47.9593, loss: 3.8257
2023-11-26 13:53:47,589 - mmseg - INFO - Iter [600/160000]	lr: 1.194e-05, eta: 1 day, 12:13:52, time: 0.769, data_time: 0.011, memory: 18766, decode.loss_ce: 2.4439, decode.acc_seg: 54.5544, aux.loss_ce: 1.3268, aux.acc_seg: 49.7643, loss: 3.7707
2023-11-26 13:54:25,714 - mmseg - INFO - Iter [650/160000]	lr: 1.293e-05, eta: 1 day, 12:01:47, time: 0.763, data_time: 0.010, memory: 18766, decode.loss_ce: 2.3036, decode.acc_seg: 55.2991, aux.loss_ce: 1.2726, aux.acc_seg: 50.8119, loss: 3.5761
2023-11-26 13:55:04,725 - mmseg - INFO - Iter [700/160000]	lr: 1.392e-05, eta: 1 day, 11:54:35, time: 0.780, data_time: 0.010, memory: 18766, decode.loss_ce: 2.2242, decode.acc_seg: 56.3488, aux.loss_ce: 1.2361, aux.acc_seg: 52.5820, loss: 3.4603
2023-11-26 13:55:42,559 - mmseg - INFO - Iter [750/160000]	lr: 1.491e-05, eta: 1 day, 11:44:11, time: 0.757, data_time: 0.011, memory: 18766, decode.loss_ce: 2.1039, decode.acc_seg: 55.5382, aux.loss_ce: 1.1705, aux.acc_seg: 51.4252, loss: 3.2744
2023-11-26 13:56:21,748 - mmseg - INFO - Iter [800/160000]	lr: 1.590e-05, eta: 1 day, 11:39:32, time: 0.784, data_time: 0.011, memory: 18766, decode.loss_ce: 2.0232, decode.acc_seg: 58.5797, aux.loss_ce: 1.1545, aux.acc_seg: 54.3429, loss: 3.1777
2023-11-26 13:56:58,852 - mmseg - INFO - Iter [850/160000]	lr: 1.689e-05, eta: 1 day, 11:28:57, time: 0.743, data_time: 0.010, memory: 18766, decode.loss_ce: 1.8920, decode.acc_seg: 58.8452, aux.loss_ce: 1.0755, aux.acc_seg: 55.2433, loss: 2.9675
2023-11-26 13:57:37,897 - mmseg - INFO - Iter [900/160000]	lr: 1.788e-05, eta: 1 day, 11:24:56, time: 0.780, data_time: 0.010, memory: 18766, decode.loss_ce: 1.8761, decode.acc_seg: 59.2677, aux.loss_ce: 1.0774, aux.acc_seg: 55.0549, loss: 2.9535
2023-11-26 13:58:15,567 - mmseg - INFO - Iter [950/160000]	lr: 1.887e-05, eta: 1 day, 11:17:31, time: 0.753, data_time: 0.011, memory: 18766, decode.loss_ce: 1.7775, decode.acc_seg: 59.3360, aux.loss_ce: 1.0191, aux.acc_seg: 55.7986, loss: 2.7967
2023-11-26 13:58:55,682 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 13:58:55,682 - mmseg - INFO - Iter [1000/160000]	lr: 1.986e-05, eta: 1 day, 11:17:18, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 1.7810, decode.acc_seg: 59.7922, aux.loss_ce: 1.0076, aux.acc_seg: 55.6180, loss: 2.7886
2023-11-26 13:59:36,017 - mmseg - INFO - Iter [1050/160000]	lr: 2.084e-05, eta: 1 day, 11:17:47, time: 0.808, data_time: 0.011, memory: 18766, decode.loss_ce: 1.7158, decode.acc_seg: 59.5246, aux.loss_ce: 0.9669, aux.acc_seg: 55.4165, loss: 2.6828
2023-11-26 14:00:13,403 - mmseg - INFO - Iter [1100/160000]	lr: 2.183e-05, eta: 1 day, 11:10:44, time: 0.746, data_time: 0.010, memory: 18766, decode.loss_ce: 1.6462, decode.acc_seg: 60.7276, aux.loss_ce: 0.9197, aux.acc_seg: 56.3061, loss: 2.5659
2023-11-26 14:00:53,376 - mmseg - INFO - Iter [1150/160000]	lr: 2.282e-05, eta: 1 day, 11:10:29, time: 0.801, data_time: 0.012, memory: 18766, decode.loss_ce: 1.5622, decode.acc_seg: 61.4263, aux.loss_ce: 0.8755, aux.acc_seg: 56.7149, loss: 2.4377
2023-11-26 14:01:32,365 - mmseg - INFO - Iter [1200/160000]	lr: 2.380e-05, eta: 1 day, 11:07:55, time: 0.780, data_time: 0.011, memory: 18766, decode.loss_ce: 1.6235, decode.acc_seg: 59.9626, aux.loss_ce: 0.8889, aux.acc_seg: 55.7410, loss: 2.5124
2023-11-26 14:02:11,733 - mmseg - INFO - Iter [1250/160000]	lr: 2.479e-05, eta: 1 day, 11:06:11, time: 0.786, data_time: 0.010, memory: 18766, decode.loss_ce: 1.5017, decode.acc_seg: 63.1377, aux.loss_ce: 0.8366, aux.acc_seg: 58.6084, loss: 2.3383
2023-11-26 14:02:53,536 - mmseg - INFO - Iter [1300/160000]	lr: 2.577e-05, eta: 1 day, 11:09:36, time: 0.836, data_time: 0.053, memory: 18766, decode.loss_ce: 1.4351, decode.acc_seg: 64.0845, aux.loss_ce: 0.8049, aux.acc_seg: 58.5296, loss: 2.2401
2023-11-26 14:03:34,318 - mmseg - INFO - Iter [1350/160000]	lr: 2.675e-05, eta: 1 day, 11:10:40, time: 0.815, data_time: 0.010, memory: 18766, decode.loss_ce: 1.4620, decode.acc_seg: 63.6032, aux.loss_ce: 0.7959, aux.acc_seg: 58.3830, loss: 2.2579
2023-11-26 14:04:14,704 - mmseg - INFO - Iter [1400/160000]	lr: 2.774e-05, eta: 1 day, 11:10:55, time: 0.808, data_time: 0.011, memory: 18766, decode.loss_ce: 1.3904, decode.acc_seg: 64.5372, aux.loss_ce: 0.7621, aux.acc_seg: 59.6482, loss: 2.1525
2023-11-26 14:04:55,543 - mmseg - INFO - Iter [1450/160000]	lr: 2.872e-05, eta: 1 day, 11:11:54, time: 0.817, data_time: 0.010, memory: 18766, decode.loss_ce: 1.3956, decode.acc_seg: 64.2565, aux.loss_ce: 0.7559, aux.acc_seg: 58.6278, loss: 2.1516
2023-11-26 14:05:36,532 - mmseg - INFO - Iter [1500/160000]	lr: 2.970e-05, eta: 1 day, 11:13:04, time: 0.820, data_time: 0.011, memory: 18766, decode.loss_ce: 1.3571, decode.acc_seg: 65.0015, aux.loss_ce: 0.7327, aux.acc_seg: 59.9661, loss: 2.0898
2023-11-26 14:06:15,891 - mmseg - INFO - Iter [1550/160000]	lr: 3.068e-05, eta: 1 day, 11:11:20, time: 0.787, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2947, decode.acc_seg: 64.8160, aux.loss_ce: 0.6943, aux.acc_seg: 59.5739, loss: 1.9890
2023-11-26 14:06:53,930 - mmseg - INFO - Iter [1600/160000]	lr: 3.166e-05, eta: 1 day, 11:07:31, time: 0.761, data_time: 0.012, memory: 18766, decode.loss_ce: 1.2524, decode.acc_seg: 66.6223, aux.loss_ce: 0.6733, aux.acc_seg: 61.3796, loss: 1.9257
2023-11-26 14:07:32,778 - mmseg - INFO - Iter [1650/160000]	lr: 3.264e-05, eta: 1 day, 11:05:04, time: 0.776, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2493, decode.acc_seg: 66.3134, aux.loss_ce: 0.6667, aux.acc_seg: 61.4702, loss: 1.9160
2023-11-26 14:08:12,598 - mmseg - INFO - Iter [1700/160000]	lr: 3.362e-05, eta: 1 day, 11:04:19, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2241, decode.acc_seg: 66.4063, aux.loss_ce: 0.6436, aux.acc_seg: 61.7166, loss: 1.8677
2023-11-26 14:08:49,564 - mmseg - INFO - Iter [1750/160000]	lr: 3.460e-05, eta: 1 day, 10:59:18, time: 0.740, data_time: 0.012, memory: 18766, decode.loss_ce: 1.2795, decode.acc_seg: 65.0684, aux.loss_ce: 0.6587, aux.acc_seg: 60.8817, loss: 1.9383
2023-11-26 14:09:27,004 - mmseg - INFO - Iter [1800/160000]	lr: 3.558e-05, eta: 1 day, 10:55:12, time: 0.749, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2116, decode.acc_seg: 66.5955, aux.loss_ce: 0.6219, aux.acc_seg: 62.6134, loss: 1.8335
2023-11-26 14:10:05,106 - mmseg - INFO - Iter [1850/160000]	lr: 3.655e-05, eta: 1 day, 10:52:09, time: 0.761, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2700, decode.acc_seg: 64.5695, aux.loss_ce: 0.6459, aux.acc_seg: 60.3903, loss: 1.9159
2023-11-26 14:10:46,747 - mmseg - INFO - Iter [1900/160000]	lr: 3.753e-05, eta: 1 day, 10:54:12, time: 0.833, data_time: 0.011, memory: 18766, decode.loss_ce: 1.2600, decode.acc_seg: 65.1126, aux.loss_ce: 0.6344, aux.acc_seg: 60.9963, loss: 1.8945
2023-11-26 14:11:25,138 - mmseg - INFO - Iter [1950/160000]	lr: 3.851e-05, eta: 1 day, 10:51:44, time: 0.768, data_time: 0.011, memory: 18766, decode.loss_ce: 1.1646, decode.acc_seg: 66.9767, aux.loss_ce: 0.5955, aux.acc_seg: 62.3573, loss: 1.7601
2023-11-26 14:12:05,598 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 14:12:05,598 - mmseg - INFO - Iter [2000/160000]	lr: 3.948e-05, eta: 1 day, 10:52:03, time: 0.809, data_time: 0.011, memory: 18766, decode.loss_ce: 1.1916, decode.acc_seg: 66.2312, aux.loss_ce: 0.6060, aux.acc_seg: 61.2173, loss: 1.7976
2023-11-26 14:12:45,581 - mmseg - INFO - Iter [2050/160000]	lr: 4.046e-05, eta: 1 day, 10:51:44, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 1.1705, decode.acc_seg: 65.4873, aux.loss_ce: 0.5820, aux.acc_seg: 61.7582, loss: 1.7525
2023-11-26 14:13:25,633 - mmseg - INFO - Iter [2100/160000]	lr: 4.143e-05, eta: 1 day, 10:51:28, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 1.0566, decode.acc_seg: 68.7214, aux.loss_ce: 0.5372, aux.acc_seg: 64.5557, loss: 1.5938
2023-11-26 14:14:05,770 - mmseg - INFO - Iter [2150/160000]	lr: 4.240e-05, eta: 1 day, 10:51:19, time: 0.803, data_time: 0.011, memory: 18766, decode.loss_ce: 1.1538, decode.acc_seg: 66.8170, aux.loss_ce: 0.5793, aux.acc_seg: 62.8232, loss: 1.7331
2023-11-26 14:14:46,305 - mmseg - INFO - Iter [2200/160000]	lr: 4.338e-05, eta: 1 day, 10:51:35, time: 0.811, data_time: 0.010, memory: 18766, decode.loss_ce: 1.1027, decode.acc_seg: 67.2201, aux.loss_ce: 0.5553, aux.acc_seg: 62.9690, loss: 1.6580
2023-11-26 14:15:27,458 - mmseg - INFO - Iter [2250/160000]	lr: 4.435e-05, eta: 1 day, 10:52:29, time: 0.822, data_time: 0.011, memory: 18766, decode.loss_ce: 1.1342, decode.acc_seg: 66.0378, aux.loss_ce: 0.5606, aux.acc_seg: 62.2397, loss: 1.6949
2023-11-26 14:16:08,829 - mmseg - INFO - Iter [2300/160000]	lr: 4.532e-05, eta: 1 day, 10:53:39, time: 0.828, data_time: 0.012, memory: 18766, decode.loss_ce: 1.0885, decode.acc_seg: 67.2914, aux.loss_ce: 0.5378, aux.acc_seg: 63.9245, loss: 1.6262
2023-11-26 14:16:49,964 - mmseg - INFO - Iter [2350/160000]	lr: 4.629e-05, eta: 1 day, 10:54:28, time: 0.823, data_time: 0.012, memory: 18766, decode.loss_ce: 1.1397, decode.acc_seg: 67.3095, aux.loss_ce: 0.5546, aux.acc_seg: 64.1894, loss: 1.6943
2023-11-26 14:17:30,850 - mmseg - INFO - Iter [2400/160000]	lr: 4.726e-05, eta: 1 day, 10:54:55, time: 0.818, data_time: 0.012, memory: 18766, decode.loss_ce: 1.1031, decode.acc_seg: 66.3034, aux.loss_ce: 0.5410, aux.acc_seg: 62.8136, loss: 1.6441
2023-11-26 14:18:10,741 - mmseg - INFO - Iter [2450/160000]	lr: 4.823e-05, eta: 1 day, 10:54:19, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 1.0498, decode.acc_seg: 67.8094, aux.loss_ce: 0.5197, aux.acc_seg: 64.3305, loss: 1.5694
2023-11-26 14:18:49,368 - mmseg - INFO - Iter [2500/160000]	lr: 4.920e-05, eta: 1 day, 10:52:18, time: 0.772, data_time: 0.010, memory: 18766, decode.loss_ce: 1.0653, decode.acc_seg: 68.1660, aux.loss_ce: 0.5170, aux.acc_seg: 65.3121, loss: 1.5823
2023-11-26 14:19:28,514 - mmseg - INFO - Iter [2550/160000]	lr: 5.017e-05, eta: 1 day, 10:50:57, time: 0.784, data_time: 0.055, memory: 18766, decode.loss_ce: 1.0539, decode.acc_seg: 67.6785, aux.loss_ce: 0.5038, aux.acc_seg: 64.9753, loss: 1.5578
2023-11-26 14:20:08,611 - mmseg - INFO - Iter [2600/160000]	lr: 5.114e-05, eta: 1 day, 10:50:30, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 1.0273, decode.acc_seg: 68.9354, aux.loss_ce: 0.5030, aux.acc_seg: 65.4971, loss: 1.5303
2023-11-26 14:20:47,689 - mmseg - INFO - Iter [2650/160000]	lr: 5.210e-05, eta: 1 day, 10:49:07, time: 0.782, data_time: 0.011, memory: 18766, decode.loss_ce: 1.0469, decode.acc_seg: 68.3953, aux.loss_ce: 0.5102, aux.acc_seg: 65.6404, loss: 1.5571
2023-11-26 14:21:26,330 - mmseg - INFO - Iter [2700/160000]	lr: 5.307e-05, eta: 1 day, 10:47:16, time: 0.772, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9946, decode.acc_seg: 70.0339, aux.loss_ce: 0.4870, aux.acc_seg: 67.0617, loss: 1.4816
2023-11-26 14:22:06,579 - mmseg - INFO - Iter [2750/160000]	lr: 5.404e-05, eta: 1 day, 10:47:01, time: 0.805, data_time: 0.011, memory: 18766, decode.loss_ce: 0.9805, decode.acc_seg: 68.9273, aux.loss_ce: 0.4792, aux.acc_seg: 65.8411, loss: 1.4597
2023-11-26 14:22:44,389 - mmseg - INFO - Iter [2800/160000]	lr: 5.500e-05, eta: 1 day, 10:44:31, time: 0.757, data_time: 0.011, memory: 18766, decode.loss_ce: 0.9809, decode.acc_seg: 69.3953, aux.loss_ce: 0.4778, aux.acc_seg: 66.0799, loss: 1.4587
2023-11-26 14:23:23,257 - mmseg - INFO - Iter [2850/160000]	lr: 5.597e-05, eta: 1 day, 10:43:01, time: 0.778, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9699, decode.acc_seg: 69.4594, aux.loss_ce: 0.4739, aux.acc_seg: 66.2209, loss: 1.4438
2023-11-26 14:24:00,372 - mmseg - INFO - Iter [2900/160000]	lr: 5.693e-05, eta: 1 day, 10:39:55, time: 0.741, data_time: 0.011, memory: 18766, decode.loss_ce: 1.0136, decode.acc_seg: 68.0791, aux.loss_ce: 0.4849, aux.acc_seg: 65.5527, loss: 1.4985
2023-11-26 14:24:38,304 - mmseg - INFO - Iter [2950/160000]	lr: 5.789e-05, eta: 1 day, 10:37:42, time: 0.759, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9583, decode.acc_seg: 69.6253, aux.loss_ce: 0.4697, aux.acc_seg: 66.4613, loss: 1.4279
2023-11-26 14:25:16,312 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 14:25:16,312 - mmseg - INFO - Iter [3000/160000]	lr: 5.886e-05, eta: 1 day, 10:35:35, time: 0.761, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9707, decode.acc_seg: 69.1606, aux.loss_ce: 0.4605, aux.acc_seg: 66.2382, loss: 1.4312
2023-11-26 14:25:54,511 - mmseg - INFO - Iter [3050/160000]	lr: 5.886e-05, eta: 1 day, 10:33:40, time: 0.764, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9519, decode.acc_seg: 69.6127, aux.loss_ce: 0.4556, aux.acc_seg: 66.7303, loss: 1.4074
2023-11-26 14:26:32,713 - mmseg - INFO - Iter [3100/160000]	lr: 5.884e-05, eta: 1 day, 10:31:48, time: 0.764, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9702, decode.acc_seg: 69.4816, aux.loss_ce: 0.4662, aux.acc_seg: 66.2403, loss: 1.4364
2023-11-26 14:27:11,948 - mmseg - INFO - Iter [3150/160000]	lr: 5.882e-05, eta: 1 day, 10:30:50, time: 0.785, data_time: 0.009, memory: 18766, decode.loss_ce: 0.9413, decode.acc_seg: 70.4982, aux.loss_ce: 0.4546, aux.acc_seg: 67.6339, loss: 1.3959
2023-11-26 14:27:50,701 - mmseg - INFO - Iter [3200/160000]	lr: 5.880e-05, eta: 1 day, 10:29:26, time: 0.774, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9550, decode.acc_seg: 68.8238, aux.loss_ce: 0.4529, aux.acc_seg: 65.7590, loss: 1.4079
2023-11-26 14:28:31,107 - mmseg - INFO - Iter [3250/160000]	lr: 5.878e-05, eta: 1 day, 10:29:26, time: 0.808, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9076, decode.acc_seg: 70.6507, aux.loss_ce: 0.4375, aux.acc_seg: 67.5795, loss: 1.3451
2023-11-26 14:29:10,595 - mmseg - INFO - Iter [3300/160000]	lr: 5.876e-05, eta: 1 day, 10:28:41, time: 0.790, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8942, decode.acc_seg: 70.4500, aux.loss_ce: 0.4305, aux.acc_seg: 68.0336, loss: 1.3247
2023-11-26 14:29:51,411 - mmseg - INFO - Iter [3350/160000]	lr: 5.874e-05, eta: 1 day, 10:28:56, time: 0.816, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9046, decode.acc_seg: 70.9250, aux.loss_ce: 0.4369, aux.acc_seg: 67.7680, loss: 1.3415
2023-11-26 14:30:31,945 - mmseg - INFO - Iter [3400/160000]	lr: 5.873e-05, eta: 1 day, 10:28:59, time: 0.811, data_time: 0.011, memory: 18766, decode.loss_ce: 0.9519, decode.acc_seg: 69.2783, aux.loss_ce: 0.4487, aux.acc_seg: 66.4713, loss: 1.4006
2023-11-26 14:31:11,968 - mmseg - INFO - Iter [3450/160000]	lr: 5.871e-05, eta: 1 day, 10:28:37, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8788, decode.acc_seg: 71.1215, aux.loss_ce: 0.4231, aux.acc_seg: 67.8049, loss: 1.3019
2023-11-26 14:31:51,513 - mmseg - INFO - Iter [3500/160000]	lr: 5.869e-05, eta: 1 day, 10:27:55, time: 0.792, data_time: 0.011, memory: 18766, decode.loss_ce: 0.9050, decode.acc_seg: 70.9559, aux.loss_ce: 0.4339, aux.acc_seg: 68.1708, loss: 1.3389
2023-11-26 14:32:29,985 - mmseg - INFO - Iter [3550/160000]	lr: 5.867e-05, eta: 1 day, 10:26:22, time: 0.769, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8707, decode.acc_seg: 71.3833, aux.loss_ce: 0.4087, aux.acc_seg: 69.0961, loss: 1.2794
2023-11-26 14:33:06,757 - mmseg - INFO - Iter [3600/160000]	lr: 5.865e-05, eta: 1 day, 10:23:40, time: 0.736, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8426, decode.acc_seg: 72.2928, aux.loss_ce: 0.4045, aux.acc_seg: 68.9792, loss: 1.2472
2023-11-26 14:33:47,069 - mmseg - INFO - Iter [3650/160000]	lr: 5.863e-05, eta: 1 day, 10:23:30, time: 0.806, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8633, decode.acc_seg: 71.5871, aux.loss_ce: 0.4158, aux.acc_seg: 68.4078, loss: 1.2790
2023-11-26 14:34:24,852 - mmseg - INFO - Iter [3700/160000]	lr: 5.861e-05, eta: 1 day, 10:21:36, time: 0.756, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8640, decode.acc_seg: 71.9688, aux.loss_ce: 0.3977, aux.acc_seg: 70.3688, loss: 1.2617
2023-11-26 14:35:05,168 - mmseg - INFO - Iter [3750/160000]	lr: 5.859e-05, eta: 1 day, 10:21:27, time: 0.806, data_time: 0.010, memory: 18766, decode.loss_ce: 0.9084, decode.acc_seg: 70.5001, aux.loss_ce: 0.4275, aux.acc_seg: 67.4687, loss: 1.3359
2023-11-26 14:35:47,078 - mmseg - INFO - Iter [3800/160000]	lr: 5.858e-05, eta: 1 day, 10:22:24, time: 0.838, data_time: 0.053, memory: 18766, decode.loss_ce: 0.8635, decode.acc_seg: 71.4565, aux.loss_ce: 0.4013, aux.acc_seg: 69.0320, loss: 1.2648
2023-11-26 14:36:25,754 - mmseg - INFO - Iter [3850/160000]	lr: 5.856e-05, eta: 1 day, 10:21:04, time: 0.773, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8657, decode.acc_seg: 71.7543, aux.loss_ce: 0.4045, aux.acc_seg: 69.4648, loss: 1.2702
2023-11-26 14:37:04,015 - mmseg - INFO - Iter [3900/160000]	lr: 5.854e-05, eta: 1 day, 10:19:32, time: 0.766, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8259, decode.acc_seg: 72.9954, aux.loss_ce: 0.3982, aux.acc_seg: 69.9363, loss: 1.2241
2023-11-26 14:37:42,882 - mmseg - INFO - Iter [3950/160000]	lr: 5.852e-05, eta: 1 day, 10:18:24, time: 0.777, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8097, decode.acc_seg: 72.7096, aux.loss_ce: 0.3858, aux.acc_seg: 69.5423, loss: 1.1955
2023-11-26 14:38:20,443 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 14:38:20,444 - mmseg - INFO - Iter [4000/160000]	lr: 5.850e-05, eta: 1 day, 10:16:25, time: 0.751, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8068, decode.acc_seg: 72.8445, aux.loss_ce: 0.3831, aux.acc_seg: 70.0458, loss: 1.1899
2023-11-26 14:39:00,166 - mmseg - INFO - Iter [4050/160000]	lr: 5.848e-05, eta: 1 day, 10:15:53, time: 0.795, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8378, decode.acc_seg: 71.9477, aux.loss_ce: 0.3979, aux.acc_seg: 68.7648, loss: 1.2357
2023-11-26 14:39:40,032 - mmseg - INFO - Iter [4100/160000]	lr: 5.846e-05, eta: 1 day, 10:15:25, time: 0.797, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8524, decode.acc_seg: 72.1654, aux.loss_ce: 0.4024, aux.acc_seg: 68.8464, loss: 1.2549
2023-11-26 14:40:17,415 - mmseg - INFO - Iter [4150/160000]	lr: 5.844e-05, eta: 1 day, 10:13:26, time: 0.748, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7851, decode.acc_seg: 73.4461, aux.loss_ce: 0.3635, aux.acc_seg: 71.0162, loss: 1.1486
2023-11-26 14:40:57,209 - mmseg - INFO - Iter [4200/160000]	lr: 5.843e-05, eta: 1 day, 10:12:54, time: 0.795, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8176, decode.acc_seg: 72.8117, aux.loss_ce: 0.3822, aux.acc_seg: 70.3153, loss: 1.1998
2023-11-26 14:41:37,289 - mmseg - INFO - Iter [4250/160000]	lr: 5.841e-05, eta: 1 day, 10:12:35, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7954, decode.acc_seg: 73.1617, aux.loss_ce: 0.3717, aux.acc_seg: 70.6763, loss: 1.1672
2023-11-26 14:42:15,289 - mmseg - INFO - Iter [4300/160000]	lr: 5.839e-05, eta: 1 day, 10:11:00, time: 0.760, data_time: 0.012, memory: 18766, decode.loss_ce: 0.7985, decode.acc_seg: 73.0436, aux.loss_ce: 0.3729, aux.acc_seg: 70.6539, loss: 1.1714
2023-11-26 14:42:55,271 - mmseg - INFO - Iter [4350/160000]	lr: 5.837e-05, eta: 1 day, 10:10:37, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7808, decode.acc_seg: 72.5979, aux.loss_ce: 0.3664, aux.acc_seg: 70.0157, loss: 1.1472
2023-11-26 14:43:35,146 - mmseg - INFO - Iter [4400/160000]	lr: 5.835e-05, eta: 1 day, 10:10:08, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7854, decode.acc_seg: 73.5292, aux.loss_ce: 0.3737, aux.acc_seg: 70.6279, loss: 1.1591
2023-11-26 14:44:16,689 - mmseg - INFO - Iter [4450/160000]	lr: 5.833e-05, eta: 1 day, 10:10:40, time: 0.832, data_time: 0.013, memory: 18766, decode.loss_ce: 0.8259, decode.acc_seg: 71.6684, aux.loss_ce: 0.3862, aux.acc_seg: 69.3269, loss: 1.2122
2023-11-26 14:44:56,401 - mmseg - INFO - Iter [4500/160000]	lr: 5.831e-05, eta: 1 day, 10:10:07, time: 0.795, data_time: 0.012, memory: 18766, decode.loss_ce: 0.7984, decode.acc_seg: 72.7964, aux.loss_ce: 0.3738, aux.acc_seg: 70.1071, loss: 1.1723
2023-11-26 14:45:34,409 - mmseg - INFO - Iter [4550/160000]	lr: 5.829e-05, eta: 1 day, 10:08:36, time: 0.761, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8210, decode.acc_seg: 72.3408, aux.loss_ce: 0.3759, aux.acc_seg: 70.3559, loss: 1.1969
2023-11-26 14:46:13,565 - mmseg - INFO - Iter [4600/160000]	lr: 5.828e-05, eta: 1 day, 10:07:42, time: 0.782, data_time: 0.010, memory: 18766, decode.loss_ce: 0.8147, decode.acc_seg: 72.0023, aux.loss_ce: 0.3764, aux.acc_seg: 70.1224, loss: 1.1911
2023-11-26 14:46:53,873 - mmseg - INFO - Iter [4650/160000]	lr: 5.826e-05, eta: 1 day, 10:07:29, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.8080, decode.acc_seg: 73.4427, aux.loss_ce: 0.3712, aux.acc_seg: 70.7915, loss: 1.1792
2023-11-26 14:47:33,175 - mmseg - INFO - Iter [4700/160000]	lr: 5.824e-05, eta: 1 day, 10:06:41, time: 0.786, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7799, decode.acc_seg: 73.1564, aux.loss_ce: 0.3545, aux.acc_seg: 71.3954, loss: 1.1343
2023-11-26 14:48:10,708 - mmseg - INFO - Iter [4750/160000]	lr: 5.822e-05, eta: 1 day, 10:04:56, time: 0.751, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7480, decode.acc_seg: 74.0796, aux.loss_ce: 0.3460, aux.acc_seg: 72.0353, loss: 1.0940
2023-11-26 14:48:50,782 - mmseg - INFO - Iter [4800/160000]	lr: 5.820e-05, eta: 1 day, 10:04:35, time: 0.801, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7597, decode.acc_seg: 73.3251, aux.loss_ce: 0.3500, aux.acc_seg: 71.2879, loss: 1.1097
2023-11-26 14:49:30,530 - mmseg - INFO - Iter [4850/160000]	lr: 5.818e-05, eta: 1 day, 10:04:02, time: 0.795, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7871, decode.acc_seg: 72.8860, aux.loss_ce: 0.3615, aux.acc_seg: 70.4670, loss: 1.1485
2023-11-26 14:50:11,191 - mmseg - INFO - Iter [4900/160000]	lr: 5.816e-05, eta: 1 day, 10:03:58, time: 0.813, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7815, decode.acc_seg: 73.6963, aux.loss_ce: 0.3585, aux.acc_seg: 71.2904, loss: 1.1399
2023-11-26 14:50:52,123 - mmseg - INFO - Iter [4950/160000]	lr: 5.814e-05, eta: 1 day, 10:04:03, time: 0.819, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7644, decode.acc_seg: 73.1138, aux.loss_ce: 0.3483, aux.acc_seg: 71.4769, loss: 1.1127
2023-11-26 14:51:32,426 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 14:51:32,426 - mmseg - INFO - Iter [5000/160000]	lr: 5.813e-05, eta: 1 day, 10:03:47, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7914, decode.acc_seg: 73.1034, aux.loss_ce: 0.3634, aux.acc_seg: 70.8311, loss: 1.1548
2023-11-26 14:52:12,705 - mmseg - INFO - Iter [5050/160000]	lr: 5.811e-05, eta: 1 day, 10:03:29, time: 0.806, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7520, decode.acc_seg: 73.8236, aux.loss_ce: 0.3464, aux.acc_seg: 71.5068, loss: 1.0984
2023-11-26 14:52:54,078 - mmseg - INFO - Iter [5100/160000]	lr: 5.809e-05, eta: 1 day, 10:03:44, time: 0.827, data_time: 0.053, memory: 18766, decode.loss_ce: 0.7494, decode.acc_seg: 74.7196, aux.loss_ce: 0.3443, aux.acc_seg: 72.4049, loss: 1.0937
2023-11-26 14:53:35,164 - mmseg - INFO - Iter [5150/160000]	lr: 5.807e-05, eta: 1 day, 10:03:50, time: 0.822, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6708, decode.acc_seg: 76.2027, aux.loss_ce: 0.3166, aux.acc_seg: 73.9247, loss: 0.9874
2023-11-26 14:54:15,975 - mmseg - INFO - Iter [5200/160000]	lr: 5.805e-05, eta: 1 day, 10:03:48, time: 0.817, data_time: 0.012, memory: 18766, decode.loss_ce: 0.7197, decode.acc_seg: 74.7177, aux.loss_ce: 0.3344, aux.acc_seg: 72.5350, loss: 1.0541
2023-11-26 14:54:53,148 - mmseg - INFO - Iter [5250/160000]	lr: 5.803e-05, eta: 1 day, 10:01:57, time: 0.744, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7231, decode.acc_seg: 74.5530, aux.loss_ce: 0.3315, aux.acc_seg: 72.7551, loss: 1.0547
2023-11-26 14:55:33,186 - mmseg - INFO - Iter [5300/160000]	lr: 5.801e-05, eta: 1 day, 10:01:29, time: 0.800, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7435, decode.acc_seg: 74.9104, aux.loss_ce: 0.3334, aux.acc_seg: 73.4603, loss: 1.0768
2023-11-26 14:56:14,002 - mmseg - INFO - Iter [5350/160000]	lr: 5.799e-05, eta: 1 day, 10:01:25, time: 0.817, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7320, decode.acc_seg: 73.4983, aux.loss_ce: 0.3382, aux.acc_seg: 71.7066, loss: 1.0702
2023-11-26 14:56:54,276 - mmseg - INFO - Iter [5400/160000]	lr: 5.798e-05, eta: 1 day, 10:01:05, time: 0.805, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7137, decode.acc_seg: 73.9656, aux.loss_ce: 0.3311, aux.acc_seg: 71.8841, loss: 1.0448
2023-11-26 14:57:35,116 - mmseg - INFO - Iter [5450/160000]	lr: 5.796e-05, eta: 1 day, 10:01:00, time: 0.817, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7267, decode.acc_seg: 74.3877, aux.loss_ce: 0.3292, aux.acc_seg: 72.5546, loss: 1.0560
2023-11-26 14:58:16,190 - mmseg - INFO - Iter [5500/160000]	lr: 5.794e-05, eta: 1 day, 10:01:01, time: 0.821, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7190, decode.acc_seg: 75.6827, aux.loss_ce: 0.3302, aux.acc_seg: 74.1341, loss: 1.0493
2023-11-26 14:58:55,932 - mmseg - INFO - Iter [5550/160000]	lr: 5.792e-05, eta: 1 day, 10:00:25, time: 0.795, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7228, decode.acc_seg: 74.3187, aux.loss_ce: 0.3338, aux.acc_seg: 72.2332, loss: 1.0566
2023-11-26 14:59:35,332 - mmseg - INFO - Iter [5600/160000]	lr: 5.790e-05, eta: 1 day, 9:59:40, time: 0.789, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7174, decode.acc_seg: 75.0556, aux.loss_ce: 0.3260, aux.acc_seg: 73.4663, loss: 1.0434
2023-11-26 15:00:13,715 - mmseg - INFO - Iter [5650/160000]	lr: 5.788e-05, eta: 1 day, 9:58:25, time: 0.767, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7147, decode.acc_seg: 73.9877, aux.loss_ce: 0.3201, aux.acc_seg: 72.7200, loss: 1.0348
2023-11-26 15:00:53,655 - mmseg - INFO - Iter [5700/160000]	lr: 5.786e-05, eta: 1 day, 9:57:53, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7417, decode.acc_seg: 74.2609, aux.loss_ce: 0.3375, aux.acc_seg: 72.6424, loss: 1.0792
2023-11-26 15:01:34,353 - mmseg - INFO - Iter [5750/160000]	lr: 5.784e-05, eta: 1 day, 9:57:43, time: 0.814, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7479, decode.acc_seg: 73.7720, aux.loss_ce: 0.3343, aux.acc_seg: 72.1703, loss: 1.0821
2023-11-26 15:02:14,670 - mmseg - INFO - Iter [5800/160000]	lr: 5.783e-05, eta: 1 day, 9:57:21, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6848, decode.acc_seg: 75.6351, aux.loss_ce: 0.3086, aux.acc_seg: 74.1815, loss: 0.9934
2023-11-26 15:02:55,022 - mmseg - INFO - Iter [5850/160000]	lr: 5.781e-05, eta: 1 day, 9:57:01, time: 0.807, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6893, decode.acc_seg: 75.2387, aux.loss_ce: 0.3100, aux.acc_seg: 73.6322, loss: 0.9994
2023-11-26 15:03:33,045 - mmseg - INFO - Iter [5900/160000]	lr: 5.779e-05, eta: 1 day, 9:55:39, time: 0.760, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7310, decode.acc_seg: 74.7037, aux.loss_ce: 0.3279, aux.acc_seg: 72.8383, loss: 1.0589
2023-11-26 15:04:13,196 - mmseg - INFO - Iter [5950/160000]	lr: 5.777e-05, eta: 1 day, 9:55:13, time: 0.803, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6866, decode.acc_seg: 75.3170, aux.loss_ce: 0.3072, aux.acc_seg: 74.0966, loss: 0.9938
2023-11-26 15:04:53,122 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 15:04:53,122 - mmseg - INFO - Iter [6000/160000]	lr: 5.775e-05, eta: 1 day, 9:54:42, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7073, decode.acc_seg: 75.1477, aux.loss_ce: 0.3155, aux.acc_seg: 73.4455, loss: 1.0227
2023-11-26 15:05:30,940 - mmseg - INFO - Iter [6050/160000]	lr: 5.773e-05, eta: 1 day, 9:53:14, time: 0.755, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6884, decode.acc_seg: 74.6565, aux.loss_ce: 0.3075, aux.acc_seg: 73.5304, loss: 0.9958
2023-11-26 15:06:11,897 - mmseg - INFO - Iter [6100/160000]	lr: 5.771e-05, eta: 1 day, 9:53:10, time: 0.820, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6879, decode.acc_seg: 75.4532, aux.loss_ce: 0.3135, aux.acc_seg: 73.4950, loss: 1.0014
2023-11-26 15:06:52,322 - mmseg - INFO - Iter [6150/160000]	lr: 5.769e-05, eta: 1 day, 9:52:48, time: 0.807, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7349, decode.acc_seg: 74.2111, aux.loss_ce: 0.3248, aux.acc_seg: 72.6963, loss: 1.0597
2023-11-26 15:07:32,150 - mmseg - INFO - Iter [6200/160000]	lr: 5.768e-05, eta: 1 day, 9:52:15, time: 0.798, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7372, decode.acc_seg: 73.3281, aux.loss_ce: 0.3291, aux.acc_seg: 72.3717, loss: 1.0663
2023-11-26 15:08:09,921 - mmseg - INFO - Iter [6250/160000]	lr: 5.766e-05, eta: 1 day, 9:50:49, time: 0.756, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6956, decode.acc_seg: 75.0536, aux.loss_ce: 0.3062, aux.acc_seg: 73.9125, loss: 1.0018
2023-11-26 15:08:46,659 - mmseg - INFO - Iter [6300/160000]	lr: 5.764e-05, eta: 1 day, 9:48:59, time: 0.735, data_time: 0.010, memory: 18766, decode.loss_ce: 0.7273, decode.acc_seg: 74.9307, aux.loss_ce: 0.3215, aux.acc_seg: 73.6060, loss: 1.0488
2023-11-26 15:09:26,686 - mmseg - INFO - Iter [6350/160000]	lr: 5.762e-05, eta: 1 day, 9:48:29, time: 0.800, data_time: 0.053, memory: 18766, decode.loss_ce: 0.6729, decode.acc_seg: 75.2852, aux.loss_ce: 0.2973, aux.acc_seg: 74.4520, loss: 0.9702
2023-11-26 15:10:04,754 - mmseg - INFO - Iter [6400/160000]	lr: 5.760e-05, eta: 1 day, 9:47:13, time: 0.762, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6782, decode.acc_seg: 75.9611, aux.loss_ce: 0.3039, aux.acc_seg: 74.2982, loss: 0.9820
2023-11-26 15:10:41,746 - mmseg - INFO - Iter [6450/160000]	lr: 5.758e-05, eta: 1 day, 9:45:32, time: 0.740, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6570, decode.acc_seg: 76.4500, aux.loss_ce: 0.2957, aux.acc_seg: 75.2103, loss: 0.9526
2023-11-26 15:11:21,739 - mmseg - INFO - Iter [6500/160000]	lr: 5.756e-05, eta: 1 day, 9:45:01, time: 0.799, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6872, decode.acc_seg: 75.6760, aux.loss_ce: 0.3049, aux.acc_seg: 74.1556, loss: 0.9921
2023-11-26 15:12:02,499 - mmseg - INFO - Iter [6550/160000]	lr: 5.754e-05, eta: 1 day, 9:44:49, time: 0.815, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6996, decode.acc_seg: 74.6641, aux.loss_ce: 0.3102, aux.acc_seg: 73.2055, loss: 1.0098
2023-11-26 15:12:42,110 - mmseg - INFO - Iter [6600/160000]	lr: 5.753e-05, eta: 1 day, 9:44:10, time: 0.792, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6941, decode.acc_seg: 75.7846, aux.loss_ce: 0.3102, aux.acc_seg: 74.4568, loss: 1.0043
2023-11-26 15:13:21,186 - mmseg - INFO - Iter [6650/160000]	lr: 5.751e-05, eta: 1 day, 9:43:20, time: 0.782, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6575, decode.acc_seg: 75.8858, aux.loss_ce: 0.2974, aux.acc_seg: 74.5587, loss: 0.9549
2023-11-26 15:13:59,835 - mmseg - INFO - Iter [6700/160000]	lr: 5.749e-05, eta: 1 day, 9:42:18, time: 0.772, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6638, decode.acc_seg: 76.2074, aux.loss_ce: 0.2977, aux.acc_seg: 74.6126, loss: 0.9615
2023-11-26 15:14:39,787 - mmseg - INFO - Iter [6750/160000]	lr: 5.747e-05, eta: 1 day, 9:41:46, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6712, decode.acc_seg: 76.7863, aux.loss_ce: 0.2988, aux.acc_seg: 75.8129, loss: 0.9699
2023-11-26 15:15:20,190 - mmseg - INFO - Iter [6800/160000]	lr: 5.745e-05, eta: 1 day, 9:41:26, time: 0.809, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7009, decode.acc_seg: 74.6065, aux.loss_ce: 0.3085, aux.acc_seg: 73.4525, loss: 1.0094
2023-11-26 15:15:58,392 - mmseg - INFO - Iter [6850/160000]	lr: 5.743e-05, eta: 1 day, 9:40:16, time: 0.765, data_time: 0.011, memory: 18766, decode.loss_ce: 0.7159, decode.acc_seg: 75.0260, aux.loss_ce: 0.3149, aux.acc_seg: 73.4565, loss: 1.0308
2023-11-26 15:16:35,703 - mmseg - INFO - Iter [6900/160000]	lr: 5.741e-05, eta: 1 day, 9:38:46, time: 0.746, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6857, decode.acc_seg: 76.0612, aux.loss_ce: 0.3046, aux.acc_seg: 74.5044, loss: 0.9903
2023-11-26 15:17:14,680 - mmseg - INFO - Iter [6950/160000]	lr: 5.739e-05, eta: 1 day, 9:37:53, time: 0.778, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6852, decode.acc_seg: 75.6464, aux.loss_ce: 0.3043, aux.acc_seg: 73.9632, loss: 0.9895
2023-11-26 15:17:55,312 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 15:17:55,312 - mmseg - INFO - Iter [7000/160000]	lr: 5.738e-05, eta: 1 day, 9:37:38, time: 0.814, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6549, decode.acc_seg: 77.5835, aux.loss_ce: 0.2916, aux.acc_seg: 75.8807, loss: 0.9464
2023-11-26 15:18:35,768 - mmseg - INFO - Iter [7050/160000]	lr: 5.736e-05, eta: 1 day, 9:37:16, time: 0.808, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6926, decode.acc_seg: 75.0673, aux.loss_ce: 0.3053, aux.acc_seg: 73.8355, loss: 0.9979
2023-11-26 15:19:16,794 - mmseg - INFO - Iter [7100/160000]	lr: 5.734e-05, eta: 1 day, 9:37:10, time: 0.822, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6620, decode.acc_seg: 76.3230, aux.loss_ce: 0.2941, aux.acc_seg: 75.0084, loss: 0.9561
2023-11-26 15:19:54,427 - mmseg - INFO - Iter [7150/160000]	lr: 5.732e-05, eta: 1 day, 9:35:49, time: 0.753, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6394, decode.acc_seg: 76.7735, aux.loss_ce: 0.2826, aux.acc_seg: 75.7281, loss: 0.9220
2023-11-26 15:20:31,821 - mmseg - INFO - Iter [7200/160000]	lr: 5.730e-05, eta: 1 day, 9:34:23, time: 0.748, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6201, decode.acc_seg: 76.9052, aux.loss_ce: 0.2763, aux.acc_seg: 75.4405, loss: 0.8964
2023-11-26 15:21:11,658 - mmseg - INFO - Iter [7250/160000]	lr: 5.728e-05, eta: 1 day, 9:33:49, time: 0.796, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6675, decode.acc_seg: 76.2677, aux.loss_ce: 0.2931, aux.acc_seg: 75.2194, loss: 0.9606
2023-11-26 15:21:50,911 - mmseg - INFO - Iter [7300/160000]	lr: 5.726e-05, eta: 1 day, 9:33:04, time: 0.786, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6144, decode.acc_seg: 77.1448, aux.loss_ce: 0.2702, aux.acc_seg: 75.6037, loss: 0.8846
2023-11-26 15:22:28,450 - mmseg - INFO - Iter [7350/160000]	lr: 5.724e-05, eta: 1 day, 9:31:42, time: 0.751, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6523, decode.acc_seg: 76.4218, aux.loss_ce: 0.2884, aux.acc_seg: 75.0856, loss: 0.9407
2023-11-26 15:23:08,414 - mmseg - INFO - Iter [7400/160000]	lr: 5.723e-05, eta: 1 day, 9:31:11, time: 0.798, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6909, decode.acc_seg: 75.5030, aux.loss_ce: 0.3061, aux.acc_seg: 74.1236, loss: 0.9970
2023-11-26 15:23:49,024 - mmseg - INFO - Iter [7450/160000]	lr: 5.721e-05, eta: 1 day, 9:30:53, time: 0.812, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6566, decode.acc_seg: 76.2182, aux.loss_ce: 0.2926, aux.acc_seg: 74.2811, loss: 0.9493
2023-11-26 15:24:29,924 - mmseg - INFO - Iter [7500/160000]	lr: 5.719e-05, eta: 1 day, 9:30:41, time: 0.818, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6713, decode.acc_seg: 75.6573, aux.loss_ce: 0.2942, aux.acc_seg: 74.8196, loss: 0.9655
2023-11-26 15:25:08,067 - mmseg - INFO - Iter [7550/160000]	lr: 5.717e-05, eta: 1 day, 9:29:34, time: 0.764, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6540, decode.acc_seg: 76.8115, aux.loss_ce: 0.2889, aux.acc_seg: 75.7081, loss: 0.9429
2023-11-26 15:25:48,815 - mmseg - INFO - Iter [7600/160000]	lr: 5.715e-05, eta: 1 day, 9:29:18, time: 0.814, data_time: 0.054, memory: 18766, decode.loss_ce: 0.6439, decode.acc_seg: 76.6417, aux.loss_ce: 0.2854, aux.acc_seg: 75.2932, loss: 0.9293
2023-11-26 15:26:28,762 - mmseg - INFO - Iter [7650/160000]	lr: 5.713e-05, eta: 1 day, 9:28:47, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6327, decode.acc_seg: 76.3204, aux.loss_ce: 0.2773, aux.acc_seg: 75.3759, loss: 0.9101
2023-11-26 15:27:07,164 - mmseg - INFO - Iter [7700/160000]	lr: 5.711e-05, eta: 1 day, 9:27:44, time: 0.767, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6254, decode.acc_seg: 77.5747, aux.loss_ce: 0.2761, aux.acc_seg: 76.2327, loss: 0.9014
2023-11-26 15:27:47,221 - mmseg - INFO - Iter [7750/160000]	lr: 5.709e-05, eta: 1 day, 9:27:14, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6583, decode.acc_seg: 76.0399, aux.loss_ce: 0.2888, aux.acc_seg: 75.0060, loss: 0.9471
2023-11-26 15:28:27,978 - mmseg - INFO - Iter [7800/160000]	lr: 5.708e-05, eta: 1 day, 9:26:58, time: 0.815, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5966, decode.acc_seg: 77.8072, aux.loss_ce: 0.2624, aux.acc_seg: 76.5121, loss: 0.8590
2023-11-26 15:29:05,348 - mmseg - INFO - Iter [7850/160000]	lr: 5.706e-05, eta: 1 day, 9:25:36, time: 0.748, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5961, decode.acc_seg: 78.1022, aux.loss_ce: 0.2641, aux.acc_seg: 76.9499, loss: 0.8601
2023-11-26 15:29:45,412 - mmseg - INFO - Iter [7900/160000]	lr: 5.704e-05, eta: 1 day, 9:25:06, time: 0.801, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6191, decode.acc_seg: 77.3528, aux.loss_ce: 0.2738, aux.acc_seg: 76.2043, loss: 0.8929
2023-11-26 15:30:25,175 - mmseg - INFO - Iter [7950/160000]	lr: 5.702e-05, eta: 1 day, 9:24:31, time: 0.795, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6153, decode.acc_seg: 77.2559, aux.loss_ce: 0.2743, aux.acc_seg: 75.9523, loss: 0.8896
2023-11-26 15:31:04,725 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 15:31:04,725 - mmseg - INFO - Iter [8000/160000]	lr: 5.700e-05, eta: 1 day, 9:23:51, time: 0.791, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6310, decode.acc_seg: 76.8675, aux.loss_ce: 0.2792, aux.acc_seg: 75.4111, loss: 0.9102
2023-11-26 15:31:44,719 - mmseg - INFO - Iter [8050/160000]	lr: 5.698e-05, eta: 1 day, 9:23:20, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6597, decode.acc_seg: 76.3916, aux.loss_ce: 0.2895, aux.acc_seg: 75.1871, loss: 0.9492
2023-11-26 15:32:21,647 - mmseg - INFO - Iter [8100/160000]	lr: 5.696e-05, eta: 1 day, 9:21:52, time: 0.739, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6650, decode.acc_seg: 76.2337, aux.loss_ce: 0.2872, aux.acc_seg: 75.5305, loss: 0.9521
2023-11-26 15:33:00,403 - mmseg - INFO - Iter [8150/160000]	lr: 5.694e-05, eta: 1 day, 9:20:57, time: 0.774, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6660, decode.acc_seg: 75.1118, aux.loss_ce: 0.2894, aux.acc_seg: 74.2374, loss: 0.9554
2023-11-26 15:33:39,826 - mmseg - INFO - Iter [8200/160000]	lr: 5.693e-05, eta: 1 day, 9:20:16, time: 0.788, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6242, decode.acc_seg: 76.7628, aux.loss_ce: 0.2754, aux.acc_seg: 75.7214, loss: 0.8997
2023-11-26 15:34:20,489 - mmseg - INFO - Iter [8250/160000]	lr: 5.691e-05, eta: 1 day, 9:19:57, time: 0.813, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6176, decode.acc_seg: 77.4999, aux.loss_ce: 0.2713, aux.acc_seg: 76.4118, loss: 0.8890
2023-11-26 15:35:00,486 - mmseg - INFO - Iter [8300/160000]	lr: 5.689e-05, eta: 1 day, 9:19:26, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6399, decode.acc_seg: 76.9324, aux.loss_ce: 0.2807, aux.acc_seg: 75.5464, loss: 0.9206
2023-11-26 15:35:40,948 - mmseg - INFO - Iter [8350/160000]	lr: 5.687e-05, eta: 1 day, 9:19:03, time: 0.809, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6010, decode.acc_seg: 77.8121, aux.loss_ce: 0.2653, aux.acc_seg: 76.4939, loss: 0.8663
2023-11-26 15:36:21,008 - mmseg - INFO - Iter [8400/160000]	lr: 5.685e-05, eta: 1 day, 9:18:33, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6299, decode.acc_seg: 76.8358, aux.loss_ce: 0.2739, aux.acc_seg: 75.7520, loss: 0.9038
2023-11-26 15:36:58,821 - mmseg - INFO - Iter [8450/160000]	lr: 5.683e-05, eta: 1 day, 9:17:22, time: 0.756, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6339, decode.acc_seg: 76.9491, aux.loss_ce: 0.2769, aux.acc_seg: 75.8038, loss: 0.9107
2023-11-26 15:37:39,058 - mmseg - INFO - Iter [8500/160000]	lr: 5.681e-05, eta: 1 day, 9:16:56, time: 0.805, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6259, decode.acc_seg: 77.1956, aux.loss_ce: 0.2719, aux.acc_seg: 76.4680, loss: 0.8978
2023-11-26 15:38:20,851 - mmseg - INFO - Iter [8550/160000]	lr: 5.679e-05, eta: 1 day, 9:16:55, time: 0.835, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6388, decode.acc_seg: 76.7213, aux.loss_ce: 0.2787, aux.acc_seg: 75.7706, loss: 0.9176
2023-11-26 15:39:02,802 - mmseg - INFO - Iter [8600/160000]	lr: 5.678e-05, eta: 1 day, 9:16:58, time: 0.839, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6263, decode.acc_seg: 77.6225, aux.loss_ce: 0.2765, aux.acc_seg: 76.4522, loss: 0.9028
2023-11-26 15:39:44,540 - mmseg - INFO - Iter [8650/160000]	lr: 5.676e-05, eta: 1 day, 9:16:56, time: 0.835, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6359, decode.acc_seg: 77.3392, aux.loss_ce: 0.2771, aux.acc_seg: 76.3586, loss: 0.9130
2023-11-26 15:40:25,109 - mmseg - INFO - Iter [8700/160000]	lr: 5.674e-05, eta: 1 day, 9:16:34, time: 0.812, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6124, decode.acc_seg: 77.7514, aux.loss_ce: 0.2669, aux.acc_seg: 76.7437, loss: 0.8794
2023-11-26 15:41:05,247 - mmseg - INFO - Iter [8750/160000]	lr: 5.672e-05, eta: 1 day, 9:16:04, time: 0.803, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6345, decode.acc_seg: 76.3457, aux.loss_ce: 0.2720, aux.acc_seg: 75.5483, loss: 0.9065
2023-11-26 15:41:42,837 - mmseg - INFO - Iter [8800/160000]	lr: 5.670e-05, eta: 1 day, 9:14:50, time: 0.753, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6175, decode.acc_seg: 77.1597, aux.loss_ce: 0.2672, aux.acc_seg: 76.1689, loss: 0.8847
2023-11-26 15:42:22,947 - mmseg - INFO - Iter [8850/160000]	lr: 5.668e-05, eta: 1 day, 9:14:20, time: 0.802, data_time: 0.052, memory: 18766, decode.loss_ce: 0.6530, decode.acc_seg: 76.5534, aux.loss_ce: 0.2795, aux.acc_seg: 75.4147, loss: 0.9325
2023-11-26 15:43:00,802 - mmseg - INFO - Iter [8900/160000]	lr: 5.666e-05, eta: 1 day, 9:13:11, time: 0.757, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6275, decode.acc_seg: 77.4965, aux.loss_ce: 0.2787, aux.acc_seg: 75.6566, loss: 0.9061
2023-11-26 15:43:40,262 - mmseg - INFO - Iter [8950/160000]	lr: 5.664e-05, eta: 1 day, 9:12:29, time: 0.789, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5846, decode.acc_seg: 78.0753, aux.loss_ce: 0.2562, aux.acc_seg: 76.9914, loss: 0.8408
2023-11-26 15:44:21,299 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 15:44:21,299 - mmseg - INFO - Iter [9000/160000]	lr: 5.663e-05, eta: 1 day, 9:12:13, time: 0.820, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5918, decode.acc_seg: 78.4082, aux.loss_ce: 0.2579, aux.acc_seg: 77.6196, loss: 0.8497
2023-11-26 15:45:02,056 - mmseg - INFO - Iter [9050/160000]	lr: 5.661e-05, eta: 1 day, 9:11:54, time: 0.816, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6197, decode.acc_seg: 77.4032, aux.loss_ce: 0.2668, aux.acc_seg: 76.3661, loss: 0.8865
2023-11-26 15:45:40,653 - mmseg - INFO - Iter [9100/160000]	lr: 5.659e-05, eta: 1 day, 9:10:59, time: 0.773, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5773, decode.acc_seg: 78.3345, aux.loss_ce: 0.2534, aux.acc_seg: 77.2268, loss: 0.8307
2023-11-26 15:46:19,625 - mmseg - INFO - Iter [9150/160000]	lr: 5.657e-05, eta: 1 day, 9:10:09, time: 0.779, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5676, decode.acc_seg: 79.6713, aux.loss_ce: 0.2466, aux.acc_seg: 78.7665, loss: 0.8142
2023-11-26 15:46:59,636 - mmseg - INFO - Iter [9200/160000]	lr: 5.655e-05, eta: 1 day, 9:09:36, time: 0.800, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6299, decode.acc_seg: 77.3848, aux.loss_ce: 0.2723, aux.acc_seg: 76.3031, loss: 0.9022
2023-11-26 15:47:38,174 - mmseg - INFO - Iter [9250/160000]	lr: 5.653e-05, eta: 1 day, 9:08:40, time: 0.771, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6247, decode.acc_seg: 77.6681, aux.loss_ce: 0.2722, aux.acc_seg: 76.3263, loss: 0.8970
2023-11-26 15:48:16,088 - mmseg - INFO - Iter [9300/160000]	lr: 5.651e-05, eta: 1 day, 9:07:33, time: 0.758, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5993, decode.acc_seg: 77.1126, aux.loss_ce: 0.2618, aux.acc_seg: 76.1919, loss: 0.8611
2023-11-26 15:48:56,279 - mmseg - INFO - Iter [9350/160000]	lr: 5.649e-05, eta: 1 day, 9:07:03, time: 0.803, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6223, decode.acc_seg: 77.1850, aux.loss_ce: 0.2689, aux.acc_seg: 75.9220, loss: 0.8912
2023-11-26 15:49:36,594 - mmseg - INFO - Iter [9400/160000]	lr: 5.648e-05, eta: 1 day, 9:06:35, time: 0.807, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6237, decode.acc_seg: 76.8538, aux.loss_ce: 0.2673, aux.acc_seg: 75.8639, loss: 0.8910
2023-11-26 15:50:16,547 - mmseg - INFO - Iter [9450/160000]	lr: 5.646e-05, eta: 1 day, 9:06:02, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6009, decode.acc_seg: 77.4378, aux.loss_ce: 0.2604, aux.acc_seg: 76.4353, loss: 0.8613
2023-11-26 15:50:57,116 - mmseg - INFO - Iter [9500/160000]	lr: 5.644e-05, eta: 1 day, 9:05:38, time: 0.812, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6072, decode.acc_seg: 77.6673, aux.loss_ce: 0.2643, aux.acc_seg: 76.5153, loss: 0.8715
2023-11-26 15:51:36,928 - mmseg - INFO - Iter [9550/160000]	lr: 5.642e-05, eta: 1 day, 9:05:02, time: 0.796, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6150, decode.acc_seg: 77.7153, aux.loss_ce: 0.2648, aux.acc_seg: 76.9212, loss: 0.8798
2023-11-26 15:52:16,863 - mmseg - INFO - Iter [9600/160000]	lr: 5.640e-05, eta: 1 day, 9:04:28, time: 0.799, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6136, decode.acc_seg: 77.8687, aux.loss_ce: 0.2670, aux.acc_seg: 76.7329, loss: 0.8806
2023-11-26 15:52:56,880 - mmseg - INFO - Iter [9650/160000]	lr: 5.638e-05, eta: 1 day, 9:03:55, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5833, decode.acc_seg: 78.2404, aux.loss_ce: 0.2546, aux.acc_seg: 77.1616, loss: 0.8379
2023-11-26 15:53:37,919 - mmseg - INFO - Iter [9700/160000]	lr: 5.636e-05, eta: 1 day, 9:03:38, time: 0.821, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6285, decode.acc_seg: 77.1498, aux.loss_ce: 0.2714, aux.acc_seg: 76.2499, loss: 0.8999
2023-11-26 15:54:16,040 - mmseg - INFO - Iter [9750/160000]	lr: 5.634e-05, eta: 1 day, 9:02:36, time: 0.763, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6044, decode.acc_seg: 77.6361, aux.loss_ce: 0.2660, aux.acc_seg: 76.1176, loss: 0.8703
2023-11-26 15:54:53,671 - mmseg - INFO - Iter [9800/160000]	lr: 5.633e-05, eta: 1 day, 9:01:27, time: 0.754, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6127, decode.acc_seg: 77.7873, aux.loss_ce: 0.2650, aux.acc_seg: 76.6047, loss: 0.8777
2023-11-26 15:55:30,723 - mmseg - INFO - Iter [9850/160000]	lr: 5.631e-05, eta: 1 day, 9:00:09, time: 0.741, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6170, decode.acc_seg: 77.4561, aux.loss_ce: 0.2669, aux.acc_seg: 76.3570, loss: 0.8839
2023-11-26 15:56:10,335 - mmseg - INFO - Iter [9900/160000]	lr: 5.629e-05, eta: 1 day, 8:59:29, time: 0.791, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6059, decode.acc_seg: 77.9380, aux.loss_ce: 0.2662, aux.acc_seg: 76.9047, loss: 0.8721
2023-11-26 15:56:50,483 - mmseg - INFO - Iter [9950/160000]	lr: 5.627e-05, eta: 1 day, 8:58:59, time: 0.803, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6137, decode.acc_seg: 78.2167, aux.loss_ce: 0.2642, aux.acc_seg: 77.2477, loss: 0.8779
2023-11-26 15:57:29,778 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 15:57:29,778 - mmseg - INFO - Iter [10000/160000]	lr: 5.625e-05, eta: 1 day, 8:58:15, time: 0.786, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6105, decode.acc_seg: 77.4679, aux.loss_ce: 0.2635, aux.acc_seg: 76.4215, loss: 0.8740
2023-11-26 15:58:10,182 - mmseg - INFO - Iter [10050/160000]	lr: 5.623e-05, eta: 1 day, 8:57:48, time: 0.808, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6176, decode.acc_seg: 77.0012, aux.loss_ce: 0.2694, aux.acc_seg: 75.7178, loss: 0.8870
2023-11-26 15:58:50,507 - mmseg - INFO - Iter [10100/160000]	lr: 5.621e-05, eta: 1 day, 8:57:20, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5746, decode.acc_seg: 78.5120, aux.loss_ce: 0.2449, aux.acc_seg: 77.8733, loss: 0.8195
2023-11-26 15:59:31,611 - mmseg - INFO - Iter [10150/160000]	lr: 5.619e-05, eta: 1 day, 8:57:03, time: 0.822, data_time: 0.053, memory: 18766, decode.loss_ce: 0.5729, decode.acc_seg: 78.1837, aux.loss_ce: 0.2479, aux.acc_seg: 77.6587, loss: 0.8209
2023-11-26 16:00:12,419 - mmseg - INFO - Iter [10200/160000]	lr: 5.618e-05, eta: 1 day, 8:56:41, time: 0.816, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5480, decode.acc_seg: 79.0005, aux.loss_ce: 0.2407, aux.acc_seg: 78.1948, loss: 0.7887
2023-11-26 16:00:52,157 - mmseg - INFO - Iter [10250/160000]	lr: 5.616e-05, eta: 1 day, 8:56:04, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5753, decode.acc_seg: 78.8546, aux.loss_ce: 0.2524, aux.acc_seg: 77.6040, loss: 0.8277
2023-11-26 16:01:29,706 - mmseg - INFO - Iter [10300/160000]	lr: 5.614e-05, eta: 1 day, 8:54:54, time: 0.750, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5679, decode.acc_seg: 79.1147, aux.loss_ce: 0.2482, aux.acc_seg: 77.8054, loss: 0.8161
2023-11-26 16:02:10,292 - mmseg - INFO - Iter [10350/160000]	lr: 5.612e-05, eta: 1 day, 8:54:29, time: 0.812, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6105, decode.acc_seg: 77.3312, aux.loss_ce: 0.2642, aux.acc_seg: 76.2785, loss: 0.8747
2023-11-26 16:02:49,163 - mmseg - INFO - Iter [10400/160000]	lr: 5.610e-05, eta: 1 day, 8:53:40, time: 0.778, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6008, decode.acc_seg: 78.1230, aux.loss_ce: 0.2629, aux.acc_seg: 76.7770, loss: 0.8637
2023-11-26 16:03:29,493 - mmseg - INFO - Iter [10450/160000]	lr: 5.608e-05, eta: 1 day, 8:53:11, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5627, decode.acc_seg: 78.7287, aux.loss_ce: 0.2466, aux.acc_seg: 77.4552, loss: 0.8094
2023-11-26 16:04:08,533 - mmseg - INFO - Iter [10500/160000]	lr: 5.606e-05, eta: 1 day, 8:52:23, time: 0.781, data_time: 0.012, memory: 18766, decode.loss_ce: 0.5681, decode.acc_seg: 79.0110, aux.loss_ce: 0.2464, aux.acc_seg: 78.1915, loss: 0.8144
2023-11-26 16:04:49,191 - mmseg - INFO - Iter [10550/160000]	lr: 5.604e-05, eta: 1 day, 8:52:00, time: 0.814, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5514, decode.acc_seg: 79.4412, aux.loss_ce: 0.2410, aux.acc_seg: 78.4160, loss: 0.7924
2023-11-26 16:05:29,914 - mmseg - INFO - Iter [10600/160000]	lr: 5.603e-05, eta: 1 day, 8:51:35, time: 0.813, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5742, decode.acc_seg: 78.3408, aux.loss_ce: 0.2498, aux.acc_seg: 76.8862, loss: 0.8241
2023-11-26 16:06:10,705 - mmseg - INFO - Iter [10650/160000]	lr: 5.601e-05, eta: 1 day, 8:51:13, time: 0.816, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5654, decode.acc_seg: 78.8219, aux.loss_ce: 0.2442, aux.acc_seg: 77.5649, loss: 0.8097
2023-11-26 16:06:48,938 - mmseg - INFO - Iter [10700/160000]	lr: 5.599e-05, eta: 1 day, 8:50:15, time: 0.766, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5698, decode.acc_seg: 79.1197, aux.loss_ce: 0.2437, aux.acc_seg: 78.2929, loss: 0.8135
2023-11-26 16:07:27,265 - mmseg - INFO - Iter [10750/160000]	lr: 5.597e-05, eta: 1 day, 8:49:17, time: 0.766, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5743, decode.acc_seg: 78.5993, aux.loss_ce: 0.2480, aux.acc_seg: 77.6624, loss: 0.8223
2023-11-26 16:08:07,570 - mmseg - INFO - Iter [10800/160000]	lr: 5.595e-05, eta: 1 day, 8:48:47, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5896, decode.acc_seg: 78.0501, aux.loss_ce: 0.2545, aux.acc_seg: 76.9314, loss: 0.8441
2023-11-26 16:08:48,137 - mmseg - INFO - Iter [10850/160000]	lr: 5.593e-05, eta: 1 day, 8:48:21, time: 0.811, data_time: 0.011, memory: 18766, decode.loss_ce: 0.6010, decode.acc_seg: 78.3922, aux.loss_ce: 0.2604, aux.acc_seg: 77.5060, loss: 0.8614
2023-11-26 16:09:28,880 - mmseg - INFO - Iter [10900/160000]	lr: 5.591e-05, eta: 1 day, 8:47:57, time: 0.815, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5645, decode.acc_seg: 78.2983, aux.loss_ce: 0.2449, aux.acc_seg: 77.2120, loss: 0.8094
2023-11-26 16:10:10,335 - mmseg - INFO - Iter [10950/160000]	lr: 5.589e-05, eta: 1 day, 8:47:43, time: 0.829, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5729, decode.acc_seg: 78.9262, aux.loss_ce: 0.2453, aux.acc_seg: 78.3107, loss: 0.8182
2023-11-26 16:10:49,915 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 16:10:49,916 - mmseg - INFO - Iter [11000/160000]	lr: 5.588e-05, eta: 1 day, 8:47:03, time: 0.792, data_time: 0.012, memory: 18766, decode.loss_ce: 0.6050, decode.acc_seg: 77.5904, aux.loss_ce: 0.2580, aux.acc_seg: 76.7685, loss: 0.8631
2023-11-26 16:11:30,017 - mmseg - INFO - Iter [11050/160000]	lr: 5.586e-05, eta: 1 day, 8:46:30, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5702, decode.acc_seg: 78.4157, aux.loss_ce: 0.2470, aux.acc_seg: 77.3197, loss: 0.8172
2023-11-26 16:12:10,393 - mmseg - INFO - Iter [11100/160000]	lr: 5.584e-05, eta: 1 day, 8:46:01, time: 0.808, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5772, decode.acc_seg: 78.8973, aux.loss_ce: 0.2503, aux.acc_seg: 78.0069, loss: 0.8275
2023-11-26 16:12:50,674 - mmseg - INFO - Iter [11150/160000]	lr: 5.582e-05, eta: 1 day, 8:45:30, time: 0.805, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5521, decode.acc_seg: 79.6370, aux.loss_ce: 0.2392, aux.acc_seg: 78.6828, loss: 0.7913
2023-11-26 16:13:30,850 - mmseg - INFO - Iter [11200/160000]	lr: 5.580e-05, eta: 1 day, 8:44:58, time: 0.804, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5437, decode.acc_seg: 79.1146, aux.loss_ce: 0.2386, aux.acc_seg: 77.8907, loss: 0.7823
2023-11-26 16:14:09,969 - mmseg - INFO - Iter [11250/160000]	lr: 5.578e-05, eta: 1 day, 8:44:13, time: 0.783, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5847, decode.acc_seg: 78.7674, aux.loss_ce: 0.2512, aux.acc_seg: 77.7251, loss: 0.8359
2023-11-26 16:14:48,821 - mmseg - INFO - Iter [11300/160000]	lr: 5.576e-05, eta: 1 day, 8:43:22, time: 0.776, data_time: 0.010, memory: 18766, decode.loss_ce: 0.6126, decode.acc_seg: 77.4259, aux.loss_ce: 0.2615, aux.acc_seg: 76.9102, loss: 0.8741
2023-11-26 16:15:29,508 - mmseg - INFO - Iter [11350/160000]	lr: 5.574e-05, eta: 1 day, 8:42:56, time: 0.813, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5889, decode.acc_seg: 78.0071, aux.loss_ce: 0.2534, aux.acc_seg: 77.3352, loss: 0.8423
2023-11-26 16:16:11,536 - mmseg - INFO - Iter [11400/160000]	lr: 5.573e-05, eta: 1 day, 8:42:49, time: 0.841, data_time: 0.053, memory: 18766, decode.loss_ce: 0.5783, decode.acc_seg: 78.8923, aux.loss_ce: 0.2494, aux.acc_seg: 78.0476, loss: 0.8278
2023-11-26 16:16:51,752 - mmseg - INFO - Iter [11450/160000]	lr: 5.571e-05, eta: 1 day, 8:42:17, time: 0.804, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5428, decode.acc_seg: 79.6228, aux.loss_ce: 0.2332, aux.acc_seg: 78.9015, loss: 0.7760
2023-11-26 16:17:32,064 - mmseg - INFO - Iter [11500/160000]	lr: 5.569e-05, eta: 1 day, 8:41:46, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5670, decode.acc_seg: 78.6009, aux.loss_ce: 0.2500, aux.acc_seg: 77.2317, loss: 0.8170
2023-11-26 16:18:12,362 - mmseg - INFO - Iter [11550/160000]	lr: 5.567e-05, eta: 1 day, 8:41:15, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5523, decode.acc_seg: 79.5657, aux.loss_ce: 0.2401, aux.acc_seg: 78.4125, loss: 0.7924
2023-11-26 16:18:49,655 - mmseg - INFO - Iter [11600/160000]	lr: 5.565e-05, eta: 1 day, 8:40:06, time: 0.747, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5627, decode.acc_seg: 78.7341, aux.loss_ce: 0.2393, aux.acc_seg: 77.9997, loss: 0.8020
2023-11-26 16:19:27,481 - mmseg - INFO - Iter [11650/160000]	lr: 5.563e-05, eta: 1 day, 8:39:03, time: 0.756, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5915, decode.acc_seg: 77.8575, aux.loss_ce: 0.2575, aux.acc_seg: 77.0157, loss: 0.8490
2023-11-26 16:20:04,522 - mmseg - INFO - Iter [11700/160000]	lr: 5.561e-05, eta: 1 day, 8:37:51, time: 0.741, data_time: 0.012, memory: 18766, decode.loss_ce: 0.5528, decode.acc_seg: 79.2755, aux.loss_ce: 0.2384, aux.acc_seg: 78.7405, loss: 0.7911
2023-11-26 16:20:44,316 - mmseg - INFO - Iter [11750/160000]	lr: 5.559e-05, eta: 1 day, 8:37:13, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5716, decode.acc_seg: 78.9746, aux.loss_ce: 0.2483, aux.acc_seg: 77.7508, loss: 0.8199
2023-11-26 16:21:23,158 - mmseg - INFO - Iter [11800/160000]	lr: 5.558e-05, eta: 1 day, 8:36:24, time: 0.776, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5315, decode.acc_seg: 79.8370, aux.loss_ce: 0.2318, aux.acc_seg: 79.0022, loss: 0.7633
2023-11-26 16:22:01,825 - mmseg - INFO - Iter [11850/160000]	lr: 5.556e-05, eta: 1 day, 8:35:33, time: 0.773, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5426, decode.acc_seg: 79.9208, aux.loss_ce: 0.2397, aux.acc_seg: 78.4306, loss: 0.7823
2023-11-26 16:22:42,701 - mmseg - INFO - Iter [11900/160000]	lr: 5.554e-05, eta: 1 day, 8:35:09, time: 0.817, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5813, decode.acc_seg: 78.8445, aux.loss_ce: 0.2522, aux.acc_seg: 77.5169, loss: 0.8335
2023-11-26 16:23:23,714 - mmseg - INFO - Iter [11950/160000]	lr: 5.552e-05, eta: 1 day, 8:34:47, time: 0.820, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5749, decode.acc_seg: 78.6283, aux.loss_ce: 0.2493, aux.acc_seg: 77.5692, loss: 0.8241
2023-11-26 16:24:02,259 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 16:24:02,259 - mmseg - INFO - Iter [12000/160000]	lr: 5.550e-05, eta: 1 day, 8:33:54, time: 0.772, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5823, decode.acc_seg: 78.8904, aux.loss_ce: 0.2561, aux.acc_seg: 77.7247, loss: 0.8384
2023-11-26 16:24:42,107 - mmseg - INFO - Iter [12050/160000]	lr: 5.548e-05, eta: 1 day, 8:33:17, time: 0.796, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5532, decode.acc_seg: 79.5693, aux.loss_ce: 0.2382, aux.acc_seg: 78.4456, loss: 0.7914
2023-11-26 16:25:20,594 - mmseg - INFO - Iter [12100/160000]	lr: 5.546e-05, eta: 1 day, 8:32:24, time: 0.770, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5900, decode.acc_seg: 78.3518, aux.loss_ce: 0.2495, aux.acc_seg: 77.4805, loss: 0.8395
2023-11-26 16:25:59,248 - mmseg - INFO - Iter [12150/160000]	lr: 5.544e-05, eta: 1 day, 8:31:33, time: 0.773, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5788, decode.acc_seg: 78.4435, aux.loss_ce: 0.2492, aux.acc_seg: 77.5589, loss: 0.8281
2023-11-26 16:26:39,731 - mmseg - INFO - Iter [12200/160000]	lr: 5.543e-05, eta: 1 day, 8:31:04, time: 0.810, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5510, decode.acc_seg: 78.7787, aux.loss_ce: 0.2384, aux.acc_seg: 77.6918, loss: 0.7894
2023-11-26 16:27:17,156 - mmseg - INFO - Iter [12250/160000]	lr: 5.541e-05, eta: 1 day, 8:29:58, time: 0.749, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5364, decode.acc_seg: 79.8306, aux.loss_ce: 0.2343, aux.acc_seg: 78.6994, loss: 0.7706
2023-11-26 16:27:54,665 - mmseg - INFO - Iter [12300/160000]	lr: 5.539e-05, eta: 1 day, 8:28:53, time: 0.750, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5563, decode.acc_seg: 79.5159, aux.loss_ce: 0.2437, aux.acc_seg: 78.1208, loss: 0.8001
2023-11-26 16:28:34,675 - mmseg - INFO - Iter [12350/160000]	lr: 5.537e-05, eta: 1 day, 8:28:19, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5320, decode.acc_seg: 79.7494, aux.loss_ce: 0.2323, aux.acc_seg: 78.9184, loss: 0.7642
2023-11-26 16:29:15,245 - mmseg - INFO - Iter [12400/160000]	lr: 5.535e-05, eta: 1 day, 8:27:51, time: 0.811, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5900, decode.acc_seg: 78.6908, aux.loss_ce: 0.2530, aux.acc_seg: 77.5624, loss: 0.8430
2023-11-26 16:29:56,759 - mmseg - INFO - Iter [12450/160000]	lr: 5.533e-05, eta: 1 day, 8:27:34, time: 0.831, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5554, decode.acc_seg: 79.2047, aux.loss_ce: 0.2349, aux.acc_seg: 78.4007, loss: 0.7903
2023-11-26 16:30:36,525 - mmseg - INFO - Iter [12500/160000]	lr: 5.531e-05, eta: 1 day, 8:26:57, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5912, decode.acc_seg: 78.3257, aux.loss_ce: 0.2562, aux.acc_seg: 77.8367, loss: 0.8474
2023-11-26 16:31:16,377 - mmseg - INFO - Iter [12550/160000]	lr: 5.529e-05, eta: 1 day, 8:26:20, time: 0.796, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5314, decode.acc_seg: 80.1811, aux.loss_ce: 0.2342, aux.acc_seg: 78.8603, loss: 0.7656
2023-11-26 16:31:55,518 - mmseg - INFO - Iter [12600/160000]	lr: 5.528e-05, eta: 1 day, 8:25:35, time: 0.783, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5396, decode.acc_seg: 79.5955, aux.loss_ce: 0.2291, aux.acc_seg: 79.1563, loss: 0.7687
2023-11-26 16:32:36,076 - mmseg - INFO - Iter [12650/160000]	lr: 5.526e-05, eta: 1 day, 8:25:07, time: 0.812, data_time: 0.053, memory: 18766, decode.loss_ce: 0.5157, decode.acc_seg: 81.2746, aux.loss_ce: 0.2242, aux.acc_seg: 80.2579, loss: 0.7399
2023-11-26 16:33:12,801 - mmseg - INFO - Iter [12700/160000]	lr: 5.524e-05, eta: 1 day, 8:23:54, time: 0.734, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5431, decode.acc_seg: 79.3725, aux.loss_ce: 0.2359, aux.acc_seg: 78.8330, loss: 0.7790
2023-11-26 16:33:52,929 - mmseg - INFO - Iter [12750/160000]	lr: 5.522e-05, eta: 1 day, 8:23:20, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5521, decode.acc_seg: 79.5592, aux.loss_ce: 0.2407, aux.acc_seg: 78.5665, loss: 0.7928
2023-11-26 16:34:33,567 - mmseg - INFO - Iter [12800/160000]	lr: 5.520e-05, eta: 1 day, 8:22:53, time: 0.813, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5320, decode.acc_seg: 80.0931, aux.loss_ce: 0.2276, aux.acc_seg: 79.5712, loss: 0.7596
2023-11-26 16:35:13,858 - mmseg - INFO - Iter [12850/160000]	lr: 5.518e-05, eta: 1 day, 8:22:21, time: 0.806, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5350, decode.acc_seg: 79.1767, aux.loss_ce: 0.2356, aux.acc_seg: 78.2257, loss: 0.7705
2023-11-26 16:35:54,652 - mmseg - INFO - Iter [12900/160000]	lr: 5.516e-05, eta: 1 day, 8:21:55, time: 0.816, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5344, decode.acc_seg: 80.0251, aux.loss_ce: 0.2317, aux.acc_seg: 79.1760, loss: 0.7662
2023-11-26 16:36:32,426 - mmseg - INFO - Iter [12950/160000]	lr: 5.514e-05, eta: 1 day, 8:20:55, time: 0.756, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5222, decode.acc_seg: 80.1242, aux.loss_ce: 0.2278, aux.acc_seg: 79.2477, loss: 0.7499
2023-11-26 16:37:10,063 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 16:37:10,063 - mmseg - INFO - Iter [13000/160000]	lr: 5.513e-05, eta: 1 day, 8:19:53, time: 0.753, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5174, decode.acc_seg: 80.2679, aux.loss_ce: 0.2241, aux.acc_seg: 79.3913, loss: 0.7415
2023-11-26 16:37:48,924 - mmseg - INFO - Iter [13050/160000]	lr: 5.511e-05, eta: 1 day, 8:19:05, time: 0.776, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5383, decode.acc_seg: 79.4940, aux.loss_ce: 0.2327, aux.acc_seg: 78.7726, loss: 0.7709
2023-11-26 16:38:29,548 - mmseg - INFO - Iter [13100/160000]	lr: 5.509e-05, eta: 1 day, 8:18:37, time: 0.812, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5337, decode.acc_seg: 79.5115, aux.loss_ce: 0.2298, aux.acc_seg: 78.9704, loss: 0.7635
2023-11-26 16:39:09,926 - mmseg - INFO - Iter [13150/160000]	lr: 5.507e-05, eta: 1 day, 8:18:06, time: 0.808, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5780, decode.acc_seg: 78.7638, aux.loss_ce: 0.2519, aux.acc_seg: 77.3285, loss: 0.8298
2023-11-26 16:39:50,711 - mmseg - INFO - Iter [13200/160000]	lr: 5.505e-05, eta: 1 day, 8:17:40, time: 0.815, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5207, decode.acc_seg: 80.2276, aux.loss_ce: 0.2274, aux.acc_seg: 79.1918, loss: 0.7481
2023-11-26 16:40:30,806 - mmseg - INFO - Iter [13250/160000]	lr: 5.503e-05, eta: 1 day, 8:17:06, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5032, decode.acc_seg: 80.3422, aux.loss_ce: 0.2167, aux.acc_seg: 79.7690, loss: 0.7199
2023-11-26 16:41:12,246 - mmseg - INFO - Iter [13300/160000]	lr: 5.501e-05, eta: 1 day, 8:16:47, time: 0.829, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5634, decode.acc_seg: 78.9320, aux.loss_ce: 0.2451, aux.acc_seg: 77.7492, loss: 0.8084
2023-11-26 16:41:51,478 - mmseg - INFO - Iter [13350/160000]	lr: 5.499e-05, eta: 1 day, 8:16:03, time: 0.786, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5017, decode.acc_seg: 80.6486, aux.loss_ce: 0.2189, aux.acc_seg: 79.6225, loss: 0.7206
2023-11-26 16:42:31,645 - mmseg - INFO - Iter [13400/160000]	lr: 5.498e-05, eta: 1 day, 8:15:29, time: 0.803, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5216, decode.acc_seg: 79.7209, aux.loss_ce: 0.2229, aux.acc_seg: 78.8984, loss: 0.7445
2023-11-26 16:43:11,823 - mmseg - INFO - Iter [13450/160000]	lr: 5.496e-05, eta: 1 day, 8:14:56, time: 0.804, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5212, decode.acc_seg: 80.2238, aux.loss_ce: 0.2240, aux.acc_seg: 79.3841, loss: 0.7453
2023-11-26 16:43:51,465 - mmseg - INFO - Iter [13500/160000]	lr: 5.494e-05, eta: 1 day, 8:14:17, time: 0.794, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5302, decode.acc_seg: 80.2593, aux.loss_ce: 0.2330, aux.acc_seg: 78.8418, loss: 0.7632
2023-11-26 16:44:31,337 - mmseg - INFO - Iter [13550/160000]	lr: 5.492e-05, eta: 1 day, 8:13:40, time: 0.796, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5331, decode.acc_seg: 79.9247, aux.loss_ce: 0.2331, aux.acc_seg: 78.8937, loss: 0.7662
2023-11-26 16:45:11,587 - mmseg - INFO - Iter [13600/160000]	lr: 5.490e-05, eta: 1 day, 8:13:07, time: 0.805, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5377, decode.acc_seg: 79.4311, aux.loss_ce: 0.2316, aux.acc_seg: 78.5491, loss: 0.7693
2023-11-26 16:45:52,391 - mmseg - INFO - Iter [13650/160000]	lr: 5.488e-05, eta: 1 day, 8:12:40, time: 0.817, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5617, decode.acc_seg: 79.3465, aux.loss_ce: 0.2399, aux.acc_seg: 78.5794, loss: 0.8016
2023-11-26 16:46:32,721 - mmseg - INFO - Iter [13700/160000]	lr: 5.486e-05, eta: 1 day, 8:12:08, time: 0.807, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5233, decode.acc_seg: 80.4844, aux.loss_ce: 0.2281, aux.acc_seg: 79.4876, loss: 0.7514
2023-11-26 16:47:12,963 - mmseg - INFO - Iter [13750/160000]	lr: 5.484e-05, eta: 1 day, 8:11:35, time: 0.805, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5135, decode.acc_seg: 80.7059, aux.loss_ce: 0.2223, aux.acc_seg: 79.9355, loss: 0.7358
2023-11-26 16:47:51,990 - mmseg - INFO - Iter [13800/160000]	lr: 5.483e-05, eta: 1 day, 8:10:50, time: 0.781, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5188, decode.acc_seg: 80.5537, aux.loss_ce: 0.2269, aux.acc_seg: 79.5346, loss: 0.7457
2023-11-26 16:48:31,303 - mmseg - INFO - Iter [13850/160000]	lr: 5.481e-05, eta: 1 day, 8:10:07, time: 0.786, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5355, decode.acc_seg: 79.5866, aux.loss_ce: 0.2327, aux.acc_seg: 78.5676, loss: 0.7682
2023-11-26 16:49:12,557 - mmseg - INFO - Iter [13900/160000]	lr: 5.479e-05, eta: 1 day, 8:09:44, time: 0.825, data_time: 0.053, memory: 18766, decode.loss_ce: 0.5405, decode.acc_seg: 79.7787, aux.loss_ce: 0.2346, aux.acc_seg: 78.8784, loss: 0.7751
2023-11-26 16:49:53,796 - mmseg - INFO - Iter [13950/160000]	lr: 5.477e-05, eta: 1 day, 8:09:21, time: 0.825, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5109, decode.acc_seg: 80.8168, aux.loss_ce: 0.2215, aux.acc_seg: 79.6126, loss: 0.7324
2023-11-26 16:50:33,903 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 16:50:33,903 - mmseg - INFO - Iter [14000/160000]	lr: 5.475e-05, eta: 1 day, 8:08:47, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5141, decode.acc_seg: 80.9143, aux.loss_ce: 0.2230, aux.acc_seg: 79.9536, loss: 0.7371
2023-11-26 16:51:12,751 - mmseg - INFO - Iter [14050/160000]	lr: 5.473e-05, eta: 1 day, 8:07:59, time: 0.778, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5133, decode.acc_seg: 80.9119, aux.loss_ce: 0.2253, aux.acc_seg: 79.8246, loss: 0.7385
2023-11-26 16:51:52,994 - mmseg - INFO - Iter [14100/160000]	lr: 5.471e-05, eta: 1 day, 8:07:26, time: 0.804, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5198, decode.acc_seg: 80.3909, aux.loss_ce: 0.2281, aux.acc_seg: 79.1761, loss: 0.7479
2023-11-26 16:52:32,786 - mmseg - INFO - Iter [14150/160000]	lr: 5.469e-05, eta: 1 day, 8:06:48, time: 0.796, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5196, decode.acc_seg: 80.8029, aux.loss_ce: 0.2266, aux.acc_seg: 79.9291, loss: 0.7462
2023-11-26 16:53:11,081 - mmseg - INFO - Iter [14200/160000]	lr: 5.468e-05, eta: 1 day, 8:05:55, time: 0.767, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5380, decode.acc_seg: 80.0286, aux.loss_ce: 0.2323, aux.acc_seg: 78.9396, loss: 0.7703
2023-11-26 16:53:50,429 - mmseg - INFO - Iter [14250/160000]	lr: 5.466e-05, eta: 1 day, 8:05:12, time: 0.786, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5206, decode.acc_seg: 80.3013, aux.loss_ce: 0.2260, aux.acc_seg: 78.9387, loss: 0.7466
2023-11-26 16:54:28,704 - mmseg - INFO - Iter [14300/160000]	lr: 5.464e-05, eta: 1 day, 8:04:18, time: 0.766, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5121, decode.acc_seg: 79.9541, aux.loss_ce: 0.2234, aux.acc_seg: 79.1851, loss: 0.7354
2023-11-26 16:55:08,059 - mmseg - INFO - Iter [14350/160000]	lr: 5.462e-05, eta: 1 day, 8:03:36, time: 0.787, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5007, decode.acc_seg: 80.3692, aux.loss_ce: 0.2147, aux.acc_seg: 80.0074, loss: 0.7154
2023-11-26 16:55:48,040 - mmseg - INFO - Iter [14400/160000]	lr: 5.460e-05, eta: 1 day, 8:03:00, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5053, decode.acc_seg: 80.1671, aux.loss_ce: 0.2201, aux.acc_seg: 79.2517, loss: 0.7255
2023-11-26 16:56:27,583 - mmseg - INFO - Iter [14450/160000]	lr: 5.458e-05, eta: 1 day, 8:02:20, time: 0.792, data_time: 0.010, memory: 18766, decode.loss_ce: 0.4970, decode.acc_seg: 80.9598, aux.loss_ce: 0.2198, aux.acc_seg: 79.9738, loss: 0.7167
2023-11-26 16:57:07,509 - mmseg - INFO - Iter [14500/160000]	lr: 5.456e-05, eta: 1 day, 8:01:43, time: 0.798, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5029, decode.acc_seg: 80.8139, aux.loss_ce: 0.2210, aux.acc_seg: 79.6109, loss: 0.7239
2023-11-26 16:57:48,311 - mmseg - INFO - Iter [14550/160000]	lr: 5.454e-05, eta: 1 day, 8:01:15, time: 0.816, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5366, decode.acc_seg: 79.7059, aux.loss_ce: 0.2346, aux.acc_seg: 78.7401, loss: 0.7712
2023-11-26 16:58:28,755 - mmseg - INFO - Iter [14600/160000]	lr: 5.453e-05, eta: 1 day, 8:00:44, time: 0.810, data_time: 0.012, memory: 18766, decode.loss_ce: 0.5168, decode.acc_seg: 80.6622, aux.loss_ce: 0.2210, aux.acc_seg: 80.1158, loss: 0.7378
2023-11-26 16:59:08,375 - mmseg - INFO - Iter [14650/160000]	lr: 5.451e-05, eta: 1 day, 8:00:04, time: 0.791, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5238, decode.acc_seg: 79.5564, aux.loss_ce: 0.2264, aux.acc_seg: 78.6520, loss: 0.7502
2023-11-26 16:59:48,420 - mmseg - INFO - Iter [14700/160000]	lr: 5.449e-05, eta: 1 day, 7:59:28, time: 0.801, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5703, decode.acc_seg: 78.0914, aux.loss_ce: 0.2476, aux.acc_seg: 77.2368, loss: 0.8179
2023-11-26 17:00:28,809 - mmseg - INFO - Iter [14750/160000]	lr: 5.447e-05, eta: 1 day, 7:58:57, time: 0.808, data_time: 0.012, memory: 18766, decode.loss_ce: 0.4817, decode.acc_seg: 81.2775, aux.loss_ce: 0.2108, aux.acc_seg: 80.1611, loss: 0.6925
2023-11-26 17:01:09,352 - mmseg - INFO - Iter [14800/160000]	lr: 5.445e-05, eta: 1 day, 7:58:26, time: 0.810, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5108, decode.acc_seg: 80.4063, aux.loss_ce: 0.2194, aux.acc_seg: 79.3942, loss: 0.7302
2023-11-26 17:01:49,337 - mmseg - INFO - Iter [14850/160000]	lr: 5.443e-05, eta: 1 day, 7:57:49, time: 0.800, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5269, decode.acc_seg: 79.6284, aux.loss_ce: 0.2299, aux.acc_seg: 78.6528, loss: 0.7568
2023-11-26 17:02:29,045 - mmseg - INFO - Iter [14900/160000]	lr: 5.441e-05, eta: 1 day, 7:57:10, time: 0.794, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5143, decode.acc_seg: 80.8210, aux.loss_ce: 0.2226, aux.acc_seg: 79.8274, loss: 0.7369
2023-11-26 17:03:09,769 - mmseg - INFO - Iter [14950/160000]	lr: 5.439e-05, eta: 1 day, 7:56:41, time: 0.814, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5343, decode.acc_seg: 79.6395, aux.loss_ce: 0.2270, aux.acc_seg: 79.0617, loss: 0.7612
2023-11-26 17:03:50,718 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:03:50,719 - mmseg - INFO - Iter [15000/160000]	lr: 5.438e-05, eta: 1 day, 7:56:14, time: 0.819, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5118, decode.acc_seg: 80.7048, aux.loss_ce: 0.2220, aux.acc_seg: 79.6884, loss: 0.7338
2023-11-26 17:04:28,861 - mmseg - INFO - Iter [15050/160000]	lr: 5.436e-05, eta: 1 day, 7:55:21, time: 0.764, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5030, decode.acc_seg: 81.2292, aux.loss_ce: 0.2173, aux.acc_seg: 80.4766, loss: 0.7203
2023-11-26 17:05:08,114 - mmseg - INFO - Iter [15100/160000]	lr: 5.434e-05, eta: 1 day, 7:54:37, time: 0.784, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5260, decode.acc_seg: 79.7052, aux.loss_ce: 0.2268, aux.acc_seg: 78.5391, loss: 0.7528
2023-11-26 17:05:48,200 - mmseg - INFO - Iter [15150/160000]	lr: 5.432e-05, eta: 1 day, 7:54:01, time: 0.802, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5226, decode.acc_seg: 79.9918, aux.loss_ce: 0.2255, aux.acc_seg: 79.2085, loss: 0.7480
2023-11-26 17:06:29,616 - mmseg - INFO - Iter [15200/160000]	lr: 5.430e-05, eta: 1 day, 7:53:39, time: 0.828, data_time: 0.053, memory: 18766, decode.loss_ce: 0.4980, decode.acc_seg: 81.7799, aux.loss_ce: 0.2172, aux.acc_seg: 80.7319, loss: 0.7152
2023-11-26 17:07:09,914 - mmseg - INFO - Iter [15250/160000]	lr: 5.428e-05, eta: 1 day, 7:53:05, time: 0.806, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5042, decode.acc_seg: 81.2818, aux.loss_ce: 0.2194, aux.acc_seg: 80.0584, loss: 0.7236
2023-11-26 17:07:49,758 - mmseg - INFO - Iter [15300/160000]	lr: 5.426e-05, eta: 1 day, 7:52:27, time: 0.797, data_time: 0.011, memory: 18766, decode.loss_ce: 0.4735, decode.acc_seg: 81.6593, aux.loss_ce: 0.2095, aux.acc_seg: 80.2799, loss: 0.6829
2023-11-26 17:08:29,628 - mmseg - INFO - Iter [15350/160000]	lr: 5.424e-05, eta: 1 day, 7:51:50, time: 0.798, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5146, decode.acc_seg: 80.2222, aux.loss_ce: 0.2197, aux.acc_seg: 79.3630, loss: 0.7343
2023-11-26 17:09:08,989 - mmseg - INFO - Iter [15400/160000]	lr: 5.423e-05, eta: 1 day, 7:51:08, time: 0.787, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5128, decode.acc_seg: 81.1327, aux.loss_ce: 0.2212, aux.acc_seg: 79.9688, loss: 0.7341
2023-11-26 17:09:47,023 - mmseg - INFO - Iter [15450/160000]	lr: 5.421e-05, eta: 1 day, 7:50:13, time: 0.761, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5125, decode.acc_seg: 81.0241, aux.loss_ce: 0.2244, aux.acc_seg: 79.4528, loss: 0.7369
2023-11-26 17:10:26,031 - mmseg - INFO - Iter [15500/160000]	lr: 5.419e-05, eta: 1 day, 7:49:27, time: 0.779, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5045, decode.acc_seg: 80.9897, aux.loss_ce: 0.2192, aux.acc_seg: 79.8918, loss: 0.7236
2023-11-26 17:11:05,874 - mmseg - INFO - Iter [15550/160000]	lr: 5.417e-05, eta: 1 day, 7:48:49, time: 0.797, data_time: 0.012, memory: 18766, decode.loss_ce: 0.4975, decode.acc_seg: 80.9711, aux.loss_ce: 0.2123, aux.acc_seg: 80.1744, loss: 0.7098
2023-11-26 17:11:44,523 - mmseg - INFO - Iter [15600/160000]	lr: 5.415e-05, eta: 1 day, 7:48:01, time: 0.774, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5048, decode.acc_seg: 81.0017, aux.loss_ce: 0.2199, aux.acc_seg: 79.8055, loss: 0.7247
2023-11-26 17:12:22,896 - mmseg - INFO - Iter [15650/160000]	lr: 5.413e-05, eta: 1 day, 7:47:09, time: 0.767, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5049, decode.acc_seg: 80.9408, aux.loss_ce: 0.2203, aux.acc_seg: 79.7367, loss: 0.7252
2023-11-26 17:13:03,144 - mmseg - INFO - Iter [15700/160000]	lr: 5.411e-05, eta: 1 day, 7:46:35, time: 0.805, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5194, decode.acc_seg: 80.9710, aux.loss_ce: 0.2291, aux.acc_seg: 79.9217, loss: 0.7485
2023-11-26 17:13:42,825 - mmseg - INFO - Iter [15750/160000]	lr: 5.409e-05, eta: 1 day, 7:45:56, time: 0.794, data_time: 0.011, memory: 18766, decode.loss_ce: 0.4875, decode.acc_seg: 81.9363, aux.loss_ce: 0.2121, aux.acc_seg: 80.8690, loss: 0.6996
2023-11-26 17:14:22,623 - mmseg - INFO - Iter [15800/160000]	lr: 5.408e-05, eta: 1 day, 7:45:18, time: 0.797, data_time: 0.011, memory: 18766, decode.loss_ce: 0.4899, decode.acc_seg: 81.4509, aux.loss_ce: 0.2104, aux.acc_seg: 80.7089, loss: 0.7002
2023-11-26 17:15:01,196 - mmseg - INFO - Iter [15850/160000]	lr: 5.406e-05, eta: 1 day, 7:44:28, time: 0.770, data_time: 0.010, memory: 18766, decode.loss_ce: 0.5112, decode.acc_seg: 80.4779, aux.loss_ce: 0.2198, aux.acc_seg: 79.6210, loss: 0.7310
2023-11-26 17:15:42,550 - mmseg - INFO - Iter [15900/160000]	lr: 5.404e-05, eta: 1 day, 7:44:04, time: 0.827, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5123, decode.acc_seg: 80.9086, aux.loss_ce: 0.2235, aux.acc_seg: 79.4880, loss: 0.7358
2023-11-26 17:16:23,275 - mmseg - INFO - Iter [15950/160000]	lr: 5.402e-05, eta: 1 day, 7:43:34, time: 0.815, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5311, decode.acc_seg: 79.7188, aux.loss_ce: 0.2289, aux.acc_seg: 78.8681, loss: 0.7600
2023-11-26 17:17:03,058 - mmseg - INFO - Saving checkpoint at 16000 iterations
2023-11-26 17:17:08,297 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:17:08,297 - mmseg - INFO - Iter [16000/160000]	lr: 5.400e-05, eta: 1 day, 7:43:44, time: 0.902, data_time: 0.011, memory: 18766, decode.loss_ce: 0.5226, decode.acc_seg: 79.7185, aux.loss_ce: 0.2236, aux.acc_seg: 79.0465, loss: 0.7462
2023-11-26 17:20:17,673 - mmseg - INFO - per class results:
2023-11-26 17:20:17,687 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 73.66 | 83.28 |
|       building      | 81.79 | 90.03 |
|         sky         | 93.79 | 97.77 |
|        floor        | 80.38 | 90.66 |
|         tree        | 72.55 | 85.79 |
|       ceiling       |  82.6 | 91.22 |
|         road        | 81.58 | 87.13 |
|         bed         |  86.0 | 91.44 |
|      windowpane     |  58.9 |  79.0 |
|        grass        | 62.98 | 78.83 |
|       cabinet       | 53.77 | 63.52 |
|       sidewalk      | 61.62 | 80.26 |
|        person       | 76.76 | 91.61 |
|        earth        | 32.83 | 44.93 |
|         door        | 41.42 | 57.51 |
|        table        | 53.74 | 69.51 |
|       mountain      | 55.67 | 71.74 |
|        plant        | 45.79 | 53.26 |
|       curtain       | 70.35 | 88.39 |
|        chair        | 47.41 | 58.66 |
|         car         | 82.75 | 93.37 |
|        water        | 49.69 | 60.23 |
|       painting      | 64.65 | 87.92 |
|         sofa        | 50.96 | 59.25 |
|        shelf        |  39.3 |  53.2 |
|        house        | 51.13 |  76.8 |
|         sea         | 55.83 | 84.62 |
|        mirror       | 54.06 | 64.27 |
|         rug         | 64.36 |  80.1 |
|        field        | 28.63 |  59.4 |
|       armchair      | 34.25 |  71.3 |
|         seat        | 57.28 |  71.4 |
|        fence        | 45.78 | 59.68 |
|         desk        | 37.27 | 58.19 |
|         rock        | 43.91 | 74.42 |
|       wardrobe      | 45.02 |  73.5 |
|         lamp        | 54.33 | 69.38 |
|       bathtub       | 65.42 | 95.35 |
|       railing       | 34.54 | 47.84 |
|       cushion       | 47.73 | 62.18 |
|         base        | 23.63 | 34.49 |
|         box         | 21.49 | 29.44 |
|        column       | 45.61 | 59.54 |
|      signboard      |  31.0 | 48.15 |
|   chest of drawers  | 41.87 |  62.5 |
|       counter       | 21.35 | 22.29 |
|         sand        | 33.89 | 50.57 |
|         sink        | 62.92 | 70.16 |
|      skyscraper     | 60.93 | 83.15 |
|      fireplace      | 57.02 | 90.23 |
|     refrigerator    | 57.64 |  82.1 |
|      grandstand     | 39.64 | 77.12 |
|         path        | 17.56 |  24.1 |
|        stairs       | 29.28 | 37.79 |
|        runway       | 72.55 | 96.56 |
|         case        | 60.86 | 88.57 |
|      pool table     |  92.1 | 95.76 |
|        pillow       | 54.69 | 74.57 |
|     screen door     |  54.1 | 81.53 |
|       stairway      | 42.76 | 63.22 |
|        river        | 24.31 | 52.26 |
|        bridge       | 74.59 | 86.52 |
|       bookcase      | 33.57 | 67.23 |
|        blind        | 35.97 | 40.07 |
|     coffee table    | 47.58 | 75.62 |
|        toilet       | 69.93 | 89.93 |
|        flower       | 32.95 | 49.43 |
|         book        | 40.89 | 61.58 |
|         hill        |  7.48 | 13.39 |
|        bench        | 40.36 | 50.98 |
|      countertop     | 51.22 | 71.47 |
|        stove        | 56.02 | 72.88 |
|         palm        | 47.82 | 58.21 |
|    kitchen island   | 32.49 | 77.02 |
|       computer      | 65.15 | 91.89 |
|     swivel chair    | 37.83 | 63.67 |
|         boat        | 39.99 |  61.8 |
|         bar         | 48.37 | 65.02 |
|    arcade machine   | 67.14 | 98.59 |
|        hovel        | 60.61 | 78.85 |
|         bus         |  72.9 | 93.53 |
|        towel        | 55.17 | 70.64 |
|        light        | 42.15 | 47.54 |
|        truck        | 29.35 | 48.72 |
|        tower        | 28.77 | 58.03 |
|      chandelier     | 60.42 | 85.39 |
|        awning       | 26.86 |  31.0 |
|     streetlight     | 18.74 | 22.48 |
|        booth        | 26.12 | 34.88 |
| television receiver | 67.36 | 80.38 |
|       airplane      | 52.79 | 63.51 |
|      dirt track     |  4.46 | 19.94 |
|       apparel       | 29.94 | 48.53 |
|         pole        | 16.26 | 20.22 |
|         land        |  0.12 |  0.21 |
|      bannister      |  2.26 |  2.86 |
|      escalator      | 49.77 | 77.28 |
|       ottoman       | 41.94 | 55.18 |
|        bottle       | 27.26 | 35.79 |
|        buffet       |  48.3 |  62.9 |
|        poster       | 13.43 | 14.79 |
|        stage        | 11.21 | 28.05 |
|         van         |  36.6 | 43.31 |
|         ship        | 41.17 | 89.72 |
|       fountain      | 60.62 | 62.97 |
|    conveyer belt    | 60.53 | 89.67 |
|        canopy       | 23.79 | 35.33 |
|        washer       | 66.31 | 82.68 |
|      plaything      | 13.17 |  24.4 |
|    swimming pool    | 55.18 | 85.02 |
|        stool        | 26.41 | 30.27 |
|        barrel       | 23.62 |  65.0 |
|        basket       | 30.09 | 42.66 |
|      waterfall      | 67.24 | 92.39 |
|         tent        | 90.66 | 98.79 |
|         bag         |  1.14 |  1.17 |
|       minibike      | 53.51 | 61.16 |
|        cradle       | 71.08 |  94.4 |
|         oven        | 17.54 | 25.06 |
|         ball        | 37.73 |  65.4 |
|         food        | 42.87 | 44.09 |
|         step        |  1.6  |  1.69 |
|         tank        | 32.99 | 35.13 |
|      trade name     | 14.96 | 16.39 |
|      microwave      | 66.11 | 82.46 |
|         pot         | 31.31 | 35.01 |
|        animal       | 57.87 | 60.76 |
|       bicycle       |  54.7 | 75.98 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 40.27 | 62.65 |
|        screen       | 52.94 | 91.61 |
|       blanket       |  3.46 |  3.88 |
|      sculpture      | 45.49 | 56.38 |
|         hood        | 33.92 | 69.56 |
|        sconce       | 15.11 | 16.73 |
|         vase        | 28.76 |  46.0 |
|    traffic light    | 21.23 | 37.39 |
|         tray        |  0.88 |  0.91 |
|        ashcan       | 29.61 | 45.57 |
|         fan         | 46.61 | 75.99 |
|         pier        | 43.54 |  49.6 |
|      crt screen     |  3.14 |  9.93 |
|        plate        | 44.96 | 64.62 |
|       monitor       |  6.0  |  6.97 |
|    bulletin board   | 39.68 | 44.59 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 53.72 | 68.74 |
|        glass        |  7.08 |  7.46 |
|        clock        |  26.3 | 36.19 |
|         flag        | 46.78 | 57.87 |
+---------------------+-------+-------+
2023-11-26 17:20:17,687 - mmseg - INFO - Summary:
2023-11-26 17:20:17,687 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 80.62 | 43.66 | 59.0 |
+-------+-------+------+
2023-11-26 17:20:17,693 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:20:17,694 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8062, mIoU: 0.4366, mAcc: 0.5900, IoU.wall: 0.7366, IoU.building: 0.8179, IoU.sky: 0.9379, IoU.floor: 0.8038, IoU.tree: 0.7255, IoU.ceiling: 0.8260, IoU.road: 0.8158, IoU.bed : 0.8600, IoU.windowpane: 0.5890, IoU.grass: 0.6298, IoU.cabinet: 0.5377, IoU.sidewalk: 0.6162, IoU.person: 0.7676, IoU.earth: 0.3283, IoU.door: 0.4142, IoU.table: 0.5374, IoU.mountain: 0.5567, IoU.plant: 0.4579, IoU.curtain: 0.7035, IoU.chair: 0.4741, IoU.car: 0.8275, IoU.water: 0.4969, IoU.painting: 0.6465, IoU.sofa: 0.5096, IoU.shelf: 0.3930, IoU.house: 0.5113, IoU.sea: 0.5583, IoU.mirror: 0.5406, IoU.rug: 0.6436, IoU.field: 0.2863, IoU.armchair: 0.3425, IoU.seat: 0.5728, IoU.fence: 0.4578, IoU.desk: 0.3727, IoU.rock: 0.4391, IoU.wardrobe: 0.4502, IoU.lamp: 0.5433, IoU.bathtub: 0.6542, IoU.railing: 0.3454, IoU.cushion: 0.4773, IoU.base: 0.2363, IoU.box: 0.2149, IoU.column: 0.4561, IoU.signboard: 0.3100, IoU.chest of drawers: 0.4187, IoU.counter: 0.2135, IoU.sand: 0.3389, IoU.sink: 0.6292, IoU.skyscraper: 0.6093, IoU.fireplace: 0.5702, IoU.refrigerator: 0.5764, IoU.grandstand: 0.3964, IoU.path: 0.1756, IoU.stairs: 0.2928, IoU.runway: 0.7255, IoU.case: 0.6086, IoU.pool table: 0.9210, IoU.pillow: 0.5469, IoU.screen door: 0.5410, IoU.stairway: 0.4276, IoU.river: 0.2431, IoU.bridge: 0.7459, IoU.bookcase: 0.3357, IoU.blind: 0.3597, IoU.coffee table: 0.4758, IoU.toilet: 0.6993, IoU.flower: 0.3295, IoU.book: 0.4089, IoU.hill: 0.0748, IoU.bench: 0.4036, IoU.countertop: 0.5122, IoU.stove: 0.5602, IoU.palm: 0.4782, IoU.kitchen island: 0.3249, IoU.computer: 0.6515, IoU.swivel chair: 0.3783, IoU.boat: 0.3999, IoU.bar: 0.4837, IoU.arcade machine: 0.6714, IoU.hovel: 0.6061, IoU.bus: 0.7290, IoU.towel: 0.5517, IoU.light: 0.4215, IoU.truck: 0.2935, IoU.tower: 0.2877, IoU.chandelier: 0.6042, IoU.awning: 0.2686, IoU.streetlight: 0.1874, IoU.booth: 0.2612, IoU.television receiver: 0.6736, IoU.airplane: 0.5279, IoU.dirt track: 0.0446, IoU.apparel: 0.2994, IoU.pole: 0.1626, IoU.land: 0.0012, IoU.bannister: 0.0226, IoU.escalator: 0.4977, IoU.ottoman: 0.4194, IoU.bottle: 0.2726, IoU.buffet: 0.4830, IoU.poster: 0.1343, IoU.stage: 0.1121, IoU.van: 0.3660, IoU.ship: 0.4117, IoU.fountain: 0.6062, IoU.conveyer belt: 0.6053, IoU.canopy: 0.2379, IoU.washer: 0.6631, IoU.plaything: 0.1317, IoU.swimming pool: 0.5518, IoU.stool: 0.2641, IoU.barrel: 0.2362, IoU.basket: 0.3009, IoU.waterfall: 0.6724, IoU.tent: 0.9066, IoU.bag: 0.0114, IoU.minibike: 0.5351, IoU.cradle: 0.7108, IoU.oven: 0.1754, IoU.ball: 0.3773, IoU.food: 0.4287, IoU.step: 0.0160, IoU.tank: 0.3299, IoU.trade name: 0.1496, IoU.microwave: 0.6611, IoU.pot: 0.3131, IoU.animal: 0.5787, IoU.bicycle: 0.5470, IoU.lake: 0.0000, IoU.dishwasher: 0.4027, IoU.screen: 0.5294, IoU.blanket: 0.0346, IoU.sculpture: 0.4549, IoU.hood: 0.3392, IoU.sconce: 0.1511, IoU.vase: 0.2876, IoU.traffic light: 0.2123, IoU.tray: 0.0088, IoU.ashcan: 0.2961, IoU.fan: 0.4661, IoU.pier: 0.4354, IoU.crt screen: 0.0314, IoU.plate: 0.4496, IoU.monitor: 0.0600, IoU.bulletin board: 0.3968, IoU.shower: 0.0000, IoU.radiator: 0.5372, IoU.glass: 0.0708, IoU.clock: 0.2630, IoU.flag: 0.4678, Acc.wall: 0.8328, Acc.building: 0.9003, Acc.sky: 0.9777, Acc.floor: 0.9066, Acc.tree: 0.8579, Acc.ceiling: 0.9122, Acc.road: 0.8713, Acc.bed : 0.9144, Acc.windowpane: 0.7900, Acc.grass: 0.7883, Acc.cabinet: 0.6352, Acc.sidewalk: 0.8026, Acc.person: 0.9161, Acc.earth: 0.4493, Acc.door: 0.5751, Acc.table: 0.6951, Acc.mountain: 0.7174, Acc.plant: 0.5326, Acc.curtain: 0.8839, Acc.chair: 0.5866, Acc.car: 0.9337, Acc.water: 0.6023, Acc.painting: 0.8792, Acc.sofa: 0.5925, Acc.shelf: 0.5320, Acc.house: 0.7680, Acc.sea: 0.8462, Acc.mirror: 0.6427, Acc.rug: 0.8010, Acc.field: 0.5940, Acc.armchair: 0.7130, Acc.seat: 0.7140, Acc.fence: 0.5968, Acc.desk: 0.5819, Acc.rock: 0.7442, Acc.wardrobe: 0.7350, Acc.lamp: 0.6938, Acc.bathtub: 0.9535, Acc.railing: 0.4784, Acc.cushion: 0.6218, Acc.base: 0.3449, Acc.box: 0.2944, Acc.column: 0.5954, Acc.signboard: 0.4815, Acc.chest of drawers: 0.6250, Acc.counter: 0.2229, Acc.sand: 0.5057, Acc.sink: 0.7016, Acc.skyscraper: 0.8315, Acc.fireplace: 0.9023, Acc.refrigerator: 0.8210, Acc.grandstand: 0.7712, Acc.path: 0.2410, Acc.stairs: 0.3779, Acc.runway: 0.9656, Acc.case: 0.8857, Acc.pool table: 0.9576, Acc.pillow: 0.7457, Acc.screen door: 0.8153, Acc.stairway: 0.6322, Acc.river: 0.5226, Acc.bridge: 0.8652, Acc.bookcase: 0.6723, Acc.blind: 0.4007, Acc.coffee table: 0.7562, Acc.toilet: 0.8993, Acc.flower: 0.4943, Acc.book: 0.6158, Acc.hill: 0.1339, Acc.bench: 0.5098, Acc.countertop: 0.7147, Acc.stove: 0.7288, Acc.palm: 0.5821, Acc.kitchen island: 0.7702, Acc.computer: 0.9189, Acc.swivel chair: 0.6367, Acc.boat: 0.6180, Acc.bar: 0.6502, Acc.arcade machine: 0.9859, Acc.hovel: 0.7885, Acc.bus: 0.9353, Acc.towel: 0.7064, Acc.light: 0.4754, Acc.truck: 0.4872, Acc.tower: 0.5803, Acc.chandelier: 0.8539, Acc.awning: 0.3100, Acc.streetlight: 0.2248, Acc.booth: 0.3488, Acc.television receiver: 0.8038, Acc.airplane: 0.6351, Acc.dirt track: 0.1994, Acc.apparel: 0.4853, Acc.pole: 0.2022, Acc.land: 0.0021, Acc.bannister: 0.0286, Acc.escalator: 0.7728, Acc.ottoman: 0.5518, Acc.bottle: 0.3579, Acc.buffet: 0.6290, Acc.poster: 0.1479, Acc.stage: 0.2805, Acc.van: 0.4331, Acc.ship: 0.8972, Acc.fountain: 0.6297, Acc.conveyer belt: 0.8967, Acc.canopy: 0.3533, Acc.washer: 0.8268, Acc.plaything: 0.2440, Acc.swimming pool: 0.8502, Acc.stool: 0.3027, Acc.barrel: 0.6500, Acc.basket: 0.4266, Acc.waterfall: 0.9239, Acc.tent: 0.9879, Acc.bag: 0.0117, Acc.minibike: 0.6116, Acc.cradle: 0.9440, Acc.oven: 0.2506, Acc.ball: 0.6540, Acc.food: 0.4409, Acc.step: 0.0169, Acc.tank: 0.3513, Acc.trade name: 0.1639, Acc.microwave: 0.8246, Acc.pot: 0.3501, Acc.animal: 0.6076, Acc.bicycle: 0.7598, Acc.lake: 0.0000, Acc.dishwasher: 0.6265, Acc.screen: 0.9161, Acc.blanket: 0.0388, Acc.sculpture: 0.5638, Acc.hood: 0.6956, Acc.sconce: 0.1673, Acc.vase: 0.4600, Acc.traffic light: 0.3739, Acc.tray: 0.0091, Acc.ashcan: 0.4557, Acc.fan: 0.7599, Acc.pier: 0.4960, Acc.crt screen: 0.0993, Acc.plate: 0.6462, Acc.monitor: 0.0697, Acc.bulletin board: 0.4459, Acc.shower: 0.0000, Acc.radiator: 0.6874, Acc.glass: 0.0746, Acc.clock: 0.3619, Acc.flag: 0.5787
2023-11-26 17:20:56,015 - mmseg - INFO - Iter [16050/160000]	lr: 5.398e-05, eta: 1 day, 8:11:10, time: 4.554, data_time: 3.798, memory: 21695, decode.loss_ce: 0.5021, decode.acc_seg: 80.8477, aux.loss_ce: 0.2182, aux.acc_seg: 79.9135, loss: 0.7203
2023-11-26 17:21:36,505 - mmseg - INFO - Iter [16100/160000]	lr: 5.396e-05, eta: 1 day, 8:10:32, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5398, decode.acc_seg: 79.6065, aux.loss_ce: 0.2320, aux.acc_seg: 78.8374, loss: 0.7718
2023-11-26 17:22:18,135 - mmseg - INFO - Iter [16150/160000]	lr: 5.394e-05, eta: 1 day, 8:10:04, time: 0.833, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4734, decode.acc_seg: 81.9287, aux.loss_ce: 0.2034, aux.acc_seg: 80.9076, loss: 0.6768
2023-11-26 17:22:58,734 - mmseg - INFO - Iter [16200/160000]	lr: 5.393e-05, eta: 1 day, 8:09:27, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5034, decode.acc_seg: 80.8410, aux.loss_ce: 0.2166, aux.acc_seg: 79.9436, loss: 0.7200
2023-11-26 17:23:38,336 - mmseg - INFO - Iter [16250/160000]	lr: 5.391e-05, eta: 1 day, 8:08:41, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5141, decode.acc_seg: 80.6120, aux.loss_ce: 0.2214, aux.acc_seg: 79.7116, loss: 0.7355
2023-11-26 17:24:15,386 - mmseg - INFO - Iter [16300/160000]	lr: 5.389e-05, eta: 1 day, 8:07:33, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5192, decode.acc_seg: 80.5350, aux.loss_ce: 0.2277, aux.acc_seg: 79.1835, loss: 0.7468
2023-11-26 17:24:52,715 - mmseg - INFO - Iter [16350/160000]	lr: 5.387e-05, eta: 1 day, 8:06:27, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4875, decode.acc_seg: 81.4576, aux.loss_ce: 0.2114, aux.acc_seg: 80.2969, loss: 0.6988
2023-11-26 17:25:31,439 - mmseg - INFO - Iter [16400/160000]	lr: 5.385e-05, eta: 1 day, 8:05:33, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5080, decode.acc_seg: 80.3880, aux.loss_ce: 0.2202, aux.acc_seg: 79.2962, loss: 0.7282
2023-11-26 17:26:13,780 - mmseg - INFO - Iter [16450/160000]	lr: 5.383e-05, eta: 1 day, 8:05:11, time: 0.846, data_time: 0.053, memory: 21695, decode.loss_ce: 0.4464, decode.acc_seg: 83.1721, aux.loss_ce: 0.1964, aux.acc_seg: 82.2027, loss: 0.6428
2023-11-26 17:26:54,100 - mmseg - INFO - Iter [16500/160000]	lr: 5.381e-05, eta: 1 day, 8:04:32, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4565, decode.acc_seg: 82.8846, aux.loss_ce: 0.2005, aux.acc_seg: 81.4893, loss: 0.6569
2023-11-26 17:27:34,156 - mmseg - INFO - Iter [16550/160000]	lr: 5.379e-05, eta: 1 day, 8:03:50, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4915, decode.acc_seg: 80.9626, aux.loss_ce: 0.2131, aux.acc_seg: 79.9908, loss: 0.7046
2023-11-26 17:28:14,149 - mmseg - INFO - Iter [16600/160000]	lr: 5.378e-05, eta: 1 day, 8:03:08, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4608, decode.acc_seg: 82.2334, aux.loss_ce: 0.1995, aux.acc_seg: 81.3975, loss: 0.6602
2023-11-26 17:28:50,888 - mmseg - INFO - Iter [16650/160000]	lr: 5.376e-05, eta: 1 day, 8:01:58, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4866, decode.acc_seg: 81.7444, aux.loss_ce: 0.2110, aux.acc_seg: 80.8798, loss: 0.6976
2023-11-26 17:29:27,487 - mmseg - INFO - Iter [16700/160000]	lr: 5.374e-05, eta: 1 day, 8:00:46, time: 0.732, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4519, decode.acc_seg: 82.3006, aux.loss_ce: 0.1978, aux.acc_seg: 81.4441, loss: 0.6497
2023-11-26 17:30:05,068 - mmseg - INFO - Iter [16750/160000]	lr: 5.372e-05, eta: 1 day, 7:59:43, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4848, decode.acc_seg: 81.0476, aux.loss_ce: 0.2096, aux.acc_seg: 80.3166, loss: 0.6944
2023-11-26 17:30:44,963 - mmseg - INFO - Iter [16800/160000]	lr: 5.370e-05, eta: 1 day, 7:59:01, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4796, decode.acc_seg: 81.5174, aux.loss_ce: 0.2096, aux.acc_seg: 80.4095, loss: 0.6891
2023-11-26 17:31:22,888 - mmseg - INFO - Iter [16850/160000]	lr: 5.368e-05, eta: 1 day, 7:58:01, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4709, decode.acc_seg: 82.4796, aux.loss_ce: 0.2032, aux.acc_seg: 81.4973, loss: 0.6741
2023-11-26 17:32:01,890 - mmseg - INFO - Iter [16900/160000]	lr: 5.366e-05, eta: 1 day, 7:57:11, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5342, decode.acc_seg: 79.8298, aux.loss_ce: 0.2328, aux.acc_seg: 78.6859, loss: 0.7670
2023-11-26 17:32:42,034 - mmseg - INFO - Iter [16950/160000]	lr: 5.364e-05, eta: 1 day, 7:56:30, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5033, decode.acc_seg: 80.9187, aux.loss_ce: 0.2171, aux.acc_seg: 80.1176, loss: 0.7203
2023-11-26 17:33:21,956 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:33:21,956 - mmseg - INFO - Iter [17000/160000]	lr: 5.363e-05, eta: 1 day, 7:55:48, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5233, decode.acc_seg: 79.9822, aux.loss_ce: 0.2272, aux.acc_seg: 78.7430, loss: 0.7505
2023-11-26 17:34:01,025 - mmseg - INFO - Iter [17050/160000]	lr: 5.361e-05, eta: 1 day, 7:54:58, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4942, decode.acc_seg: 81.0457, aux.loss_ce: 0.2147, aux.acc_seg: 80.1355, loss: 0.7089
2023-11-26 17:34:39,317 - mmseg - INFO - Iter [17100/160000]	lr: 5.359e-05, eta: 1 day, 7:54:02, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4975, decode.acc_seg: 81.1035, aux.loss_ce: 0.2161, aux.acc_seg: 80.1369, loss: 0.7136
2023-11-26 17:35:20,625 - mmseg - INFO - Iter [17150/160000]	lr: 5.357e-05, eta: 1 day, 7:53:31, time: 0.827, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4837, decode.acc_seg: 81.3120, aux.loss_ce: 0.2092, aux.acc_seg: 80.3057, loss: 0.6929
2023-11-26 17:36:00,940 - mmseg - INFO - Iter [17200/160000]	lr: 5.355e-05, eta: 1 day, 7:52:52, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5019, decode.acc_seg: 80.4477, aux.loss_ce: 0.2199, aux.acc_seg: 79.2870, loss: 0.7218
2023-11-26 17:36:39,107 - mmseg - INFO - Iter [17250/160000]	lr: 5.353e-05, eta: 1 day, 7:51:55, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4807, decode.acc_seg: 82.3194, aux.loss_ce: 0.2117, aux.acc_seg: 81.1715, loss: 0.6924
2023-11-26 17:37:19,784 - mmseg - INFO - Iter [17300/160000]	lr: 5.351e-05, eta: 1 day, 7:51:19, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4921, decode.acc_seg: 81.1236, aux.loss_ce: 0.2124, aux.acc_seg: 80.1535, loss: 0.7045
2023-11-26 17:38:00,052 - mmseg - INFO - Iter [17350/160000]	lr: 5.349e-05, eta: 1 day, 7:50:40, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5012, decode.acc_seg: 81.5803, aux.loss_ce: 0.2157, aux.acc_seg: 80.5855, loss: 0.7169
2023-11-26 17:38:40,356 - mmseg - INFO - Iter [17400/160000]	lr: 5.348e-05, eta: 1 day, 7:50:00, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5158, decode.acc_seg: 80.7018, aux.loss_ce: 0.2221, aux.acc_seg: 79.7726, loss: 0.7378
2023-11-26 17:39:20,819 - mmseg - INFO - Iter [17450/160000]	lr: 5.346e-05, eta: 1 day, 7:49:22, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4907, decode.acc_seg: 81.4283, aux.loss_ce: 0.2089, aux.acc_seg: 80.7137, loss: 0.6996
2023-11-26 17:40:01,241 - mmseg - INFO - Iter [17500/160000]	lr: 5.344e-05, eta: 1 day, 7:48:44, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5179, decode.acc_seg: 80.7370, aux.loss_ce: 0.2225, aux.acc_seg: 79.8578, loss: 0.7404
2023-11-26 17:40:40,769 - mmseg - INFO - Iter [17550/160000]	lr: 5.342e-05, eta: 1 day, 7:47:59, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4922, decode.acc_seg: 81.1035, aux.loss_ce: 0.2151, aux.acc_seg: 79.7560, loss: 0.7073
2023-11-26 17:41:20,478 - mmseg - INFO - Iter [17600/160000]	lr: 5.340e-05, eta: 1 day, 7:47:15, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5367, decode.acc_seg: 79.4275, aux.loss_ce: 0.2319, aux.acc_seg: 78.7758, loss: 0.7686
2023-11-26 17:42:00,488 - mmseg - INFO - Iter [17650/160000]	lr: 5.338e-05, eta: 1 day, 7:46:33, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4683, decode.acc_seg: 81.6731, aux.loss_ce: 0.2027, aux.acc_seg: 80.7524, loss: 0.6710
2023-11-26 17:42:42,496 - mmseg - INFO - Iter [17700/160000]	lr: 5.336e-05, eta: 1 day, 7:46:08, time: 0.840, data_time: 0.053, memory: 21695, decode.loss_ce: 0.4677, decode.acc_seg: 82.1075, aux.loss_ce: 0.2028, aux.acc_seg: 81.1999, loss: 0.6705
2023-11-26 17:43:21,625 - mmseg - INFO - Iter [17750/160000]	lr: 5.334e-05, eta: 1 day, 7:45:19, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4562, decode.acc_seg: 82.2055, aux.loss_ce: 0.1993, aux.acc_seg: 81.1365, loss: 0.6555
2023-11-26 17:43:58,865 - mmseg - INFO - Iter [17800/160000]	lr: 5.333e-05, eta: 1 day, 7:44:15, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4326, decode.acc_seg: 83.1444, aux.loss_ce: 0.1895, aux.acc_seg: 82.1779, loss: 0.6220
2023-11-26 17:44:38,989 - mmseg - INFO - Iter [17850/160000]	lr: 5.331e-05, eta: 1 day, 7:43:35, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4667, decode.acc_seg: 82.1454, aux.loss_ce: 0.2050, aux.acc_seg: 81.0658, loss: 0.6717
2023-11-26 17:45:19,178 - mmseg - INFO - Iter [17900/160000]	lr: 5.329e-05, eta: 1 day, 7:42:55, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4540, decode.acc_seg: 82.7062, aux.loss_ce: 0.1991, aux.acc_seg: 81.7819, loss: 0.6530
2023-11-26 17:45:59,310 - mmseg - INFO - Iter [17950/160000]	lr: 5.327e-05, eta: 1 day, 7:42:14, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4752, decode.acc_seg: 81.7907, aux.loss_ce: 0.2064, aux.acc_seg: 80.8566, loss: 0.6817
2023-11-26 17:46:39,022 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:46:39,022 - mmseg - INFO - Iter [18000/160000]	lr: 5.325e-05, eta: 1 day, 7:41:31, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4860, decode.acc_seg: 81.8470, aux.loss_ce: 0.2147, aux.acc_seg: 80.4893, loss: 0.7007
2023-11-26 17:47:17,181 - mmseg - INFO - Iter [18050/160000]	lr: 5.323e-05, eta: 1 day, 7:40:34, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.5058, decode.acc_seg: 80.9673, aux.loss_ce: 0.2182, aux.acc_seg: 80.1238, loss: 0.7240
2023-11-26 17:47:57,622 - mmseg - INFO - Iter [18100/160000]	lr: 5.321e-05, eta: 1 day, 7:39:56, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4662, decode.acc_seg: 82.1479, aux.loss_ce: 0.2052, aux.acc_seg: 81.0456, loss: 0.6714
2023-11-26 17:48:38,003 - mmseg - INFO - Iter [18150/160000]	lr: 5.319e-05, eta: 1 day, 7:39:18, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5000, decode.acc_seg: 81.3316, aux.loss_ce: 0.2166, aux.acc_seg: 80.5295, loss: 0.7166
2023-11-26 17:49:18,813 - mmseg - INFO - Iter [18200/160000]	lr: 5.318e-05, eta: 1 day, 7:38:43, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4826, decode.acc_seg: 81.1397, aux.loss_ce: 0.2089, aux.acc_seg: 80.0892, loss: 0.6915
2023-11-26 17:49:59,073 - mmseg - INFO - Iter [18250/160000]	lr: 5.316e-05, eta: 1 day, 7:38:03, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4938, decode.acc_seg: 81.4815, aux.loss_ce: 0.2140, aux.acc_seg: 80.4206, loss: 0.7078
2023-11-26 17:50:40,675 - mmseg - INFO - Iter [18300/160000]	lr: 5.314e-05, eta: 1 day, 7:37:34, time: 0.832, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4926, decode.acc_seg: 80.8243, aux.loss_ce: 0.2123, aux.acc_seg: 79.8240, loss: 0.7049
2023-11-26 17:51:21,737 - mmseg - INFO - Iter [18350/160000]	lr: 5.312e-05, eta: 1 day, 7:37:00, time: 0.821, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4707, decode.acc_seg: 81.7482, aux.loss_ce: 0.2044, aux.acc_seg: 80.9543, loss: 0.6751
2023-11-26 17:52:02,395 - mmseg - INFO - Iter [18400/160000]	lr: 5.310e-05, eta: 1 day, 7:36:24, time: 0.814, data_time: 0.012, memory: 21695, decode.loss_ce: 0.5157, decode.acc_seg: 80.2257, aux.loss_ce: 0.2257, aux.acc_seg: 78.9918, loss: 0.7414
2023-11-26 17:52:41,344 - mmseg - INFO - Iter [18450/160000]	lr: 5.308e-05, eta: 1 day, 7:35:34, time: 0.779, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4663, decode.acc_seg: 82.5900, aux.loss_ce: 0.2005, aux.acc_seg: 81.5954, loss: 0.6667
2023-11-26 17:53:20,320 - mmseg - INFO - Iter [18500/160000]	lr: 5.306e-05, eta: 1 day, 7:34:46, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4882, decode.acc_seg: 80.7288, aux.loss_ce: 0.2114, aux.acc_seg: 79.8948, loss: 0.6996
2023-11-26 17:53:58,378 - mmseg - INFO - Iter [18550/160000]	lr: 5.304e-05, eta: 1 day, 7:33:49, time: 0.760, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4829, decode.acc_seg: 81.2378, aux.loss_ce: 0.2110, aux.acc_seg: 80.1833, loss: 0.6940
2023-11-26 17:54:35,971 - mmseg - INFO - Iter [18600/160000]	lr: 5.303e-05, eta: 1 day, 7:32:49, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4540, decode.acc_seg: 82.3053, aux.loss_ce: 0.1944, aux.acc_seg: 81.7200, loss: 0.6484
2023-11-26 17:55:15,783 - mmseg - INFO - Iter [18650/160000]	lr: 5.301e-05, eta: 1 day, 7:32:06, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4927, decode.acc_seg: 81.3862, aux.loss_ce: 0.2156, aux.acc_seg: 80.4245, loss: 0.7083
2023-11-26 17:55:54,340 - mmseg - INFO - Iter [18700/160000]	lr: 5.299e-05, eta: 1 day, 7:31:14, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4537, decode.acc_seg: 82.6053, aux.loss_ce: 0.1972, aux.acc_seg: 81.7880, loss: 0.6509
2023-11-26 17:56:34,498 - mmseg - INFO - Iter [18750/160000]	lr: 5.297e-05, eta: 1 day, 7:30:34, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4920, decode.acc_seg: 80.8090, aux.loss_ce: 0.2142, aux.acc_seg: 79.8749, loss: 0.7062
2023-11-26 17:57:12,576 - mmseg - INFO - Iter [18800/160000]	lr: 5.295e-05, eta: 1 day, 7:29:38, time: 0.761, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4822, decode.acc_seg: 81.0142, aux.loss_ce: 0.2105, aux.acc_seg: 80.0782, loss: 0.6928
2023-11-26 17:57:52,941 - mmseg - INFO - Iter [18850/160000]	lr: 5.293e-05, eta: 1 day, 7:29:00, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5045, decode.acc_seg: 81.0483, aux.loss_ce: 0.2193, aux.acc_seg: 79.9907, loss: 0.7238
2023-11-26 17:58:32,218 - mmseg - INFO - Iter [18900/160000]	lr: 5.291e-05, eta: 1 day, 7:28:13, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5044, decode.acc_seg: 81.1061, aux.loss_ce: 0.2204, aux.acc_seg: 79.9345, loss: 0.7248
2023-11-26 17:59:12,915 - mmseg - INFO - Iter [18950/160000]	lr: 5.289e-05, eta: 1 day, 7:27:37, time: 0.814, data_time: 0.052, memory: 21695, decode.loss_ce: 0.4882, decode.acc_seg: 81.2979, aux.loss_ce: 0.2121, aux.acc_seg: 80.3503, loss: 0.7003
2023-11-26 17:59:50,968 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 17:59:50,969 - mmseg - INFO - Iter [19000/160000]	lr: 5.288e-05, eta: 1 day, 7:26:41, time: 0.759, data_time: 0.009, memory: 21695, decode.loss_ce: 0.4364, decode.acc_seg: 83.4965, aux.loss_ce: 0.1902, aux.acc_seg: 82.6851, loss: 0.6266
2023-11-26 18:00:32,125 - mmseg - INFO - Iter [19050/160000]	lr: 5.286e-05, eta: 1 day, 7:26:09, time: 0.825, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4228, decode.acc_seg: 82.7134, aux.loss_ce: 0.1849, aux.acc_seg: 81.9873, loss: 0.6077
2023-11-26 18:01:10,617 - mmseg - INFO - Iter [19100/160000]	lr: 5.284e-05, eta: 1 day, 7:25:17, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4310, decode.acc_seg: 83.9355, aux.loss_ce: 0.1904, aux.acc_seg: 82.8508, loss: 0.6214
2023-11-26 18:01:49,607 - mmseg - INFO - Iter [19150/160000]	lr: 5.282e-05, eta: 1 day, 7:24:28, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4594, decode.acc_seg: 82.2834, aux.loss_ce: 0.1995, aux.acc_seg: 81.3023, loss: 0.6589
2023-11-26 18:02:28,607 - mmseg - INFO - Iter [19200/160000]	lr: 5.280e-05, eta: 1 day, 7:23:39, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4527, decode.acc_seg: 82.3219, aux.loss_ce: 0.1985, aux.acc_seg: 81.4839, loss: 0.6512
2023-11-26 18:03:09,498 - mmseg - INFO - Iter [19250/160000]	lr: 5.278e-05, eta: 1 day, 7:23:05, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4655, decode.acc_seg: 82.1120, aux.loss_ce: 0.2066, aux.acc_seg: 80.7942, loss: 0.6721
2023-11-26 18:03:47,654 - mmseg - INFO - Iter [19300/160000]	lr: 5.276e-05, eta: 1 day, 7:22:10, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4464, decode.acc_seg: 82.6995, aux.loss_ce: 0.1967, aux.acc_seg: 81.7148, loss: 0.6431
2023-11-26 18:04:29,046 - mmseg - INFO - Iter [19350/160000]	lr: 5.274e-05, eta: 1 day, 7:21:39, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4763, decode.acc_seg: 82.0523, aux.loss_ce: 0.2066, aux.acc_seg: 80.7801, loss: 0.6829
2023-11-26 18:05:08,279 - mmseg - INFO - Iter [19400/160000]	lr: 5.273e-05, eta: 1 day, 7:20:53, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4673, decode.acc_seg: 82.3577, aux.loss_ce: 0.2051, aux.acc_seg: 81.2303, loss: 0.6724
2023-11-26 18:05:45,718 - mmseg - INFO - Iter [19450/160000]	lr: 5.271e-05, eta: 1 day, 7:19:53, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4681, decode.acc_seg: 82.3636, aux.loss_ce: 0.2068, aux.acc_seg: 81.0475, loss: 0.6749
2023-11-26 18:06:25,203 - mmseg - INFO - Iter [19500/160000]	lr: 5.269e-05, eta: 1 day, 7:19:08, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4481, decode.acc_seg: 82.3475, aux.loss_ce: 0.1938, aux.acc_seg: 81.6213, loss: 0.6419
2023-11-26 18:07:02,060 - mmseg - INFO - Iter [19550/160000]	lr: 5.267e-05, eta: 1 day, 7:18:05, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.5010, decode.acc_seg: 80.1490, aux.loss_ce: 0.2184, aux.acc_seg: 79.0302, loss: 0.7194
2023-11-26 18:07:41,118 - mmseg - INFO - Iter [19600/160000]	lr: 5.265e-05, eta: 1 day, 7:17:17, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4626, decode.acc_seg: 82.1942, aux.loss_ce: 0.2045, aux.acc_seg: 81.3158, loss: 0.6671
2023-11-26 18:08:20,986 - mmseg - INFO - Iter [19650/160000]	lr: 5.263e-05, eta: 1 day, 7:16:35, time: 0.798, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4548, decode.acc_seg: 82.3300, aux.loss_ce: 0.1984, aux.acc_seg: 81.4604, loss: 0.6532
2023-11-26 18:09:01,257 - mmseg - INFO - Iter [19700/160000]	lr: 5.261e-05, eta: 1 day, 7:15:56, time: 0.805, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4699, decode.acc_seg: 81.9217, aux.loss_ce: 0.2051, aux.acc_seg: 81.0193, loss: 0.6749
2023-11-26 18:09:42,068 - mmseg - INFO - Iter [19750/160000]	lr: 5.259e-05, eta: 1 day, 7:15:21, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4505, decode.acc_seg: 82.6103, aux.loss_ce: 0.1996, aux.acc_seg: 81.3005, loss: 0.6501
2023-11-26 18:10:21,518 - mmseg - INFO - Iter [19800/160000]	lr: 5.258e-05, eta: 1 day, 7:14:36, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4640, decode.acc_seg: 81.8132, aux.loss_ce: 0.2027, aux.acc_seg: 80.6866, loss: 0.6668
2023-11-26 18:11:00,382 - mmseg - INFO - Iter [19850/160000]	lr: 5.256e-05, eta: 1 day, 7:13:47, time: 0.778, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4705, decode.acc_seg: 81.8757, aux.loss_ce: 0.2059, aux.acc_seg: 80.6464, loss: 0.6764
2023-11-26 18:11:40,944 - mmseg - INFO - Iter [19900/160000]	lr: 5.254e-05, eta: 1 day, 7:13:10, time: 0.811, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4851, decode.acc_seg: 81.1818, aux.loss_ce: 0.2123, aux.acc_seg: 80.5143, loss: 0.6975
2023-11-26 18:12:19,998 - mmseg - INFO - Iter [19950/160000]	lr: 5.252e-05, eta: 1 day, 7:12:23, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4543, decode.acc_seg: 83.3897, aux.loss_ce: 0.1963, aux.acc_seg: 82.4782, loss: 0.6506
2023-11-26 18:12:56,991 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 18:12:56,991 - mmseg - INFO - Iter [20000/160000]	lr: 5.250e-05, eta: 1 day, 7:11:21, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4474, decode.acc_seg: 81.8526, aux.loss_ce: 0.1978, aux.acc_seg: 80.8377, loss: 0.6452
2023-11-26 18:13:37,262 - mmseg - INFO - Iter [20050/160000]	lr: 5.248e-05, eta: 1 day, 7:10:42, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4542, decode.acc_seg: 82.5848, aux.loss_ce: 0.1990, aux.acc_seg: 81.3975, loss: 0.6532
2023-11-26 18:14:17,165 - mmseg - INFO - Iter [20100/160000]	lr: 5.246e-05, eta: 1 day, 7:10:00, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4731, decode.acc_seg: 82.1208, aux.loss_ce: 0.2054, aux.acc_seg: 81.1014, loss: 0.6785
2023-11-26 18:14:57,422 - mmseg - INFO - Iter [20150/160000]	lr: 5.244e-05, eta: 1 day, 7:09:21, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4910, decode.acc_seg: 81.5088, aux.loss_ce: 0.2137, aux.acc_seg: 80.6503, loss: 0.7047
2023-11-26 18:15:38,642 - mmseg - INFO - Iter [20200/160000]	lr: 5.243e-05, eta: 1 day, 7:08:49, time: 0.824, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4724, decode.acc_seg: 81.7267, aux.loss_ce: 0.2026, aux.acc_seg: 80.7437, loss: 0.6750
2023-11-26 18:16:20,788 - mmseg - INFO - Iter [20250/160000]	lr: 5.241e-05, eta: 1 day, 7:08:23, time: 0.843, data_time: 0.053, memory: 21695, decode.loss_ce: 0.4420, decode.acc_seg: 82.8277, aux.loss_ce: 0.1995, aux.acc_seg: 81.1690, loss: 0.6415
2023-11-26 18:17:00,683 - mmseg - INFO - Iter [20300/160000]	lr: 5.239e-05, eta: 1 day, 7:07:41, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4353, decode.acc_seg: 83.5064, aux.loss_ce: 0.1881, aux.acc_seg: 82.7890, loss: 0.6233
2023-11-26 18:17:39,281 - mmseg - INFO - Iter [20350/160000]	lr: 5.237e-05, eta: 1 day, 7:06:51, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4310, decode.acc_seg: 83.6351, aux.loss_ce: 0.1906, aux.acc_seg: 82.4292, loss: 0.6216
2023-11-26 18:18:19,861 - mmseg - INFO - Iter [20400/160000]	lr: 5.235e-05, eta: 1 day, 7:06:14, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4384, decode.acc_seg: 83.2723, aux.loss_ce: 0.1929, aux.acc_seg: 82.3810, loss: 0.6313
2023-11-26 18:19:00,334 - mmseg - INFO - Iter [20450/160000]	lr: 5.233e-05, eta: 1 day, 7:05:36, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4420, decode.acc_seg: 83.4486, aux.loss_ce: 0.1944, aux.acc_seg: 82.2766, loss: 0.6364
2023-11-26 18:19:37,903 - mmseg - INFO - Iter [20500/160000]	lr: 5.231e-05, eta: 1 day, 7:04:39, time: 0.752, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4399, decode.acc_seg: 83.2568, aux.loss_ce: 0.1931, aux.acc_seg: 82.1024, loss: 0.6330
2023-11-26 18:20:17,894 - mmseg - INFO - Iter [20550/160000]	lr: 5.229e-05, eta: 1 day, 7:03:58, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4360, decode.acc_seg: 82.7287, aux.loss_ce: 0.1897, aux.acc_seg: 81.9511, loss: 0.6256
2023-11-26 18:20:58,938 - mmseg - INFO - Iter [20600/160000]	lr: 5.228e-05, eta: 1 day, 7:03:24, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4607, decode.acc_seg: 82.2053, aux.loss_ce: 0.1994, aux.acc_seg: 81.0140, loss: 0.6601
2023-11-26 18:21:38,928 - mmseg - INFO - Iter [20650/160000]	lr: 5.226e-05, eta: 1 day, 7:02:44, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4727, decode.acc_seg: 81.3272, aux.loss_ce: 0.2049, aux.acc_seg: 80.4973, loss: 0.6776
2023-11-26 18:22:15,734 - mmseg - INFO - Iter [20700/160000]	lr: 5.224e-05, eta: 1 day, 7:01:42, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4843, decode.acc_seg: 81.5649, aux.loss_ce: 0.2097, aux.acc_seg: 80.6316, loss: 0.6939
2023-11-26 18:22:52,651 - mmseg - INFO - Iter [20750/160000]	lr: 5.222e-05, eta: 1 day, 7:00:40, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4672, decode.acc_seg: 82.3893, aux.loss_ce: 0.2025, aux.acc_seg: 81.3497, loss: 0.6697
2023-11-26 18:23:30,483 - mmseg - INFO - Iter [20800/160000]	lr: 5.220e-05, eta: 1 day, 6:59:45, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4697, decode.acc_seg: 82.0105, aux.loss_ce: 0.2025, aux.acc_seg: 81.4942, loss: 0.6722
2023-11-26 18:24:09,134 - mmseg - INFO - Iter [20850/160000]	lr: 5.218e-05, eta: 1 day, 6:58:55, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4538, decode.acc_seg: 82.2126, aux.loss_ce: 0.2002, aux.acc_seg: 80.9496, loss: 0.6540
2023-11-26 18:24:49,451 - mmseg - INFO - Iter [20900/160000]	lr: 5.216e-05, eta: 1 day, 6:58:17, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4322, decode.acc_seg: 83.8402, aux.loss_ce: 0.1893, aux.acc_seg: 82.6822, loss: 0.6215
2023-11-26 18:25:29,840 - mmseg - INFO - Iter [20950/160000]	lr: 5.214e-05, eta: 1 day, 6:57:39, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4670, decode.acc_seg: 82.3943, aux.loss_ce: 0.2046, aux.acc_seg: 80.9195, loss: 0.6716
2023-11-26 18:26:10,040 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 18:26:10,040 - mmseg - INFO - Iter [21000/160000]	lr: 5.213e-05, eta: 1 day, 6:57:00, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4584, decode.acc_seg: 82.9320, aux.loss_ce: 0.2023, aux.acc_seg: 81.7879, loss: 0.6607
2023-11-26 18:26:49,647 - mmseg - INFO - Iter [21050/160000]	lr: 5.211e-05, eta: 1 day, 6:56:16, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4540, decode.acc_seg: 82.5475, aux.loss_ce: 0.1984, aux.acc_seg: 81.4262, loss: 0.6524
2023-11-26 18:27:29,072 - mmseg - INFO - Iter [21100/160000]	lr: 5.209e-05, eta: 1 day, 6:55:32, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4410, decode.acc_seg: 82.6163, aux.loss_ce: 0.1929, aux.acc_seg: 81.7458, loss: 0.6339
2023-11-26 18:28:08,227 - mmseg - INFO - Iter [21150/160000]	lr: 5.207e-05, eta: 1 day, 6:54:46, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4449, decode.acc_seg: 82.9159, aux.loss_ce: 0.1942, aux.acc_seg: 81.8227, loss: 0.6390
2023-11-26 18:28:47,272 - mmseg - INFO - Iter [21200/160000]	lr: 5.205e-05, eta: 1 day, 6:53:59, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4666, decode.acc_seg: 81.9382, aux.loss_ce: 0.2030, aux.acc_seg: 81.0140, loss: 0.6696
2023-11-26 18:29:26,177 - mmseg - INFO - Iter [21250/160000]	lr: 5.203e-05, eta: 1 day, 6:53:11, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4399, decode.acc_seg: 83.0634, aux.loss_ce: 0.1914, aux.acc_seg: 81.8197, loss: 0.6313
2023-11-26 18:30:04,109 - mmseg - INFO - Iter [21300/160000]	lr: 5.201e-05, eta: 1 day, 6:52:17, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4718, decode.acc_seg: 82.0217, aux.loss_ce: 0.2074, aux.acc_seg: 80.5318, loss: 0.6793
2023-11-26 18:30:41,949 - mmseg - INFO - Iter [21350/160000]	lr: 5.199e-05, eta: 1 day, 6:51:23, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4553, decode.acc_seg: 82.8798, aux.loss_ce: 0.1962, aux.acc_seg: 81.8700, loss: 0.6515
2023-11-26 18:31:20,245 - mmseg - INFO - Iter [21400/160000]	lr: 5.198e-05, eta: 1 day, 6:50:31, time: 0.767, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4708, decode.acc_seg: 82.0883, aux.loss_ce: 0.2055, aux.acc_seg: 80.9515, loss: 0.6763
2023-11-26 18:31:58,790 - mmseg - INFO - Iter [21450/160000]	lr: 5.196e-05, eta: 1 day, 6:49:42, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4455, decode.acc_seg: 82.8202, aux.loss_ce: 0.1975, aux.acc_seg: 81.4802, loss: 0.6431
2023-11-26 18:32:38,873 - mmseg - INFO - Iter [21500/160000]	lr: 5.194e-05, eta: 1 day, 6:49:01, time: 0.801, data_time: 0.052, memory: 21695, decode.loss_ce: 0.4467, decode.acc_seg: 82.9088, aux.loss_ce: 0.1982, aux.acc_seg: 81.7719, loss: 0.6449
2023-11-26 18:33:17,376 - mmseg - INFO - Iter [21550/160000]	lr: 5.192e-05, eta: 1 day, 6:48:11, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4381, decode.acc_seg: 83.0471, aux.loss_ce: 0.1945, aux.acc_seg: 82.0197, loss: 0.6326
2023-11-26 18:33:54,396 - mmseg - INFO - Iter [21600/160000]	lr: 5.190e-05, eta: 1 day, 6:47:12, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4413, decode.acc_seg: 83.3071, aux.loss_ce: 0.1961, aux.acc_seg: 82.0742, loss: 0.6375
2023-11-26 18:34:33,210 - mmseg - INFO - Iter [21650/160000]	lr: 5.188e-05, eta: 1 day, 6:46:24, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4404, decode.acc_seg: 82.6677, aux.loss_ce: 0.1944, aux.acc_seg: 81.5137, loss: 0.6348
2023-11-26 18:35:13,243 - mmseg - INFO - Iter [21700/160000]	lr: 5.186e-05, eta: 1 day, 6:45:44, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4517, decode.acc_seg: 82.5619, aux.loss_ce: 0.1975, aux.acc_seg: 81.6389, loss: 0.6492
2023-11-26 18:35:54,085 - mmseg - INFO - Iter [21750/160000]	lr: 5.184e-05, eta: 1 day, 6:45:09, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4276, decode.acc_seg: 83.5465, aux.loss_ce: 0.1894, aux.acc_seg: 82.4704, loss: 0.6170
2023-11-26 18:36:34,068 - mmseg - INFO - Iter [21800/160000]	lr: 5.183e-05, eta: 1 day, 6:44:29, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4269, decode.acc_seg: 83.6884, aux.loss_ce: 0.1874, aux.acc_seg: 82.9535, loss: 0.6143
2023-11-26 18:37:12,884 - mmseg - INFO - Iter [21850/160000]	lr: 5.181e-05, eta: 1 day, 6:43:41, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4278, decode.acc_seg: 83.3717, aux.loss_ce: 0.1880, aux.acc_seg: 82.1788, loss: 0.6158
2023-11-26 18:37:53,168 - mmseg - INFO - Iter [21900/160000]	lr: 5.179e-05, eta: 1 day, 6:43:02, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4285, decode.acc_seg: 83.0949, aux.loss_ce: 0.1887, aux.acc_seg: 82.0637, loss: 0.6172
2023-11-26 18:38:33,459 - mmseg - INFO - Iter [21950/160000]	lr: 5.177e-05, eta: 1 day, 6:42:24, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4298, decode.acc_seg: 83.2746, aux.loss_ce: 0.1880, aux.acc_seg: 82.4892, loss: 0.6178
2023-11-26 18:39:11,748 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 18:39:11,749 - mmseg - INFO - Iter [22000/160000]	lr: 5.175e-05, eta: 1 day, 6:41:33, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4666, decode.acc_seg: 82.1391, aux.loss_ce: 0.2044, aux.acc_seg: 81.0339, loss: 0.6710
2023-11-26 18:39:52,734 - mmseg - INFO - Iter [22050/160000]	lr: 5.173e-05, eta: 1 day, 6:40:59, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4626, decode.acc_seg: 82.3657, aux.loss_ce: 0.1983, aux.acc_seg: 81.5435, loss: 0.6610
2023-11-26 18:40:34,100 - mmseg - INFO - Iter [22100/160000]	lr: 5.171e-05, eta: 1 day, 6:40:27, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4420, decode.acc_seg: 82.8838, aux.loss_ce: 0.1964, aux.acc_seg: 81.6112, loss: 0.6384
2023-11-26 18:41:14,074 - mmseg - INFO - Iter [22150/160000]	lr: 5.169e-05, eta: 1 day, 6:39:47, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4303, decode.acc_seg: 83.7235, aux.loss_ce: 0.1897, aux.acc_seg: 82.6437, loss: 0.6199
2023-11-26 18:41:54,036 - mmseg - INFO - Iter [22200/160000]	lr: 5.168e-05, eta: 1 day, 6:39:06, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4175, decode.acc_seg: 83.5633, aux.loss_ce: 0.1851, aux.acc_seg: 82.6352, loss: 0.6026
2023-11-26 18:42:34,128 - mmseg - INFO - Iter [22250/160000]	lr: 5.166e-05, eta: 1 day, 6:38:27, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4462, decode.acc_seg: 82.5129, aux.loss_ce: 0.1956, aux.acc_seg: 81.4374, loss: 0.6418
2023-11-26 18:43:13,738 - mmseg - INFO - Iter [22300/160000]	lr: 5.164e-05, eta: 1 day, 6:37:44, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4261, decode.acc_seg: 82.9686, aux.loss_ce: 0.1878, aux.acc_seg: 81.8191, loss: 0.6139
2023-11-26 18:43:54,671 - mmseg - INFO - Iter [22350/160000]	lr: 5.162e-05, eta: 1 day, 6:37:10, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4472, decode.acc_seg: 83.0306, aux.loss_ce: 0.1985, aux.acc_seg: 81.5792, loss: 0.6457
2023-11-26 18:44:31,946 - mmseg - INFO - Iter [22400/160000]	lr: 5.160e-05, eta: 1 day, 6:36:13, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4350, decode.acc_seg: 82.9408, aux.loss_ce: 0.1869, aux.acc_seg: 82.1999, loss: 0.6219
2023-11-26 18:45:11,176 - mmseg - INFO - Iter [22450/160000]	lr: 5.158e-05, eta: 1 day, 6:35:27, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4447, decode.acc_seg: 82.8709, aux.loss_ce: 0.1906, aux.acc_seg: 82.1485, loss: 0.6353
2023-11-26 18:45:51,004 - mmseg - INFO - Iter [22500/160000]	lr: 5.156e-05, eta: 1 day, 6:34:46, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4583, decode.acc_seg: 82.3864, aux.loss_ce: 0.1984, aux.acc_seg: 81.6845, loss: 0.6567
2023-11-26 18:46:31,044 - mmseg - INFO - Iter [22550/160000]	lr: 5.154e-05, eta: 1 day, 6:34:06, time: 0.802, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4470, decode.acc_seg: 82.9129, aux.loss_ce: 0.1944, aux.acc_seg: 81.7761, loss: 0.6414
2023-11-26 18:47:11,127 - mmseg - INFO - Iter [22600/160000]	lr: 5.153e-05, eta: 1 day, 6:33:26, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4685, decode.acc_seg: 82.5844, aux.loss_ce: 0.2033, aux.acc_seg: 81.6902, loss: 0.6718
2023-11-26 18:47:49,896 - mmseg - INFO - Iter [22650/160000]	lr: 5.151e-05, eta: 1 day, 6:32:39, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4669, decode.acc_seg: 82.1022, aux.loss_ce: 0.2054, aux.acc_seg: 80.6652, loss: 0.6723
2023-11-26 18:48:28,342 - mmseg - INFO - Iter [22700/160000]	lr: 5.149e-05, eta: 1 day, 6:31:49, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4345, decode.acc_seg: 82.9529, aux.loss_ce: 0.1881, aux.acc_seg: 82.2780, loss: 0.6226
2023-11-26 18:49:08,509 - mmseg - INFO - Iter [22750/160000]	lr: 5.147e-05, eta: 1 day, 6:31:10, time: 0.802, data_time: 0.052, memory: 21695, decode.loss_ce: 0.4221, decode.acc_seg: 83.1393, aux.loss_ce: 0.1853, aux.acc_seg: 81.9753, loss: 0.6075
2023-11-26 18:49:49,370 - mmseg - INFO - Iter [22800/160000]	lr: 5.145e-05, eta: 1 day, 6:30:35, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4221, decode.acc_seg: 83.7225, aux.loss_ce: 0.1869, aux.acc_seg: 82.2854, loss: 0.6090
2023-11-26 18:50:29,537 - mmseg - INFO - Iter [22850/160000]	lr: 5.143e-05, eta: 1 day, 6:29:56, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4362, decode.acc_seg: 82.8990, aux.loss_ce: 0.1922, aux.acc_seg: 81.9359, loss: 0.6284
2023-11-26 18:51:08,445 - mmseg - INFO - Iter [22900/160000]	lr: 5.141e-05, eta: 1 day, 6:29:09, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4200, decode.acc_seg: 83.9372, aux.loss_ce: 0.1879, aux.acc_seg: 82.3501, loss: 0.6078
2023-11-26 18:51:45,076 - mmseg - INFO - Iter [22950/160000]	lr: 5.139e-05, eta: 1 day, 6:28:09, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4176, decode.acc_seg: 83.4203, aux.loss_ce: 0.1832, aux.acc_seg: 82.4155, loss: 0.6008
2023-11-26 18:52:24,068 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 18:52:24,068 - mmseg - INFO - Iter [23000/160000]	lr: 5.138e-05, eta: 1 day, 6:27:22, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4230, decode.acc_seg: 83.7210, aux.loss_ce: 0.1859, aux.acc_seg: 82.4854, loss: 0.6089
2023-11-26 18:53:02,886 - mmseg - INFO - Iter [23050/160000]	lr: 5.136e-05, eta: 1 day, 6:26:36, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4323, decode.acc_seg: 83.0605, aux.loss_ce: 0.1901, aux.acc_seg: 81.8343, loss: 0.6224
2023-11-26 18:53:41,247 - mmseg - INFO - Iter [23100/160000]	lr: 5.134e-05, eta: 1 day, 6:25:45, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4439, decode.acc_seg: 83.5251, aux.loss_ce: 0.1995, aux.acc_seg: 82.1133, loss: 0.6434
2023-11-26 18:54:19,990 - mmseg - INFO - Iter [23150/160000]	lr: 5.132e-05, eta: 1 day, 6:24:58, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4301, decode.acc_seg: 83.7921, aux.loss_ce: 0.1881, aux.acc_seg: 82.7240, loss: 0.6181
2023-11-26 18:54:59,955 - mmseg - INFO - Iter [23200/160000]	lr: 5.130e-05, eta: 1 day, 6:24:18, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4480, decode.acc_seg: 83.1226, aux.loss_ce: 0.1977, aux.acc_seg: 82.0524, loss: 0.6457
2023-11-26 18:55:39,546 - mmseg - INFO - Iter [23250/160000]	lr: 5.128e-05, eta: 1 day, 6:23:35, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4323, decode.acc_seg: 82.9432, aux.loss_ce: 0.1899, aux.acc_seg: 81.9841, loss: 0.6222
2023-11-26 18:56:18,985 - mmseg - INFO - Iter [23300/160000]	lr: 5.126e-05, eta: 1 day, 6:22:52, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4255, decode.acc_seg: 83.0659, aux.loss_ce: 0.1849, aux.acc_seg: 82.3932, loss: 0.6103
2023-11-26 18:57:00,301 - mmseg - INFO - Iter [23350/160000]	lr: 5.124e-05, eta: 1 day, 6:22:20, time: 0.826, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4440, decode.acc_seg: 83.1461, aux.loss_ce: 0.1934, aux.acc_seg: 82.2221, loss: 0.6374
2023-11-26 18:57:41,336 - mmseg - INFO - Iter [23400/160000]	lr: 5.123e-05, eta: 1 day, 6:21:46, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4306, decode.acc_seg: 83.5651, aux.loss_ce: 0.1869, aux.acc_seg: 82.6517, loss: 0.6175
2023-11-26 18:58:21,820 - mmseg - INFO - Iter [23450/160000]	lr: 5.121e-05, eta: 1 day, 6:21:08, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4420, decode.acc_seg: 83.2967, aux.loss_ce: 0.1953, aux.acc_seg: 82.2480, loss: 0.6373
2023-11-26 18:59:01,607 - mmseg - INFO - Iter [23500/160000]	lr: 5.119e-05, eta: 1 day, 6:20:27, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4419, decode.acc_seg: 82.8853, aux.loss_ce: 0.1947, aux.acc_seg: 81.8222, loss: 0.6366
2023-11-26 18:59:41,686 - mmseg - INFO - Iter [23550/160000]	lr: 5.117e-05, eta: 1 day, 6:19:47, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4146, decode.acc_seg: 83.6448, aux.loss_ce: 0.1829, aux.acc_seg: 82.6503, loss: 0.5975
2023-11-26 19:00:20,595 - mmseg - INFO - Iter [23600/160000]	lr: 5.115e-05, eta: 1 day, 6:19:01, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4686, decode.acc_seg: 82.6548, aux.loss_ce: 0.2030, aux.acc_seg: 81.7052, loss: 0.6717
2023-11-26 19:01:02,005 - mmseg - INFO - Iter [23650/160000]	lr: 5.113e-05, eta: 1 day, 6:18:29, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4183, decode.acc_seg: 83.2071, aux.loss_ce: 0.1858, aux.acc_seg: 82.1547, loss: 0.6041
2023-11-26 19:01:41,421 - mmseg - INFO - Iter [23700/160000]	lr: 5.111e-05, eta: 1 day, 6:17:46, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4794, decode.acc_seg: 81.3616, aux.loss_ce: 0.2062, aux.acc_seg: 80.6410, loss: 0.6856
2023-11-26 19:02:19,108 - mmseg - INFO - Iter [23750/160000]	lr: 5.109e-05, eta: 1 day, 6:16:53, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4274, decode.acc_seg: 83.2887, aux.loss_ce: 0.1862, aux.acc_seg: 82.2483, loss: 0.6136
2023-11-26 19:02:57,375 - mmseg - INFO - Iter [23800/160000]	lr: 5.108e-05, eta: 1 day, 6:16:03, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4369, decode.acc_seg: 83.6360, aux.loss_ce: 0.1935, aux.acc_seg: 82.6969, loss: 0.6304
2023-11-26 19:03:37,199 - mmseg - INFO - Iter [23850/160000]	lr: 5.106e-05, eta: 1 day, 6:15:21, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4704, decode.acc_seg: 81.8534, aux.loss_ce: 0.2064, aux.acc_seg: 80.6875, loss: 0.6768
2023-11-26 19:04:15,022 - mmseg - INFO - Iter [23900/160000]	lr: 5.104e-05, eta: 1 day, 6:14:29, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4328, decode.acc_seg: 82.6643, aux.loss_ce: 0.1884, aux.acc_seg: 81.7507, loss: 0.6212
2023-11-26 19:04:53,078 - mmseg - INFO - Iter [23950/160000]	lr: 5.102e-05, eta: 1 day, 6:13:38, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4125, decode.acc_seg: 83.2303, aux.loss_ce: 0.1804, aux.acc_seg: 82.0422, loss: 0.5929
2023-11-26 19:05:32,414 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 19:05:32,414 - mmseg - INFO - Iter [24000/160000]	lr: 5.100e-05, eta: 1 day, 6:12:54, time: 0.785, data_time: 0.054, memory: 21695, decode.loss_ce: 0.4576, decode.acc_seg: 82.1798, aux.loss_ce: 0.1982, aux.acc_seg: 81.2473, loss: 0.6559
2023-11-26 19:06:11,534 - mmseg - INFO - Iter [24050/160000]	lr: 5.098e-05, eta: 1 day, 6:12:10, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4043, decode.acc_seg: 84.1083, aux.loss_ce: 0.1775, aux.acc_seg: 82.9980, loss: 0.5818
2023-11-26 19:06:49,563 - mmseg - INFO - Iter [24100/160000]	lr: 5.096e-05, eta: 1 day, 6:11:19, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4264, decode.acc_seg: 83.5589, aux.loss_ce: 0.1853, aux.acc_seg: 82.5148, loss: 0.6117
2023-11-26 19:07:28,122 - mmseg - INFO - Iter [24150/160000]	lr: 5.094e-05, eta: 1 day, 6:10:30, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4302, decode.acc_seg: 83.0797, aux.loss_ce: 0.1911, aux.acc_seg: 81.8382, loss: 0.6213
2023-11-26 19:08:08,278 - mmseg - INFO - Iter [24200/160000]	lr: 5.093e-05, eta: 1 day, 6:09:51, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4029, decode.acc_seg: 83.9526, aux.loss_ce: 0.1802, aux.acc_seg: 82.8280, loss: 0.5831
2023-11-26 19:08:49,009 - mmseg - INFO - Iter [24250/160000]	lr: 5.091e-05, eta: 1 day, 6:09:16, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4212, decode.acc_seg: 83.6484, aux.loss_ce: 0.1890, aux.acc_seg: 82.2051, loss: 0.6102
2023-11-26 19:09:25,930 - mmseg - INFO - Iter [24300/160000]	lr: 5.089e-05, eta: 1 day, 6:08:19, time: 0.739, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4307, decode.acc_seg: 83.6256, aux.loss_ce: 0.1900, aux.acc_seg: 82.5299, loss: 0.6208
2023-11-26 19:10:02,964 - mmseg - INFO - Iter [24350/160000]	lr: 5.087e-05, eta: 1 day, 6:07:22, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4384, decode.acc_seg: 82.9059, aux.loss_ce: 0.1935, aux.acc_seg: 81.8567, loss: 0.6319
2023-11-26 19:10:39,888 - mmseg - INFO - Iter [24400/160000]	lr: 5.085e-05, eta: 1 day, 6:06:25, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4154, decode.acc_seg: 83.4607, aux.loss_ce: 0.1800, aux.acc_seg: 82.5371, loss: 0.5954
2023-11-26 19:11:19,135 - mmseg - INFO - Iter [24450/160000]	lr: 5.083e-05, eta: 1 day, 6:05:41, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4414, decode.acc_seg: 82.7106, aux.loss_ce: 0.1931, aux.acc_seg: 81.5443, loss: 0.6345
2023-11-26 19:11:59,188 - mmseg - INFO - Iter [24500/160000]	lr: 5.081e-05, eta: 1 day, 6:05:02, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4172, decode.acc_seg: 83.5077, aux.loss_ce: 0.1831, aux.acc_seg: 82.3199, loss: 0.6003
2023-11-26 19:12:39,692 - mmseg - INFO - Iter [24550/160000]	lr: 5.079e-05, eta: 1 day, 6:04:25, time: 0.810, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4012, decode.acc_seg: 84.1907, aux.loss_ce: 0.1783, aux.acc_seg: 83.0396, loss: 0.5795
2023-11-26 19:13:20,412 - mmseg - INFO - Iter [24600/160000]	lr: 5.078e-05, eta: 1 day, 6:03:49, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4290, decode.acc_seg: 83.5391, aux.loss_ce: 0.1907, aux.acc_seg: 82.1782, loss: 0.6197
2023-11-26 19:13:59,791 - mmseg - INFO - Iter [24650/160000]	lr: 5.076e-05, eta: 1 day, 6:03:06, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4195, decode.acc_seg: 83.3563, aux.loss_ce: 0.1850, aux.acc_seg: 82.2163, loss: 0.6045
2023-11-26 19:14:40,150 - mmseg - INFO - Iter [24700/160000]	lr: 5.074e-05, eta: 1 day, 6:02:28, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4104, decode.acc_seg: 83.8458, aux.loss_ce: 0.1811, aux.acc_seg: 82.9051, loss: 0.5915
2023-11-26 19:15:21,106 - mmseg - INFO - Iter [24750/160000]	lr: 5.072e-05, eta: 1 day, 6:01:53, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4426, decode.acc_seg: 82.3774, aux.loss_ce: 0.1947, aux.acc_seg: 81.3401, loss: 0.6373
2023-11-26 19:15:58,697 - mmseg - INFO - Iter [24800/160000]	lr: 5.070e-05, eta: 1 day, 6:01:00, time: 0.752, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4328, decode.acc_seg: 83.3065, aux.loss_ce: 0.1883, aux.acc_seg: 82.4140, loss: 0.6211
2023-11-26 19:16:37,091 - mmseg - INFO - Iter [24850/160000]	lr: 5.068e-05, eta: 1 day, 6:00:12, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4299, decode.acc_seg: 83.0918, aux.loss_ce: 0.1903, aux.acc_seg: 81.8663, loss: 0.6202
2023-11-26 19:17:17,091 - mmseg - INFO - Iter [24900/160000]	lr: 5.066e-05, eta: 1 day, 5:59:32, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4314, decode.acc_seg: 83.2095, aux.loss_ce: 0.1893, aux.acc_seg: 82.3790, loss: 0.6207
2023-11-26 19:17:56,529 - mmseg - INFO - Iter [24950/160000]	lr: 5.064e-05, eta: 1 day, 5:58:49, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3899, decode.acc_seg: 84.5802, aux.loss_ce: 0.1712, aux.acc_seg: 83.6386, loss: 0.5611
2023-11-26 19:18:36,426 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 19:18:36,426 - mmseg - INFO - Iter [25000/160000]	lr: 5.063e-05, eta: 1 day, 5:58:09, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4341, decode.acc_seg: 82.9765, aux.loss_ce: 0.1890, aux.acc_seg: 81.9093, loss: 0.6230
2023-11-26 19:19:17,547 - mmseg - INFO - Iter [25050/160000]	lr: 5.061e-05, eta: 1 day, 5:57:35, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4032, decode.acc_seg: 84.1468, aux.loss_ce: 0.1793, aux.acc_seg: 83.0923, loss: 0.5824
2023-11-26 19:19:58,421 - mmseg - INFO - Iter [25100/160000]	lr: 5.059e-05, eta: 1 day, 5:57:00, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4171, decode.acc_seg: 83.6327, aux.loss_ce: 0.1841, aux.acc_seg: 82.8990, loss: 0.6012
2023-11-26 19:20:37,650 - mmseg - INFO - Iter [25150/160000]	lr: 5.057e-05, eta: 1 day, 5:56:17, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4316, decode.acc_seg: 83.3404, aux.loss_ce: 0.1914, aux.acc_seg: 81.9311, loss: 0.6230
2023-11-26 19:21:17,959 - mmseg - INFO - Iter [25200/160000]	lr: 5.055e-05, eta: 1 day, 5:55:38, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4448, decode.acc_seg: 83.0722, aux.loss_ce: 0.1942, aux.acc_seg: 81.8663, loss: 0.6390
2023-11-26 19:21:57,507 - mmseg - INFO - Iter [25250/160000]	lr: 5.053e-05, eta: 1 day, 5:54:56, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4139, decode.acc_seg: 83.8678, aux.loss_ce: 0.1801, aux.acc_seg: 83.1420, loss: 0.5940
2023-11-26 19:22:38,096 - mmseg - INFO - Iter [25300/160000]	lr: 5.051e-05, eta: 1 day, 5:54:19, time: 0.811, data_time: 0.052, memory: 21695, decode.loss_ce: 0.4128, decode.acc_seg: 83.6923, aux.loss_ce: 0.1819, aux.acc_seg: 82.5510, loss: 0.5947
2023-11-26 19:23:19,023 - mmseg - INFO - Iter [25350/160000]	lr: 5.049e-05, eta: 1 day, 5:53:45, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3844, decode.acc_seg: 84.8777, aux.loss_ce: 0.1721, aux.acc_seg: 83.8169, loss: 0.5564
2023-11-26 19:24:00,359 - mmseg - INFO - Iter [25400/160000]	lr: 5.048e-05, eta: 1 day, 5:53:12, time: 0.827, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4154, decode.acc_seg: 83.6385, aux.loss_ce: 0.1811, aux.acc_seg: 82.8637, loss: 0.5965
2023-11-26 19:24:41,320 - mmseg - INFO - Iter [25450/160000]	lr: 5.046e-05, eta: 1 day, 5:52:37, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4319, decode.acc_seg: 83.6758, aux.loss_ce: 0.1897, aux.acc_seg: 82.3661, loss: 0.6216
2023-11-26 19:25:22,160 - mmseg - INFO - Iter [25500/160000]	lr: 5.044e-05, eta: 1 day, 5:52:02, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4309, decode.acc_seg: 83.2430, aux.loss_ce: 0.1900, aux.acc_seg: 82.1532, loss: 0.6209
2023-11-26 19:26:03,026 - mmseg - INFO - Iter [25550/160000]	lr: 5.042e-05, eta: 1 day, 5:51:27, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4087, decode.acc_seg: 84.1398, aux.loss_ce: 0.1789, aux.acc_seg: 83.0301, loss: 0.5876
2023-11-26 19:26:42,538 - mmseg - INFO - Iter [25600/160000]	lr: 5.040e-05, eta: 1 day, 5:50:44, time: 0.791, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4014, decode.acc_seg: 84.0897, aux.loss_ce: 0.1803, aux.acc_seg: 82.9046, loss: 0.5817
2023-11-26 19:27:20,879 - mmseg - INFO - Iter [25650/160000]	lr: 5.038e-05, eta: 1 day, 5:49:56, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4136, decode.acc_seg: 84.3781, aux.loss_ce: 0.1806, aux.acc_seg: 83.0035, loss: 0.5942
2023-11-26 19:27:58,258 - mmseg - INFO - Iter [25700/160000]	lr: 5.036e-05, eta: 1 day, 5:49:02, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4318, decode.acc_seg: 83.4329, aux.loss_ce: 0.1903, aux.acc_seg: 82.5183, loss: 0.6221
2023-11-26 19:28:35,248 - mmseg - INFO - Iter [25750/160000]	lr: 5.034e-05, eta: 1 day, 5:48:07, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4244, decode.acc_seg: 83.6037, aux.loss_ce: 0.1846, aux.acc_seg: 82.6090, loss: 0.6090
2023-11-26 19:29:12,264 - mmseg - INFO - Iter [25800/160000]	lr: 5.033e-05, eta: 1 day, 5:47:11, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4290, decode.acc_seg: 82.9753, aux.loss_ce: 0.1902, aux.acc_seg: 82.1121, loss: 0.6192
2023-11-26 19:29:51,534 - mmseg - INFO - Iter [25850/160000]	lr: 5.031e-05, eta: 1 day, 5:46:28, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3952, decode.acc_seg: 84.1233, aux.loss_ce: 0.1758, aux.acc_seg: 83.0355, loss: 0.5710
2023-11-26 19:30:31,220 - mmseg - INFO - Iter [25900/160000]	lr: 5.029e-05, eta: 1 day, 5:45:47, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4178, decode.acc_seg: 83.2555, aux.loss_ce: 0.1837, aux.acc_seg: 82.3400, loss: 0.6015
2023-11-26 19:31:09,311 - mmseg - INFO - Iter [25950/160000]	lr: 5.027e-05, eta: 1 day, 5:44:57, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4188, decode.acc_seg: 83.7632, aux.loss_ce: 0.1892, aux.acc_seg: 82.3083, loss: 0.6080
2023-11-26 19:31:49,910 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 19:31:49,911 - mmseg - INFO - Iter [26000/160000]	lr: 5.025e-05, eta: 1 day, 5:44:21, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4084, decode.acc_seg: 84.1415, aux.loss_ce: 0.1819, aux.acc_seg: 83.1510, loss: 0.5904
2023-11-26 19:32:28,465 - mmseg - INFO - Iter [26050/160000]	lr: 5.023e-05, eta: 1 day, 5:43:34, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4309, decode.acc_seg: 83.0204, aux.loss_ce: 0.1863, aux.acc_seg: 82.1823, loss: 0.6172
2023-11-26 19:33:06,187 - mmseg - INFO - Iter [26100/160000]	lr: 5.021e-05, eta: 1 day, 5:42:42, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4297, decode.acc_seg: 83.7277, aux.loss_ce: 0.1922, aux.acc_seg: 82.4850, loss: 0.6219
2023-11-26 19:33:46,475 - mmseg - INFO - Iter [26150/160000]	lr: 5.019e-05, eta: 1 day, 5:42:04, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4238, decode.acc_seg: 83.5552, aux.loss_ce: 0.1867, aux.acc_seg: 82.4020, loss: 0.6105
2023-11-26 19:34:27,214 - mmseg - INFO - Iter [26200/160000]	lr: 5.018e-05, eta: 1 day, 5:41:28, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4180, decode.acc_seg: 83.6785, aux.loss_ce: 0.1833, aux.acc_seg: 82.5975, loss: 0.6013
2023-11-26 19:35:07,488 - mmseg - INFO - Iter [26250/160000]	lr: 5.016e-05, eta: 1 day, 5:40:50, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3905, decode.acc_seg: 84.5113, aux.loss_ce: 0.1731, aux.acc_seg: 83.3198, loss: 0.5637
2023-11-26 19:35:45,261 - mmseg - INFO - Iter [26300/160000]	lr: 5.014e-05, eta: 1 day, 5:39:59, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4007, decode.acc_seg: 84.2700, aux.loss_ce: 0.1762, aux.acc_seg: 83.1485, loss: 0.5769
2023-11-26 19:36:24,447 - mmseg - INFO - Iter [26350/160000]	lr: 5.012e-05, eta: 1 day, 5:39:15, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4096, decode.acc_seg: 83.9188, aux.loss_ce: 0.1830, aux.acc_seg: 83.2064, loss: 0.5925
2023-11-26 19:37:04,344 - mmseg - INFO - Iter [26400/160000]	lr: 5.010e-05, eta: 1 day, 5:38:35, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4095, decode.acc_seg: 84.0273, aux.loss_ce: 0.1801, aux.acc_seg: 82.9797, loss: 0.5896
2023-11-26 19:37:44,218 - mmseg - INFO - Iter [26450/160000]	lr: 5.008e-05, eta: 1 day, 5:37:55, time: 0.798, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4298, decode.acc_seg: 83.1903, aux.loss_ce: 0.1901, aux.acc_seg: 81.8922, loss: 0.6200
2023-11-26 19:38:24,154 - mmseg - INFO - Iter [26500/160000]	lr: 5.006e-05, eta: 1 day, 5:37:15, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4072, decode.acc_seg: 83.9829, aux.loss_ce: 0.1830, aux.acc_seg: 82.1985, loss: 0.5902
2023-11-26 19:39:06,521 - mmseg - INFO - Iter [26550/160000]	lr: 5.004e-05, eta: 1 day, 5:36:47, time: 0.847, data_time: 0.053, memory: 21695, decode.loss_ce: 0.4183, decode.acc_seg: 83.8836, aux.loss_ce: 0.1837, aux.acc_seg: 82.5828, loss: 0.6020
2023-11-26 19:39:47,096 - mmseg - INFO - Iter [26600/160000]	lr: 5.003e-05, eta: 1 day, 5:36:10, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4117, decode.acc_seg: 84.2374, aux.loss_ce: 0.1845, aux.acc_seg: 83.1122, loss: 0.5961
2023-11-26 19:40:26,778 - mmseg - INFO - Iter [26650/160000]	lr: 5.001e-05, eta: 1 day, 5:35:29, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4156, decode.acc_seg: 84.1041, aux.loss_ce: 0.1862, aux.acc_seg: 82.7758, loss: 0.6018
2023-11-26 19:41:06,740 - mmseg - INFO - Iter [26700/160000]	lr: 4.999e-05, eta: 1 day, 5:34:49, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3929, decode.acc_seg: 84.5327, aux.loss_ce: 0.1749, aux.acc_seg: 83.3646, loss: 0.5679
2023-11-26 19:41:46,122 - mmseg - INFO - Iter [26750/160000]	lr: 4.997e-05, eta: 1 day, 5:34:06, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3925, decode.acc_seg: 84.8022, aux.loss_ce: 0.1743, aux.acc_seg: 83.6513, loss: 0.5668
2023-11-26 19:42:26,258 - mmseg - INFO - Iter [26800/160000]	lr: 4.995e-05, eta: 1 day, 5:33:27, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3836, decode.acc_seg: 84.8190, aux.loss_ce: 0.1713, aux.acc_seg: 83.7993, loss: 0.5550
2023-11-26 19:43:06,392 - mmseg - INFO - Iter [26850/160000]	lr: 4.993e-05, eta: 1 day, 5:32:48, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3900, decode.acc_seg: 84.9511, aux.loss_ce: 0.1737, aux.acc_seg: 83.7974, loss: 0.5637
2023-11-26 19:43:46,403 - mmseg - INFO - Iter [26900/160000]	lr: 4.991e-05, eta: 1 day, 5:32:09, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4125, decode.acc_seg: 83.8108, aux.loss_ce: 0.1804, aux.acc_seg: 82.6346, loss: 0.5928
2023-11-26 19:44:26,203 - mmseg - INFO - Iter [26950/160000]	lr: 4.989e-05, eta: 1 day, 5:31:28, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4083, decode.acc_seg: 83.7476, aux.loss_ce: 0.1798, aux.acc_seg: 82.8028, loss: 0.5881
2023-11-26 19:45:03,712 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 19:45:03,713 - mmseg - INFO - Iter [27000/160000]	lr: 4.988e-05, eta: 1 day, 5:30:36, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4148, decode.acc_seg: 84.2736, aux.loss_ce: 0.1837, aux.acc_seg: 83.0338, loss: 0.5985
2023-11-26 19:45:42,300 - mmseg - INFO - Iter [27050/160000]	lr: 4.986e-05, eta: 1 day, 5:29:49, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4164, decode.acc_seg: 83.6860, aux.loss_ce: 0.1827, aux.acc_seg: 82.4941, loss: 0.5991
2023-11-26 19:46:22,766 - mmseg - INFO - Iter [27100/160000]	lr: 4.984e-05, eta: 1 day, 5:29:12, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4078, decode.acc_seg: 84.4307, aux.loss_ce: 0.1806, aux.acc_seg: 83.2556, loss: 0.5884
2023-11-26 19:47:03,045 - mmseg - INFO - Iter [27150/160000]	lr: 4.982e-05, eta: 1 day, 5:28:34, time: 0.807, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4038, decode.acc_seg: 84.1478, aux.loss_ce: 0.1776, aux.acc_seg: 83.2083, loss: 0.5813
2023-11-26 19:47:40,573 - mmseg - INFO - Iter [27200/160000]	lr: 4.980e-05, eta: 1 day, 5:27:42, time: 0.749, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3960, decode.acc_seg: 84.3038, aux.loss_ce: 0.1745, aux.acc_seg: 83.0902, loss: 0.5705
2023-11-26 19:48:20,757 - mmseg - INFO - Iter [27250/160000]	lr: 4.978e-05, eta: 1 day, 5:27:03, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4333, decode.acc_seg: 83.2574, aux.loss_ce: 0.1868, aux.acc_seg: 82.6431, loss: 0.6201
2023-11-26 19:49:00,475 - mmseg - INFO - Iter [27300/160000]	lr: 4.976e-05, eta: 1 day, 5:26:23, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3979, decode.acc_seg: 84.3560, aux.loss_ce: 0.1763, aux.acc_seg: 83.3153, loss: 0.5742
2023-11-26 19:49:39,237 - mmseg - INFO - Iter [27350/160000]	lr: 4.974e-05, eta: 1 day, 5:25:37, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4166, decode.acc_seg: 84.0467, aux.loss_ce: 0.1850, aux.acc_seg: 82.7079, loss: 0.6016
2023-11-26 19:50:16,783 - mmseg - INFO - Iter [27400/160000]	lr: 4.973e-05, eta: 1 day, 5:24:45, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4181, decode.acc_seg: 84.0288, aux.loss_ce: 0.1848, aux.acc_seg: 82.8858, loss: 0.6029
2023-11-26 19:50:57,588 - mmseg - INFO - Iter [27450/160000]	lr: 4.971e-05, eta: 1 day, 5:24:10, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3946, decode.acc_seg: 84.3045, aux.loss_ce: 0.1759, aux.acc_seg: 83.1514, loss: 0.5705
2023-11-26 19:51:38,287 - mmseg - INFO - Iter [27500/160000]	lr: 4.969e-05, eta: 1 day, 5:23:34, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4125, decode.acc_seg: 83.9112, aux.loss_ce: 0.1811, aux.acc_seg: 82.8125, loss: 0.5937
2023-11-26 19:52:17,503 - mmseg - INFO - Iter [27550/160000]	lr: 4.967e-05, eta: 1 day, 5:22:50, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3970, decode.acc_seg: 84.6382, aux.loss_ce: 0.1739, aux.acc_seg: 83.4246, loss: 0.5709
2023-11-26 19:52:57,441 - mmseg - INFO - Iter [27600/160000]	lr: 4.965e-05, eta: 1 day, 5:22:10, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3961, decode.acc_seg: 84.0219, aux.loss_ce: 0.1760, aux.acc_seg: 82.8409, loss: 0.5720
2023-11-26 19:53:36,467 - mmseg - INFO - Iter [27650/160000]	lr: 4.963e-05, eta: 1 day, 5:21:26, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4478, decode.acc_seg: 82.9194, aux.loss_ce: 0.1969, aux.acc_seg: 81.8542, loss: 0.6447
2023-11-26 19:54:17,293 - mmseg - INFO - Iter [27700/160000]	lr: 4.961e-05, eta: 1 day, 5:20:50, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4322, decode.acc_seg: 83.1676, aux.loss_ce: 0.1872, aux.acc_seg: 81.9857, loss: 0.6193
2023-11-26 19:54:57,844 - mmseg - INFO - Iter [27750/160000]	lr: 4.959e-05, eta: 1 day, 5:20:14, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4474, decode.acc_seg: 83.5739, aux.loss_ce: 0.1941, aux.acc_seg: 82.9274, loss: 0.6415
2023-11-26 19:55:38,360 - mmseg - INFO - Iter [27800/160000]	lr: 4.958e-05, eta: 1 day, 5:19:36, time: 0.810, data_time: 0.052, memory: 21695, decode.loss_ce: 0.4140, decode.acc_seg: 83.6778, aux.loss_ce: 0.1825, aux.acc_seg: 82.0433, loss: 0.5965
2023-11-26 19:56:17,115 - mmseg - INFO - Iter [27850/160000]	lr: 4.956e-05, eta: 1 day, 5:18:51, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3886, decode.acc_seg: 84.9141, aux.loss_ce: 0.1731, aux.acc_seg: 83.9945, loss: 0.5617
2023-11-26 19:56:53,784 - mmseg - INFO - Iter [27900/160000]	lr: 4.954e-05, eta: 1 day, 5:17:56, time: 0.733, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3981, decode.acc_seg: 84.6005, aux.loss_ce: 0.1802, aux.acc_seg: 83.0766, loss: 0.5783
2023-11-26 19:57:33,704 - mmseg - INFO - Iter [27950/160000]	lr: 4.952e-05, eta: 1 day, 5:17:16, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3844, decode.acc_seg: 84.6327, aux.loss_ce: 0.1697, aux.acc_seg: 83.8538, loss: 0.5541
2023-11-26 19:58:14,028 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 19:58:14,028 - mmseg - INFO - Iter [28000/160000]	lr: 4.950e-05, eta: 1 day, 5:16:37, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4035, decode.acc_seg: 84.5600, aux.loss_ce: 0.1793, aux.acc_seg: 83.5260, loss: 0.5828
2023-11-26 19:58:52,510 - mmseg - INFO - Iter [28050/160000]	lr: 4.948e-05, eta: 1 day, 5:15:51, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3690, decode.acc_seg: 85.1889, aux.loss_ce: 0.1654, aux.acc_seg: 84.0395, loss: 0.5344
2023-11-26 19:59:32,596 - mmseg - INFO - Iter [28100/160000]	lr: 4.946e-05, eta: 1 day, 5:15:12, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3728, decode.acc_seg: 85.4289, aux.loss_ce: 0.1667, aux.acc_seg: 84.3250, loss: 0.5395
2023-11-26 20:00:12,831 - mmseg - INFO - Iter [28150/160000]	lr: 4.944e-05, eta: 1 day, 5:14:33, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3985, decode.acc_seg: 84.5140, aux.loss_ce: 0.1760, aux.acc_seg: 83.7007, loss: 0.5745
2023-11-26 20:00:53,176 - mmseg - INFO - Iter [28200/160000]	lr: 4.943e-05, eta: 1 day, 5:13:55, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3947, decode.acc_seg: 84.8647, aux.loss_ce: 0.1756, aux.acc_seg: 83.5783, loss: 0.5703
2023-11-26 20:01:33,539 - mmseg - INFO - Iter [28250/160000]	lr: 4.941e-05, eta: 1 day, 5:13:17, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3890, decode.acc_seg: 84.5775, aux.loss_ce: 0.1731, aux.acc_seg: 83.4723, loss: 0.5621
2023-11-26 20:02:11,015 - mmseg - INFO - Iter [28300/160000]	lr: 4.939e-05, eta: 1 day, 5:12:26, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4001, decode.acc_seg: 84.0429, aux.loss_ce: 0.1771, aux.acc_seg: 82.7658, loss: 0.5772
2023-11-26 20:02:51,216 - mmseg - INFO - Iter [28350/160000]	lr: 4.937e-05, eta: 1 day, 5:11:47, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4068, decode.acc_seg: 84.1558, aux.loss_ce: 0.1802, aux.acc_seg: 83.1158, loss: 0.5871
2023-11-26 20:03:29,394 - mmseg - INFO - Iter [28400/160000]	lr: 4.935e-05, eta: 1 day, 5:10:59, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3874, decode.acc_seg: 84.4399, aux.loss_ce: 0.1752, aux.acc_seg: 83.2994, loss: 0.5626
2023-11-26 20:04:09,796 - mmseg - INFO - Iter [28450/160000]	lr: 4.933e-05, eta: 1 day, 5:10:22, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4018, decode.acc_seg: 84.3578, aux.loss_ce: 0.1764, aux.acc_seg: 83.2277, loss: 0.5781
2023-11-26 20:04:49,716 - mmseg - INFO - Iter [28500/160000]	lr: 4.931e-05, eta: 1 day, 5:09:42, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4024, decode.acc_seg: 84.5428, aux.loss_ce: 0.1763, aux.acc_seg: 83.7300, loss: 0.5787
2023-11-26 20:05:29,868 - mmseg - INFO - Iter [28550/160000]	lr: 4.929e-05, eta: 1 day, 5:09:03, time: 0.804, data_time: 0.012, memory: 21695, decode.loss_ce: 0.4003, decode.acc_seg: 84.2112, aux.loss_ce: 0.1742, aux.acc_seg: 83.2774, loss: 0.5745
2023-11-26 20:06:06,883 - mmseg - INFO - Iter [28600/160000]	lr: 4.928e-05, eta: 1 day, 5:08:10, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4238, decode.acc_seg: 83.7196, aux.loss_ce: 0.1870, aux.acc_seg: 82.6459, loss: 0.6109
2023-11-26 20:06:47,702 - mmseg - INFO - Iter [28650/160000]	lr: 4.926e-05, eta: 1 day, 5:07:34, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3961, decode.acc_seg: 84.3400, aux.loss_ce: 0.1739, aux.acc_seg: 83.1110, loss: 0.5700
2023-11-26 20:07:28,673 - mmseg - INFO - Iter [28700/160000]	lr: 4.924e-05, eta: 1 day, 5:06:59, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3952, decode.acc_seg: 83.9695, aux.loss_ce: 0.1742, aux.acc_seg: 82.9601, loss: 0.5694
2023-11-26 20:08:09,586 - mmseg - INFO - Iter [28750/160000]	lr: 4.922e-05, eta: 1 day, 5:06:23, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3905, decode.acc_seg: 85.0866, aux.loss_ce: 0.1706, aux.acc_seg: 83.9832, loss: 0.5611
2023-11-26 20:08:50,301 - mmseg - INFO - Iter [28800/160000]	lr: 4.920e-05, eta: 1 day, 5:05:47, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3959, decode.acc_seg: 84.3838, aux.loss_ce: 0.1739, aux.acc_seg: 83.3080, loss: 0.5698
2023-11-26 20:09:27,626 - mmseg - INFO - Iter [28850/160000]	lr: 4.918e-05, eta: 1 day, 5:04:56, time: 0.747, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4110, decode.acc_seg: 84.3687, aux.loss_ce: 0.1771, aux.acc_seg: 83.7228, loss: 0.5880
2023-11-26 20:10:04,819 - mmseg - INFO - Iter [28900/160000]	lr: 4.916e-05, eta: 1 day, 5:04:03, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3925, decode.acc_seg: 84.5081, aux.loss_ce: 0.1747, aux.acc_seg: 83.2516, loss: 0.5672
2023-11-26 20:10:41,416 - mmseg - INFO - Iter [28950/160000]	lr: 4.914e-05, eta: 1 day, 5:03:09, time: 0.732, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3974, decode.acc_seg: 84.3114, aux.loss_ce: 0.1763, aux.acc_seg: 83.1570, loss: 0.5737
2023-11-26 20:11:21,418 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 20:11:21,419 - mmseg - INFO - Iter [29000/160000]	lr: 4.913e-05, eta: 1 day, 5:02:29, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3852, decode.acc_seg: 84.8971, aux.loss_ce: 0.1719, aux.acc_seg: 83.7753, loss: 0.5570
2023-11-26 20:12:01,059 - mmseg - INFO - Iter [29050/160000]	lr: 4.911e-05, eta: 1 day, 5:01:48, time: 0.794, data_time: 0.053, memory: 21695, decode.loss_ce: 0.4131, decode.acc_seg: 83.6795, aux.loss_ce: 0.1816, aux.acc_seg: 82.3506, loss: 0.5947
2023-11-26 20:12:40,840 - mmseg - INFO - Iter [29100/160000]	lr: 4.909e-05, eta: 1 day, 5:01:07, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3886, decode.acc_seg: 84.7119, aux.loss_ce: 0.1703, aux.acc_seg: 83.7508, loss: 0.5590
2023-11-26 20:13:21,006 - mmseg - INFO - Iter [29150/160000]	lr: 4.907e-05, eta: 1 day, 5:00:29, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3694, decode.acc_seg: 85.0547, aux.loss_ce: 0.1673, aux.acc_seg: 83.6765, loss: 0.5367
2023-11-26 20:13:59,458 - mmseg - INFO - Iter [29200/160000]	lr: 4.905e-05, eta: 1 day, 4:59:42, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3755, decode.acc_seg: 85.1403, aux.loss_ce: 0.1696, aux.acc_seg: 83.8195, loss: 0.5452
2023-11-26 20:14:40,827 - mmseg - INFO - Iter [29250/160000]	lr: 4.903e-05, eta: 1 day, 4:59:09, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3818, decode.acc_seg: 84.8534, aux.loss_ce: 0.1698, aux.acc_seg: 83.9591, loss: 0.5516
2023-11-26 20:15:19,899 - mmseg - INFO - Iter [29300/160000]	lr: 4.901e-05, eta: 1 day, 4:58:25, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4020, decode.acc_seg: 83.9805, aux.loss_ce: 0.1787, aux.acc_seg: 83.0470, loss: 0.5807
2023-11-26 20:15:56,322 - mmseg - INFO - Iter [29350/160000]	lr: 4.899e-05, eta: 1 day, 4:57:30, time: 0.729, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3946, decode.acc_seg: 84.8095, aux.loss_ce: 0.1728, aux.acc_seg: 83.9157, loss: 0.5675
2023-11-26 20:16:34,660 - mmseg - INFO - Iter [29400/160000]	lr: 4.898e-05, eta: 1 day, 4:56:43, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4123, decode.acc_seg: 84.3312, aux.loss_ce: 0.1829, aux.acc_seg: 82.9805, loss: 0.5952
2023-11-26 20:17:14,957 - mmseg - INFO - Iter [29450/160000]	lr: 4.896e-05, eta: 1 day, 4:56:05, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3823, decode.acc_seg: 84.9706, aux.loss_ce: 0.1686, aux.acc_seg: 83.8828, loss: 0.5509
2023-11-26 20:17:55,382 - mmseg - INFO - Iter [29500/160000]	lr: 4.894e-05, eta: 1 day, 4:55:27, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3941, decode.acc_seg: 84.9956, aux.loss_ce: 0.1760, aux.acc_seg: 83.7324, loss: 0.5701
2023-11-26 20:18:35,532 - mmseg - INFO - Iter [29550/160000]	lr: 4.892e-05, eta: 1 day, 4:54:48, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3808, decode.acc_seg: 85.1046, aux.loss_ce: 0.1703, aux.acc_seg: 83.9706, loss: 0.5511
2023-11-26 20:19:14,396 - mmseg - INFO - Iter [29600/160000]	lr: 4.890e-05, eta: 1 day, 4:54:04, time: 0.779, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3891, decode.acc_seg: 84.9663, aux.loss_ce: 0.1732, aux.acc_seg: 84.0257, loss: 0.5623
2023-11-26 20:19:54,914 - mmseg - INFO - Iter [29650/160000]	lr: 4.888e-05, eta: 1 day, 4:53:27, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3899, decode.acc_seg: 85.1099, aux.loss_ce: 0.1729, aux.acc_seg: 84.0388, loss: 0.5628
2023-11-26 20:20:35,890 - mmseg - INFO - Iter [29700/160000]	lr: 4.886e-05, eta: 1 day, 4:52:52, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3599, decode.acc_seg: 85.5107, aux.loss_ce: 0.1599, aux.acc_seg: 84.4139, loss: 0.5198
2023-11-26 20:21:15,527 - mmseg - INFO - Iter [29750/160000]	lr: 4.884e-05, eta: 1 day, 4:52:11, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3751, decode.acc_seg: 85.2979, aux.loss_ce: 0.1670, aux.acc_seg: 84.2334, loss: 0.5421
2023-11-26 20:21:53,851 - mmseg - INFO - Iter [29800/160000]	lr: 4.883e-05, eta: 1 day, 4:51:24, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3709, decode.acc_seg: 85.1161, aux.loss_ce: 0.1653, aux.acc_seg: 83.9920, loss: 0.5361
2023-11-26 20:22:34,836 - mmseg - INFO - Iter [29850/160000]	lr: 4.881e-05, eta: 1 day, 4:50:49, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3763, decode.acc_seg: 85.2112, aux.loss_ce: 0.1665, aux.acc_seg: 83.9712, loss: 0.5428
2023-11-26 20:23:15,582 - mmseg - INFO - Iter [29900/160000]	lr: 4.879e-05, eta: 1 day, 4:50:13, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3961, decode.acc_seg: 84.1171, aux.loss_ce: 0.1768, aux.acc_seg: 82.7447, loss: 0.5729
2023-11-26 20:23:55,870 - mmseg - INFO - Iter [29950/160000]	lr: 4.877e-05, eta: 1 day, 4:49:34, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3888, decode.acc_seg: 84.8716, aux.loss_ce: 0.1721, aux.acc_seg: 83.7122, loss: 0.5609
2023-11-26 20:24:35,230 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 20:24:35,230 - mmseg - INFO - Iter [30000/160000]	lr: 4.875e-05, eta: 1 day, 4:48:52, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3810, decode.acc_seg: 84.8398, aux.loss_ce: 0.1705, aux.acc_seg: 83.5840, loss: 0.5516
2023-11-26 20:25:15,272 - mmseg - INFO - Iter [30050/160000]	lr: 4.873e-05, eta: 1 day, 4:48:13, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3893, decode.acc_seg: 84.5413, aux.loss_ce: 0.1754, aux.acc_seg: 83.2479, loss: 0.5647
2023-11-26 20:25:54,589 - mmseg - INFO - Iter [30100/160000]	lr: 4.871e-05, eta: 1 day, 4:47:31, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3899, decode.acc_seg: 84.7081, aux.loss_ce: 0.1702, aux.acc_seg: 83.7454, loss: 0.5601
2023-11-26 20:26:32,280 - mmseg - INFO - Iter [30150/160000]	lr: 4.869e-05, eta: 1 day, 4:46:41, time: 0.752, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3999, decode.acc_seg: 84.4573, aux.loss_ce: 0.1784, aux.acc_seg: 83.3117, loss: 0.5783
2023-11-26 20:27:12,353 - mmseg - INFO - Iter [30200/160000]	lr: 4.868e-05, eta: 1 day, 4:46:02, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3767, decode.acc_seg: 84.9961, aux.loss_ce: 0.1687, aux.acc_seg: 83.8090, loss: 0.5454
2023-11-26 20:27:50,028 - mmseg - INFO - Iter [30250/160000]	lr: 4.866e-05, eta: 1 day, 4:45:13, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3638, decode.acc_seg: 86.1621, aux.loss_ce: 0.1638, aux.acc_seg: 84.7481, loss: 0.5275
2023-11-26 20:28:29,235 - mmseg - INFO - Iter [30300/160000]	lr: 4.864e-05, eta: 1 day, 4:44:30, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3841, decode.acc_seg: 84.8489, aux.loss_ce: 0.1716, aux.acc_seg: 83.6996, loss: 0.5557
2023-11-26 20:29:09,579 - mmseg - INFO - Iter [30350/160000]	lr: 4.862e-05, eta: 1 day, 4:43:52, time: 0.806, data_time: 0.052, memory: 21695, decode.loss_ce: 0.3715, decode.acc_seg: 85.1835, aux.loss_ce: 0.1677, aux.acc_seg: 84.2206, loss: 0.5392
2023-11-26 20:29:49,602 - mmseg - INFO - Iter [30400/160000]	lr: 4.860e-05, eta: 1 day, 4:43:13, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3736, decode.acc_seg: 85.5851, aux.loss_ce: 0.1660, aux.acc_seg: 84.2685, loss: 0.5396
2023-11-26 20:30:29,339 - mmseg - INFO - Iter [30450/160000]	lr: 4.858e-05, eta: 1 day, 4:42:32, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3859, decode.acc_seg: 84.8875, aux.loss_ce: 0.1729, aux.acc_seg: 83.7575, loss: 0.5588
2023-11-26 20:31:06,485 - mmseg - INFO - Iter [30500/160000]	lr: 4.856e-05, eta: 1 day, 4:41:40, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3718, decode.acc_seg: 85.2989, aux.loss_ce: 0.1681, aux.acc_seg: 83.9842, loss: 0.5398
2023-11-26 20:31:46,719 - mmseg - INFO - Iter [30550/160000]	lr: 4.854e-05, eta: 1 day, 4:41:02, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3722, decode.acc_seg: 85.6718, aux.loss_ce: 0.1681, aux.acc_seg: 84.3589, loss: 0.5404
2023-11-26 20:32:24,749 - mmseg - INFO - Iter [30600/160000]	lr: 4.853e-05, eta: 1 day, 4:40:14, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3807, decode.acc_seg: 84.7635, aux.loss_ce: 0.1720, aux.acc_seg: 83.3605, loss: 0.5527
2023-11-26 20:33:01,887 - mmseg - INFO - Iter [30650/160000]	lr: 4.851e-05, eta: 1 day, 4:39:23, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3860, decode.acc_seg: 84.8181, aux.loss_ce: 0.1715, aux.acc_seg: 83.7098, loss: 0.5575
2023-11-26 20:33:40,299 - mmseg - INFO - Iter [30700/160000]	lr: 4.849e-05, eta: 1 day, 4:38:37, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3905, decode.acc_seg: 84.9038, aux.loss_ce: 0.1725, aux.acc_seg: 83.6727, loss: 0.5630
2023-11-26 20:34:20,434 - mmseg - INFO - Iter [30750/160000]	lr: 4.847e-05, eta: 1 day, 4:37:58, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3967, decode.acc_seg: 84.8198, aux.loss_ce: 0.1733, aux.acc_seg: 83.8729, loss: 0.5700
2023-11-26 20:35:01,567 - mmseg - INFO - Iter [30800/160000]	lr: 4.845e-05, eta: 1 day, 4:37:23, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3575, decode.acc_seg: 85.4364, aux.loss_ce: 0.1595, aux.acc_seg: 84.5039, loss: 0.5170
2023-11-26 20:35:40,223 - mmseg - INFO - Iter [30850/160000]	lr: 4.843e-05, eta: 1 day, 4:36:39, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3960, decode.acc_seg: 84.7610, aux.loss_ce: 0.1747, aux.acc_seg: 83.6946, loss: 0.5707
2023-11-26 20:36:18,887 - mmseg - INFO - Iter [30900/160000]	lr: 4.841e-05, eta: 1 day, 4:35:53, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3896, decode.acc_seg: 85.0740, aux.loss_ce: 0.1718, aux.acc_seg: 83.8478, loss: 0.5614
2023-11-26 20:36:58,873 - mmseg - INFO - Iter [30950/160000]	lr: 4.839e-05, eta: 1 day, 4:35:14, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3725, decode.acc_seg: 85.4127, aux.loss_ce: 0.1657, aux.acc_seg: 84.2929, loss: 0.5382
2023-11-26 20:37:38,147 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 20:37:38,147 - mmseg - INFO - Iter [31000/160000]	lr: 4.838e-05, eta: 1 day, 4:34:32, time: 0.786, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3755, decode.acc_seg: 85.4251, aux.loss_ce: 0.1677, aux.acc_seg: 84.6952, loss: 0.5432
2023-11-26 20:38:18,737 - mmseg - INFO - Iter [31050/160000]	lr: 4.836e-05, eta: 1 day, 4:33:55, time: 0.812, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3807, decode.acc_seg: 85.5980, aux.loss_ce: 0.1688, aux.acc_seg: 84.6391, loss: 0.5495
2023-11-26 20:38:59,446 - mmseg - INFO - Iter [31100/160000]	lr: 4.834e-05, eta: 1 day, 4:33:18, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4082, decode.acc_seg: 84.2578, aux.loss_ce: 0.1811, aux.acc_seg: 83.1032, loss: 0.5893
2023-11-26 20:39:37,866 - mmseg - INFO - Iter [31150/160000]	lr: 4.832e-05, eta: 1 day, 4:32:33, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3723, decode.acc_seg: 85.5930, aux.loss_ce: 0.1642, aux.acc_seg: 84.5166, loss: 0.5364
2023-11-26 20:40:15,815 - mmseg - INFO - Iter [31200/160000]	lr: 4.830e-05, eta: 1 day, 4:31:45, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.4134, decode.acc_seg: 83.8282, aux.loss_ce: 0.1865, aux.acc_seg: 82.3216, loss: 0.5999
2023-11-26 20:40:52,943 - mmseg - INFO - Iter [31250/160000]	lr: 4.828e-05, eta: 1 day, 4:30:54, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3957, decode.acc_seg: 84.7580, aux.loss_ce: 0.1744, aux.acc_seg: 83.5331, loss: 0.5701
2023-11-26 20:41:32,783 - mmseg - INFO - Iter [31300/160000]	lr: 4.826e-05, eta: 1 day, 4:30:14, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3988, decode.acc_seg: 84.1783, aux.loss_ce: 0.1767, aux.acc_seg: 82.7166, loss: 0.5755
2023-11-26 20:42:12,751 - mmseg - INFO - Iter [31350/160000]	lr: 4.824e-05, eta: 1 day, 4:29:34, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4030, decode.acc_seg: 84.2834, aux.loss_ce: 0.1772, aux.acc_seg: 83.0833, loss: 0.5802
2023-11-26 20:42:52,750 - mmseg - INFO - Iter [31400/160000]	lr: 4.823e-05, eta: 1 day, 4:28:55, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4039, decode.acc_seg: 84.0017, aux.loss_ce: 0.1756, aux.acc_seg: 83.1324, loss: 0.5795
2023-11-26 20:43:32,010 - mmseg - INFO - Iter [31450/160000]	lr: 4.821e-05, eta: 1 day, 4:28:12, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3719, decode.acc_seg: 85.2393, aux.loss_ce: 0.1667, aux.acc_seg: 83.9281, loss: 0.5386
2023-11-26 20:44:11,980 - mmseg - INFO - Iter [31500/160000]	lr: 4.819e-05, eta: 1 day, 4:27:33, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3652, decode.acc_seg: 85.7643, aux.loss_ce: 0.1642, aux.acc_seg: 84.6421, loss: 0.5294
2023-11-26 20:44:52,734 - mmseg - INFO - Iter [31550/160000]	lr: 4.817e-05, eta: 1 day, 4:26:57, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3912, decode.acc_seg: 84.8114, aux.loss_ce: 0.1743, aux.acc_seg: 83.2622, loss: 0.5655
2023-11-26 20:45:32,197 - mmseg - INFO - Iter [31600/160000]	lr: 4.815e-05, eta: 1 day, 4:26:15, time: 0.791, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3700, decode.acc_seg: 85.6458, aux.loss_ce: 0.1640, aux.acc_seg: 84.4874, loss: 0.5340
2023-11-26 20:46:11,199 - mmseg - INFO - Iter [31650/160000]	lr: 4.813e-05, eta: 1 day, 4:25:32, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3698, decode.acc_seg: 85.5621, aux.loss_ce: 0.1650, aux.acc_seg: 84.2315, loss: 0.5348
2023-11-26 20:46:49,548 - mmseg - INFO - Iter [31700/160000]	lr: 4.811e-05, eta: 1 day, 4:24:46, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3612, decode.acc_seg: 85.4600, aux.loss_ce: 0.1613, aux.acc_seg: 84.4870, loss: 0.5225
2023-11-26 20:47:29,607 - mmseg - INFO - Iter [31750/160000]	lr: 4.809e-05, eta: 1 day, 4:24:07, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3777, decode.acc_seg: 85.3323, aux.loss_ce: 0.1707, aux.acc_seg: 83.8868, loss: 0.5483
2023-11-26 20:48:07,588 - mmseg - INFO - Iter [31800/160000]	lr: 4.808e-05, eta: 1 day, 4:23:19, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3956, decode.acc_seg: 84.5193, aux.loss_ce: 0.1764, aux.acc_seg: 83.2485, loss: 0.5720
2023-11-26 20:48:47,918 - mmseg - INFO - Iter [31850/160000]	lr: 4.806e-05, eta: 1 day, 4:22:41, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3998, decode.acc_seg: 84.7664, aux.loss_ce: 0.1755, aux.acc_seg: 83.6476, loss: 0.5753
2023-11-26 20:49:28,590 - mmseg - INFO - Iter [31900/160000]	lr: 4.804e-05, eta: 1 day, 4:22:05, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3541, decode.acc_seg: 85.9568, aux.loss_ce: 0.1640, aux.acc_seg: 84.2681, loss: 0.5181
2023-11-26 20:50:09,177 - mmseg - INFO - Iter [31950/160000]	lr: 4.802e-05, eta: 1 day, 4:21:28, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3924, decode.acc_seg: 85.0385, aux.loss_ce: 0.1721, aux.acc_seg: 83.9738, loss: 0.5645
2023-11-26 20:50:48,955 - mmseg - INFO - Saving checkpoint at 32000 iterations
2023-11-26 20:50:54,122 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 20:50:54,122 - mmseg - INFO - Iter [32000/160000]	lr: 4.800e-05, eta: 1 day, 4:21:09, time: 0.900, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3409, decode.acc_seg: 86.1367, aux.loss_ce: 0.1511, aux.acc_seg: 85.1821, loss: 0.4919
2023-11-26 20:52:26,432 - mmseg - INFO - per class results:
2023-11-26 20:52:26,446 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 75.93 | 85.88 |
|       building      | 81.75 | 91.41 |
|         sky         | 93.95 | 96.85 |
|        floor        |  80.5 | 88.37 |
|         tree        | 74.46 | 87.54 |
|       ceiling       | 81.95 | 90.65 |
|         road        | 81.51 | 90.09 |
|         bed         | 86.58 | 94.47 |
|      windowpane     | 60.55 | 79.63 |
|        grass        | 66.82 | 78.81 |
|       cabinet       | 56.65 | 66.25 |
|       sidewalk      | 64.03 | 78.26 |
|        person       | 78.44 | 92.89 |
|        earth        | 34.01 | 48.68 |
|         door        | 45.92 | 56.78 |
|        table        |  55.0 | 71.47 |
|       mountain      | 57.23 | 73.22 |
|        plant        | 51.94 |  63.6 |
|       curtain       | 74.43 | 85.38 |
|        chair        | 54.28 | 66.86 |
|         car         | 84.08 | 93.16 |
|        water        | 62.35 | 77.73 |
|       painting      | 65.88 | 83.94 |
|         sofa        | 64.11 | 82.17 |
|        shelf        | 40.05 | 60.95 |
|        house        | 51.92 | 65.99 |
|         sea         | 63.92 | 73.66 |
|        mirror       | 63.87 | 72.87 |
|         rug         | 66.79 | 82.67 |
|        field        | 31.76 | 58.05 |
|       armchair      | 35.49 | 50.84 |
|         seat        | 60.16 | 82.32 |
|        fence        | 44.44 | 62.86 |
|         desk        | 43.78 | 67.36 |
|         rock        | 44.93 | 69.08 |
|       wardrobe      | 44.61 | 74.69 |
|         lamp        | 58.82 | 68.67 |
|       bathtub       | 75.89 | 87.76 |
|       railing       | 32.88 | 39.93 |
|       cushion       | 52.16 | 62.21 |
|         base        | 32.63 | 49.54 |
|         box         | 26.45 | 35.38 |
|        column       | 45.08 | 55.93 |
|      signboard      | 37.03 | 48.58 |
|   chest of drawers  |  40.2 | 62.42 |
|       counter       | 30.66 | 35.93 |
|         sand        | 32.48 |  61.7 |
|         sink        | 64.23 | 78.17 |
|      skyscraper     | 46.09 | 63.81 |
|      fireplace      |  70.8 | 88.12 |
|     refrigerator    | 73.02 | 85.03 |
|      grandstand     | 48.59 | 73.52 |
|         path        | 17.23 | 24.26 |
|        stairs       |  35.4 | 42.02 |
|        runway       | 72.23 | 94.44 |
|         case        | 48.57 | 57.09 |
|      pool table     | 91.81 | 96.98 |
|        pillow       | 59.36 | 79.18 |
|     screen door     | 66.54 | 80.24 |
|       stairway      | 43.55 | 53.08 |
|        river        | 12.79 |  31.0 |
|        bridge       | 69.75 | 79.93 |
|       bookcase      | 31.59 | 66.07 |
|        blind        | 37.94 | 46.16 |
|     coffee table    | 47.27 |  84.0 |
|        toilet       | 83.67 | 89.14 |
|        flower       | 32.06 | 50.78 |
|         book        | 33.54 | 45.83 |
|         hill        |  6.69 | 14.14 |
|        bench        | 42.69 | 53.58 |
|      countertop     | 56.38 | 74.66 |
|        stove        | 61.93 | 78.73 |
|         palm        | 52.93 | 74.92 |
|    kitchen island   | 32.28 | 83.23 |
|       computer      | 61.18 | 80.92 |
|     swivel chair    | 49.71 | 70.53 |
|         boat        | 39.22 | 52.44 |
|         bar         |  48.2 | 65.08 |
|    arcade machine   | 74.57 | 90.28 |
|        hovel        | 51.35 | 75.58 |
|         bus         | 86.58 | 95.68 |
|        towel        | 59.85 | 80.18 |
|        light        | 52.85 | 61.25 |
|        truck        |  31.0 | 46.92 |
|        tower        | 19.74 | 40.82 |
|      chandelier     | 61.04 | 84.72 |
|        awning       | 23.38 | 27.83 |
|     streetlight     | 23.72 | 31.27 |
|        booth        | 54.04 |  69.8 |
| television receiver | 65.91 |  74.9 |
|       airplane      | 54.61 | 65.69 |
|      dirt track     |  4.4  | 11.57 |
|       apparel       | 35.38 | 49.63 |
|         pole        | 18.76 | 25.48 |
|         land        |  1.87 |  3.81 |
|      bannister      | 11.89 | 16.42 |
|      escalator      | 46.55 | 81.34 |
|       ottoman       | 43.35 | 66.44 |
|        bottle       | 34.14 | 51.57 |
|        buffet       | 45.47 | 62.31 |
|        poster       |  26.1 | 40.88 |
|        stage        | 18.43 | 24.89 |
|         van         | 38.51 | 44.89 |
|         ship        |  5.39 |  8.67 |
|       fountain      | 41.38 | 41.79 |
|    conveyer belt    | 66.29 | 85.79 |
|        canopy       | 24.02 |  37.4 |
|        washer       | 72.66 |  79.1 |
|      plaything      | 20.65 | 38.69 |
|    swimming pool    | 77.08 | 88.81 |
|        stool        | 42.85 | 58.52 |
|        barrel       | 26.36 | 65.12 |
|        basket       | 30.18 | 47.15 |
|      waterfall      | 65.44 | 94.65 |
|         tent        | 89.67 | 98.63 |
|         bag         | 12.97 | 16.12 |
|       minibike      |  69.4 | 78.43 |
|        cradle       | 77.02 | 97.11 |
|         oven        | 31.74 |  36.3 |
|         ball        | 42.07 | 66.04 |
|         food        | 56.87 | 66.12 |
|         step        |  6.8  |  7.61 |
|         tank        | 33.34 | 38.48 |
|      trade name     | 13.12 | 13.45 |
|      microwave      | 79.48 | 91.73 |
|         pot         | 42.35 | 48.37 |
|        animal       | 63.92 | 67.58 |
|       bicycle       | 57.08 | 79.54 |
|         lake        |  59.2 | 67.01 |
|      dishwasher     | 44.05 | 55.63 |
|        screen       | 67.92 | 90.17 |
|       blanket       |  10.5 | 14.31 |
|      sculpture      | 54.02 | 71.23 |
|         hood        | 49.24 | 52.66 |
|        sconce       |  33.7 | 43.02 |
|         vase        | 33.65 | 45.81 |
|    traffic light    | 24.76 | 49.33 |
|         tray        |  4.47 |  5.9  |
|        ashcan       | 33.79 |  55.8 |
|         fan         | 55.67 | 71.38 |
|         pier        | 60.57 | 80.01 |
|      crt screen     |  5.41 | 17.59 |
|        plate        | 52.23 | 64.24 |
|       monitor       |  7.3  | 10.78 |
|    bulletin board   | 50.93 | 58.49 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 60.74 | 66.15 |
|        glass        | 10.52 |  11.5 |
|        clock        | 30.42 | 41.03 |
|         flag        | 35.96 | 40.65 |
+---------------------+-------+-------+
2023-11-26 20:52:26,447 - mmseg - INFO - Summary:
2023-11-26 20:52:26,447 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 81.99 | 47.62 | 61.32 |
+-------+-------+-------+
2023-11-26 20:52:26,452 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 20:52:26,453 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8199, mIoU: 0.4762, mAcc: 0.6132, IoU.wall: 0.7593, IoU.building: 0.8175, IoU.sky: 0.9395, IoU.floor: 0.8050, IoU.tree: 0.7446, IoU.ceiling: 0.8195, IoU.road: 0.8151, IoU.bed : 0.8658, IoU.windowpane: 0.6055, IoU.grass: 0.6682, IoU.cabinet: 0.5665, IoU.sidewalk: 0.6403, IoU.person: 0.7844, IoU.earth: 0.3401, IoU.door: 0.4592, IoU.table: 0.5500, IoU.mountain: 0.5723, IoU.plant: 0.5194, IoU.curtain: 0.7443, IoU.chair: 0.5428, IoU.car: 0.8408, IoU.water: 0.6235, IoU.painting: 0.6588, IoU.sofa: 0.6411, IoU.shelf: 0.4005, IoU.house: 0.5192, IoU.sea: 0.6392, IoU.mirror: 0.6387, IoU.rug: 0.6679, IoU.field: 0.3176, IoU.armchair: 0.3549, IoU.seat: 0.6016, IoU.fence: 0.4444, IoU.desk: 0.4378, IoU.rock: 0.4493, IoU.wardrobe: 0.4461, IoU.lamp: 0.5882, IoU.bathtub: 0.7589, IoU.railing: 0.3288, IoU.cushion: 0.5216, IoU.base: 0.3263, IoU.box: 0.2645, IoU.column: 0.4508, IoU.signboard: 0.3703, IoU.chest of drawers: 0.4020, IoU.counter: 0.3066, IoU.sand: 0.3248, IoU.sink: 0.6423, IoU.skyscraper: 0.4609, IoU.fireplace: 0.7080, IoU.refrigerator: 0.7302, IoU.grandstand: 0.4859, IoU.path: 0.1723, IoU.stairs: 0.3540, IoU.runway: 0.7223, IoU.case: 0.4857, IoU.pool table: 0.9181, IoU.pillow: 0.5936, IoU.screen door: 0.6654, IoU.stairway: 0.4355, IoU.river: 0.1279, IoU.bridge: 0.6975, IoU.bookcase: 0.3159, IoU.blind: 0.3794, IoU.coffee table: 0.4727, IoU.toilet: 0.8367, IoU.flower: 0.3206, IoU.book: 0.3354, IoU.hill: 0.0669, IoU.bench: 0.4269, IoU.countertop: 0.5638, IoU.stove: 0.6193, IoU.palm: 0.5293, IoU.kitchen island: 0.3228, IoU.computer: 0.6118, IoU.swivel chair: 0.4971, IoU.boat: 0.3922, IoU.bar: 0.4820, IoU.arcade machine: 0.7457, IoU.hovel: 0.5135, IoU.bus: 0.8658, IoU.towel: 0.5985, IoU.light: 0.5285, IoU.truck: 0.3100, IoU.tower: 0.1974, IoU.chandelier: 0.6104, IoU.awning: 0.2338, IoU.streetlight: 0.2372, IoU.booth: 0.5404, IoU.television receiver: 0.6591, IoU.airplane: 0.5461, IoU.dirt track: 0.0440, IoU.apparel: 0.3538, IoU.pole: 0.1876, IoU.land: 0.0187, IoU.bannister: 0.1189, IoU.escalator: 0.4655, IoU.ottoman: 0.4335, IoU.bottle: 0.3414, IoU.buffet: 0.4547, IoU.poster: 0.2610, IoU.stage: 0.1843, IoU.van: 0.3851, IoU.ship: 0.0539, IoU.fountain: 0.4138, IoU.conveyer belt: 0.6629, IoU.canopy: 0.2402, IoU.washer: 0.7266, IoU.plaything: 0.2065, IoU.swimming pool: 0.7708, IoU.stool: 0.4285, IoU.barrel: 0.2636, IoU.basket: 0.3018, IoU.waterfall: 0.6544, IoU.tent: 0.8967, IoU.bag: 0.1297, IoU.minibike: 0.6940, IoU.cradle: 0.7702, IoU.oven: 0.3174, IoU.ball: 0.4207, IoU.food: 0.5687, IoU.step: 0.0680, IoU.tank: 0.3334, IoU.trade name: 0.1312, IoU.microwave: 0.7948, IoU.pot: 0.4235, IoU.animal: 0.6392, IoU.bicycle: 0.5708, IoU.lake: 0.5920, IoU.dishwasher: 0.4405, IoU.screen: 0.6792, IoU.blanket: 0.1050, IoU.sculpture: 0.5402, IoU.hood: 0.4924, IoU.sconce: 0.3370, IoU.vase: 0.3365, IoU.traffic light: 0.2476, IoU.tray: 0.0447, IoU.ashcan: 0.3379, IoU.fan: 0.5567, IoU.pier: 0.6057, IoU.crt screen: 0.0541, IoU.plate: 0.5223, IoU.monitor: 0.0730, IoU.bulletin board: 0.5093, IoU.shower: 0.0000, IoU.radiator: 0.6074, IoU.glass: 0.1052, IoU.clock: 0.3042, IoU.flag: 0.3596, Acc.wall: 0.8588, Acc.building: 0.9141, Acc.sky: 0.9685, Acc.floor: 0.8837, Acc.tree: 0.8754, Acc.ceiling: 0.9065, Acc.road: 0.9009, Acc.bed : 0.9447, Acc.windowpane: 0.7963, Acc.grass: 0.7881, Acc.cabinet: 0.6625, Acc.sidewalk: 0.7826, Acc.person: 0.9289, Acc.earth: 0.4868, Acc.door: 0.5678, Acc.table: 0.7147, Acc.mountain: 0.7322, Acc.plant: 0.6360, Acc.curtain: 0.8538, Acc.chair: 0.6686, Acc.car: 0.9316, Acc.water: 0.7773, Acc.painting: 0.8394, Acc.sofa: 0.8217, Acc.shelf: 0.6095, Acc.house: 0.6599, Acc.sea: 0.7366, Acc.mirror: 0.7287, Acc.rug: 0.8267, Acc.field: 0.5805, Acc.armchair: 0.5084, Acc.seat: 0.8232, Acc.fence: 0.6286, Acc.desk: 0.6736, Acc.rock: 0.6908, Acc.wardrobe: 0.7469, Acc.lamp: 0.6867, Acc.bathtub: 0.8776, Acc.railing: 0.3993, Acc.cushion: 0.6221, Acc.base: 0.4954, Acc.box: 0.3538, Acc.column: 0.5593, Acc.signboard: 0.4858, Acc.chest of drawers: 0.6242, Acc.counter: 0.3593, Acc.sand: 0.6170, Acc.sink: 0.7817, Acc.skyscraper: 0.6381, Acc.fireplace: 0.8812, Acc.refrigerator: 0.8503, Acc.grandstand: 0.7352, Acc.path: 0.2426, Acc.stairs: 0.4202, Acc.runway: 0.9444, Acc.case: 0.5709, Acc.pool table: 0.9698, Acc.pillow: 0.7918, Acc.screen door: 0.8024, Acc.stairway: 0.5308, Acc.river: 0.3100, Acc.bridge: 0.7993, Acc.bookcase: 0.6607, Acc.blind: 0.4616, Acc.coffee table: 0.8400, Acc.toilet: 0.8914, Acc.flower: 0.5078, Acc.book: 0.4583, Acc.hill: 0.1414, Acc.bench: 0.5358, Acc.countertop: 0.7466, Acc.stove: 0.7873, Acc.palm: 0.7492, Acc.kitchen island: 0.8323, Acc.computer: 0.8092, Acc.swivel chair: 0.7053, Acc.boat: 0.5244, Acc.bar: 0.6508, Acc.arcade machine: 0.9028, Acc.hovel: 0.7558, Acc.bus: 0.9568, Acc.towel: 0.8018, Acc.light: 0.6125, Acc.truck: 0.4692, Acc.tower: 0.4082, Acc.chandelier: 0.8472, Acc.awning: 0.2783, Acc.streetlight: 0.3127, Acc.booth: 0.6980, Acc.television receiver: 0.7490, Acc.airplane: 0.6569, Acc.dirt track: 0.1157, Acc.apparel: 0.4963, Acc.pole: 0.2548, Acc.land: 0.0381, Acc.bannister: 0.1642, Acc.escalator: 0.8134, Acc.ottoman: 0.6644, Acc.bottle: 0.5157, Acc.buffet: 0.6231, Acc.poster: 0.4088, Acc.stage: 0.2489, Acc.van: 0.4489, Acc.ship: 0.0867, Acc.fountain: 0.4179, Acc.conveyer belt: 0.8579, Acc.canopy: 0.3740, Acc.washer: 0.7910, Acc.plaything: 0.3869, Acc.swimming pool: 0.8881, Acc.stool: 0.5852, Acc.barrel: 0.6512, Acc.basket: 0.4715, Acc.waterfall: 0.9465, Acc.tent: 0.9863, Acc.bag: 0.1612, Acc.minibike: 0.7843, Acc.cradle: 0.9711, Acc.oven: 0.3630, Acc.ball: 0.6604, Acc.food: 0.6612, Acc.step: 0.0761, Acc.tank: 0.3848, Acc.trade name: 0.1345, Acc.microwave: 0.9173, Acc.pot: 0.4837, Acc.animal: 0.6758, Acc.bicycle: 0.7954, Acc.lake: 0.6701, Acc.dishwasher: 0.5563, Acc.screen: 0.9017, Acc.blanket: 0.1431, Acc.sculpture: 0.7123, Acc.hood: 0.5266, Acc.sconce: 0.4302, Acc.vase: 0.4581, Acc.traffic light: 0.4933, Acc.tray: 0.0590, Acc.ashcan: 0.5580, Acc.fan: 0.7138, Acc.pier: 0.8001, Acc.crt screen: 0.1759, Acc.plate: 0.6424, Acc.monitor: 0.1078, Acc.bulletin board: 0.5849, Acc.shower: 0.0000, Acc.radiator: 0.6615, Acc.glass: 0.1150, Acc.clock: 0.4103, Acc.flag: 0.4065
2023-11-26 20:53:03,812 - mmseg - INFO - Iter [32050/160000]	lr: 4.798e-05, eta: 1 day, 4:26:27, time: 2.593, data_time: 1.857, memory: 21695, decode.loss_ce: 0.3440, decode.acc_seg: 86.0171, aux.loss_ce: 0.1553, aux.acc_seg: 84.9345, loss: 0.4992
2023-11-26 20:53:43,565 - mmseg - INFO - Iter [32100/160000]	lr: 4.796e-05, eta: 1 day, 4:25:46, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3709, decode.acc_seg: 85.1906, aux.loss_ce: 0.1679, aux.acc_seg: 83.6266, loss: 0.5388
2023-11-26 20:54:24,126 - mmseg - INFO - Iter [32150/160000]	lr: 4.794e-05, eta: 1 day, 4:25:08, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3625, decode.acc_seg: 85.7565, aux.loss_ce: 0.1642, aux.acc_seg: 84.4032, loss: 0.5267
2023-11-26 20:55:03,479 - mmseg - INFO - Iter [32200/160000]	lr: 4.793e-05, eta: 1 day, 4:24:26, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3845, decode.acc_seg: 84.9179, aux.loss_ce: 0.1704, aux.acc_seg: 83.7731, loss: 0.5548
2023-11-26 20:55:40,255 - mmseg - INFO - Iter [32250/160000]	lr: 4.791e-05, eta: 1 day, 4:23:33, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3643, decode.acc_seg: 85.4538, aux.loss_ce: 0.1630, aux.acc_seg: 84.1577, loss: 0.5273
2023-11-26 20:56:20,674 - mmseg - INFO - Iter [32300/160000]	lr: 4.789e-05, eta: 1 day, 4:22:54, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3966, decode.acc_seg: 84.6822, aux.loss_ce: 0.1753, aux.acc_seg: 83.2714, loss: 0.5719
2023-11-26 20:57:00,126 - mmseg - INFO - Iter [32350/160000]	lr: 4.787e-05, eta: 1 day, 4:22:12, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3844, decode.acc_seg: 84.8337, aux.loss_ce: 0.1694, aux.acc_seg: 84.0881, loss: 0.5538
2023-11-26 20:57:39,609 - mmseg - INFO - Iter [32400/160000]	lr: 4.785e-05, eta: 1 day, 4:21:30, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3650, decode.acc_seg: 85.5642, aux.loss_ce: 0.1613, aux.acc_seg: 84.6083, loss: 0.5263
2023-11-26 20:58:16,656 - mmseg - INFO - Iter [32450/160000]	lr: 4.783e-05, eta: 1 day, 4:20:39, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3702, decode.acc_seg: 85.2672, aux.loss_ce: 0.1645, aux.acc_seg: 84.0860, loss: 0.5347
2023-11-26 20:58:53,639 - mmseg - INFO - Iter [32500/160000]	lr: 4.781e-05, eta: 1 day, 4:19:47, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3644, decode.acc_seg: 85.8055, aux.loss_ce: 0.1613, aux.acc_seg: 84.6664, loss: 0.5257
2023-11-26 20:59:32,212 - mmseg - INFO - Iter [32550/160000]	lr: 4.779e-05, eta: 1 day, 4:19:01, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3809, decode.acc_seg: 85.3320, aux.loss_ce: 0.1705, aux.acc_seg: 84.0264, loss: 0.5515
2023-11-26 21:00:10,201 - mmseg - INFO - Iter [32600/160000]	lr: 4.778e-05, eta: 1 day, 4:18:13, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3975, decode.acc_seg: 84.8180, aux.loss_ce: 0.1729, aux.acc_seg: 83.9197, loss: 0.5704
2023-11-26 21:00:49,043 - mmseg - INFO - Iter [32650/160000]	lr: 4.776e-05, eta: 1 day, 4:17:29, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3862, decode.acc_seg: 85.2319, aux.loss_ce: 0.1701, aux.acc_seg: 84.1138, loss: 0.5563
2023-11-26 21:01:29,287 - mmseg - INFO - Iter [32700/160000]	lr: 4.774e-05, eta: 1 day, 4:16:50, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3838, decode.acc_seg: 84.9795, aux.loss_ce: 0.1719, aux.acc_seg: 83.5945, loss: 0.5557
2023-11-26 21:02:05,876 - mmseg - INFO - Iter [32750/160000]	lr: 4.772e-05, eta: 1 day, 4:15:57, time: 0.733, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3732, decode.acc_seg: 85.1610, aux.loss_ce: 0.1696, aux.acc_seg: 83.8968, loss: 0.5428
2023-11-26 21:02:42,635 - mmseg - INFO - Iter [32800/160000]	lr: 4.770e-05, eta: 1 day, 4:15:04, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3716, decode.acc_seg: 85.2101, aux.loss_ce: 0.1670, aux.acc_seg: 83.7192, loss: 0.5386
2023-11-26 21:03:22,181 - mmseg - INFO - Iter [32850/160000]	lr: 4.768e-05, eta: 1 day, 4:14:23, time: 0.791, data_time: 0.052, memory: 21695, decode.loss_ce: 0.3715, decode.acc_seg: 85.4637, aux.loss_ce: 0.1633, aux.acc_seg: 84.5708, loss: 0.5347
2023-11-26 21:04:02,364 - mmseg - INFO - Iter [32900/160000]	lr: 4.766e-05, eta: 1 day, 4:13:43, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3540, decode.acc_seg: 85.7730, aux.loss_ce: 0.1580, aux.acc_seg: 84.7825, loss: 0.5120
2023-11-26 21:04:42,740 - mmseg - INFO - Iter [32950/160000]	lr: 4.764e-05, eta: 1 day, 4:13:05, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3610, decode.acc_seg: 85.3723, aux.loss_ce: 0.1644, aux.acc_seg: 83.9609, loss: 0.5253
2023-11-26 21:05:21,824 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 21:05:21,824 - mmseg - INFO - Iter [33000/160000]	lr: 4.763e-05, eta: 1 day, 4:12:21, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3745, decode.acc_seg: 85.2809, aux.loss_ce: 0.1656, aux.acc_seg: 84.2098, loss: 0.5401
2023-11-26 21:06:02,223 - mmseg - INFO - Iter [33050/160000]	lr: 4.761e-05, eta: 1 day, 4:11:43, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3764, decode.acc_seg: 84.9301, aux.loss_ce: 0.1670, aux.acc_seg: 83.9650, loss: 0.5434
2023-11-26 21:06:42,247 - mmseg - INFO - Iter [33100/160000]	lr: 4.759e-05, eta: 1 day, 4:11:03, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3481, decode.acc_seg: 86.6019, aux.loss_ce: 0.1557, aux.acc_seg: 85.2735, loss: 0.5038
2023-11-26 21:07:19,354 - mmseg - INFO - Iter [33150/160000]	lr: 4.757e-05, eta: 1 day, 4:10:12, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3414, decode.acc_seg: 86.5761, aux.loss_ce: 0.1524, aux.acc_seg: 85.4879, loss: 0.4938
2023-11-26 21:07:59,374 - mmseg - INFO - Iter [33200/160000]	lr: 4.755e-05, eta: 1 day, 4:09:32, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3509, decode.acc_seg: 86.2233, aux.loss_ce: 0.1562, aux.acc_seg: 85.1093, loss: 0.5071
2023-11-26 21:08:39,837 - mmseg - INFO - Iter [33250/160000]	lr: 4.753e-05, eta: 1 day, 4:08:54, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3950, decode.acc_seg: 84.5877, aux.loss_ce: 0.1745, aux.acc_seg: 83.4356, loss: 0.5695
2023-11-26 21:09:20,488 - mmseg - INFO - Iter [33300/160000]	lr: 4.751e-05, eta: 1 day, 4:08:17, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3490, decode.acc_seg: 85.9030, aux.loss_ce: 0.1563, aux.acc_seg: 84.6727, loss: 0.5053
2023-11-26 21:10:00,647 - mmseg - INFO - Iter [33350/160000]	lr: 4.749e-05, eta: 1 day, 4:07:38, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3326, decode.acc_seg: 86.8656, aux.loss_ce: 0.1464, aux.acc_seg: 85.9513, loss: 0.4791
2023-11-26 21:10:41,416 - mmseg - INFO - Iter [33400/160000]	lr: 4.748e-05, eta: 1 day, 4:07:01, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3709, decode.acc_seg: 85.1545, aux.loss_ce: 0.1642, aux.acc_seg: 84.1701, loss: 0.5351
2023-11-26 21:11:20,368 - mmseg - INFO - Iter [33450/160000]	lr: 4.746e-05, eta: 1 day, 4:06:17, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3888, decode.acc_seg: 84.8379, aux.loss_ce: 0.1709, aux.acc_seg: 83.7718, loss: 0.5597
2023-11-26 21:11:57,985 - mmseg - INFO - Iter [33500/160000]	lr: 4.744e-05, eta: 1 day, 4:05:28, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3763, decode.acc_seg: 85.3274, aux.loss_ce: 0.1674, aux.acc_seg: 84.2378, loss: 0.5437
2023-11-26 21:12:35,703 - mmseg - INFO - Iter [33550/160000]	lr: 4.742e-05, eta: 1 day, 4:04:40, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3658, decode.acc_seg: 85.6653, aux.loss_ce: 0.1659, aux.acc_seg: 84.1188, loss: 0.5318
2023-11-26 21:13:14,894 - mmseg - INFO - Iter [33600/160000]	lr: 4.740e-05, eta: 1 day, 4:03:57, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3520, decode.acc_seg: 85.5469, aux.loss_ce: 0.1575, aux.acc_seg: 84.4113, loss: 0.5094
2023-11-26 21:13:52,842 - mmseg - INFO - Iter [33650/160000]	lr: 4.738e-05, eta: 1 day, 4:03:09, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3967, decode.acc_seg: 84.4282, aux.loss_ce: 0.1789, aux.acc_seg: 83.0048, loss: 0.5756
2023-11-26 21:14:32,112 - mmseg - INFO - Iter [33700/160000]	lr: 4.736e-05, eta: 1 day, 4:02:26, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3536, decode.acc_seg: 85.6685, aux.loss_ce: 0.1553, aux.acc_seg: 84.7698, loss: 0.5089
2023-11-26 21:15:10,729 - mmseg - INFO - Iter [33750/160000]	lr: 4.734e-05, eta: 1 day, 4:01:41, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3640, decode.acc_seg: 85.6081, aux.loss_ce: 0.1617, aux.acc_seg: 84.5747, loss: 0.5257
2023-11-26 21:15:49,417 - mmseg - INFO - Iter [33800/160000]	lr: 4.733e-05, eta: 1 day, 4:00:57, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3826, decode.acc_seg: 84.9149, aux.loss_ce: 0.1684, aux.acc_seg: 83.9739, loss: 0.5510
2023-11-26 21:16:30,091 - mmseg - INFO - Iter [33850/160000]	lr: 4.731e-05, eta: 1 day, 4:00:19, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3523, decode.acc_seg: 85.6855, aux.loss_ce: 0.1560, aux.acc_seg: 84.8020, loss: 0.5083
2023-11-26 21:17:10,195 - mmseg - INFO - Iter [33900/160000]	lr: 4.729e-05, eta: 1 day, 3:59:40, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3649, decode.acc_seg: 85.6402, aux.loss_ce: 0.1649, aux.acc_seg: 84.3226, loss: 0.5298
2023-11-26 21:17:50,237 - mmseg - INFO - Iter [33950/160000]	lr: 4.727e-05, eta: 1 day, 3:59:01, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3606, decode.acc_seg: 85.9966, aux.loss_ce: 0.1615, aux.acc_seg: 84.8217, loss: 0.5221
2023-11-26 21:18:27,415 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 21:18:27,416 - mmseg - INFO - Iter [34000/160000]	lr: 4.725e-05, eta: 1 day, 3:58:10, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3898, decode.acc_seg: 84.4662, aux.loss_ce: 0.1707, aux.acc_seg: 83.5593, loss: 0.5606
2023-11-26 21:19:06,798 - mmseg - INFO - Iter [34050/160000]	lr: 4.723e-05, eta: 1 day, 3:57:28, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3795, decode.acc_seg: 85.1821, aux.loss_ce: 0.1674, aux.acc_seg: 84.3044, loss: 0.5470
2023-11-26 21:19:47,087 - mmseg - INFO - Iter [34100/160000]	lr: 4.721e-05, eta: 1 day, 3:56:49, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3652, decode.acc_seg: 85.5588, aux.loss_ce: 0.1628, aux.acc_seg: 84.3989, loss: 0.5279
2023-11-26 21:20:26,425 - mmseg - INFO - Iter [34150/160000]	lr: 4.719e-05, eta: 1 day, 3:56:07, time: 0.787, data_time: 0.052, memory: 21695, decode.loss_ce: 0.3630, decode.acc_seg: 85.5466, aux.loss_ce: 0.1631, aux.acc_seg: 84.7130, loss: 0.5261
2023-11-26 21:21:06,409 - mmseg - INFO - Iter [34200/160000]	lr: 4.718e-05, eta: 1 day, 3:55:27, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3473, decode.acc_seg: 86.4856, aux.loss_ce: 0.1566, aux.acc_seg: 85.0897, loss: 0.5039
2023-11-26 21:21:47,185 - mmseg - INFO - Iter [34250/160000]	lr: 4.716e-05, eta: 1 day, 3:54:50, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3331, decode.acc_seg: 86.7035, aux.loss_ce: 0.1502, aux.acc_seg: 85.5425, loss: 0.4833
2023-11-26 21:22:26,783 - mmseg - INFO - Iter [34300/160000]	lr: 4.714e-05, eta: 1 day, 3:54:09, time: 0.793, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3745, decode.acc_seg: 85.5376, aux.loss_ce: 0.1667, aux.acc_seg: 84.3497, loss: 0.5411
2023-11-26 21:23:05,478 - mmseg - INFO - Iter [34350/160000]	lr: 4.712e-05, eta: 1 day, 3:53:25, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3699, decode.acc_seg: 85.8057, aux.loss_ce: 0.1653, aux.acc_seg: 84.4043, loss: 0.5352
2023-11-26 21:23:43,303 - mmseg - INFO - Iter [34400/160000]	lr: 4.710e-05, eta: 1 day, 3:52:37, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3661, decode.acc_seg: 85.6347, aux.loss_ce: 0.1620, aux.acc_seg: 84.6091, loss: 0.5281
2023-11-26 21:24:23,137 - mmseg - INFO - Iter [34450/160000]	lr: 4.708e-05, eta: 1 day, 3:51:56, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3496, decode.acc_seg: 85.7877, aux.loss_ce: 0.1566, aux.acc_seg: 84.6938, loss: 0.5062
2023-11-26 21:25:03,207 - mmseg - INFO - Iter [34500/160000]	lr: 4.706e-05, eta: 1 day, 3:51:17, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3853, decode.acc_seg: 85.1297, aux.loss_ce: 0.1709, aux.acc_seg: 83.8612, loss: 0.5563
2023-11-26 21:25:43,137 - mmseg - INFO - Iter [34550/160000]	lr: 4.704e-05, eta: 1 day, 3:50:37, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3602, decode.acc_seg: 85.8768, aux.loss_ce: 0.1640, aux.acc_seg: 84.5895, loss: 0.5242
2023-11-26 21:26:21,158 - mmseg - INFO - Iter [34600/160000]	lr: 4.703e-05, eta: 1 day, 3:49:50, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3784, decode.acc_seg: 85.4790, aux.loss_ce: 0.1678, aux.acc_seg: 84.2614, loss: 0.5463
2023-11-26 21:26:59,872 - mmseg - INFO - Iter [34650/160000]	lr: 4.701e-05, eta: 1 day, 3:49:05, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3706, decode.acc_seg: 85.2972, aux.loss_ce: 0.1666, aux.acc_seg: 83.9661, loss: 0.5372
2023-11-26 21:27:37,204 - mmseg - INFO - Iter [34700/160000]	lr: 4.699e-05, eta: 1 day, 3:48:16, time: 0.747, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3638, decode.acc_seg: 85.4975, aux.loss_ce: 0.1609, aux.acc_seg: 84.7817, loss: 0.5247
2023-11-26 21:28:15,927 - mmseg - INFO - Iter [34750/160000]	lr: 4.697e-05, eta: 1 day, 3:47:32, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3563, decode.acc_seg: 86.1379, aux.loss_ce: 0.1589, aux.acc_seg: 84.8900, loss: 0.5152
2023-11-26 21:28:56,346 - mmseg - INFO - Iter [34800/160000]	lr: 4.695e-05, eta: 1 day, 3:46:53, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3726, decode.acc_seg: 85.2000, aux.loss_ce: 0.1643, aux.acc_seg: 84.1941, loss: 0.5369
2023-11-26 21:29:36,996 - mmseg - INFO - Iter [34850/160000]	lr: 4.693e-05, eta: 1 day, 3:46:16, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3454, decode.acc_seg: 86.0033, aux.loss_ce: 0.1548, aux.acc_seg: 85.0013, loss: 0.5002
2023-11-26 21:30:17,987 - mmseg - INFO - Iter [34900/160000]	lr: 4.691e-05, eta: 1 day, 3:45:40, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3591, decode.acc_seg: 85.9999, aux.loss_ce: 0.1606, aux.acc_seg: 84.4684, loss: 0.5198
2023-11-26 21:30:59,129 - mmseg - INFO - Iter [34950/160000]	lr: 4.689e-05, eta: 1 day, 3:45:04, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3565, decode.acc_seg: 85.5507, aux.loss_ce: 0.1573, aux.acc_seg: 84.4805, loss: 0.5138
2023-11-26 21:31:39,450 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 21:31:39,451 - mmseg - INFO - Iter [35000/160000]	lr: 4.688e-05, eta: 1 day, 3:44:26, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3850, decode.acc_seg: 85.0165, aux.loss_ce: 0.1708, aux.acc_seg: 83.8054, loss: 0.5558
2023-11-26 21:32:19,412 - mmseg - INFO - Iter [35050/160000]	lr: 4.686e-05, eta: 1 day, 3:43:46, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3846, decode.acc_seg: 84.3320, aux.loss_ce: 0.1703, aux.acc_seg: 83.2643, loss: 0.5548
2023-11-26 21:32:58,397 - mmseg - INFO - Iter [35100/160000]	lr: 4.684e-05, eta: 1 day, 3:43:02, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3717, decode.acc_seg: 84.9298, aux.loss_ce: 0.1692, aux.acc_seg: 83.7621, loss: 0.5409
2023-11-26 21:33:35,906 - mmseg - INFO - Iter [35150/160000]	lr: 4.682e-05, eta: 1 day, 3:42:14, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3803, decode.acc_seg: 85.2772, aux.loss_ce: 0.1714, aux.acc_seg: 83.8816, loss: 0.5517
2023-11-26 21:34:15,534 - mmseg - INFO - Iter [35200/160000]	lr: 4.680e-05, eta: 1 day, 3:41:33, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3713, decode.acc_seg: 85.4392, aux.loss_ce: 0.1633, aux.acc_seg: 84.5123, loss: 0.5346
2023-11-26 21:34:55,040 - mmseg - INFO - Iter [35250/160000]	lr: 4.678e-05, eta: 1 day, 3:40:51, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3836, decode.acc_seg: 84.9960, aux.loss_ce: 0.1689, aux.acc_seg: 84.0266, loss: 0.5524
2023-11-26 21:35:34,592 - mmseg - INFO - Iter [35300/160000]	lr: 4.676e-05, eta: 1 day, 3:40:10, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3864, decode.acc_seg: 85.2565, aux.loss_ce: 0.1727, aux.acc_seg: 84.1829, loss: 0.5592
2023-11-26 21:36:14,119 - mmseg - INFO - Iter [35350/160000]	lr: 4.674e-05, eta: 1 day, 3:39:28, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3751, decode.acc_seg: 85.3413, aux.loss_ce: 0.1680, aux.acc_seg: 84.0714, loss: 0.5431
2023-11-26 21:36:54,112 - mmseg - INFO - Iter [35400/160000]	lr: 4.673e-05, eta: 1 day, 3:38:49, time: 0.801, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3349, decode.acc_seg: 86.7055, aux.loss_ce: 0.1508, aux.acc_seg: 85.4280, loss: 0.4857
2023-11-26 21:37:33,158 - mmseg - INFO - Iter [35450/160000]	lr: 4.671e-05, eta: 1 day, 3:38:06, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3359, decode.acc_seg: 86.4246, aux.loss_ce: 0.1521, aux.acc_seg: 85.1299, loss: 0.4880
2023-11-26 21:38:13,583 - mmseg - INFO - Iter [35500/160000]	lr: 4.669e-05, eta: 1 day, 3:37:27, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3547, decode.acc_seg: 86.1827, aux.loss_ce: 0.1587, aux.acc_seg: 85.2230, loss: 0.5134
2023-11-26 21:38:54,339 - mmseg - INFO - Iter [35550/160000]	lr: 4.667e-05, eta: 1 day, 3:36:50, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3660, decode.acc_seg: 85.6938, aux.loss_ce: 0.1596, aux.acc_seg: 84.7534, loss: 0.5256
2023-11-26 21:39:34,586 - mmseg - INFO - Iter [35600/160000]	lr: 4.665e-05, eta: 1 day, 3:36:11, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3621, decode.acc_seg: 85.6950, aux.loss_ce: 0.1628, aux.acc_seg: 84.5136, loss: 0.5248
2023-11-26 21:40:14,569 - mmseg - INFO - Iter [35650/160000]	lr: 4.663e-05, eta: 1 day, 3:35:32, time: 0.800, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3320, decode.acc_seg: 86.5584, aux.loss_ce: 0.1495, aux.acc_seg: 85.5927, loss: 0.4815
2023-11-26 21:40:55,708 - mmseg - INFO - Iter [35700/160000]	lr: 4.661e-05, eta: 1 day, 3:34:56, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3592, decode.acc_seg: 85.6475, aux.loss_ce: 0.1593, aux.acc_seg: 84.6678, loss: 0.5184
2023-11-26 21:41:36,055 - mmseg - INFO - Iter [35750/160000]	lr: 4.659e-05, eta: 1 day, 3:34:17, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3383, decode.acc_seg: 86.7517, aux.loss_ce: 0.1523, aux.acc_seg: 85.6662, loss: 0.4906
2023-11-26 21:42:14,921 - mmseg - INFO - Iter [35800/160000]	lr: 4.658e-05, eta: 1 day, 3:33:34, time: 0.778, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3600, decode.acc_seg: 85.3425, aux.loss_ce: 0.1623, aux.acc_seg: 84.2499, loss: 0.5223
2023-11-26 21:42:55,193 - mmseg - INFO - Iter [35850/160000]	lr: 4.656e-05, eta: 1 day, 3:32:55, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3409, decode.acc_seg: 86.1614, aux.loss_ce: 0.1537, aux.acc_seg: 85.0547, loss: 0.4946
2023-11-26 21:43:35,523 - mmseg - INFO - Iter [35900/160000]	lr: 4.654e-05, eta: 1 day, 3:32:16, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3596, decode.acc_seg: 85.8294, aux.loss_ce: 0.1574, aux.acc_seg: 85.0277, loss: 0.5170
2023-11-26 21:44:12,356 - mmseg - INFO - Iter [35950/160000]	lr: 4.652e-05, eta: 1 day, 3:31:26, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3608, decode.acc_seg: 85.7930, aux.loss_ce: 0.1614, aux.acc_seg: 84.5396, loss: 0.5222
2023-11-26 21:44:50,258 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 21:44:50,259 - mmseg - INFO - Iter [36000/160000]	lr: 4.650e-05, eta: 1 day, 3:30:39, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3712, decode.acc_seg: 85.6770, aux.loss_ce: 0.1644, aux.acc_seg: 84.5418, loss: 0.5356
2023-11-26 21:45:29,881 - mmseg - INFO - Iter [36050/160000]	lr: 4.648e-05, eta: 1 day, 3:29:58, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3391, decode.acc_seg: 86.0827, aux.loss_ce: 0.1512, aux.acc_seg: 85.0323, loss: 0.4903
2023-11-26 21:46:07,859 - mmseg - INFO - Iter [36100/160000]	lr: 4.646e-05, eta: 1 day, 3:29:11, time: 0.761, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3431, decode.acc_seg: 86.3484, aux.loss_ce: 0.1567, aux.acc_seg: 84.6124, loss: 0.4998
2023-11-26 21:46:46,000 - mmseg - INFO - Iter [36150/160000]	lr: 4.644e-05, eta: 1 day, 3:28:25, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3651, decode.acc_seg: 85.2671, aux.loss_ce: 0.1632, aux.acc_seg: 84.2535, loss: 0.5283
2023-11-26 21:47:24,634 - mmseg - INFO - Iter [36200/160000]	lr: 4.643e-05, eta: 1 day, 3:27:41, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3393, decode.acc_seg: 86.3475, aux.loss_ce: 0.1528, aux.acc_seg: 85.1258, loss: 0.4921
2023-11-26 21:48:04,297 - mmseg - INFO - Iter [36250/160000]	lr: 4.641e-05, eta: 1 day, 3:27:00, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3710, decode.acc_seg: 85.6285, aux.loss_ce: 0.1672, aux.acc_seg: 84.2731, loss: 0.5381
2023-11-26 21:48:43,751 - mmseg - INFO - Iter [36300/160000]	lr: 4.639e-05, eta: 1 day, 3:26:18, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3784, decode.acc_seg: 84.8811, aux.loss_ce: 0.1709, aux.acc_seg: 83.5234, loss: 0.5493
2023-11-26 21:49:23,611 - mmseg - INFO - Iter [36350/160000]	lr: 4.637e-05, eta: 1 day, 3:25:38, time: 0.797, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3572, decode.acc_seg: 86.1872, aux.loss_ce: 0.1614, aux.acc_seg: 84.9451, loss: 0.5186
2023-11-26 21:50:04,013 - mmseg - INFO - Iter [36400/160000]	lr: 4.635e-05, eta: 1 day, 3:25:00, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3522, decode.acc_seg: 86.1020, aux.loss_ce: 0.1582, aux.acc_seg: 84.8918, loss: 0.5105
2023-11-26 21:50:44,398 - mmseg - INFO - Iter [36450/160000]	lr: 4.633e-05, eta: 1 day, 3:24:21, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3665, decode.acc_seg: 85.5813, aux.loss_ce: 0.1642, aux.acc_seg: 84.3003, loss: 0.5307
2023-11-26 21:51:24,291 - mmseg - INFO - Iter [36500/160000]	lr: 4.631e-05, eta: 1 day, 3:23:41, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3774, decode.acc_seg: 85.1158, aux.loss_ce: 0.1673, aux.acc_seg: 83.8286, loss: 0.5447
2023-11-26 21:52:03,047 - mmseg - INFO - Iter [36550/160000]	lr: 4.629e-05, eta: 1 day, 3:22:57, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3750, decode.acc_seg: 85.4392, aux.loss_ce: 0.1654, aux.acc_seg: 84.4069, loss: 0.5404
2023-11-26 21:52:44,094 - mmseg - INFO - Iter [36600/160000]	lr: 4.628e-05, eta: 1 day, 3:22:21, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3662, decode.acc_seg: 85.4875, aux.loss_ce: 0.1621, aux.acc_seg: 84.2747, loss: 0.5283
2023-11-26 21:53:25,723 - mmseg - INFO - Iter [36650/160000]	lr: 4.626e-05, eta: 1 day, 3:21:47, time: 0.833, data_time: 0.054, memory: 21695, decode.loss_ce: 0.3505, decode.acc_seg: 86.7246, aux.loss_ce: 0.1593, aux.acc_seg: 85.2539, loss: 0.5098
2023-11-26 21:54:04,538 - mmseg - INFO - Iter [36700/160000]	lr: 4.624e-05, eta: 1 day, 3:21:03, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3595, decode.acc_seg: 85.8692, aux.loss_ce: 0.1619, aux.acc_seg: 84.5595, loss: 0.5214
2023-11-26 21:54:45,385 - mmseg - INFO - Iter [36750/160000]	lr: 4.622e-05, eta: 1 day, 3:20:26, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3839, decode.acc_seg: 85.2656, aux.loss_ce: 0.1683, aux.acc_seg: 84.1707, loss: 0.5522
2023-11-26 21:55:25,770 - mmseg - INFO - Iter [36800/160000]	lr: 4.620e-05, eta: 1 day, 3:19:48, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3666, decode.acc_seg: 85.3561, aux.loss_ce: 0.1627, aux.acc_seg: 84.2520, loss: 0.5293
2023-11-26 21:56:05,758 - mmseg - INFO - Iter [36850/160000]	lr: 4.618e-05, eta: 1 day, 3:19:08, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3346, decode.acc_seg: 86.4263, aux.loss_ce: 0.1517, aux.acc_seg: 85.0494, loss: 0.4864
2023-11-26 21:56:45,407 - mmseg - INFO - Iter [36900/160000]	lr: 4.616e-05, eta: 1 day, 3:18:27, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3396, decode.acc_seg: 86.5183, aux.loss_ce: 0.1546, aux.acc_seg: 85.2798, loss: 0.4942
2023-11-26 21:57:25,574 - mmseg - INFO - Iter [36950/160000]	lr: 4.614e-05, eta: 1 day, 3:17:48, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3770, decode.acc_seg: 85.2667, aux.loss_ce: 0.1674, aux.acc_seg: 84.3838, loss: 0.5444
2023-11-26 21:58:05,747 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 21:58:05,747 - mmseg - INFO - Iter [37000/160000]	lr: 4.613e-05, eta: 1 day, 3:17:09, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3370, decode.acc_seg: 86.5664, aux.loss_ce: 0.1499, aux.acc_seg: 85.5154, loss: 0.4869
2023-11-26 21:58:46,459 - mmseg - INFO - Iter [37050/160000]	lr: 4.611e-05, eta: 1 day, 3:16:32, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3515, decode.acc_seg: 86.0319, aux.loss_ce: 0.1565, aux.acc_seg: 84.9749, loss: 0.5080
2023-11-26 21:59:26,351 - mmseg - INFO - Iter [37100/160000]	lr: 4.609e-05, eta: 1 day, 3:15:52, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3654, decode.acc_seg: 85.0487, aux.loss_ce: 0.1640, aux.acc_seg: 83.8813, loss: 0.5294
2023-11-26 22:00:04,944 - mmseg - INFO - Iter [37150/160000]	lr: 4.607e-05, eta: 1 day, 3:15:07, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3651, decode.acc_seg: 85.7964, aux.loss_ce: 0.1594, aux.acc_seg: 84.9650, loss: 0.5245
2023-11-26 22:00:45,235 - mmseg - INFO - Iter [37200/160000]	lr: 4.605e-05, eta: 1 day, 3:14:29, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3286, decode.acc_seg: 86.9102, aux.loss_ce: 0.1472, aux.acc_seg: 85.7789, loss: 0.4758
2023-11-26 22:01:24,359 - mmseg - INFO - Iter [37250/160000]	lr: 4.603e-05, eta: 1 day, 3:13:46, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3358, decode.acc_seg: 86.3689, aux.loss_ce: 0.1503, aux.acc_seg: 85.3303, loss: 0.4861
2023-11-26 22:02:03,801 - mmseg - INFO - Iter [37300/160000]	lr: 4.601e-05, eta: 1 day, 3:13:05, time: 0.790, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3745, decode.acc_seg: 84.8363, aux.loss_ce: 0.1630, aux.acc_seg: 83.9935, loss: 0.5375
2023-11-26 22:02:43,330 - mmseg - INFO - Iter [37350/160000]	lr: 4.599e-05, eta: 1 day, 3:12:23, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3439, decode.acc_seg: 86.1078, aux.loss_ce: 0.1546, aux.acc_seg: 85.0725, loss: 0.4985
2023-11-26 22:03:23,330 - mmseg - INFO - Iter [37400/160000]	lr: 4.598e-05, eta: 1 day, 3:11:44, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3311, decode.acc_seg: 86.7311, aux.loss_ce: 0.1488, aux.acc_seg: 85.6504, loss: 0.4799
2023-11-26 22:04:03,258 - mmseg - INFO - Iter [37450/160000]	lr: 4.596e-05, eta: 1 day, 3:11:04, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3445, decode.acc_seg: 86.3878, aux.loss_ce: 0.1531, aux.acc_seg: 85.2485, loss: 0.4976
2023-11-26 22:04:42,378 - mmseg - INFO - Iter [37500/160000]	lr: 4.594e-05, eta: 1 day, 3:10:21, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3305, decode.acc_seg: 86.6430, aux.loss_ce: 0.1468, aux.acc_seg: 85.6350, loss: 0.4773
2023-11-26 22:05:23,123 - mmseg - INFO - Iter [37550/160000]	lr: 4.592e-05, eta: 1 day, 3:09:44, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.4002, decode.acc_seg: 84.4618, aux.loss_ce: 0.1774, aux.acc_seg: 83.1541, loss: 0.5776
2023-11-26 22:06:01,706 - mmseg - INFO - Iter [37600/160000]	lr: 4.590e-05, eta: 1 day, 3:09:00, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3650, decode.acc_seg: 85.8508, aux.loss_ce: 0.1624, aux.acc_seg: 84.2892, loss: 0.5274
2023-11-26 22:06:42,455 - mmseg - INFO - Iter [37650/160000]	lr: 4.588e-05, eta: 1 day, 3:08:22, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3522, decode.acc_seg: 86.3080, aux.loss_ce: 0.1584, aux.acc_seg: 85.0639, loss: 0.5106
2023-11-26 22:07:19,403 - mmseg - INFO - Iter [37700/160000]	lr: 4.586e-05, eta: 1 day, 3:07:33, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3673, decode.acc_seg: 85.6363, aux.loss_ce: 0.1639, aux.acc_seg: 84.1726, loss: 0.5312
2023-11-26 22:07:56,540 - mmseg - INFO - Iter [37750/160000]	lr: 4.584e-05, eta: 1 day, 3:06:44, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3833, decode.acc_seg: 85.4503, aux.loss_ce: 0.1712, aux.acc_seg: 84.0983, loss: 0.5546
2023-11-26 22:08:35,360 - mmseg - INFO - Iter [37800/160000]	lr: 4.583e-05, eta: 1 day, 3:06:00, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3488, decode.acc_seg: 86.4085, aux.loss_ce: 0.1582, aux.acc_seg: 85.0055, loss: 0.5069
2023-11-26 22:09:15,290 - mmseg - INFO - Iter [37850/160000]	lr: 4.581e-05, eta: 1 day, 3:05:20, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3444, decode.acc_seg: 86.4694, aux.loss_ce: 0.1551, aux.acc_seg: 85.2344, loss: 0.4995
2023-11-26 22:09:56,582 - mmseg - INFO - Iter [37900/160000]	lr: 4.579e-05, eta: 1 day, 3:04:45, time: 0.827, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3531, decode.acc_seg: 85.6084, aux.loss_ce: 0.1560, aux.acc_seg: 84.3224, loss: 0.5091
2023-11-26 22:10:37,326 - mmseg - INFO - Iter [37950/160000]	lr: 4.577e-05, eta: 1 day, 3:04:08, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3476, decode.acc_seg: 86.5254, aux.loss_ce: 0.1566, aux.acc_seg: 85.3545, loss: 0.5042
2023-11-26 22:11:16,999 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 22:11:17,000 - mmseg - INFO - Iter [38000/160000]	lr: 4.575e-05, eta: 1 day, 3:03:27, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3293, decode.acc_seg: 86.8304, aux.loss_ce: 0.1488, aux.acc_seg: 85.6585, loss: 0.4781
2023-11-26 22:11:57,485 - mmseg - INFO - Iter [38050/160000]	lr: 4.573e-05, eta: 1 day, 3:02:49, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3303, decode.acc_seg: 86.4553, aux.loss_ce: 0.1490, aux.acc_seg: 85.2903, loss: 0.4793
2023-11-26 22:12:38,302 - mmseg - INFO - Iter [38100/160000]	lr: 4.571e-05, eta: 1 day, 3:02:12, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3539, decode.acc_seg: 86.0121, aux.loss_ce: 0.1599, aux.acc_seg: 84.5033, loss: 0.5139
2023-11-26 22:13:19,210 - mmseg - INFO - Iter [38150/160000]	lr: 4.569e-05, eta: 1 day, 3:01:35, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3777, decode.acc_seg: 85.2586, aux.loss_ce: 0.1693, aux.acc_seg: 83.9418, loss: 0.5470
2023-11-26 22:13:57,290 - mmseg - INFO - Iter [38200/160000]	lr: 4.568e-05, eta: 1 day, 3:00:49, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3553, decode.acc_seg: 86.0769, aux.loss_ce: 0.1575, aux.acc_seg: 85.1684, loss: 0.5128
2023-11-26 22:14:37,590 - mmseg - INFO - Iter [38250/160000]	lr: 4.566e-05, eta: 1 day, 3:00:10, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3494, decode.acc_seg: 86.4443, aux.loss_ce: 0.1558, aux.acc_seg: 85.2016, loss: 0.5052
2023-11-26 22:15:17,457 - mmseg - INFO - Iter [38300/160000]	lr: 4.564e-05, eta: 1 day, 2:59:30, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3424, decode.acc_seg: 86.3051, aux.loss_ce: 0.1553, aux.acc_seg: 85.2566, loss: 0.4978
2023-11-26 22:15:55,778 - mmseg - INFO - Iter [38350/160000]	lr: 4.562e-05, eta: 1 day, 2:58:46, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3313, decode.acc_seg: 87.1862, aux.loss_ce: 0.1502, aux.acc_seg: 85.7486, loss: 0.4815
2023-11-26 22:16:34,472 - mmseg - INFO - Iter [38400/160000]	lr: 4.560e-05, eta: 1 day, 2:58:02, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3380, decode.acc_seg: 86.9385, aux.loss_ce: 0.1535, aux.acc_seg: 85.5511, loss: 0.4915
2023-11-26 22:17:14,944 - mmseg - INFO - Iter [38450/160000]	lr: 4.558e-05, eta: 1 day, 2:57:23, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3455, decode.acc_seg: 86.0332, aux.loss_ce: 0.1557, aux.acc_seg: 84.9717, loss: 0.5011
2023-11-26 22:17:53,088 - mmseg - INFO - Iter [38500/160000]	lr: 4.556e-05, eta: 1 day, 2:56:38, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3402, decode.acc_seg: 86.3197, aux.loss_ce: 0.1536, aux.acc_seg: 85.1118, loss: 0.4939
2023-11-26 22:18:29,598 - mmseg - INFO - Iter [38550/160000]	lr: 4.554e-05, eta: 1 day, 2:55:47, time: 0.730, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3682, decode.acc_seg: 85.6312, aux.loss_ce: 0.1630, aux.acc_seg: 84.4490, loss: 0.5312
2023-11-26 22:19:10,733 - mmseg - INFO - Iter [38600/160000]	lr: 4.553e-05, eta: 1 day, 2:55:11, time: 0.822, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3368, decode.acc_seg: 86.6328, aux.loss_ce: 0.1518, aux.acc_seg: 85.3754, loss: 0.4886
2023-11-26 22:19:51,451 - mmseg - INFO - Iter [38650/160000]	lr: 4.551e-05, eta: 1 day, 2:54:34, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3525, decode.acc_seg: 86.1329, aux.loss_ce: 0.1576, aux.acc_seg: 84.9957, loss: 0.5101
2023-11-26 22:20:29,560 - mmseg - INFO - Iter [38700/160000]	lr: 4.549e-05, eta: 1 day, 2:53:48, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3541, decode.acc_seg: 85.9955, aux.loss_ce: 0.1596, aux.acc_seg: 84.6904, loss: 0.5137
2023-11-26 22:21:07,798 - mmseg - INFO - Iter [38750/160000]	lr: 4.547e-05, eta: 1 day, 2:53:03, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3652, decode.acc_seg: 85.3057, aux.loss_ce: 0.1633, aux.acc_seg: 84.0896, loss: 0.5285
2023-11-26 22:21:46,986 - mmseg - INFO - Iter [38800/160000]	lr: 4.545e-05, eta: 1 day, 2:52:21, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3382, decode.acc_seg: 86.5053, aux.loss_ce: 0.1532, aux.acc_seg: 85.1625, loss: 0.4914
2023-11-26 22:22:26,660 - mmseg - INFO - Iter [38850/160000]	lr: 4.543e-05, eta: 1 day, 2:51:40, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3587, decode.acc_seg: 86.0747, aux.loss_ce: 0.1587, aux.acc_seg: 84.9111, loss: 0.5174
2023-11-26 22:23:05,488 - mmseg - INFO - Iter [38900/160000]	lr: 4.541e-05, eta: 1 day, 2:50:57, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3573, decode.acc_seg: 86.0225, aux.loss_ce: 0.1575, aux.acc_seg: 85.0152, loss: 0.5148
2023-11-26 22:23:42,434 - mmseg - INFO - Iter [38950/160000]	lr: 4.539e-05, eta: 1 day, 2:50:08, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3284, decode.acc_seg: 86.8346, aux.loss_ce: 0.1470, aux.acc_seg: 85.7203, loss: 0.4755
2023-11-26 22:24:21,837 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 22:24:21,837 - mmseg - INFO - Iter [39000/160000]	lr: 4.538e-05, eta: 1 day, 2:49:26, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3465, decode.acc_seg: 86.2060, aux.loss_ce: 0.1559, aux.acc_seg: 85.0922, loss: 0.5024
2023-11-26 22:25:02,138 - mmseg - INFO - Iter [39050/160000]	lr: 4.536e-05, eta: 1 day, 2:48:48, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3483, decode.acc_seg: 86.6811, aux.loss_ce: 0.1585, aux.acc_seg: 85.2866, loss: 0.5068
2023-11-26 22:25:42,560 - mmseg - INFO - Iter [39100/160000]	lr: 4.534e-05, eta: 1 day, 2:48:09, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3451, decode.acc_seg: 86.1745, aux.loss_ce: 0.1528, aux.acc_seg: 85.0161, loss: 0.4979
2023-11-26 22:26:22,923 - mmseg - INFO - Iter [39150/160000]	lr: 4.532e-05, eta: 1 day, 2:47:31, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3378, decode.acc_seg: 86.3884, aux.loss_ce: 0.1510, aux.acc_seg: 85.3981, loss: 0.4888
2023-11-26 22:27:03,665 - mmseg - INFO - Iter [39200/160000]	lr: 4.530e-05, eta: 1 day, 2:46:54, time: 0.815, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3202, decode.acc_seg: 87.0403, aux.loss_ce: 0.1481, aux.acc_seg: 85.6833, loss: 0.4683
2023-11-26 22:27:42,600 - mmseg - INFO - Iter [39250/160000]	lr: 4.528e-05, eta: 1 day, 2:46:11, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3192, decode.acc_seg: 87.2054, aux.loss_ce: 0.1466, aux.acc_seg: 85.9125, loss: 0.4658
2023-11-26 22:28:22,065 - mmseg - INFO - Iter [39300/160000]	lr: 4.526e-05, eta: 1 day, 2:45:29, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3291, decode.acc_seg: 86.4259, aux.loss_ce: 0.1489, aux.acc_seg: 85.2297, loss: 0.4779
2023-11-26 22:29:02,284 - mmseg - INFO - Iter [39350/160000]	lr: 4.524e-05, eta: 1 day, 2:44:50, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3293, decode.acc_seg: 87.1456, aux.loss_ce: 0.1508, aux.acc_seg: 85.9207, loss: 0.4801
2023-11-26 22:29:42,729 - mmseg - INFO - Iter [39400/160000]	lr: 4.523e-05, eta: 1 day, 2:44:12, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3326, decode.acc_seg: 86.9207, aux.loss_ce: 0.1515, aux.acc_seg: 85.6769, loss: 0.4841
2023-11-26 22:30:22,674 - mmseg - INFO - Iter [39450/160000]	lr: 4.521e-05, eta: 1 day, 2:43:33, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3329, decode.acc_seg: 86.8605, aux.loss_ce: 0.1525, aux.acc_seg: 85.4597, loss: 0.4854
2023-11-26 22:31:01,087 - mmseg - INFO - Iter [39500/160000]	lr: 4.519e-05, eta: 1 day, 2:42:48, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3481, decode.acc_seg: 86.2747, aux.loss_ce: 0.1535, aux.acc_seg: 85.4392, loss: 0.5016
2023-11-26 22:31:38,861 - mmseg - INFO - Iter [39550/160000]	lr: 4.517e-05, eta: 1 day, 2:42:02, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3382, decode.acc_seg: 86.1190, aux.loss_ce: 0.1544, aux.acc_seg: 85.0178, loss: 0.4925
2023-11-26 22:32:16,253 - mmseg - INFO - Iter [39600/160000]	lr: 4.515e-05, eta: 1 day, 2:41:14, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3424, decode.acc_seg: 86.0665, aux.loss_ce: 0.1535, aux.acc_seg: 85.1685, loss: 0.4960
2023-11-26 22:32:56,613 - mmseg - INFO - Iter [39650/160000]	lr: 4.513e-05, eta: 1 day, 2:40:36, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3490, decode.acc_seg: 86.3054, aux.loss_ce: 0.1546, aux.acc_seg: 85.0770, loss: 0.5036
2023-11-26 22:33:36,958 - mmseg - INFO - Iter [39700/160000]	lr: 4.511e-05, eta: 1 day, 2:39:57, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3622, decode.acc_seg: 85.5118, aux.loss_ce: 0.1621, aux.acc_seg: 84.1808, loss: 0.5244
2023-11-26 22:34:17,501 - mmseg - INFO - Iter [39750/160000]	lr: 4.509e-05, eta: 1 day, 2:39:19, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3670, decode.acc_seg: 85.3733, aux.loss_ce: 0.1630, aux.acc_seg: 84.2044, loss: 0.5300
2023-11-26 22:34:57,557 - mmseg - INFO - Iter [39800/160000]	lr: 4.508e-05, eta: 1 day, 2:38:40, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3467, decode.acc_seg: 86.2457, aux.loss_ce: 0.1537, aux.acc_seg: 85.3175, loss: 0.5004
2023-11-26 22:35:37,101 - mmseg - INFO - Iter [39850/160000]	lr: 4.506e-05, eta: 1 day, 2:37:59, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3209, decode.acc_seg: 87.1061, aux.loss_ce: 0.1460, aux.acc_seg: 85.9070, loss: 0.4669
2023-11-26 22:36:15,412 - mmseg - INFO - Iter [39900/160000]	lr: 4.504e-05, eta: 1 day, 2:37:14, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3585, decode.acc_seg: 85.5750, aux.loss_ce: 0.1611, aux.acc_seg: 84.4616, loss: 0.5196
2023-11-26 22:36:55,325 - mmseg - INFO - Iter [39950/160000]	lr: 4.502e-05, eta: 1 day, 2:36:34, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3475, decode.acc_seg: 86.4460, aux.loss_ce: 0.1545, aux.acc_seg: 85.4234, loss: 0.5019
2023-11-26 22:37:35,553 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 22:37:35,553 - mmseg - INFO - Iter [40000/160000]	lr: 4.500e-05, eta: 1 day, 2:35:55, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3509, decode.acc_seg: 86.2139, aux.loss_ce: 0.1589, aux.acc_seg: 84.8741, loss: 0.5099
2023-11-26 22:38:13,725 - mmseg - INFO - Iter [40050/160000]	lr: 4.498e-05, eta: 1 day, 2:35:10, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3309, decode.acc_seg: 86.5862, aux.loss_ce: 0.1495, aux.acc_seg: 85.4858, loss: 0.4804
2023-11-26 22:38:51,327 - mmseg - INFO - Iter [40100/160000]	lr: 4.496e-05, eta: 1 day, 2:34:23, time: 0.751, data_time: 0.009, memory: 21695, decode.loss_ce: 0.3230, decode.acc_seg: 87.3695, aux.loss_ce: 0.1474, aux.acc_seg: 85.9068, loss: 0.4704
2023-11-26 22:39:29,732 - mmseg - INFO - Iter [40150/160000]	lr: 4.494e-05, eta: 1 day, 2:33:39, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3290, decode.acc_seg: 87.0535, aux.loss_ce: 0.1481, aux.acc_seg: 85.8191, loss: 0.4771
2023-11-26 22:40:09,724 - mmseg - INFO - Iter [40200/160000]	lr: 4.493e-05, eta: 1 day, 2:32:59, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3486, decode.acc_seg: 86.3605, aux.loss_ce: 0.1575, aux.acc_seg: 84.9011, loss: 0.5061
2023-11-26 22:40:50,418 - mmseg - INFO - Iter [40250/160000]	lr: 4.491e-05, eta: 1 day, 2:32:22, time: 0.814, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3320, decode.acc_seg: 86.9831, aux.loss_ce: 0.1494, aux.acc_seg: 86.0314, loss: 0.4814
2023-11-26 22:41:30,734 - mmseg - INFO - Iter [40300/160000]	lr: 4.489e-05, eta: 1 day, 2:31:43, time: 0.806, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3450, decode.acc_seg: 86.3478, aux.loss_ce: 0.1539, aux.acc_seg: 85.3983, loss: 0.4989
2023-11-26 22:42:10,709 - mmseg - INFO - Iter [40350/160000]	lr: 4.487e-05, eta: 1 day, 2:31:04, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3343, decode.acc_seg: 86.8318, aux.loss_ce: 0.1514, aux.acc_seg: 85.6013, loss: 0.4857
2023-11-26 22:42:47,611 - mmseg - INFO - Iter [40400/160000]	lr: 4.485e-05, eta: 1 day, 2:30:15, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3267, decode.acc_seg: 86.8096, aux.loss_ce: 0.1454, aux.acc_seg: 85.6114, loss: 0.4722
2023-11-26 22:43:27,309 - mmseg - INFO - Iter [40450/160000]	lr: 4.483e-05, eta: 1 day, 2:29:35, time: 0.795, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3416, decode.acc_seg: 86.1766, aux.loss_ce: 0.1546, aux.acc_seg: 84.8920, loss: 0.4962
2023-11-26 22:44:07,464 - mmseg - INFO - Iter [40500/160000]	lr: 4.481e-05, eta: 1 day, 2:28:55, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3332, decode.acc_seg: 86.7831, aux.loss_ce: 0.1516, aux.acc_seg: 85.3639, loss: 0.4847
2023-11-26 22:44:47,170 - mmseg - INFO - Iter [40550/160000]	lr: 4.479e-05, eta: 1 day, 2:28:15, time: 0.795, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3327, decode.acc_seg: 86.4971, aux.loss_ce: 0.1524, aux.acc_seg: 85.0767, loss: 0.4851
2023-11-26 22:45:27,226 - mmseg - INFO - Iter [40600/160000]	lr: 4.478e-05, eta: 1 day, 2:27:35, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3395, decode.acc_seg: 86.5575, aux.loss_ce: 0.1548, aux.acc_seg: 85.3562, loss: 0.4943
2023-11-26 22:46:07,098 - mmseg - INFO - Iter [40650/160000]	lr: 4.476e-05, eta: 1 day, 2:26:56, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3248, decode.acc_seg: 86.5578, aux.loss_ce: 0.1467, aux.acc_seg: 85.5293, loss: 0.4715
2023-11-26 22:46:47,098 - mmseg - INFO - Iter [40700/160000]	lr: 4.474e-05, eta: 1 day, 2:26:16, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3258, decode.acc_seg: 86.9035, aux.loss_ce: 0.1481, aux.acc_seg: 85.5782, loss: 0.4739
2023-11-26 22:47:27,450 - mmseg - INFO - Iter [40750/160000]	lr: 4.472e-05, eta: 1 day, 2:25:37, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3411, decode.acc_seg: 86.9481, aux.loss_ce: 0.1542, aux.acc_seg: 85.6986, loss: 0.4954
2023-11-26 22:48:06,827 - mmseg - INFO - Iter [40800/160000]	lr: 4.470e-05, eta: 1 day, 2:24:56, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3263, decode.acc_seg: 86.9077, aux.loss_ce: 0.1448, aux.acc_seg: 85.9856, loss: 0.4711
2023-11-26 22:48:46,978 - mmseg - INFO - Iter [40850/160000]	lr: 4.468e-05, eta: 1 day, 2:24:17, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3470, decode.acc_seg: 86.6195, aux.loss_ce: 0.1533, aux.acc_seg: 85.6308, loss: 0.5003
2023-11-26 22:49:27,047 - mmseg - INFO - Iter [40900/160000]	lr: 4.466e-05, eta: 1 day, 2:23:38, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3509, decode.acc_seg: 86.3447, aux.loss_ce: 0.1580, aux.acc_seg: 85.1557, loss: 0.5090
2023-11-26 22:50:06,291 - mmseg - INFO - Iter [40950/160000]	lr: 4.464e-05, eta: 1 day, 2:22:56, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3360, decode.acc_seg: 86.5587, aux.loss_ce: 0.1537, aux.acc_seg: 85.3277, loss: 0.4897
2023-11-26 22:50:46,985 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 22:50:46,986 - mmseg - INFO - Iter [41000/160000]	lr: 4.463e-05, eta: 1 day, 2:22:18, time: 0.814, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3118, decode.acc_seg: 87.1782, aux.loss_ce: 0.1413, aux.acc_seg: 86.2040, loss: 0.4531
2023-11-26 22:51:25,784 - mmseg - INFO - Iter [41050/160000]	lr: 4.461e-05, eta: 1 day, 2:21:35, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3305, decode.acc_seg: 86.7990, aux.loss_ce: 0.1474, aux.acc_seg: 85.5260, loss: 0.4779
2023-11-26 22:52:04,525 - mmseg - INFO - Iter [41100/160000]	lr: 4.459e-05, eta: 1 day, 2:20:52, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3164, decode.acc_seg: 87.0062, aux.loss_ce: 0.1428, aux.acc_seg: 86.0196, loss: 0.4592
2023-11-26 22:52:41,463 - mmseg - INFO - Iter [41150/160000]	lr: 4.457e-05, eta: 1 day, 2:20:04, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3314, decode.acc_seg: 86.3695, aux.loss_ce: 0.1468, aux.acc_seg: 85.4234, loss: 0.4782
2023-11-26 22:53:20,635 - mmseg - INFO - Iter [41200/160000]	lr: 4.455e-05, eta: 1 day, 2:19:22, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3445, decode.acc_seg: 86.6079, aux.loss_ce: 0.1561, aux.acc_seg: 85.2239, loss: 0.5007
2023-11-26 22:54:00,148 - mmseg - INFO - Iter [41250/160000]	lr: 4.453e-05, eta: 1 day, 2:18:41, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3137, decode.acc_seg: 87.3081, aux.loss_ce: 0.1438, aux.acc_seg: 85.7917, loss: 0.4575
2023-11-26 22:54:39,612 - mmseg - INFO - Iter [41300/160000]	lr: 4.451e-05, eta: 1 day, 2:18:00, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3427, decode.acc_seg: 86.5770, aux.loss_ce: 0.1533, aux.acc_seg: 85.3291, loss: 0.4960
2023-11-26 22:55:20,440 - mmseg - INFO - Iter [41350/160000]	lr: 4.449e-05, eta: 1 day, 2:17:22, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3547, decode.acc_seg: 85.8113, aux.loss_ce: 0.1567, aux.acc_seg: 84.5868, loss: 0.5114
2023-11-26 22:55:57,634 - mmseg - INFO - Iter [41400/160000]	lr: 4.448e-05, eta: 1 day, 2:16:35, time: 0.745, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3450, decode.acc_seg: 86.7291, aux.loss_ce: 0.1577, aux.acc_seg: 85.2921, loss: 0.5027
2023-11-26 22:56:35,921 - mmseg - INFO - Iter [41450/160000]	lr: 4.446e-05, eta: 1 day, 2:15:50, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3474, decode.acc_seg: 86.2342, aux.loss_ce: 0.1588, aux.acc_seg: 84.8976, loss: 0.5062
2023-11-26 22:57:15,225 - mmseg - INFO - Iter [41500/160000]	lr: 4.444e-05, eta: 1 day, 2:15:09, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3247, decode.acc_seg: 87.2350, aux.loss_ce: 0.1473, aux.acc_seg: 86.1774, loss: 0.4721
2023-11-26 22:57:52,893 - mmseg - INFO - Iter [41550/160000]	lr: 4.442e-05, eta: 1 day, 2:14:23, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3439, decode.acc_seg: 86.6600, aux.loss_ce: 0.1555, aux.acc_seg: 85.2955, loss: 0.4995
2023-11-26 22:58:32,550 - mmseg - INFO - Iter [41600/160000]	lr: 4.440e-05, eta: 1 day, 2:13:42, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3485, decode.acc_seg: 86.5299, aux.loss_ce: 0.1547, aux.acc_seg: 85.1928, loss: 0.5032
2023-11-26 22:59:09,442 - mmseg - INFO - Iter [41650/160000]	lr: 4.438e-05, eta: 1 day, 2:12:54, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3348, decode.acc_seg: 86.7768, aux.loss_ce: 0.1506, aux.acc_seg: 85.5813, loss: 0.4854
2023-11-26 22:59:50,032 - mmseg - INFO - Iter [41700/160000]	lr: 4.436e-05, eta: 1 day, 2:12:16, time: 0.812, data_time: 0.052, memory: 21695, decode.loss_ce: 0.3288, decode.acc_seg: 86.8862, aux.loss_ce: 0.1487, aux.acc_seg: 85.8371, loss: 0.4775
2023-11-26 23:00:26,923 - mmseg - INFO - Iter [41750/160000]	lr: 4.434e-05, eta: 1 day, 2:11:28, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3208, decode.acc_seg: 87.3699, aux.loss_ce: 0.1452, aux.acc_seg: 86.2486, loss: 0.4660
2023-11-26 23:01:06,241 - mmseg - INFO - Iter [41800/160000]	lr: 4.433e-05, eta: 1 day, 2:10:46, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3523, decode.acc_seg: 86.2677, aux.loss_ce: 0.1580, aux.acc_seg: 85.2376, loss: 0.5103
2023-11-26 23:01:44,559 - mmseg - INFO - Iter [41850/160000]	lr: 4.431e-05, eta: 1 day, 2:10:02, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3541, decode.acc_seg: 86.0291, aux.loss_ce: 0.1592, aux.acc_seg: 84.9032, loss: 0.5133
2023-11-26 23:02:24,408 - mmseg - INFO - Iter [41900/160000]	lr: 4.429e-05, eta: 1 day, 2:09:22, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3094, decode.acc_seg: 87.3721, aux.loss_ce: 0.1411, aux.acc_seg: 86.1506, loss: 0.4505
2023-11-26 23:03:04,678 - mmseg - INFO - Iter [41950/160000]	lr: 4.427e-05, eta: 1 day, 2:08:43, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3300, decode.acc_seg: 86.7242, aux.loss_ce: 0.1495, aux.acc_seg: 85.5139, loss: 0.4795
2023-11-26 23:03:44,964 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 23:03:44,965 - mmseg - INFO - Iter [42000/160000]	lr: 4.425e-05, eta: 1 day, 2:08:05, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3186, decode.acc_seg: 87.1582, aux.loss_ce: 0.1439, aux.acc_seg: 86.0668, loss: 0.4625
2023-11-26 23:04:24,902 - mmseg - INFO - Iter [42050/160000]	lr: 4.423e-05, eta: 1 day, 2:07:25, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3288, decode.acc_seg: 87.1933, aux.loss_ce: 0.1497, aux.acc_seg: 85.5540, loss: 0.4785
2023-11-26 23:05:04,267 - mmseg - INFO - Iter [42100/160000]	lr: 4.421e-05, eta: 1 day, 2:06:44, time: 0.787, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3330, decode.acc_seg: 86.8437, aux.loss_ce: 0.1504, aux.acc_seg: 85.5687, loss: 0.4834
2023-11-26 23:05:44,671 - mmseg - INFO - Iter [42150/160000]	lr: 4.419e-05, eta: 1 day, 2:06:05, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3377, decode.acc_seg: 86.3657, aux.loss_ce: 0.1511, aux.acc_seg: 85.2072, loss: 0.4887
2023-11-26 23:06:24,643 - mmseg - INFO - Iter [42200/160000]	lr: 4.418e-05, eta: 1 day, 2:05:26, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3249, decode.acc_seg: 87.4913, aux.loss_ce: 0.1449, aux.acc_seg: 86.2909, loss: 0.4698
2023-11-26 23:07:04,531 - mmseg - INFO - Iter [42250/160000]	lr: 4.416e-05, eta: 1 day, 2:04:46, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3451, decode.acc_seg: 86.8349, aux.loss_ce: 0.1533, aux.acc_seg: 85.6334, loss: 0.4985
2023-11-26 23:07:44,522 - mmseg - INFO - Iter [42300/160000]	lr: 4.414e-05, eta: 1 day, 2:04:06, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3232, decode.acc_seg: 87.2626, aux.loss_ce: 0.1457, aux.acc_seg: 86.1100, loss: 0.4689
2023-11-26 23:08:24,466 - mmseg - INFO - Iter [42350/160000]	lr: 4.412e-05, eta: 1 day, 2:03:27, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3214, decode.acc_seg: 87.4227, aux.loss_ce: 0.1432, aux.acc_seg: 86.3206, loss: 0.4646
2023-11-26 23:09:04,698 - mmseg - INFO - Iter [42400/160000]	lr: 4.410e-05, eta: 1 day, 2:02:48, time: 0.805, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3238, decode.acc_seg: 86.8415, aux.loss_ce: 0.1468, aux.acc_seg: 85.8374, loss: 0.4706
2023-11-26 23:09:45,225 - mmseg - INFO - Iter [42450/160000]	lr: 4.408e-05, eta: 1 day, 2:02:10, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3387, decode.acc_seg: 86.9440, aux.loss_ce: 0.1543, aux.acc_seg: 85.4293, loss: 0.4930
2023-11-26 23:10:22,357 - mmseg - INFO - Iter [42500/160000]	lr: 4.406e-05, eta: 1 day, 2:01:23, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3218, decode.acc_seg: 87.2346, aux.loss_ce: 0.1445, aux.acc_seg: 86.0411, loss: 0.4663
2023-11-26 23:11:02,353 - mmseg - INFO - Iter [42550/160000]	lr: 4.404e-05, eta: 1 day, 2:00:43, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3479, decode.acc_seg: 86.5995, aux.loss_ce: 0.1566, aux.acc_seg: 85.4727, loss: 0.5045
2023-11-26 23:11:41,379 - mmseg - INFO - Iter [42600/160000]	lr: 4.403e-05, eta: 1 day, 2:00:01, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3326, decode.acc_seg: 86.6757, aux.loss_ce: 0.1502, aux.acc_seg: 85.4193, loss: 0.4827
2023-11-26 23:12:19,796 - mmseg - INFO - Iter [42650/160000]	lr: 4.401e-05, eta: 1 day, 1:59:17, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3543, decode.acc_seg: 85.7819, aux.loss_ce: 0.1595, aux.acc_seg: 84.5216, loss: 0.5138
2023-11-26 23:12:57,952 - mmseg - INFO - Iter [42700/160000]	lr: 4.399e-05, eta: 1 day, 1:58:32, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3359, decode.acc_seg: 86.6045, aux.loss_ce: 0.1497, aux.acc_seg: 85.4973, loss: 0.4856
2023-11-26 23:13:38,000 - mmseg - INFO - Iter [42750/160000]	lr: 4.397e-05, eta: 1 day, 1:57:53, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3390, decode.acc_seg: 86.7045, aux.loss_ce: 0.1533, aux.acc_seg: 85.2528, loss: 0.4923
2023-11-26 23:14:15,506 - mmseg - INFO - Iter [42800/160000]	lr: 4.395e-05, eta: 1 day, 1:57:07, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3136, decode.acc_seg: 87.0032, aux.loss_ce: 0.1428, aux.acc_seg: 85.7787, loss: 0.4565
2023-11-26 23:14:52,287 - mmseg - INFO - Iter [42850/160000]	lr: 4.393e-05, eta: 1 day, 1:56:19, time: 0.735, data_time: 0.009, memory: 21695, decode.loss_ce: 0.3577, decode.acc_seg: 85.7355, aux.loss_ce: 0.1602, aux.acc_seg: 84.8937, loss: 0.5179
2023-11-26 23:15:30,848 - mmseg - INFO - Iter [42900/160000]	lr: 4.391e-05, eta: 1 day, 1:55:35, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3693, decode.acc_seg: 85.4500, aux.loss_ce: 0.1653, aux.acc_seg: 84.0144, loss: 0.5345
2023-11-26 23:16:10,091 - mmseg - INFO - Iter [42950/160000]	lr: 4.389e-05, eta: 1 day, 1:54:54, time: 0.784, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3238, decode.acc_seg: 86.8663, aux.loss_ce: 0.1440, aux.acc_seg: 85.9306, loss: 0.4678
2023-11-26 23:16:49,944 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 23:16:49,944 - mmseg - INFO - Iter [43000/160000]	lr: 4.388e-05, eta: 1 day, 1:54:14, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3009, decode.acc_seg: 87.8248, aux.loss_ce: 0.1393, aux.acc_seg: 86.4412, loss: 0.4403
2023-11-26 23:17:29,896 - mmseg - INFO - Iter [43050/160000]	lr: 4.386e-05, eta: 1 day, 1:53:34, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3389, decode.acc_seg: 86.8066, aux.loss_ce: 0.1526, aux.acc_seg: 85.5722, loss: 0.4915
2023-11-26 23:18:08,311 - mmseg - INFO - Iter [43100/160000]	lr: 4.384e-05, eta: 1 day, 1:52:51, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3312, decode.acc_seg: 86.3963, aux.loss_ce: 0.1487, aux.acc_seg: 85.2209, loss: 0.4799
2023-11-26 23:18:46,454 - mmseg - INFO - Iter [43150/160000]	lr: 4.382e-05, eta: 1 day, 1:52:06, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3155, decode.acc_seg: 87.5039, aux.loss_ce: 0.1416, aux.acc_seg: 86.5296, loss: 0.4571
2023-11-26 23:19:25,357 - mmseg - INFO - Iter [43200/160000]	lr: 4.380e-05, eta: 1 day, 1:51:24, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3221, decode.acc_seg: 87.3900, aux.loss_ce: 0.1449, aux.acc_seg: 86.2545, loss: 0.4670
2023-11-26 23:20:05,899 - mmseg - INFO - Iter [43250/160000]	lr: 4.378e-05, eta: 1 day, 1:50:46, time: 0.810, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3287, decode.acc_seg: 86.6618, aux.loss_ce: 0.1460, aux.acc_seg: 85.7241, loss: 0.4746
2023-11-26 23:20:44,917 - mmseg - INFO - Iter [43300/160000]	lr: 4.376e-05, eta: 1 day, 1:50:03, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3322, decode.acc_seg: 87.2980, aux.loss_ce: 0.1494, aux.acc_seg: 86.0094, loss: 0.4816
2023-11-26 23:21:25,495 - mmseg - INFO - Iter [43350/160000]	lr: 4.374e-05, eta: 1 day, 1:49:26, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3284, decode.acc_seg: 87.1934, aux.loss_ce: 0.1504, aux.acc_seg: 85.6914, loss: 0.4789
2023-11-26 23:22:05,870 - mmseg - INFO - Iter [43400/160000]	lr: 4.373e-05, eta: 1 day, 1:48:47, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3182, decode.acc_seg: 87.2554, aux.loss_ce: 0.1431, aux.acc_seg: 86.1606, loss: 0.4613
2023-11-26 23:22:44,679 - mmseg - INFO - Iter [43450/160000]	lr: 4.371e-05, eta: 1 day, 1:48:05, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3460, decode.acc_seg: 86.1394, aux.loss_ce: 0.1539, aux.acc_seg: 85.3365, loss: 0.5000
2023-11-26 23:23:24,625 - mmseg - INFO - Iter [43500/160000]	lr: 4.369e-05, eta: 1 day, 1:47:25, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3501, decode.acc_seg: 86.2077, aux.loss_ce: 0.1582, aux.acc_seg: 85.0758, loss: 0.5083
2023-11-26 23:24:05,378 - mmseg - INFO - Iter [43550/160000]	lr: 4.367e-05, eta: 1 day, 1:46:47, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3189, decode.acc_seg: 87.2232, aux.loss_ce: 0.1478, aux.acc_seg: 85.8993, loss: 0.4667
2023-11-26 23:24:44,761 - mmseg - INFO - Iter [43600/160000]	lr: 4.365e-05, eta: 1 day, 1:46:07, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3443, decode.acc_seg: 86.2414, aux.loss_ce: 0.1546, aux.acc_seg: 84.9639, loss: 0.4988
2023-11-26 23:25:23,742 - mmseg - INFO - Iter [43650/160000]	lr: 4.363e-05, eta: 1 day, 1:45:24, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3486, decode.acc_seg: 86.4577, aux.loss_ce: 0.1569, aux.acc_seg: 85.0029, loss: 0.5055
2023-11-26 23:26:00,511 - mmseg - INFO - Iter [43700/160000]	lr: 4.361e-05, eta: 1 day, 1:44:36, time: 0.735, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3171, decode.acc_seg: 87.5519, aux.loss_ce: 0.1453, aux.acc_seg: 86.1939, loss: 0.4624
2023-11-26 23:26:40,927 - mmseg - INFO - Iter [43750/160000]	lr: 4.359e-05, eta: 1 day, 1:43:58, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3223, decode.acc_seg: 87.3157, aux.loss_ce: 0.1462, aux.acc_seg: 86.1998, loss: 0.4685
2023-11-26 23:27:21,270 - mmseg - INFO - Iter [43800/160000]	lr: 4.358e-05, eta: 1 day, 1:43:19, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3211, decode.acc_seg: 87.2024, aux.loss_ce: 0.1436, aux.acc_seg: 86.1168, loss: 0.4647
2023-11-26 23:28:01,251 - mmseg - INFO - Iter [43850/160000]	lr: 4.356e-05, eta: 1 day, 1:42:40, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3297, decode.acc_seg: 86.6396, aux.loss_ce: 0.1494, aux.acc_seg: 85.4458, loss: 0.4791
2023-11-26 23:28:41,840 - mmseg - INFO - Iter [43900/160000]	lr: 4.354e-05, eta: 1 day, 1:42:02, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3166, decode.acc_seg: 87.1456, aux.loss_ce: 0.1462, aux.acc_seg: 85.7279, loss: 0.4628
2023-11-26 23:29:21,029 - mmseg - INFO - Iter [43950/160000]	lr: 4.352e-05, eta: 1 day, 1:41:20, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3164, decode.acc_seg: 87.3899, aux.loss_ce: 0.1455, aux.acc_seg: 85.9851, loss: 0.4619
2023-11-26 23:30:02,410 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 23:30:02,411 - mmseg - INFO - Iter [44000/160000]	lr: 4.350e-05, eta: 1 day, 1:40:45, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3370, decode.acc_seg: 86.3729, aux.loss_ce: 0.1540, aux.acc_seg: 84.9966, loss: 0.4910
2023-11-26 23:30:43,490 - mmseg - INFO - Iter [44050/160000]	lr: 4.348e-05, eta: 1 day, 1:40:08, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3314, decode.acc_seg: 87.0934, aux.loss_ce: 0.1487, aux.acc_seg: 85.7325, loss: 0.4801
2023-11-26 23:31:24,082 - mmseg - INFO - Iter [44100/160000]	lr: 4.346e-05, eta: 1 day, 1:39:30, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3428, decode.acc_seg: 86.4285, aux.loss_ce: 0.1541, aux.acc_seg: 85.1004, loss: 0.4968
2023-11-26 23:32:03,166 - mmseg - INFO - Iter [44150/160000]	lr: 4.344e-05, eta: 1 day, 1:38:48, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3238, decode.acc_seg: 87.1956, aux.loss_ce: 0.1465, aux.acc_seg: 86.0605, loss: 0.4703
2023-11-26 23:32:43,544 - mmseg - INFO - Iter [44200/160000]	lr: 4.343e-05, eta: 1 day, 1:38:10, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3432, decode.acc_seg: 86.0777, aux.loss_ce: 0.1565, aux.acc_seg: 84.6285, loss: 0.4997
2023-11-26 23:33:24,769 - mmseg - INFO - Iter [44250/160000]	lr: 4.341e-05, eta: 1 day, 1:37:34, time: 0.825, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3320, decode.acc_seg: 87.2214, aux.loss_ce: 0.1512, aux.acc_seg: 85.8258, loss: 0.4832
2023-11-26 23:34:04,852 - mmseg - INFO - Iter [44300/160000]	lr: 4.339e-05, eta: 1 day, 1:36:54, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3321, decode.acc_seg: 87.1381, aux.loss_ce: 0.1460, aux.acc_seg: 86.0108, loss: 0.4781
2023-11-26 23:34:43,803 - mmseg - INFO - Iter [44350/160000]	lr: 4.337e-05, eta: 1 day, 1:36:12, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3303, decode.acc_seg: 86.8805, aux.loss_ce: 0.1519, aux.acc_seg: 85.5241, loss: 0.4822
2023-11-26 23:35:20,943 - mmseg - INFO - Iter [44400/160000]	lr: 4.335e-05, eta: 1 day, 1:35:25, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3200, decode.acc_seg: 87.2378, aux.loss_ce: 0.1441, aux.acc_seg: 86.1836, loss: 0.4641
2023-11-26 23:36:00,488 - mmseg - INFO - Iter [44450/160000]	lr: 4.333e-05, eta: 1 day, 1:34:45, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3024, decode.acc_seg: 87.7369, aux.loss_ce: 0.1368, aux.acc_seg: 86.4608, loss: 0.4392
2023-11-26 23:36:40,270 - mmseg - INFO - Iter [44500/160000]	lr: 4.331e-05, eta: 1 day, 1:34:05, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3296, decode.acc_seg: 86.6378, aux.loss_ce: 0.1475, aux.acc_seg: 85.5065, loss: 0.4772
2023-11-26 23:37:20,519 - mmseg - INFO - Iter [44550/160000]	lr: 4.329e-05, eta: 1 day, 1:33:26, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3243, decode.acc_seg: 87.3716, aux.loss_ce: 0.1454, aux.acc_seg: 86.1802, loss: 0.4697
2023-11-26 23:37:59,271 - mmseg - INFO - Iter [44600/160000]	lr: 4.328e-05, eta: 1 day, 1:32:43, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3203, decode.acc_seg: 86.9134, aux.loss_ce: 0.1454, aux.acc_seg: 85.8718, loss: 0.4656
2023-11-26 23:38:39,214 - mmseg - INFO - Iter [44650/160000]	lr: 4.326e-05, eta: 1 day, 1:32:03, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3260, decode.acc_seg: 86.9707, aux.loss_ce: 0.1499, aux.acc_seg: 85.7813, loss: 0.4759
2023-11-26 23:39:19,436 - mmseg - INFO - Iter [44700/160000]	lr: 4.324e-05, eta: 1 day, 1:31:25, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3236, decode.acc_seg: 87.1632, aux.loss_ce: 0.1433, aux.acc_seg: 86.1097, loss: 0.4670
2023-11-26 23:39:58,865 - mmseg - INFO - Iter [44750/160000]	lr: 4.322e-05, eta: 1 day, 1:30:44, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3398, decode.acc_seg: 86.6113, aux.loss_ce: 0.1535, aux.acc_seg: 85.4156, loss: 0.4933
2023-11-26 23:40:36,683 - mmseg - INFO - Iter [44800/160000]	lr: 4.320e-05, eta: 1 day, 1:29:59, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3126, decode.acc_seg: 87.5520, aux.loss_ce: 0.1402, aux.acc_seg: 86.4024, loss: 0.4528
2023-11-26 23:41:17,060 - mmseg - INFO - Iter [44850/160000]	lr: 4.318e-05, eta: 1 day, 1:29:20, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3269, decode.acc_seg: 86.8822, aux.loss_ce: 0.1499, aux.acc_seg: 85.5883, loss: 0.4768
2023-11-26 23:41:56,530 - mmseg - INFO - Iter [44900/160000]	lr: 4.316e-05, eta: 1 day, 1:28:39, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3224, decode.acc_seg: 86.8820, aux.loss_ce: 0.1460, aux.acc_seg: 85.6858, loss: 0.4684
2023-11-26 23:42:37,057 - mmseg - INFO - Iter [44950/160000]	lr: 4.314e-05, eta: 1 day, 1:28:01, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3401, decode.acc_seg: 86.5257, aux.loss_ce: 0.1523, aux.acc_seg: 85.3089, loss: 0.4924
2023-11-26 23:43:17,097 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 23:43:17,097 - mmseg - INFO - Iter [45000/160000]	lr: 4.313e-05, eta: 1 day, 1:27:22, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3371, decode.acc_seg: 86.8176, aux.loss_ce: 0.1504, aux.acc_seg: 85.6555, loss: 0.4875
2023-11-26 23:43:56,988 - mmseg - INFO - Iter [45050/160000]	lr: 4.311e-05, eta: 1 day, 1:26:42, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3371, decode.acc_seg: 86.6179, aux.loss_ce: 0.1530, aux.acc_seg: 85.4723, loss: 0.4900
2023-11-26 23:44:34,580 - mmseg - INFO - Iter [45100/160000]	lr: 4.309e-05, eta: 1 day, 1:25:57, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3327, decode.acc_seg: 86.3984, aux.loss_ce: 0.1497, aux.acc_seg: 85.3642, loss: 0.4825
2023-11-26 23:45:12,261 - mmseg - INFO - Iter [45150/160000]	lr: 4.307e-05, eta: 1 day, 1:25:11, time: 0.753, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3164, decode.acc_seg: 87.1750, aux.loss_ce: 0.1454, aux.acc_seg: 85.7524, loss: 0.4618
2023-11-26 23:45:53,037 - mmseg - INFO - Iter [45200/160000]	lr: 4.305e-05, eta: 1 day, 1:24:34, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2968, decode.acc_seg: 88.1141, aux.loss_ce: 0.1345, aux.acc_seg: 87.0314, loss: 0.4313
2023-11-26 23:46:33,781 - mmseg - INFO - Iter [45250/160000]	lr: 4.303e-05, eta: 1 day, 1:23:56, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3273, decode.acc_seg: 86.9008, aux.loss_ce: 0.1464, aux.acc_seg: 85.6856, loss: 0.4737
2023-11-26 23:47:14,291 - mmseg - INFO - Iter [45300/160000]	lr: 4.301e-05, eta: 1 day, 1:23:18, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3228, decode.acc_seg: 87.1462, aux.loss_ce: 0.1486, aux.acc_seg: 85.9169, loss: 0.4714
2023-11-26 23:47:54,982 - mmseg - INFO - Iter [45350/160000]	lr: 4.299e-05, eta: 1 day, 1:22:40, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3241, decode.acc_seg: 86.5912, aux.loss_ce: 0.1442, aux.acc_seg: 85.5831, loss: 0.4683
2023-11-26 23:48:34,447 - mmseg - INFO - Iter [45400/160000]	lr: 4.298e-05, eta: 1 day, 1:22:00, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3213, decode.acc_seg: 86.7980, aux.loss_ce: 0.1449, aux.acc_seg: 85.7015, loss: 0.4662
2023-11-26 23:49:14,332 - mmseg - INFO - Iter [45450/160000]	lr: 4.296e-05, eta: 1 day, 1:21:20, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3307, decode.acc_seg: 86.9968, aux.loss_ce: 0.1476, aux.acc_seg: 85.9244, loss: 0.4783
2023-11-26 23:49:55,306 - mmseg - INFO - Iter [45500/160000]	lr: 4.294e-05, eta: 1 day, 1:20:43, time: 0.819, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3213, decode.acc_seg: 87.3274, aux.loss_ce: 0.1441, aux.acc_seg: 86.3613, loss: 0.4654
2023-11-26 23:50:35,296 - mmseg - INFO - Iter [45550/160000]	lr: 4.292e-05, eta: 1 day, 1:20:03, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3293, decode.acc_seg: 86.9242, aux.loss_ce: 0.1515, aux.acc_seg: 85.3469, loss: 0.4808
2023-11-26 23:51:12,222 - mmseg - INFO - Iter [45600/160000]	lr: 4.290e-05, eta: 1 day, 1:19:16, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3087, decode.acc_seg: 87.3917, aux.loss_ce: 0.1422, aux.acc_seg: 86.0618, loss: 0.4509
2023-11-26 23:51:51,208 - mmseg - INFO - Iter [45650/160000]	lr: 4.288e-05, eta: 1 day, 1:18:34, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3094, decode.acc_seg: 87.6013, aux.loss_ce: 0.1424, aux.acc_seg: 86.0483, loss: 0.4518
2023-11-26 23:52:31,391 - mmseg - INFO - Iter [45700/160000]	lr: 4.286e-05, eta: 1 day, 1:17:55, time: 0.804, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3167, decode.acc_seg: 87.0935, aux.loss_ce: 0.1419, aux.acc_seg: 85.7310, loss: 0.4586
2023-11-26 23:53:11,753 - mmseg - INFO - Iter [45750/160000]	lr: 4.284e-05, eta: 1 day, 1:17:17, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3149, decode.acc_seg: 87.3051, aux.loss_ce: 0.1406, aux.acc_seg: 86.4357, loss: 0.4555
2023-11-26 23:53:51,707 - mmseg - INFO - Iter [45800/160000]	lr: 4.283e-05, eta: 1 day, 1:16:37, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2915, decode.acc_seg: 88.1186, aux.loss_ce: 0.1315, aux.acc_seg: 87.0978, loss: 0.4230
2023-11-26 23:54:30,483 - mmseg - INFO - Iter [45850/160000]	lr: 4.281e-05, eta: 1 day, 1:15:55, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2940, decode.acc_seg: 88.3067, aux.loss_ce: 0.1346, aux.acc_seg: 87.2154, loss: 0.4286
2023-11-26 23:55:08,250 - mmseg - INFO - Iter [45900/160000]	lr: 4.279e-05, eta: 1 day, 1:15:10, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3067, decode.acc_seg: 87.4077, aux.loss_ce: 0.1418, aux.acc_seg: 86.1462, loss: 0.4485
2023-11-26 23:55:47,371 - mmseg - INFO - Iter [45950/160000]	lr: 4.277e-05, eta: 1 day, 1:14:28, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3047, decode.acc_seg: 87.7418, aux.loss_ce: 0.1406, aux.acc_seg: 86.4521, loss: 0.4452
2023-11-26 23:56:26,798 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-26 23:56:26,798 - mmseg - INFO - Iter [46000/160000]	lr: 4.275e-05, eta: 1 day, 1:13:47, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3063, decode.acc_seg: 87.4866, aux.loss_ce: 0.1398, aux.acc_seg: 86.1990, loss: 0.4462
2023-11-26 23:57:06,443 - mmseg - INFO - Iter [46050/160000]	lr: 4.273e-05, eta: 1 day, 1:13:07, time: 0.794, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3211, decode.acc_seg: 87.3479, aux.loss_ce: 0.1458, aux.acc_seg: 86.1280, loss: 0.4670
2023-11-26 23:57:43,177 - mmseg - INFO - Iter [46100/160000]	lr: 4.271e-05, eta: 1 day, 1:12:19, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3216, decode.acc_seg: 87.3515, aux.loss_ce: 0.1468, aux.acc_seg: 86.0236, loss: 0.4684
2023-11-26 23:58:19,891 - mmseg - INFO - Iter [46150/160000]	lr: 4.269e-05, eta: 1 day, 1:11:32, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3236, decode.acc_seg: 86.7116, aux.loss_ce: 0.1474, aux.acc_seg: 85.4500, loss: 0.4710
2023-11-26 23:58:57,195 - mmseg - INFO - Iter [46200/160000]	lr: 4.268e-05, eta: 1 day, 1:10:46, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3136, decode.acc_seg: 87.1355, aux.loss_ce: 0.1398, aux.acc_seg: 86.2093, loss: 0.4533
2023-11-26 23:59:36,039 - mmseg - INFO - Iter [46250/160000]	lr: 4.266e-05, eta: 1 day, 1:10:04, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3408, decode.acc_seg: 86.5251, aux.loss_ce: 0.1507, aux.acc_seg: 85.4950, loss: 0.4915
2023-11-27 00:00:16,659 - mmseg - INFO - Iter [46300/160000]	lr: 4.264e-05, eta: 1 day, 1:09:26, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3163, decode.acc_seg: 87.3058, aux.loss_ce: 0.1413, aux.acc_seg: 86.3673, loss: 0.4575
2023-11-27 00:00:57,087 - mmseg - INFO - Iter [46350/160000]	lr: 4.262e-05, eta: 1 day, 1:08:47, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3368, decode.acc_seg: 86.6744, aux.loss_ce: 0.1498, aux.acc_seg: 85.6028, loss: 0.4865
2023-11-27 00:01:37,054 - mmseg - INFO - Iter [46400/160000]	lr: 4.260e-05, eta: 1 day, 1:08:08, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3236, decode.acc_seg: 86.8376, aux.loss_ce: 0.1466, aux.acc_seg: 85.7081, loss: 0.4702
2023-11-27 00:02:15,676 - mmseg - INFO - Iter [46450/160000]	lr: 4.258e-05, eta: 1 day, 1:07:25, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3248, decode.acc_seg: 86.8102, aux.loss_ce: 0.1487, aux.acc_seg: 85.6076, loss: 0.4736
2023-11-27 00:02:52,293 - mmseg - INFO - Iter [46500/160000]	lr: 4.256e-05, eta: 1 day, 1:06:37, time: 0.732, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3351, decode.acc_seg: 86.6482, aux.loss_ce: 0.1516, aux.acc_seg: 85.5013, loss: 0.4867
2023-11-27 00:03:30,761 - mmseg - INFO - Iter [46550/160000]	lr: 4.254e-05, eta: 1 day, 1:05:54, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3346, decode.acc_seg: 86.8189, aux.loss_ce: 0.1517, aux.acc_seg: 85.5510, loss: 0.4862
2023-11-27 00:04:10,964 - mmseg - INFO - Iter [46600/160000]	lr: 4.253e-05, eta: 1 day, 1:05:15, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3101, decode.acc_seg: 87.6203, aux.loss_ce: 0.1398, aux.acc_seg: 86.5729, loss: 0.4499
2023-11-27 00:04:51,080 - mmseg - INFO - Iter [46650/160000]	lr: 4.251e-05, eta: 1 day, 1:04:36, time: 0.802, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3276, decode.acc_seg: 87.1285, aux.loss_ce: 0.1494, aux.acc_seg: 85.8200, loss: 0.4770
2023-11-27 00:05:31,572 - mmseg - INFO - Iter [46700/160000]	lr: 4.249e-05, eta: 1 day, 1:03:58, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3110, decode.acc_seg: 87.3518, aux.loss_ce: 0.1412, aux.acc_seg: 86.1612, loss: 0.4523
2023-11-27 00:06:12,567 - mmseg - INFO - Iter [46750/160000]	lr: 4.247e-05, eta: 1 day, 1:03:21, time: 0.820, data_time: 0.054, memory: 21695, decode.loss_ce: 0.3213, decode.acc_seg: 87.7102, aux.loss_ce: 0.1436, aux.acc_seg: 86.4469, loss: 0.4649
2023-11-27 00:06:52,494 - mmseg - INFO - Iter [46800/160000]	lr: 4.245e-05, eta: 1 day, 1:02:42, time: 0.799, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3096, decode.acc_seg: 87.6083, aux.loss_ce: 0.1431, aux.acc_seg: 86.3540, loss: 0.4527
2023-11-27 00:07:29,218 - mmseg - INFO - Iter [46850/160000]	lr: 4.243e-05, eta: 1 day, 1:01:54, time: 0.734, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3082, decode.acc_seg: 87.6270, aux.loss_ce: 0.1396, aux.acc_seg: 86.3842, loss: 0.4478
2023-11-27 00:08:09,499 - mmseg - INFO - Iter [46900/160000]	lr: 4.241e-05, eta: 1 day, 1:01:15, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3140, decode.acc_seg: 87.7844, aux.loss_ce: 0.1421, aux.acc_seg: 86.6312, loss: 0.4561
2023-11-27 00:08:49,620 - mmseg - INFO - Iter [46950/160000]	lr: 4.239e-05, eta: 1 day, 1:00:36, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3113, decode.acc_seg: 87.4561, aux.loss_ce: 0.1425, aux.acc_seg: 86.1092, loss: 0.4539
2023-11-27 00:09:28,028 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 00:09:28,028 - mmseg - INFO - Iter [47000/160000]	lr: 4.238e-05, eta: 1 day, 0:59:53, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3099, decode.acc_seg: 87.5180, aux.loss_ce: 0.1414, aux.acc_seg: 86.2538, loss: 0.4513
2023-11-27 00:10:05,753 - mmseg - INFO - Iter [47050/160000]	lr: 4.236e-05, eta: 1 day, 0:59:08, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3197, decode.acc_seg: 87.3067, aux.loss_ce: 0.1448, aux.acc_seg: 86.1418, loss: 0.4646
2023-11-27 00:10:45,630 - mmseg - INFO - Iter [47100/160000]	lr: 4.234e-05, eta: 1 day, 0:58:29, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3111, decode.acc_seg: 87.6677, aux.loss_ce: 0.1420, aux.acc_seg: 86.3717, loss: 0.4531
2023-11-27 00:11:25,531 - mmseg - INFO - Iter [47150/160000]	lr: 4.232e-05, eta: 1 day, 0:57:49, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3048, decode.acc_seg: 88.1243, aux.loss_ce: 0.1387, aux.acc_seg: 86.9593, loss: 0.4435
2023-11-27 00:12:03,068 - mmseg - INFO - Iter [47200/160000]	lr: 4.230e-05, eta: 1 day, 0:57:04, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3133, decode.acc_seg: 87.3241, aux.loss_ce: 0.1436, aux.acc_seg: 86.0347, loss: 0.4569
2023-11-27 00:12:41,361 - mmseg - INFO - Iter [47250/160000]	lr: 4.228e-05, eta: 1 day, 0:56:20, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3447, decode.acc_seg: 86.5243, aux.loss_ce: 0.1554, aux.acc_seg: 85.3671, loss: 0.5002
2023-11-27 00:13:21,775 - mmseg - INFO - Iter [47300/160000]	lr: 4.226e-05, eta: 1 day, 0:55:42, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3086, decode.acc_seg: 87.6904, aux.loss_ce: 0.1404, aux.acc_seg: 86.3774, loss: 0.4490
2023-11-27 00:13:58,688 - mmseg - INFO - Iter [47350/160000]	lr: 4.224e-05, eta: 1 day, 0:54:55, time: 0.738, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2893, decode.acc_seg: 88.0857, aux.loss_ce: 0.1305, aux.acc_seg: 86.9327, loss: 0.4198
2023-11-27 00:14:39,281 - mmseg - INFO - Iter [47400/160000]	lr: 4.223e-05, eta: 1 day, 0:54:17, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3440, decode.acc_seg: 86.5087, aux.loss_ce: 0.1551, aux.acc_seg: 85.2817, loss: 0.4992
2023-11-27 00:15:20,059 - mmseg - INFO - Iter [47450/160000]	lr: 4.221e-05, eta: 1 day, 0:53:40, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3054, decode.acc_seg: 88.1046, aux.loss_ce: 0.1408, aux.acc_seg: 87.0190, loss: 0.4461
2023-11-27 00:15:59,516 - mmseg - INFO - Iter [47500/160000]	lr: 4.219e-05, eta: 1 day, 0:52:59, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3266, decode.acc_seg: 87.1687, aux.loss_ce: 0.1472, aux.acc_seg: 85.8041, loss: 0.4738
2023-11-27 00:16:38,607 - mmseg - INFO - Iter [47550/160000]	lr: 4.217e-05, eta: 1 day, 0:52:18, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3275, decode.acc_seg: 86.9504, aux.loss_ce: 0.1483, aux.acc_seg: 85.6456, loss: 0.4758
2023-11-27 00:17:18,410 - mmseg - INFO - Iter [47600/160000]	lr: 4.215e-05, eta: 1 day, 0:51:38, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3173, decode.acc_seg: 87.3259, aux.loss_ce: 0.1432, aux.acc_seg: 86.1924, loss: 0.4605
2023-11-27 00:17:55,460 - mmseg - INFO - Iter [47650/160000]	lr: 4.213e-05, eta: 1 day, 0:50:51, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3173, decode.acc_seg: 87.6002, aux.loss_ce: 0.1422, aux.acc_seg: 86.5687, loss: 0.4595
2023-11-27 00:18:35,352 - mmseg - INFO - Iter [47700/160000]	lr: 4.211e-05, eta: 1 day, 0:50:12, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3144, decode.acc_seg: 87.6187, aux.loss_ce: 0.1423, aux.acc_seg: 86.4289, loss: 0.4567
2023-11-27 00:19:16,070 - mmseg - INFO - Iter [47750/160000]	lr: 4.209e-05, eta: 1 day, 0:49:34, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3080, decode.acc_seg: 87.5523, aux.loss_ce: 0.1422, aux.acc_seg: 86.2811, loss: 0.4502
2023-11-27 00:19:54,907 - mmseg - INFO - Iter [47800/160000]	lr: 4.208e-05, eta: 1 day, 0:48:52, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3102, decode.acc_seg: 87.3527, aux.loss_ce: 0.1397, aux.acc_seg: 86.2616, loss: 0.4499
2023-11-27 00:20:32,944 - mmseg - INFO - Iter [47850/160000]	lr: 4.206e-05, eta: 1 day, 0:48:08, time: 0.761, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3193, decode.acc_seg: 87.2347, aux.loss_ce: 0.1423, aux.acc_seg: 86.2648, loss: 0.4616
2023-11-27 00:21:12,700 - mmseg - INFO - Iter [47900/160000]	lr: 4.204e-05, eta: 1 day, 0:47:28, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2871, decode.acc_seg: 88.1487, aux.loss_ce: 0.1340, aux.acc_seg: 86.8318, loss: 0.4211
2023-11-27 00:21:52,961 - mmseg - INFO - Iter [47950/160000]	lr: 4.202e-05, eta: 1 day, 0:46:49, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3102, decode.acc_seg: 87.7176, aux.loss_ce: 0.1404, aux.acc_seg: 86.5293, loss: 0.4505
2023-11-27 00:22:34,485 - mmseg - INFO - Saving checkpoint at 48000 iterations
2023-11-27 00:22:39,616 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 00:22:39,616 - mmseg - INFO - Iter [48000/160000]	lr: 4.200e-05, eta: 1 day, 0:46:26, time: 0.934, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2977, decode.acc_seg: 88.0408, aux.loss_ce: 0.1346, aux.acc_seg: 86.8634, loss: 0.4323
2023-11-27 00:24:25,939 - mmseg - INFO - per class results:
2023-11-27 00:24:25,953 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 76.43 | 86.76 |
|       building      | 80.46 | 89.55 |
|         sky         |  94.3 | 97.61 |
|        floor        | 82.18 | 89.98 |
|         tree        |  74.4 | 87.88 |
|       ceiling       | 81.68 | 91.16 |
|         road        | 81.88 | 89.58 |
|         bed         | 87.08 | 93.21 |
|      windowpane     | 60.08 | 80.18 |
|        grass        | 65.66 | 80.64 |
|       cabinet       | 59.47 | 70.77 |
|       sidewalk      | 64.44 | 80.51 |
|        person       | 80.34 | 91.71 |
|        earth        | 31.18 | 41.68 |
|         door        | 48.45 | 66.27 |
|        table        | 55.81 | 72.88 |
|       mountain      | 55.42 | 67.99 |
|        plant        | 49.34 | 57.52 |
|       curtain       | 74.65 | 85.95 |
|        chair        | 54.34 | 67.02 |
|         car         | 84.75 | 93.33 |
|        water        | 59.32 | 75.06 |
|       painting      | 74.18 | 85.38 |
|         sofa        | 62.67 | 82.89 |
|        shelf        |  42.8 | 61.67 |
|        house        | 47.15 |  72.6 |
|         sea         | 66.82 | 74.78 |
|        mirror       | 60.65 | 68.36 |
|         rug         | 66.44 |  79.7 |
|        field        | 31.08 | 59.06 |
|       armchair      |  38.6 | 58.12 |
|         seat        | 51.43 | 81.39 |
|        fence        | 47.92 | 65.02 |
|         desk        | 45.78 | 67.17 |
|         rock        | 47.97 | 73.02 |
|       wardrobe      | 42.92 |  67.8 |
|         lamp        | 61.29 | 72.72 |
|       bathtub       | 76.67 | 86.36 |
|       railing       | 36.92 | 51.38 |
|       cushion       | 55.42 | 70.27 |
|         base        | 34.65 | 44.52 |
|         box         | 27.38 |  34.3 |
|        column       | 45.45 | 55.33 |
|      signboard      |  36.4 | 46.68 |
|   chest of drawers  | 40.52 | 56.08 |
|       counter       | 33.23 | 39.56 |
|         sand        | 37.09 | 67.59 |
|         sink        | 67.05 | 78.65 |
|      skyscraper     | 26.39 | 30.03 |
|      fireplace      | 73.42 | 88.85 |
|     refrigerator    | 70.89 | 79.44 |
|      grandstand     | 36.42 | 76.93 |
|         path        | 15.65 | 23.01 |
|        stairs       |  21.5 | 27.18 |
|        runway       | 70.54 | 93.53 |
|         case        | 67.68 | 82.88 |
|      pool table     | 92.65 |  96.2 |
|        pillow       | 57.88 | 68.07 |
|     screen door     | 55.34 | 69.01 |
|       stairway      | 30.04 | 48.44 |
|        river        |  8.55 | 24.67 |
|        bridge       | 72.55 |  85.8 |
|       bookcase      |  33.2 | 55.44 |
|        blind        | 39.28 | 43.12 |
|     coffee table    | 50.65 | 82.77 |
|        toilet       |  79.1 |  89.9 |
|        flower       | 30.46 | 58.74 |
|         book        | 44.86 | 62.49 |
|         hill        |  4.77 |  7.58 |
|        bench        | 43.61 | 50.67 |
|      countertop     | 47.64 | 65.09 |
|        stove        | 64.62 | 71.89 |
|         palm        |  50.1 | 66.29 |
|    kitchen island   | 44.99 | 87.66 |
|       computer      | 59.03 | 71.77 |
|     swivel chair    | 48.22 | 70.59 |
|         boat        | 41.91 | 52.46 |
|         bar         | 44.82 | 63.28 |
|    arcade machine   | 83.57 | 93.18 |
|        hovel        | 55.74 | 73.65 |
|         bus         | 85.45 |  96.2 |
|        towel        | 62.02 | 82.63 |
|        light        | 53.77 | 61.28 |
|        truck        |  32.3 | 43.23 |
|        tower        | 19.42 |  34.9 |
|      chandelier     | 62.89 | 74.96 |
|        awning       | 25.12 | 29.49 |
|     streetlight     | 23.06 | 29.27 |
|        booth        | 35.72 | 37.58 |
| television receiver | 67.46 | 79.89 |
|       airplane      |  55.3 | 63.48 |
|      dirt track     |  2.61 | 18.53 |
|       apparel       | 39.36 | 48.58 |
|         pole        | 23.28 | 31.99 |
|         land        |  0.43 |  1.14 |
|      bannister      | 12.56 |  15.3 |
|      escalator      | 41.48 | 58.21 |
|       ottoman       | 47.03 | 55.16 |
|        bottle       | 36.69 | 63.82 |
|        buffet       | 47.02 | 61.39 |
|        poster       | 24.95 | 42.06 |
|        stage        | 14.33 | 21.98 |
|         van         | 44.16 | 56.41 |
|         ship        | 56.75 | 96.77 |
|       fountain      | 21.39 | 21.67 |
|    conveyer belt    | 69.09 | 91.67 |
|        canopy       | 27.45 | 43.27 |
|        washer       | 73.48 | 77.78 |
|      plaything      | 25.44 | 44.82 |
|    swimming pool    | 83.41 | 93.02 |
|        stool        | 42.04 | 53.62 |
|        barrel       | 13.25 | 66.14 |
|        basket       | 31.47 | 48.41 |
|      waterfall      | 49.95 |  88.7 |
|         tent        | 60.84 | 98.84 |
|         bag         | 12.68 | 14.63 |
|       minibike      | 70.93 | 81.08 |
|        cradle       | 76.91 | 98.19 |
|         oven        | 39.49 | 48.57 |
|         ball        | 48.06 | 65.86 |
|         food        | 47.31 | 54.81 |
|         step        | 13.19 | 14.13 |
|         tank        | 40.18 | 45.64 |
|      trade name     | 20.84 | 22.99 |
|      microwave      |  80.7 | 93.38 |
|         pot         | 45.05 | 51.68 |
|        animal       | 57.67 | 60.43 |
|       bicycle       | 50.12 | 79.09 |
|         lake        | 56.07 | 63.61 |
|      dishwasher     | 50.39 | 53.26 |
|        screen       |  62.6 | 92.33 |
|       blanket       |  7.57 |  8.84 |
|      sculpture      | 53.12 |  70.5 |
|         hood        |  58.1 | 68.19 |
|        sconce       | 39.91 | 49.64 |
|         vase        | 35.19 | 58.63 |
|    traffic light    | 25.52 | 49.79 |
|         tray        |  5.49 |  6.8  |
|        ashcan       |  31.3 | 47.43 |
|         fan         | 60.05 |  71.3 |
|         pier        | 29.09 | 40.61 |
|      crt screen     |  4.69 | 16.82 |
|        plate        | 51.38 | 74.96 |
|       monitor       |  7.89 | 11.17 |
|    bulletin board   | 45.62 | 60.86 |
|        shower       |  0.18 |  0.43 |
|       radiator      | 65.19 | 74.06 |
|        glass        |  9.1  |  9.4  |
|        clock        | 34.37 | 40.61 |
|         flag        | 41.02 | 44.07 |
+---------------------+-------+-------+
2023-11-27 00:24:25,953 - mmseg - INFO - Summary:
2023-11-27 00:24:25,954 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 82.05 | 47.56 | 61.3 |
+-------+-------+------+
2023-11-27 00:24:26,007 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 00:24:26,007 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8205, mIoU: 0.4756, mAcc: 0.6130, IoU.wall: 0.7643, IoU.building: 0.8046, IoU.sky: 0.9430, IoU.floor: 0.8218, IoU.tree: 0.7440, IoU.ceiling: 0.8168, IoU.road: 0.8188, IoU.bed : 0.8708, IoU.windowpane: 0.6008, IoU.grass: 0.6566, IoU.cabinet: 0.5947, IoU.sidewalk: 0.6444, IoU.person: 0.8034, IoU.earth: 0.3118, IoU.door: 0.4845, IoU.table: 0.5581, IoU.mountain: 0.5542, IoU.plant: 0.4934, IoU.curtain: 0.7465, IoU.chair: 0.5434, IoU.car: 0.8475, IoU.water: 0.5932, IoU.painting: 0.7418, IoU.sofa: 0.6267, IoU.shelf: 0.4280, IoU.house: 0.4715, IoU.sea: 0.6682, IoU.mirror: 0.6065, IoU.rug: 0.6644, IoU.field: 0.3108, IoU.armchair: 0.3860, IoU.seat: 0.5143, IoU.fence: 0.4792, IoU.desk: 0.4578, IoU.rock: 0.4797, IoU.wardrobe: 0.4292, IoU.lamp: 0.6129, IoU.bathtub: 0.7667, IoU.railing: 0.3692, IoU.cushion: 0.5542, IoU.base: 0.3465, IoU.box: 0.2738, IoU.column: 0.4545, IoU.signboard: 0.3640, IoU.chest of drawers: 0.4052, IoU.counter: 0.3323, IoU.sand: 0.3709, IoU.sink: 0.6705, IoU.skyscraper: 0.2639, IoU.fireplace: 0.7342, IoU.refrigerator: 0.7089, IoU.grandstand: 0.3642, IoU.path: 0.1565, IoU.stairs: 0.2150, IoU.runway: 0.7054, IoU.case: 0.6768, IoU.pool table: 0.9265, IoU.pillow: 0.5788, IoU.screen door: 0.5534, IoU.stairway: 0.3004, IoU.river: 0.0855, IoU.bridge: 0.7255, IoU.bookcase: 0.3320, IoU.blind: 0.3928, IoU.coffee table: 0.5065, IoU.toilet: 0.7910, IoU.flower: 0.3046, IoU.book: 0.4486, IoU.hill: 0.0477, IoU.bench: 0.4361, IoU.countertop: 0.4764, IoU.stove: 0.6462, IoU.palm: 0.5010, IoU.kitchen island: 0.4499, IoU.computer: 0.5903, IoU.swivel chair: 0.4822, IoU.boat: 0.4191, IoU.bar: 0.4482, IoU.arcade machine: 0.8357, IoU.hovel: 0.5574, IoU.bus: 0.8545, IoU.towel: 0.6202, IoU.light: 0.5377, IoU.truck: 0.3230, IoU.tower: 0.1942, IoU.chandelier: 0.6289, IoU.awning: 0.2512, IoU.streetlight: 0.2306, IoU.booth: 0.3572, IoU.television receiver: 0.6746, IoU.airplane: 0.5530, IoU.dirt track: 0.0261, IoU.apparel: 0.3936, IoU.pole: 0.2328, IoU.land: 0.0043, IoU.bannister: 0.1256, IoU.escalator: 0.4148, IoU.ottoman: 0.4703, IoU.bottle: 0.3669, IoU.buffet: 0.4702, IoU.poster: 0.2495, IoU.stage: 0.1433, IoU.van: 0.4416, IoU.ship: 0.5675, IoU.fountain: 0.2139, IoU.conveyer belt: 0.6909, IoU.canopy: 0.2745, IoU.washer: 0.7348, IoU.plaything: 0.2544, IoU.swimming pool: 0.8341, IoU.stool: 0.4204, IoU.barrel: 0.1325, IoU.basket: 0.3147, IoU.waterfall: 0.4995, IoU.tent: 0.6084, IoU.bag: 0.1268, IoU.minibike: 0.7093, IoU.cradle: 0.7691, IoU.oven: 0.3949, IoU.ball: 0.4806, IoU.food: 0.4731, IoU.step: 0.1319, IoU.tank: 0.4018, IoU.trade name: 0.2084, IoU.microwave: 0.8070, IoU.pot: 0.4505, IoU.animal: 0.5767, IoU.bicycle: 0.5012, IoU.lake: 0.5607, IoU.dishwasher: 0.5039, IoU.screen: 0.6260, IoU.blanket: 0.0757, IoU.sculpture: 0.5312, IoU.hood: 0.5810, IoU.sconce: 0.3991, IoU.vase: 0.3519, IoU.traffic light: 0.2552, IoU.tray: 0.0549, IoU.ashcan: 0.3130, IoU.fan: 0.6005, IoU.pier: 0.2909, IoU.crt screen: 0.0469, IoU.plate: 0.5138, IoU.monitor: 0.0789, IoU.bulletin board: 0.4562, IoU.shower: 0.0018, IoU.radiator: 0.6519, IoU.glass: 0.0910, IoU.clock: 0.3437, IoU.flag: 0.4102, Acc.wall: 0.8676, Acc.building: 0.8955, Acc.sky: 0.9761, Acc.floor: 0.8998, Acc.tree: 0.8788, Acc.ceiling: 0.9116, Acc.road: 0.8958, Acc.bed : 0.9321, Acc.windowpane: 0.8018, Acc.grass: 0.8064, Acc.cabinet: 0.7077, Acc.sidewalk: 0.8051, Acc.person: 0.9171, Acc.earth: 0.4168, Acc.door: 0.6627, Acc.table: 0.7288, Acc.mountain: 0.6799, Acc.plant: 0.5752, Acc.curtain: 0.8595, Acc.chair: 0.6702, Acc.car: 0.9333, Acc.water: 0.7506, Acc.painting: 0.8538, Acc.sofa: 0.8289, Acc.shelf: 0.6167, Acc.house: 0.7260, Acc.sea: 0.7478, Acc.mirror: 0.6836, Acc.rug: 0.7970, Acc.field: 0.5906, Acc.armchair: 0.5812, Acc.seat: 0.8139, Acc.fence: 0.6502, Acc.desk: 0.6717, Acc.rock: 0.7302, Acc.wardrobe: 0.6780, Acc.lamp: 0.7272, Acc.bathtub: 0.8636, Acc.railing: 0.5138, Acc.cushion: 0.7027, Acc.base: 0.4452, Acc.box: 0.3430, Acc.column: 0.5533, Acc.signboard: 0.4668, Acc.chest of drawers: 0.5608, Acc.counter: 0.3956, Acc.sand: 0.6759, Acc.sink: 0.7865, Acc.skyscraper: 0.3003, Acc.fireplace: 0.8885, Acc.refrigerator: 0.7944, Acc.grandstand: 0.7693, Acc.path: 0.2301, Acc.stairs: 0.2718, Acc.runway: 0.9353, Acc.case: 0.8288, Acc.pool table: 0.9620, Acc.pillow: 0.6807, Acc.screen door: 0.6901, Acc.stairway: 0.4844, Acc.river: 0.2467, Acc.bridge: 0.8580, Acc.bookcase: 0.5544, Acc.blind: 0.4312, Acc.coffee table: 0.8277, Acc.toilet: 0.8990, Acc.flower: 0.5874, Acc.book: 0.6249, Acc.hill: 0.0758, Acc.bench: 0.5067, Acc.countertop: 0.6509, Acc.stove: 0.7189, Acc.palm: 0.6629, Acc.kitchen island: 0.8766, Acc.computer: 0.7177, Acc.swivel chair: 0.7059, Acc.boat: 0.5246, Acc.bar: 0.6328, Acc.arcade machine: 0.9318, Acc.hovel: 0.7365, Acc.bus: 0.9620, Acc.towel: 0.8263, Acc.light: 0.6128, Acc.truck: 0.4323, Acc.tower: 0.3490, Acc.chandelier: 0.7496, Acc.awning: 0.2949, Acc.streetlight: 0.2927, Acc.booth: 0.3758, Acc.television receiver: 0.7989, Acc.airplane: 0.6348, Acc.dirt track: 0.1853, Acc.apparel: 0.4858, Acc.pole: 0.3199, Acc.land: 0.0114, Acc.bannister: 0.1530, Acc.escalator: 0.5821, Acc.ottoman: 0.5516, Acc.bottle: 0.6382, Acc.buffet: 0.6139, Acc.poster: 0.4206, Acc.stage: 0.2198, Acc.van: 0.5641, Acc.ship: 0.9677, Acc.fountain: 0.2167, Acc.conveyer belt: 0.9167, Acc.canopy: 0.4327, Acc.washer: 0.7778, Acc.plaything: 0.4482, Acc.swimming pool: 0.9302, Acc.stool: 0.5362, Acc.barrel: 0.6614, Acc.basket: 0.4841, Acc.waterfall: 0.8870, Acc.tent: 0.9884, Acc.bag: 0.1463, Acc.minibike: 0.8108, Acc.cradle: 0.9819, Acc.oven: 0.4857, Acc.ball: 0.6586, Acc.food: 0.5481, Acc.step: 0.1413, Acc.tank: 0.4564, Acc.trade name: 0.2299, Acc.microwave: 0.9338, Acc.pot: 0.5168, Acc.animal: 0.6043, Acc.bicycle: 0.7909, Acc.lake: 0.6361, Acc.dishwasher: 0.5326, Acc.screen: 0.9233, Acc.blanket: 0.0884, Acc.sculpture: 0.7050, Acc.hood: 0.6819, Acc.sconce: 0.4964, Acc.vase: 0.5863, Acc.traffic light: 0.4979, Acc.tray: 0.0680, Acc.ashcan: 0.4743, Acc.fan: 0.7130, Acc.pier: 0.4061, Acc.crt screen: 0.1682, Acc.plate: 0.7496, Acc.monitor: 0.1117, Acc.bulletin board: 0.6086, Acc.shower: 0.0043, Acc.radiator: 0.7406, Acc.glass: 0.0940, Acc.clock: 0.4061, Acc.flag: 0.4407
2023-11-27 00:25:06,323 - mmseg - INFO - Iter [48050/160000]	lr: 4.198e-05, eta: 1 day, 0:49:55, time: 2.933, data_time: 2.138, memory: 21695, decode.loss_ce: 0.2891, decode.acc_seg: 88.4965, aux.loss_ce: 0.1320, aux.acc_seg: 87.1527, loss: 0.4211
2023-11-27 00:25:48,272 - mmseg - INFO - Iter [48100/160000]	lr: 4.196e-05, eta: 1 day, 0:49:19, time: 0.839, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3027, decode.acc_seg: 87.9812, aux.loss_ce: 0.1368, aux.acc_seg: 86.8365, loss: 0.4395
2023-11-27 00:26:27,944 - mmseg - INFO - Iter [48150/160000]	lr: 4.194e-05, eta: 1 day, 0:48:39, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2992, decode.acc_seg: 87.9651, aux.loss_ce: 0.1358, aux.acc_seg: 86.9118, loss: 0.4349
2023-11-27 00:27:06,679 - mmseg - INFO - Iter [48200/160000]	lr: 4.193e-05, eta: 1 day, 0:47:56, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3019, decode.acc_seg: 87.8956, aux.loss_ce: 0.1404, aux.acc_seg: 86.5403, loss: 0.4423
2023-11-27 00:27:43,469 - mmseg - INFO - Iter [48250/160000]	lr: 4.191e-05, eta: 1 day, 0:47:09, time: 0.736, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3179, decode.acc_seg: 87.2844, aux.loss_ce: 0.1426, aux.acc_seg: 86.1455, loss: 0.4605
2023-11-27 00:28:22,025 - mmseg - INFO - Iter [48300/160000]	lr: 4.189e-05, eta: 1 day, 0:46:26, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3088, decode.acc_seg: 87.2387, aux.loss_ce: 0.1421, aux.acc_seg: 85.9529, loss: 0.4508
2023-11-27 00:29:02,152 - mmseg - INFO - Iter [48350/160000]	lr: 4.187e-05, eta: 1 day, 0:45:47, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3081, decode.acc_seg: 87.8773, aux.loss_ce: 0.1383, aux.acc_seg: 86.6046, loss: 0.4463
2023-11-27 00:29:42,198 - mmseg - INFO - Iter [48400/160000]	lr: 4.185e-05, eta: 1 day, 0:45:07, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2874, decode.acc_seg: 88.4974, aux.loss_ce: 0.1307, aux.acc_seg: 87.3456, loss: 0.4181
2023-11-27 00:30:21,378 - mmseg - INFO - Iter [48450/160000]	lr: 4.183e-05, eta: 1 day, 0:44:25, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2998, decode.acc_seg: 87.8461, aux.loss_ce: 0.1373, aux.acc_seg: 86.6090, loss: 0.4370
2023-11-27 00:30:59,804 - mmseg - INFO - Iter [48500/160000]	lr: 4.181e-05, eta: 1 day, 0:43:42, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3155, decode.acc_seg: 87.4537, aux.loss_ce: 0.1443, aux.acc_seg: 86.1944, loss: 0.4598
2023-11-27 00:31:39,703 - mmseg - INFO - Iter [48550/160000]	lr: 4.179e-05, eta: 1 day, 0:43:02, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3336, decode.acc_seg: 86.9075, aux.loss_ce: 0.1504, aux.acc_seg: 85.7295, loss: 0.4840
2023-11-27 00:32:19,832 - mmseg - INFO - Iter [48600/160000]	lr: 4.178e-05, eta: 1 day, 0:42:22, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2916, decode.acc_seg: 88.2149, aux.loss_ce: 0.1342, aux.acc_seg: 86.8740, loss: 0.4258
2023-11-27 00:32:57,361 - mmseg - INFO - Iter [48650/160000]	lr: 4.176e-05, eta: 1 day, 0:41:37, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2967, decode.acc_seg: 88.0597, aux.loss_ce: 0.1339, aux.acc_seg: 86.7470, loss: 0.4306
2023-11-27 00:33:36,591 - mmseg - INFO - Iter [48700/160000]	lr: 4.174e-05, eta: 1 day, 0:40:56, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3171, decode.acc_seg: 87.2050, aux.loss_ce: 0.1437, aux.acc_seg: 85.8717, loss: 0.4607
2023-11-27 00:34:13,640 - mmseg - INFO - Iter [48750/160000]	lr: 4.172e-05, eta: 1 day, 0:40:09, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2931, decode.acc_seg: 88.2914, aux.loss_ce: 0.1333, aux.acc_seg: 87.1791, loss: 0.4264
2023-11-27 00:34:54,132 - mmseg - INFO - Iter [48800/160000]	lr: 4.170e-05, eta: 1 day, 0:39:31, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3071, decode.acc_seg: 87.6661, aux.loss_ce: 0.1405, aux.acc_seg: 86.3848, loss: 0.4475
2023-11-27 00:35:33,988 - mmseg - INFO - Iter [48850/160000]	lr: 4.168e-05, eta: 1 day, 0:38:50, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3173, decode.acc_seg: 87.6423, aux.loss_ce: 0.1443, aux.acc_seg: 86.2411, loss: 0.4616
2023-11-27 00:36:14,329 - mmseg - INFO - Iter [48900/160000]	lr: 4.166e-05, eta: 1 day, 0:38:12, time: 0.807, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3151, decode.acc_seg: 87.0239, aux.loss_ce: 0.1435, aux.acc_seg: 85.8183, loss: 0.4586
2023-11-27 00:36:54,357 - mmseg - INFO - Iter [48950/160000]	lr: 4.164e-05, eta: 1 day, 0:37:32, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2914, decode.acc_seg: 88.0927, aux.loss_ce: 0.1350, aux.acc_seg: 86.8566, loss: 0.4264
2023-11-27 00:37:34,278 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 00:37:34,278 - mmseg - INFO - Iter [49000/160000]	lr: 4.163e-05, eta: 1 day, 0:36:52, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3165, decode.acc_seg: 87.0021, aux.loss_ce: 0.1446, aux.acc_seg: 85.8672, loss: 0.4611
2023-11-27 00:38:13,407 - mmseg - INFO - Iter [49050/160000]	lr: 4.161e-05, eta: 1 day, 0:36:10, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3101, decode.acc_seg: 87.6079, aux.loss_ce: 0.1418, aux.acc_seg: 86.3664, loss: 0.4520
2023-11-27 00:38:53,575 - mmseg - INFO - Iter [49100/160000]	lr: 4.159e-05, eta: 1 day, 0:35:31, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3173, decode.acc_seg: 87.1457, aux.loss_ce: 0.1450, aux.acc_seg: 85.9094, loss: 0.4623
2023-11-27 00:39:33,189 - mmseg - INFO - Iter [49150/160000]	lr: 4.157e-05, eta: 1 day, 0:34:50, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3182, decode.acc_seg: 87.2605, aux.loss_ce: 0.1418, aux.acc_seg: 86.2291, loss: 0.4601
2023-11-27 00:40:13,310 - mmseg - INFO - Iter [49200/160000]	lr: 4.155e-05, eta: 1 day, 0:34:11, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2802, decode.acc_seg: 88.4948, aux.loss_ce: 0.1282, aux.acc_seg: 87.2468, loss: 0.4084
2023-11-27 00:40:51,697 - mmseg - INFO - Iter [49250/160000]	lr: 4.153e-05, eta: 1 day, 0:33:28, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3181, decode.acc_seg: 87.2459, aux.loss_ce: 0.1446, aux.acc_seg: 85.9118, loss: 0.4627
2023-11-27 00:41:33,057 - mmseg - INFO - Iter [49300/160000]	lr: 4.151e-05, eta: 1 day, 0:32:51, time: 0.827, data_time: 0.053, memory: 21695, decode.loss_ce: 0.3016, decode.acc_seg: 87.5515, aux.loss_ce: 0.1394, aux.acc_seg: 86.2398, loss: 0.4410
2023-11-27 00:42:11,926 - mmseg - INFO - Iter [49350/160000]	lr: 4.149e-05, eta: 1 day, 0:32:09, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3031, decode.acc_seg: 88.1648, aux.loss_ce: 0.1403, aux.acc_seg: 86.8301, loss: 0.4435
2023-11-27 00:42:51,724 - mmseg - INFO - Iter [49400/160000]	lr: 4.148e-05, eta: 1 day, 0:31:29, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3102, decode.acc_seg: 87.7060, aux.loss_ce: 0.1384, aux.acc_seg: 86.5779, loss: 0.4487
2023-11-27 00:43:31,595 - mmseg - INFO - Iter [49450/160000]	lr: 4.146e-05, eta: 1 day, 0:30:48, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3128, decode.acc_seg: 87.6152, aux.loss_ce: 0.1406, aux.acc_seg: 86.1757, loss: 0.4534
2023-11-27 00:44:11,497 - mmseg - INFO - Iter [49500/160000]	lr: 4.144e-05, eta: 1 day, 0:30:09, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2858, decode.acc_seg: 88.1388, aux.loss_ce: 0.1307, aux.acc_seg: 86.9800, loss: 0.4166
2023-11-27 00:44:48,850 - mmseg - INFO - Iter [49550/160000]	lr: 4.142e-05, eta: 1 day, 0:29:23, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3040, decode.acc_seg: 87.9043, aux.loss_ce: 0.1370, aux.acc_seg: 86.8605, loss: 0.4410
2023-11-27 00:45:27,210 - mmseg - INFO - Iter [49600/160000]	lr: 4.140e-05, eta: 1 day, 0:28:40, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3268, decode.acc_seg: 87.4625, aux.loss_ce: 0.1467, aux.acc_seg: 86.0123, loss: 0.4734
2023-11-27 00:46:04,142 - mmseg - INFO - Iter [49650/160000]	lr: 4.138e-05, eta: 1 day, 0:27:53, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3200, decode.acc_seg: 87.5238, aux.loss_ce: 0.1457, aux.acc_seg: 86.1546, loss: 0.4657
2023-11-27 00:46:40,961 - mmseg - INFO - Iter [49700/160000]	lr: 4.136e-05, eta: 1 day, 0:27:06, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3290, decode.acc_seg: 86.9964, aux.loss_ce: 0.1518, aux.acc_seg: 85.8323, loss: 0.4808
2023-11-27 00:47:19,769 - mmseg - INFO - Iter [49750/160000]	lr: 4.134e-05, eta: 1 day, 0:26:24, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3007, decode.acc_seg: 87.6833, aux.loss_ce: 0.1385, aux.acc_seg: 86.2782, loss: 0.4391
2023-11-27 00:47:59,409 - mmseg - INFO - Iter [49800/160000]	lr: 4.133e-05, eta: 1 day, 0:25:43, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3129, decode.acc_seg: 87.6905, aux.loss_ce: 0.1413, aux.acc_seg: 86.5823, loss: 0.4543
2023-11-27 00:48:37,686 - mmseg - INFO - Iter [49850/160000]	lr: 4.131e-05, eta: 1 day, 0:25:00, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2793, decode.acc_seg: 88.3096, aux.loss_ce: 0.1272, aux.acc_seg: 86.9884, loss: 0.4066
2023-11-27 00:49:18,685 - mmseg - INFO - Iter [49900/160000]	lr: 4.129e-05, eta: 1 day, 0:24:22, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3028, decode.acc_seg: 88.1789, aux.loss_ce: 0.1365, aux.acc_seg: 86.9789, loss: 0.4393
2023-11-27 00:49:58,590 - mmseg - INFO - Iter [49950/160000]	lr: 4.127e-05, eta: 1 day, 0:23:43, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2998, decode.acc_seg: 88.1022, aux.loss_ce: 0.1367, aux.acc_seg: 87.0522, loss: 0.4365
2023-11-27 00:50:37,901 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 00:50:37,901 - mmseg - INFO - Iter [50000/160000]	lr: 4.125e-05, eta: 1 day, 0:23:01, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3184, decode.acc_seg: 87.0469, aux.loss_ce: 0.1431, aux.acc_seg: 85.8233, loss: 0.4615
2023-11-27 00:51:16,555 - mmseg - INFO - Iter [50050/160000]	lr: 4.123e-05, eta: 1 day, 0:22:19, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3245, decode.acc_seg: 87.4129, aux.loss_ce: 0.1462, aux.acc_seg: 86.1471, loss: 0.4706
2023-11-27 00:51:55,868 - mmseg - INFO - Iter [50100/160000]	lr: 4.121e-05, eta: 1 day, 0:21:37, time: 0.787, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3230, decode.acc_seg: 87.1917, aux.loss_ce: 0.1483, aux.acc_seg: 85.8908, loss: 0.4714
2023-11-27 00:52:36,009 - mmseg - INFO - Iter [50150/160000]	lr: 4.119e-05, eta: 1 day, 0:20:58, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2981, decode.acc_seg: 87.8613, aux.loss_ce: 0.1339, aux.acc_seg: 86.7469, loss: 0.4321
2023-11-27 00:53:15,521 - mmseg - INFO - Iter [50200/160000]	lr: 4.118e-05, eta: 1 day, 0:20:17, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3151, decode.acc_seg: 87.5114, aux.loss_ce: 0.1432, aux.acc_seg: 86.1227, loss: 0.4583
2023-11-27 00:53:53,873 - mmseg - INFO - Iter [50250/160000]	lr: 4.116e-05, eta: 1 day, 0:19:34, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3033, decode.acc_seg: 87.9622, aux.loss_ce: 0.1391, aux.acc_seg: 86.5633, loss: 0.4424
2023-11-27 00:54:34,673 - mmseg - INFO - Iter [50300/160000]	lr: 4.114e-05, eta: 1 day, 0:18:56, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3259, decode.acc_seg: 86.7617, aux.loss_ce: 0.1477, aux.acc_seg: 85.7090, loss: 0.4736
2023-11-27 00:55:13,602 - mmseg - INFO - Iter [50350/160000]	lr: 4.112e-05, eta: 1 day, 0:18:14, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3093, decode.acc_seg: 86.9958, aux.loss_ce: 0.1396, aux.acc_seg: 85.9553, loss: 0.4489
2023-11-27 00:55:50,951 - mmseg - INFO - Iter [50400/160000]	lr: 4.110e-05, eta: 1 day, 0:17:29, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3099, decode.acc_seg: 87.4593, aux.loss_ce: 0.1398, aux.acc_seg: 86.4027, loss: 0.4497
2023-11-27 00:56:31,259 - mmseg - INFO - Iter [50450/160000]	lr: 4.108e-05, eta: 1 day, 0:16:50, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3067, decode.acc_seg: 87.7883, aux.loss_ce: 0.1391, aux.acc_seg: 86.7623, loss: 0.4458
2023-11-27 00:57:11,438 - mmseg - INFO - Iter [50500/160000]	lr: 4.106e-05, eta: 1 day, 0:16:10, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2980, decode.acc_seg: 87.9934, aux.loss_ce: 0.1350, aux.acc_seg: 87.0007, loss: 0.4330
2023-11-27 00:57:53,716 - mmseg - INFO - Iter [50550/160000]	lr: 4.104e-05, eta: 1 day, 0:15:36, time: 0.846, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2888, decode.acc_seg: 88.5956, aux.loss_ce: 0.1330, aux.acc_seg: 87.0767, loss: 0.4219
2023-11-27 00:58:33,190 - mmseg - INFO - Iter [50600/160000]	lr: 4.103e-05, eta: 1 day, 0:14:55, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3036, decode.acc_seg: 87.7433, aux.loss_ce: 0.1406, aux.acc_seg: 86.2863, loss: 0.4441
2023-11-27 00:59:10,918 - mmseg - INFO - Iter [50650/160000]	lr: 4.101e-05, eta: 1 day, 0:14:10, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3115, decode.acc_seg: 87.5348, aux.loss_ce: 0.1456, aux.acc_seg: 85.8405, loss: 0.4571
2023-11-27 00:59:51,116 - mmseg - INFO - Iter [50700/160000]	lr: 4.099e-05, eta: 1 day, 0:13:31, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2913, decode.acc_seg: 87.9619, aux.loss_ce: 0.1340, aux.acc_seg: 86.7925, loss: 0.4253
2023-11-27 01:00:30,887 - mmseg - INFO - Iter [50750/160000]	lr: 4.097e-05, eta: 1 day, 0:12:51, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2921, decode.acc_seg: 88.2240, aux.loss_ce: 0.1354, aux.acc_seg: 86.7924, loss: 0.4275
2023-11-27 01:01:11,377 - mmseg - INFO - Iter [50800/160000]	lr: 4.095e-05, eta: 1 day, 0:12:12, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2941, decode.acc_seg: 88.2210, aux.loss_ce: 0.1359, aux.acc_seg: 86.8238, loss: 0.4300
2023-11-27 01:01:51,095 - mmseg - INFO - Iter [50850/160000]	lr: 4.093e-05, eta: 1 day, 0:11:32, time: 0.793, data_time: 0.009, memory: 21695, decode.loss_ce: 0.3025, decode.acc_seg: 87.6473, aux.loss_ce: 0.1410, aux.acc_seg: 85.8955, loss: 0.4434
2023-11-27 01:02:29,855 - mmseg - INFO - Iter [50900/160000]	lr: 4.091e-05, eta: 1 day, 0:10:50, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3104, decode.acc_seg: 87.6649, aux.loss_ce: 0.1420, aux.acc_seg: 86.2538, loss: 0.4524
2023-11-27 01:03:09,920 - mmseg - INFO - Iter [50950/160000]	lr: 4.089e-05, eta: 1 day, 0:10:10, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2868, decode.acc_seg: 88.4988, aux.loss_ce: 0.1331, aux.acc_seg: 86.9903, loss: 0.4199
2023-11-27 01:03:50,418 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 01:03:50,419 - mmseg - INFO - Iter [51000/160000]	lr: 4.088e-05, eta: 1 day, 0:09:32, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2962, decode.acc_seg: 87.8753, aux.loss_ce: 0.1359, aux.acc_seg: 86.7437, loss: 0.4321
2023-11-27 01:04:29,646 - mmseg - INFO - Iter [51050/160000]	lr: 4.086e-05, eta: 1 day, 0:08:50, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2859, decode.acc_seg: 88.3000, aux.loss_ce: 0.1312, aux.acc_seg: 86.9766, loss: 0.4171
2023-11-27 01:05:08,371 - mmseg - INFO - Iter [51100/160000]	lr: 4.084e-05, eta: 1 day, 0:08:08, time: 0.775, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3202, decode.acc_seg: 87.3435, aux.loss_ce: 0.1442, aux.acc_seg: 85.9367, loss: 0.4645
2023-11-27 01:05:47,976 - mmseg - INFO - Iter [51150/160000]	lr: 4.082e-05, eta: 1 day, 0:07:27, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3078, decode.acc_seg: 87.7413, aux.loss_ce: 0.1403, aux.acc_seg: 86.4401, loss: 0.4480
2023-11-27 01:06:28,059 - mmseg - INFO - Iter [51200/160000]	lr: 4.080e-05, eta: 1 day, 0:06:48, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2985, decode.acc_seg: 88.2320, aux.loss_ce: 0.1369, aux.acc_seg: 86.7257, loss: 0.4354
2023-11-27 01:07:07,939 - mmseg - INFO - Iter [51250/160000]	lr: 4.078e-05, eta: 1 day, 0:06:08, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3034, decode.acc_seg: 87.6939, aux.loss_ce: 0.1382, aux.acc_seg: 86.4166, loss: 0.4416
2023-11-27 01:07:48,039 - mmseg - INFO - Iter [51300/160000]	lr: 4.076e-05, eta: 1 day, 0:05:28, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3033, decode.acc_seg: 87.6875, aux.loss_ce: 0.1404, aux.acc_seg: 86.1848, loss: 0.4436
2023-11-27 01:08:28,176 - mmseg - INFO - Iter [51350/160000]	lr: 4.074e-05, eta: 1 day, 0:04:49, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3181, decode.acc_seg: 87.5129, aux.loss_ce: 0.1451, aux.acc_seg: 86.0197, loss: 0.4632
2023-11-27 01:09:07,439 - mmseg - INFO - Iter [51400/160000]	lr: 4.073e-05, eta: 1 day, 0:04:08, time: 0.786, data_time: 0.012, memory: 21695, decode.loss_ce: 0.3045, decode.acc_seg: 87.5591, aux.loss_ce: 0.1382, aux.acc_seg: 86.4095, loss: 0.4428
2023-11-27 01:09:46,385 - mmseg - INFO - Iter [51450/160000]	lr: 4.071e-05, eta: 1 day, 0:03:26, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2970, decode.acc_seg: 87.9968, aux.loss_ce: 0.1356, aux.acc_seg: 86.6461, loss: 0.4326
2023-11-27 01:10:23,314 - mmseg - INFO - Iter [51500/160000]	lr: 4.069e-05, eta: 1 day, 0:02:40, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3192, decode.acc_seg: 86.8627, aux.loss_ce: 0.1463, aux.acc_seg: 85.6016, loss: 0.4655
2023-11-27 01:11:03,958 - mmseg - INFO - Iter [51550/160000]	lr: 4.067e-05, eta: 1 day, 0:02:02, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2877, decode.acc_seg: 88.3602, aux.loss_ce: 0.1324, aux.acc_seg: 86.9268, loss: 0.4201
2023-11-27 01:11:42,941 - mmseg - INFO - Iter [51600/160000]	lr: 4.065e-05, eta: 1 day, 0:01:20, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3120, decode.acc_seg: 87.8974, aux.loss_ce: 0.1426, aux.acc_seg: 86.5478, loss: 0.4546
2023-11-27 01:12:23,253 - mmseg - INFO - Iter [51650/160000]	lr: 4.063e-05, eta: 1 day, 0:00:41, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3196, decode.acc_seg: 87.6251, aux.loss_ce: 0.1480, aux.acc_seg: 86.2750, loss: 0.4676
2023-11-27 01:13:03,041 - mmseg - INFO - Iter [51700/160000]	lr: 4.061e-05, eta: 1 day, 0:00:01, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2898, decode.acc_seg: 88.2884, aux.loss_ce: 0.1325, aux.acc_seg: 87.1319, loss: 0.4223
2023-11-27 01:13:40,017 - mmseg - INFO - Iter [51750/160000]	lr: 4.059e-05, eta: 23:59:15, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3176, decode.acc_seg: 87.1424, aux.loss_ce: 0.1445, aux.acc_seg: 85.8360, loss: 0.4621
2023-11-27 01:14:21,129 - mmseg - INFO - Iter [51800/160000]	lr: 4.058e-05, eta: 23:58:37, time: 0.821, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2948, decode.acc_seg: 88.1678, aux.loss_ce: 0.1341, aux.acc_seg: 86.8982, loss: 0.4289
2023-11-27 01:15:02,559 - mmseg - INFO - Iter [51850/160000]	lr: 4.056e-05, eta: 23:58:01, time: 0.829, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2771, decode.acc_seg: 88.4774, aux.loss_ce: 0.1280, aux.acc_seg: 87.2542, loss: 0.4051
2023-11-27 01:15:43,503 - mmseg - INFO - Iter [51900/160000]	lr: 4.054e-05, eta: 23:57:23, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2872, decode.acc_seg: 88.1102, aux.loss_ce: 0.1317, aux.acc_seg: 86.7652, loss: 0.4190
2023-11-27 01:16:23,357 - mmseg - INFO - Iter [51950/160000]	lr: 4.052e-05, eta: 23:56:43, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2950, decode.acc_seg: 88.0691, aux.loss_ce: 0.1325, aux.acc_seg: 86.9098, loss: 0.4275
2023-11-27 01:17:00,871 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 01:17:00,871 - mmseg - INFO - Iter [52000/160000]	lr: 4.050e-05, eta: 23:55:58, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2812, decode.acc_seg: 88.6278, aux.loss_ce: 0.1281, aux.acc_seg: 87.4498, loss: 0.4093
2023-11-27 01:17:39,460 - mmseg - INFO - Iter [52050/160000]	lr: 4.048e-05, eta: 23:55:16, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2880, decode.acc_seg: 88.3538, aux.loss_ce: 0.1327, aux.acc_seg: 86.9473, loss: 0.4207
2023-11-27 01:18:19,834 - mmseg - INFO - Iter [52100/160000]	lr: 4.046e-05, eta: 23:54:37, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3005, decode.acc_seg: 87.9698, aux.loss_ce: 0.1364, aux.acc_seg: 86.8278, loss: 0.4369
2023-11-27 01:19:00,700 - mmseg - INFO - Iter [52150/160000]	lr: 4.044e-05, eta: 23:53:59, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2862, decode.acc_seg: 88.3335, aux.loss_ce: 0.1317, aux.acc_seg: 87.1566, loss: 0.4179
2023-11-27 01:19:41,690 - mmseg - INFO - Iter [52200/160000]	lr: 4.043e-05, eta: 23:53:21, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2892, decode.acc_seg: 88.4379, aux.loss_ce: 0.1314, aux.acc_seg: 87.0368, loss: 0.4207
2023-11-27 01:20:22,443 - mmseg - INFO - Iter [52250/160000]	lr: 4.041e-05, eta: 23:52:43, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2927, decode.acc_seg: 88.0910, aux.loss_ce: 0.1336, aux.acc_seg: 86.6896, loss: 0.4263
2023-11-27 01:21:03,817 - mmseg - INFO - Iter [52300/160000]	lr: 4.039e-05, eta: 23:52:06, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2982, decode.acc_seg: 87.9673, aux.loss_ce: 0.1367, aux.acc_seg: 86.9723, loss: 0.4349
2023-11-27 01:21:43,565 - mmseg - INFO - Iter [52350/160000]	lr: 4.037e-05, eta: 23:51:26, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2855, decode.acc_seg: 88.7391, aux.loss_ce: 0.1331, aux.acc_seg: 87.1955, loss: 0.4186
2023-11-27 01:22:24,378 - mmseg - INFO - Iter [52400/160000]	lr: 4.035e-05, eta: 23:50:48, time: 0.816, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2908, decode.acc_seg: 88.2165, aux.loss_ce: 0.1321, aux.acc_seg: 87.0697, loss: 0.4229
2023-11-27 01:23:05,105 - mmseg - INFO - Iter [52450/160000]	lr: 4.033e-05, eta: 23:50:10, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3297, decode.acc_seg: 86.6218, aux.loss_ce: 0.1488, aux.acc_seg: 85.3945, loss: 0.4784
2023-11-27 01:23:45,082 - mmseg - INFO - Iter [52500/160000]	lr: 4.031e-05, eta: 23:49:30, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2923, decode.acc_seg: 88.1710, aux.loss_ce: 0.1352, aux.acc_seg: 86.8904, loss: 0.4275
2023-11-27 01:24:23,832 - mmseg - INFO - Iter [52550/160000]	lr: 4.029e-05, eta: 23:48:48, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3041, decode.acc_seg: 88.1647, aux.loss_ce: 0.1394, aux.acc_seg: 86.9271, loss: 0.4434
2023-11-27 01:25:01,525 - mmseg - INFO - Iter [52600/160000]	lr: 4.028e-05, eta: 23:48:04, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2958, decode.acc_seg: 88.0553, aux.loss_ce: 0.1331, aux.acc_seg: 86.8938, loss: 0.4290
2023-11-27 01:25:42,713 - mmseg - INFO - Iter [52650/160000]	lr: 4.026e-05, eta: 23:47:26, time: 0.823, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3072, decode.acc_seg: 87.8290, aux.loss_ce: 0.1406, aux.acc_seg: 86.7814, loss: 0.4478
2023-11-27 01:26:21,846 - mmseg - INFO - Iter [52700/160000]	lr: 4.024e-05, eta: 23:46:45, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3022, decode.acc_seg: 88.2453, aux.loss_ce: 0.1359, aux.acc_seg: 87.0531, loss: 0.4381
2023-11-27 01:27:01,619 - mmseg - INFO - Iter [52750/160000]	lr: 4.022e-05, eta: 23:46:05, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3030, decode.acc_seg: 87.7569, aux.loss_ce: 0.1406, aux.acc_seg: 86.2885, loss: 0.4436
2023-11-27 01:27:40,369 - mmseg - INFO - Iter [52800/160000]	lr: 4.020e-05, eta: 23:45:23, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3093, decode.acc_seg: 87.5325, aux.loss_ce: 0.1396, aux.acc_seg: 86.5735, loss: 0.4489
2023-11-27 01:28:20,202 - mmseg - INFO - Iter [52850/160000]	lr: 4.018e-05, eta: 23:44:43, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2890, decode.acc_seg: 88.0918, aux.loss_ce: 0.1328, aux.acc_seg: 87.0195, loss: 0.4218
2023-11-27 01:29:00,424 - mmseg - INFO - Iter [52900/160000]	lr: 4.016e-05, eta: 23:44:03, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2906, decode.acc_seg: 88.3979, aux.loss_ce: 0.1343, aux.acc_seg: 87.1321, loss: 0.4249
2023-11-27 01:29:40,044 - mmseg - INFO - Iter [52950/160000]	lr: 4.014e-05, eta: 23:43:23, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3013, decode.acc_seg: 87.9055, aux.loss_ce: 0.1365, aux.acc_seg: 86.8709, loss: 0.4378
2023-11-27 01:30:17,067 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 01:30:17,067 - mmseg - INFO - Iter [53000/160000]	lr: 4.013e-05, eta: 23:42:37, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3051, decode.acc_seg: 88.0762, aux.loss_ce: 0.1383, aux.acc_seg: 86.5608, loss: 0.4434
2023-11-27 01:30:56,036 - mmseg - INFO - Iter [53050/160000]	lr: 4.011e-05, eta: 23:41:56, time: 0.779, data_time: 0.051, memory: 21695, decode.loss_ce: 0.3010, decode.acc_seg: 87.8643, aux.loss_ce: 0.1387, aux.acc_seg: 86.2931, loss: 0.4396
2023-11-27 01:31:33,164 - mmseg - INFO - Iter [53100/160000]	lr: 4.009e-05, eta: 23:41:10, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2895, decode.acc_seg: 88.0042, aux.loss_ce: 0.1310, aux.acc_seg: 87.0598, loss: 0.4205
2023-11-27 01:32:10,233 - mmseg - INFO - Iter [53150/160000]	lr: 4.007e-05, eta: 23:40:25, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2859, decode.acc_seg: 88.5959, aux.loss_ce: 0.1310, aux.acc_seg: 87.3928, loss: 0.4169
2023-11-27 01:32:48,167 - mmseg - INFO - Iter [53200/160000]	lr: 4.005e-05, eta: 23:39:41, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2841, decode.acc_seg: 88.3646, aux.loss_ce: 0.1310, aux.acc_seg: 87.1330, loss: 0.4150
2023-11-27 01:33:28,583 - mmseg - INFO - Iter [53250/160000]	lr: 4.003e-05, eta: 23:39:02, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2899, decode.acc_seg: 88.4405, aux.loss_ce: 0.1339, aux.acc_seg: 87.0377, loss: 0.4238
2023-11-27 01:34:08,632 - mmseg - INFO - Iter [53300/160000]	lr: 4.001e-05, eta: 23:38:22, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2969, decode.acc_seg: 88.2602, aux.loss_ce: 0.1369, aux.acc_seg: 86.7139, loss: 0.4338
2023-11-27 01:34:47,855 - mmseg - INFO - Iter [53350/160000]	lr: 3.999e-05, eta: 23:37:41, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2829, decode.acc_seg: 88.3331, aux.loss_ce: 0.1312, aux.acc_seg: 87.0301, loss: 0.4141
2023-11-27 01:35:25,549 - mmseg - INFO - Iter [53400/160000]	lr: 3.998e-05, eta: 23:36:57, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3027, decode.acc_seg: 88.0412, aux.loss_ce: 0.1405, aux.acc_seg: 86.5466, loss: 0.4432
2023-11-27 01:36:06,323 - mmseg - INFO - Iter [53450/160000]	lr: 3.996e-05, eta: 23:36:19, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2888, decode.acc_seg: 88.1274, aux.loss_ce: 0.1330, aux.acc_seg: 86.7749, loss: 0.4218
2023-11-27 01:36:46,925 - mmseg - INFO - Iter [53500/160000]	lr: 3.994e-05, eta: 23:35:40, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2857, decode.acc_seg: 88.2589, aux.loss_ce: 0.1309, aux.acc_seg: 86.7623, loss: 0.4166
2023-11-27 01:37:24,770 - mmseg - INFO - Iter [53550/160000]	lr: 3.992e-05, eta: 23:34:56, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2963, decode.acc_seg: 88.2494, aux.loss_ce: 0.1342, aux.acc_seg: 87.1060, loss: 0.4305
2023-11-27 01:38:05,383 - mmseg - INFO - Iter [53600/160000]	lr: 3.990e-05, eta: 23:34:18, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2834, decode.acc_seg: 88.7373, aux.loss_ce: 0.1279, aux.acc_seg: 87.6777, loss: 0.4113
2023-11-27 01:38:44,084 - mmseg - INFO - Iter [53650/160000]	lr: 3.988e-05, eta: 23:33:36, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2945, decode.acc_seg: 88.0648, aux.loss_ce: 0.1348, aux.acc_seg: 87.0657, loss: 0.4293
2023-11-27 01:39:24,423 - mmseg - INFO - Iter [53700/160000]	lr: 3.986e-05, eta: 23:32:57, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3007, decode.acc_seg: 87.4649, aux.loss_ce: 0.1379, aux.acc_seg: 86.2345, loss: 0.4386
2023-11-27 01:40:04,814 - mmseg - INFO - Iter [53750/160000]	lr: 3.984e-05, eta: 23:32:18, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2921, decode.acc_seg: 88.3263, aux.loss_ce: 0.1368, aux.acc_seg: 86.9065, loss: 0.4289
2023-11-27 01:40:44,694 - mmseg - INFO - Iter [53800/160000]	lr: 3.983e-05, eta: 23:31:38, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2906, decode.acc_seg: 88.3709, aux.loss_ce: 0.1315, aux.acc_seg: 87.2323, loss: 0.4221
2023-11-27 01:41:24,490 - mmseg - INFO - Iter [53850/160000]	lr: 3.981e-05, eta: 23:30:58, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2707, decode.acc_seg: 88.6399, aux.loss_ce: 0.1249, aux.acc_seg: 87.3460, loss: 0.3956
2023-11-27 01:42:03,731 - mmseg - INFO - Iter [53900/160000]	lr: 3.979e-05, eta: 23:30:17, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2991, decode.acc_seg: 88.2583, aux.loss_ce: 0.1365, aux.acc_seg: 87.0157, loss: 0.4356
2023-11-27 01:42:42,137 - mmseg - INFO - Iter [53950/160000]	lr: 3.977e-05, eta: 23:29:34, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3068, decode.acc_seg: 87.7836, aux.loss_ce: 0.1391, aux.acc_seg: 86.5051, loss: 0.4459
2023-11-27 01:43:22,154 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 01:43:22,154 - mmseg - INFO - Iter [54000/160000]	lr: 3.975e-05, eta: 23:28:55, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3003, decode.acc_seg: 87.8098, aux.loss_ce: 0.1405, aux.acc_seg: 86.4241, loss: 0.4408
2023-11-27 01:44:00,477 - mmseg - INFO - Iter [54050/160000]	lr: 3.973e-05, eta: 23:28:12, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2638, decode.acc_seg: 89.3199, aux.loss_ce: 0.1216, aux.acc_seg: 88.2481, loss: 0.3854
2023-11-27 01:44:39,107 - mmseg - INFO - Iter [54100/160000]	lr: 3.971e-05, eta: 23:27:29, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3022, decode.acc_seg: 87.9052, aux.loss_ce: 0.1371, aux.acc_seg: 86.8002, loss: 0.4393
2023-11-27 01:45:16,992 - mmseg - INFO - Iter [54150/160000]	lr: 3.969e-05, eta: 23:26:46, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2834, decode.acc_seg: 88.3285, aux.loss_ce: 0.1302, aux.acc_seg: 86.9719, loss: 0.4137
2023-11-27 01:45:57,034 - mmseg - INFO - Iter [54200/160000]	lr: 3.968e-05, eta: 23:26:06, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2968, decode.acc_seg: 87.9858, aux.loss_ce: 0.1373, aux.acc_seg: 86.4151, loss: 0.4341
2023-11-27 01:46:37,064 - mmseg - INFO - Iter [54250/160000]	lr: 3.966e-05, eta: 23:25:27, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3073, decode.acc_seg: 87.4562, aux.loss_ce: 0.1414, aux.acc_seg: 85.9636, loss: 0.4487
2023-11-27 01:47:15,585 - mmseg - INFO - Iter [54300/160000]	lr: 3.964e-05, eta: 23:24:44, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3056, decode.acc_seg: 88.0852, aux.loss_ce: 0.1393, aux.acc_seg: 86.9959, loss: 0.4449
2023-11-27 01:47:54,606 - mmseg - INFO - Iter [54350/160000]	lr: 3.962e-05, eta: 23:24:03, time: 0.780, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2907, decode.acc_seg: 88.1196, aux.loss_ce: 0.1334, aux.acc_seg: 86.9097, loss: 0.4241
2023-11-27 01:48:31,663 - mmseg - INFO - Iter [54400/160000]	lr: 3.960e-05, eta: 23:23:17, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2850, decode.acc_seg: 88.1490, aux.loss_ce: 0.1319, aux.acc_seg: 86.7852, loss: 0.4169
2023-11-27 01:49:11,597 - mmseg - INFO - Iter [54450/160000]	lr: 3.958e-05, eta: 23:22:38, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2850, decode.acc_seg: 88.1956, aux.loss_ce: 0.1333, aux.acc_seg: 86.7909, loss: 0.4183
2023-11-27 01:49:49,104 - mmseg - INFO - Iter [54500/160000]	lr: 3.956e-05, eta: 23:21:53, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2922, decode.acc_seg: 88.3728, aux.loss_ce: 0.1332, aux.acc_seg: 87.1306, loss: 0.4253
2023-11-27 01:50:29,289 - mmseg - INFO - Iter [54550/160000]	lr: 3.954e-05, eta: 23:21:14, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2924, decode.acc_seg: 88.1160, aux.loss_ce: 0.1359, aux.acc_seg: 86.8223, loss: 0.4283
2023-11-27 01:51:10,549 - mmseg - INFO - Iter [54600/160000]	lr: 3.953e-05, eta: 23:20:37, time: 0.825, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2984, decode.acc_seg: 88.0490, aux.loss_ce: 0.1372, aux.acc_seg: 86.5657, loss: 0.4357
2023-11-27 01:51:49,989 - mmseg - INFO - Iter [54650/160000]	lr: 3.951e-05, eta: 23:19:56, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3060, decode.acc_seg: 87.7694, aux.loss_ce: 0.1373, aux.acc_seg: 86.5366, loss: 0.4433
2023-11-27 01:52:26,628 - mmseg - INFO - Iter [54700/160000]	lr: 3.949e-05, eta: 23:19:10, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3072, decode.acc_seg: 87.2422, aux.loss_ce: 0.1392, aux.acc_seg: 86.0119, loss: 0.4464
2023-11-27 01:53:04,453 - mmseg - INFO - Iter [54750/160000]	lr: 3.947e-05, eta: 23:18:26, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2948, decode.acc_seg: 88.2883, aux.loss_ce: 0.1351, aux.acc_seg: 86.7420, loss: 0.4299
2023-11-27 01:53:44,092 - mmseg - INFO - Iter [54800/160000]	lr: 3.945e-05, eta: 23:17:46, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2938, decode.acc_seg: 88.2076, aux.loss_ce: 0.1333, aux.acc_seg: 86.9525, loss: 0.4271
2023-11-27 01:54:23,612 - mmseg - INFO - Iter [54850/160000]	lr: 3.943e-05, eta: 23:17:05, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3026, decode.acc_seg: 87.9522, aux.loss_ce: 0.1396, aux.acc_seg: 86.5831, loss: 0.4422
2023-11-27 01:55:02,074 - mmseg - INFO - Iter [54900/160000]	lr: 3.941e-05, eta: 23:16:23, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2896, decode.acc_seg: 88.0911, aux.loss_ce: 0.1313, aux.acc_seg: 87.1195, loss: 0.4209
2023-11-27 01:55:39,577 - mmseg - INFO - Iter [54950/160000]	lr: 3.939e-05, eta: 23:15:38, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2812, decode.acc_seg: 88.4167, aux.loss_ce: 0.1280, aux.acc_seg: 87.3034, loss: 0.4092
2023-11-27 01:56:16,343 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 01:56:16,343 - mmseg - INFO - Iter [55000/160000]	lr: 3.938e-05, eta: 23:14:53, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2850, decode.acc_seg: 88.5547, aux.loss_ce: 0.1330, aux.acc_seg: 87.0175, loss: 0.4180
2023-11-27 01:56:55,946 - mmseg - INFO - Iter [55050/160000]	lr: 3.936e-05, eta: 23:14:12, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2795, decode.acc_seg: 88.7561, aux.loss_ce: 0.1300, aux.acc_seg: 87.3521, loss: 0.4095
2023-11-27 01:57:36,973 - mmseg - INFO - Iter [55100/160000]	lr: 3.934e-05, eta: 23:13:35, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2928, decode.acc_seg: 88.3104, aux.loss_ce: 0.1327, aux.acc_seg: 87.2561, loss: 0.4255
2023-11-27 01:58:16,339 - mmseg - INFO - Iter [55150/160000]	lr: 3.932e-05, eta: 23:12:54, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3133, decode.acc_seg: 87.3117, aux.loss_ce: 0.1420, aux.acc_seg: 86.1476, loss: 0.4553
2023-11-27 01:58:56,170 - mmseg - INFO - Iter [55200/160000]	lr: 3.930e-05, eta: 23:12:14, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2898, decode.acc_seg: 88.3133, aux.loss_ce: 0.1334, aux.acc_seg: 86.8037, loss: 0.4232
2023-11-27 01:59:36,570 - mmseg - INFO - Iter [55250/160000]	lr: 3.928e-05, eta: 23:11:35, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2963, decode.acc_seg: 88.2672, aux.loss_ce: 0.1365, aux.acc_seg: 86.8917, loss: 0.4328
2023-11-27 02:00:13,831 - mmseg - INFO - Iter [55300/160000]	lr: 3.926e-05, eta: 23:10:50, time: 0.746, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2629, decode.acc_seg: 89.0820, aux.loss_ce: 0.1202, aux.acc_seg: 87.9095, loss: 0.3831
2023-11-27 02:00:53,474 - mmseg - INFO - Iter [55350/160000]	lr: 3.924e-05, eta: 23:10:10, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2938, decode.acc_seg: 88.0713, aux.loss_ce: 0.1349, aux.acc_seg: 86.7397, loss: 0.4287
2023-11-27 02:01:31,199 - mmseg - INFO - Iter [55400/160000]	lr: 3.923e-05, eta: 23:09:26, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3009, decode.acc_seg: 88.0156, aux.loss_ce: 0.1365, aux.acc_seg: 86.8323, loss: 0.4374
2023-11-27 02:02:11,229 - mmseg - INFO - Iter [55450/160000]	lr: 3.921e-05, eta: 23:08:47, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3021, decode.acc_seg: 88.0720, aux.loss_ce: 0.1353, aux.acc_seg: 87.0019, loss: 0.4373
2023-11-27 02:02:50,642 - mmseg - INFO - Iter [55500/160000]	lr: 3.919e-05, eta: 23:08:06, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2942, decode.acc_seg: 88.0075, aux.loss_ce: 0.1358, aux.acc_seg: 86.5354, loss: 0.4300
2023-11-27 02:03:29,021 - mmseg - INFO - Iter [55550/160000]	lr: 3.917e-05, eta: 23:07:24, time: 0.769, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2941, decode.acc_seg: 88.1357, aux.loss_ce: 0.1340, aux.acc_seg: 87.0520, loss: 0.4281
2023-11-27 02:04:08,210 - mmseg - INFO - Iter [55600/160000]	lr: 3.915e-05, eta: 23:06:42, time: 0.783, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2819, decode.acc_seg: 88.7809, aux.loss_ce: 0.1275, aux.acc_seg: 87.8371, loss: 0.4094
2023-11-27 02:04:46,671 - mmseg - INFO - Iter [55650/160000]	lr: 3.913e-05, eta: 23:06:00, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2839, decode.acc_seg: 88.7553, aux.loss_ce: 0.1293, aux.acc_seg: 87.6051, loss: 0.4131
2023-11-27 02:05:23,984 - mmseg - INFO - Iter [55700/160000]	lr: 3.911e-05, eta: 23:05:15, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2777, decode.acc_seg: 88.6944, aux.loss_ce: 0.1279, aux.acc_seg: 87.5983, loss: 0.4056
2023-11-27 02:06:00,786 - mmseg - INFO - Iter [55750/160000]	lr: 3.909e-05, eta: 23:04:30, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2794, decode.acc_seg: 88.4988, aux.loss_ce: 0.1296, aux.acc_seg: 87.3004, loss: 0.4090
2023-11-27 02:06:38,711 - mmseg - INFO - Iter [55800/160000]	lr: 3.908e-05, eta: 23:03:46, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2817, decode.acc_seg: 88.7761, aux.loss_ce: 0.1298, aux.acc_seg: 87.2492, loss: 0.4115
2023-11-27 02:07:18,977 - mmseg - INFO - Iter [55850/160000]	lr: 3.906e-05, eta: 23:03:07, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2792, decode.acc_seg: 88.6704, aux.loss_ce: 0.1303, aux.acc_seg: 87.3858, loss: 0.4096
2023-11-27 02:07:59,350 - mmseg - INFO - Iter [55900/160000]	lr: 3.904e-05, eta: 23:02:28, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2789, decode.acc_seg: 88.8762, aux.loss_ce: 0.1256, aux.acc_seg: 87.6338, loss: 0.4046
2023-11-27 02:08:39,664 - mmseg - INFO - Iter [55950/160000]	lr: 3.902e-05, eta: 23:01:49, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2757, decode.acc_seg: 88.4906, aux.loss_ce: 0.1286, aux.acc_seg: 87.2028, loss: 0.4043
2023-11-27 02:09:19,488 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 02:09:19,489 - mmseg - INFO - Iter [56000/160000]	lr: 3.900e-05, eta: 23:01:10, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2982, decode.acc_seg: 87.8711, aux.loss_ce: 0.1337, aux.acc_seg: 86.6323, loss: 0.4319
2023-11-27 02:09:58,734 - mmseg - INFO - Iter [56050/160000]	lr: 3.898e-05, eta: 23:00:29, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3124, decode.acc_seg: 87.4865, aux.loss_ce: 0.1418, aux.acc_seg: 86.2167, loss: 0.4542
2023-11-27 02:10:36,642 - mmseg - INFO - Iter [56100/160000]	lr: 3.896e-05, eta: 22:59:45, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2629, decode.acc_seg: 89.4688, aux.loss_ce: 0.1211, aux.acc_seg: 88.1913, loss: 0.3840
2023-11-27 02:11:14,465 - mmseg - INFO - Iter [56150/160000]	lr: 3.894e-05, eta: 22:59:02, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2745, decode.acc_seg: 88.9075, aux.loss_ce: 0.1253, aux.acc_seg: 87.8375, loss: 0.3997
2023-11-27 02:11:52,429 - mmseg - INFO - Iter [56200/160000]	lr: 3.893e-05, eta: 22:58:18, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2994, decode.acc_seg: 87.9882, aux.loss_ce: 0.1401, aux.acc_seg: 86.3924, loss: 0.4395
2023-11-27 02:12:29,724 - mmseg - INFO - Iter [56250/160000]	lr: 3.891e-05, eta: 22:57:34, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3017, decode.acc_seg: 87.7296, aux.loss_ce: 0.1390, aux.acc_seg: 86.3624, loss: 0.4406
2023-11-27 02:13:07,312 - mmseg - INFO - Iter [56300/160000]	lr: 3.889e-05, eta: 22:56:50, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2699, decode.acc_seg: 88.7996, aux.loss_ce: 0.1246, aux.acc_seg: 87.4175, loss: 0.3946
2023-11-27 02:13:47,897 - mmseg - INFO - Iter [56350/160000]	lr: 3.887e-05, eta: 22:56:11, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2883, decode.acc_seg: 88.5072, aux.loss_ce: 0.1321, aux.acc_seg: 87.2093, loss: 0.4204
2023-11-27 02:14:27,740 - mmseg - INFO - Iter [56400/160000]	lr: 3.885e-05, eta: 22:55:32, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2912, decode.acc_seg: 88.2188, aux.loss_ce: 0.1331, aux.acc_seg: 86.8924, loss: 0.4242
2023-11-27 02:15:05,615 - mmseg - INFO - Iter [56450/160000]	lr: 3.883e-05, eta: 22:54:48, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2692, decode.acc_seg: 88.9657, aux.loss_ce: 0.1245, aux.acc_seg: 87.6011, loss: 0.3937
2023-11-27 02:15:44,746 - mmseg - INFO - Iter [56500/160000]	lr: 3.881e-05, eta: 22:54:07, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2804, decode.acc_seg: 88.4145, aux.loss_ce: 0.1296, aux.acc_seg: 87.3800, loss: 0.4100
2023-11-27 02:16:24,142 - mmseg - INFO - Iter [56550/160000]	lr: 3.879e-05, eta: 22:53:27, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2725, decode.acc_seg: 88.6530, aux.loss_ce: 0.1246, aux.acc_seg: 87.7010, loss: 0.3970
2023-11-27 02:17:02,283 - mmseg - INFO - Iter [56600/160000]	lr: 3.878e-05, eta: 22:52:44, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3094, decode.acc_seg: 87.7172, aux.loss_ce: 0.1407, aux.acc_seg: 86.2142, loss: 0.4501
2023-11-27 02:17:42,259 - mmseg - INFO - Iter [56650/160000]	lr: 3.876e-05, eta: 22:52:04, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2974, decode.acc_seg: 88.0325, aux.loss_ce: 0.1359, aux.acc_seg: 86.9028, loss: 0.4333
2023-11-27 02:18:22,838 - mmseg - INFO - Iter [56700/160000]	lr: 3.874e-05, eta: 22:51:26, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3010, decode.acc_seg: 88.2736, aux.loss_ce: 0.1364, aux.acc_seg: 87.1840, loss: 0.4373
2023-11-27 02:19:03,113 - mmseg - INFO - Iter [56750/160000]	lr: 3.872e-05, eta: 22:50:47, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2949, decode.acc_seg: 88.0042, aux.loss_ce: 0.1353, aux.acc_seg: 86.5573, loss: 0.4302
2023-11-27 02:19:43,476 - mmseg - INFO - Iter [56800/160000]	lr: 3.870e-05, eta: 22:50:08, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2927, decode.acc_seg: 88.0652, aux.loss_ce: 0.1349, aux.acc_seg: 86.8365, loss: 0.4276
2023-11-27 02:20:25,374 - mmseg - INFO - Iter [56850/160000]	lr: 3.868e-05, eta: 22:49:32, time: 0.838, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2842, decode.acc_seg: 88.3650, aux.loss_ce: 0.1339, aux.acc_seg: 86.7375, loss: 0.4181
2023-11-27 02:21:05,475 - mmseg - INFO - Iter [56900/160000]	lr: 3.866e-05, eta: 22:48:52, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2827, decode.acc_seg: 88.3546, aux.loss_ce: 0.1308, aux.acc_seg: 87.0184, loss: 0.4135
2023-11-27 02:21:46,003 - mmseg - INFO - Iter [56950/160000]	lr: 3.864e-05, eta: 22:48:14, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2981, decode.acc_seg: 88.0721, aux.loss_ce: 0.1348, aux.acc_seg: 86.9695, loss: 0.4329
2023-11-27 02:22:26,075 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 02:22:26,075 - mmseg - INFO - Iter [57000/160000]	lr: 3.863e-05, eta: 22:47:34, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2716, decode.acc_seg: 88.8088, aux.loss_ce: 0.1254, aux.acc_seg: 87.7347, loss: 0.3971
2023-11-27 02:23:06,045 - mmseg - INFO - Iter [57050/160000]	lr: 3.861e-05, eta: 22:46:55, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2904, decode.acc_seg: 88.2260, aux.loss_ce: 0.1322, aux.acc_seg: 87.1397, loss: 0.4226
2023-11-27 02:23:46,038 - mmseg - INFO - Iter [57100/160000]	lr: 3.859e-05, eta: 22:46:15, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2899, decode.acc_seg: 87.8716, aux.loss_ce: 0.1335, aux.acc_seg: 86.4414, loss: 0.4234
2023-11-27 02:24:26,563 - mmseg - INFO - Iter [57150/160000]	lr: 3.857e-05, eta: 22:45:37, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2633, decode.acc_seg: 88.9669, aux.loss_ce: 0.1235, aux.acc_seg: 87.4960, loss: 0.3868
2023-11-27 02:25:06,955 - mmseg - INFO - Iter [57200/160000]	lr: 3.855e-05, eta: 22:44:58, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2753, decode.acc_seg: 88.6132, aux.loss_ce: 0.1276, aux.acc_seg: 87.2999, loss: 0.4029
2023-11-27 02:25:46,771 - mmseg - INFO - Iter [57250/160000]	lr: 3.853e-05, eta: 22:44:18, time: 0.796, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2697, decode.acc_seg: 89.2268, aux.loss_ce: 0.1238, aux.acc_seg: 88.1073, loss: 0.3935
2023-11-27 02:26:26,832 - mmseg - INFO - Iter [57300/160000]	lr: 3.851e-05, eta: 22:43:38, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2737, decode.acc_seg: 88.7455, aux.loss_ce: 0.1274, aux.acc_seg: 87.6734, loss: 0.4010
2023-11-27 02:27:06,954 - mmseg - INFO - Iter [57350/160000]	lr: 3.849e-05, eta: 22:42:59, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2812, decode.acc_seg: 88.7036, aux.loss_ce: 0.1285, aux.acc_seg: 87.4883, loss: 0.4098
2023-11-27 02:27:46,688 - mmseg - INFO - Iter [57400/160000]	lr: 3.848e-05, eta: 22:42:19, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2797, decode.acc_seg: 88.6351, aux.loss_ce: 0.1296, aux.acc_seg: 87.3315, loss: 0.4093
2023-11-27 02:28:26,295 - mmseg - INFO - Iter [57450/160000]	lr: 3.846e-05, eta: 22:41:39, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2952, decode.acc_seg: 88.3998, aux.loss_ce: 0.1353, aux.acc_seg: 87.1702, loss: 0.4305
2023-11-27 02:29:07,402 - mmseg - INFO - Iter [57500/160000]	lr: 3.844e-05, eta: 22:41:01, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2737, decode.acc_seg: 89.0861, aux.loss_ce: 0.1302, aux.acc_seg: 87.3461, loss: 0.4039
2023-11-27 02:29:47,663 - mmseg - INFO - Iter [57550/160000]	lr: 3.842e-05, eta: 22:40:22, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2736, decode.acc_seg: 88.9316, aux.loss_ce: 0.1277, aux.acc_seg: 87.7990, loss: 0.4014
2023-11-27 02:30:28,058 - mmseg - INFO - Iter [57600/160000]	lr: 3.840e-05, eta: 22:39:43, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3055, decode.acc_seg: 88.1619, aux.loss_ce: 0.1375, aux.acc_seg: 87.2008, loss: 0.4429
2023-11-27 02:31:07,345 - mmseg - INFO - Iter [57650/160000]	lr: 3.838e-05, eta: 22:39:03, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2630, decode.acc_seg: 89.3254, aux.loss_ce: 0.1214, aux.acc_seg: 87.9917, loss: 0.3845
2023-11-27 02:31:46,779 - mmseg - INFO - Iter [57700/160000]	lr: 3.836e-05, eta: 22:38:22, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3029, decode.acc_seg: 87.7408, aux.loss_ce: 0.1374, aux.acc_seg: 86.4028, loss: 0.4403
2023-11-27 02:32:26,607 - mmseg - INFO - Iter [57750/160000]	lr: 3.834e-05, eta: 22:37:42, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2825, decode.acc_seg: 88.5592, aux.loss_ce: 0.1294, aux.acc_seg: 87.3853, loss: 0.4119
2023-11-27 02:33:05,792 - mmseg - INFO - Iter [57800/160000]	lr: 3.833e-05, eta: 22:37:01, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3032, decode.acc_seg: 88.1006, aux.loss_ce: 0.1374, aux.acc_seg: 86.9986, loss: 0.4407
2023-11-27 02:33:42,662 - mmseg - INFO - Iter [57850/160000]	lr: 3.831e-05, eta: 22:36:16, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3107, decode.acc_seg: 87.7237, aux.loss_ce: 0.1420, aux.acc_seg: 86.6157, loss: 0.4528
2023-11-27 02:34:23,238 - mmseg - INFO - Iter [57900/160000]	lr: 3.829e-05, eta: 22:35:38, time: 0.811, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2997, decode.acc_seg: 88.2804, aux.loss_ce: 0.1368, aux.acc_seg: 87.0101, loss: 0.4365
2023-11-27 02:35:03,823 - mmseg - INFO - Iter [57950/160000]	lr: 3.827e-05, eta: 22:34:59, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3022, decode.acc_seg: 87.7153, aux.loss_ce: 0.1374, aux.acc_seg: 86.5055, loss: 0.4396
2023-11-27 02:35:44,443 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 02:35:44,444 - mmseg - INFO - Iter [58000/160000]	lr: 3.825e-05, eta: 22:34:21, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2904, decode.acc_seg: 88.2479, aux.loss_ce: 0.1342, aux.acc_seg: 86.9960, loss: 0.4246
2023-11-27 02:36:21,303 - mmseg - INFO - Iter [58050/160000]	lr: 3.823e-05, eta: 22:33:36, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2764, decode.acc_seg: 88.8319, aux.loss_ce: 0.1281, aux.acc_seg: 87.2794, loss: 0.4045
2023-11-27 02:37:00,085 - mmseg - INFO - Iter [58100/160000]	lr: 3.821e-05, eta: 22:32:54, time: 0.776, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2828, decode.acc_seg: 88.2997, aux.loss_ce: 0.1306, aux.acc_seg: 87.1566, loss: 0.4134
2023-11-27 02:37:36,844 - mmseg - INFO - Iter [58150/160000]	lr: 3.819e-05, eta: 22:32:09, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2666, decode.acc_seg: 89.0254, aux.loss_ce: 0.1213, aux.acc_seg: 88.0113, loss: 0.3879
2023-11-27 02:38:15,514 - mmseg - INFO - Iter [58200/160000]	lr: 3.818e-05, eta: 22:31:27, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2727, decode.acc_seg: 88.9586, aux.loss_ce: 0.1284, aux.acc_seg: 87.3530, loss: 0.4011
2023-11-27 02:38:54,352 - mmseg - INFO - Iter [58250/160000]	lr: 3.816e-05, eta: 22:30:45, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2902, decode.acc_seg: 88.4424, aux.loss_ce: 0.1320, aux.acc_seg: 87.2070, loss: 0.4222
2023-11-27 02:39:34,470 - mmseg - INFO - Iter [58300/160000]	lr: 3.814e-05, eta: 22:30:06, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2808, decode.acc_seg: 88.2950, aux.loss_ce: 0.1291, aux.acc_seg: 87.1205, loss: 0.4098
2023-11-27 02:40:14,597 - mmseg - INFO - Iter [58350/160000]	lr: 3.812e-05, eta: 22:29:27, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2593, decode.acc_seg: 89.4505, aux.loss_ce: 0.1200, aux.acc_seg: 88.1862, loss: 0.3794
2023-11-27 02:40:54,488 - mmseg - INFO - Iter [58400/160000]	lr: 3.810e-05, eta: 22:28:47, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2868, decode.acc_seg: 88.4849, aux.loss_ce: 0.1335, aux.acc_seg: 86.9840, loss: 0.4203
2023-11-27 02:41:34,411 - mmseg - INFO - Iter [58450/160000]	lr: 3.808e-05, eta: 22:28:07, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2732, decode.acc_seg: 88.9555, aux.loss_ce: 0.1220, aux.acc_seg: 88.0298, loss: 0.3952
2023-11-27 02:42:14,796 - mmseg - INFO - Iter [58500/160000]	lr: 3.806e-05, eta: 22:27:28, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2822, decode.acc_seg: 88.6497, aux.loss_ce: 0.1306, aux.acc_seg: 87.4191, loss: 0.4127
2023-11-27 02:42:55,335 - mmseg - INFO - Iter [58550/160000]	lr: 3.804e-05, eta: 22:26:50, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2775, decode.acc_seg: 88.6778, aux.loss_ce: 0.1300, aux.acc_seg: 87.2906, loss: 0.4075
2023-11-27 02:43:35,451 - mmseg - INFO - Iter [58600/160000]	lr: 3.803e-05, eta: 22:26:11, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2696, decode.acc_seg: 88.9640, aux.loss_ce: 0.1220, aux.acc_seg: 87.7733, loss: 0.3916
2023-11-27 02:44:12,386 - mmseg - INFO - Iter [58650/160000]	lr: 3.801e-05, eta: 22:25:26, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2846, decode.acc_seg: 88.7435, aux.loss_ce: 0.1303, aux.acc_seg: 87.3384, loss: 0.4149
2023-11-27 02:44:51,573 - mmseg - INFO - Iter [58700/160000]	lr: 3.799e-05, eta: 22:24:45, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2876, decode.acc_seg: 88.4462, aux.loss_ce: 0.1309, aux.acc_seg: 86.9990, loss: 0.4185
2023-11-27 02:45:32,093 - mmseg - INFO - Iter [58750/160000]	lr: 3.797e-05, eta: 22:24:06, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2793, decode.acc_seg: 88.4454, aux.loss_ce: 0.1284, aux.acc_seg: 87.0165, loss: 0.4077
2023-11-27 02:46:12,334 - mmseg - INFO - Iter [58800/160000]	lr: 3.795e-05, eta: 22:23:27, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2922, decode.acc_seg: 87.9863, aux.loss_ce: 0.1367, aux.acc_seg: 86.3241, loss: 0.4289
2023-11-27 02:46:51,052 - mmseg - INFO - Iter [58850/160000]	lr: 3.793e-05, eta: 22:22:45, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2868, decode.acc_seg: 88.3920, aux.loss_ce: 0.1322, aux.acc_seg: 87.1741, loss: 0.4190
2023-11-27 02:47:30,460 - mmseg - INFO - Iter [58900/160000]	lr: 3.791e-05, eta: 22:22:05, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.3000, decode.acc_seg: 88.2886, aux.loss_ce: 0.1353, aux.acc_seg: 86.8772, loss: 0.4353
2023-11-27 02:48:10,422 - mmseg - INFO - Iter [58950/160000]	lr: 3.789e-05, eta: 22:21:25, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2567, decode.acc_seg: 89.5151, aux.loss_ce: 0.1168, aux.acc_seg: 88.4906, loss: 0.3735
2023-11-27 02:48:50,862 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 02:48:50,862 - mmseg - INFO - Iter [59000/160000]	lr: 3.788e-05, eta: 22:20:46, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2917, decode.acc_seg: 88.3156, aux.loss_ce: 0.1341, aux.acc_seg: 87.2231, loss: 0.4258
2023-11-27 02:49:30,533 - mmseg - INFO - Iter [59050/160000]	lr: 3.786e-05, eta: 22:20:06, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2903, decode.acc_seg: 88.4015, aux.loss_ce: 0.1338, aux.acc_seg: 87.0873, loss: 0.4241
2023-11-27 02:50:08,196 - mmseg - INFO - Iter [59100/160000]	lr: 3.784e-05, eta: 22:19:23, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2814, decode.acc_seg: 88.5204, aux.loss_ce: 0.1277, aux.acc_seg: 87.5750, loss: 0.4091
2023-11-27 02:50:49,322 - mmseg - INFO - Iter [59150/160000]	lr: 3.782e-05, eta: 22:18:45, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2824, decode.acc_seg: 88.6237, aux.loss_ce: 0.1289, aux.acc_seg: 87.2295, loss: 0.4113
2023-11-27 02:51:29,310 - mmseg - INFO - Iter [59200/160000]	lr: 3.780e-05, eta: 22:18:06, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2887, decode.acc_seg: 88.2305, aux.loss_ce: 0.1332, aux.acc_seg: 87.0443, loss: 0.4219
2023-11-27 02:52:10,052 - mmseg - INFO - Iter [59250/160000]	lr: 3.778e-05, eta: 22:17:27, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.3051, decode.acc_seg: 87.7034, aux.loss_ce: 0.1385, aux.acc_seg: 86.3977, loss: 0.4436
2023-11-27 02:52:50,529 - mmseg - INFO - Iter [59300/160000]	lr: 3.776e-05, eta: 22:16:49, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2785, decode.acc_seg: 88.5230, aux.loss_ce: 0.1287, aux.acc_seg: 87.1042, loss: 0.4072
2023-11-27 02:53:29,076 - mmseg - INFO - Iter [59350/160000]	lr: 3.774e-05, eta: 22:16:07, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2782, decode.acc_seg: 88.5159, aux.loss_ce: 0.1274, aux.acc_seg: 87.2557, loss: 0.4056
2023-11-27 02:54:08,567 - mmseg - INFO - Iter [59400/160000]	lr: 3.773e-05, eta: 22:15:26, time: 0.791, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2724, decode.acc_seg: 88.9421, aux.loss_ce: 0.1249, aux.acc_seg: 87.8415, loss: 0.3973
2023-11-27 02:54:48,898 - mmseg - INFO - Iter [59450/160000]	lr: 3.771e-05, eta: 22:14:47, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2854, decode.acc_seg: 88.5172, aux.loss_ce: 0.1310, aux.acc_seg: 87.2035, loss: 0.4164
2023-11-27 02:55:28,854 - mmseg - INFO - Iter [59500/160000]	lr: 3.769e-05, eta: 22:14:08, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2890, decode.acc_seg: 88.4705, aux.loss_ce: 0.1320, aux.acc_seg: 87.3546, loss: 0.4210
2023-11-27 02:56:07,115 - mmseg - INFO - Iter [59550/160000]	lr: 3.767e-05, eta: 22:13:25, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2761, decode.acc_seg: 88.6523, aux.loss_ce: 0.1262, aux.acc_seg: 87.5352, loss: 0.4023
2023-11-27 02:56:47,476 - mmseg - INFO - Iter [59600/160000]	lr: 3.765e-05, eta: 22:12:46, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2750, decode.acc_seg: 88.8932, aux.loss_ce: 0.1283, aux.acc_seg: 87.6271, loss: 0.4033
2023-11-27 02:57:27,429 - mmseg - INFO - Iter [59650/160000]	lr: 3.763e-05, eta: 22:12:07, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2797, decode.acc_seg: 88.7394, aux.loss_ce: 0.1294, aux.acc_seg: 87.3788, loss: 0.4091
2023-11-27 02:58:05,552 - mmseg - INFO - Iter [59700/160000]	lr: 3.761e-05, eta: 22:11:24, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2843, decode.acc_seg: 88.3790, aux.loss_ce: 0.1313, aux.acc_seg: 87.0612, loss: 0.4156
2023-11-27 02:58:42,442 - mmseg - INFO - Iter [59750/160000]	lr: 3.759e-05, eta: 22:10:39, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2705, decode.acc_seg: 88.9575, aux.loss_ce: 0.1249, aux.acc_seg: 87.6767, loss: 0.3954
2023-11-27 02:59:22,546 - mmseg - INFO - Iter [59800/160000]	lr: 3.758e-05, eta: 22:10:00, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2925, decode.acc_seg: 87.9689, aux.loss_ce: 0.1330, aux.acc_seg: 86.7963, loss: 0.4255
2023-11-27 03:00:02,875 - mmseg - INFO - Iter [59850/160000]	lr: 3.756e-05, eta: 22:09:21, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2703, decode.acc_seg: 89.0000, aux.loss_ce: 0.1258, aux.acc_seg: 87.6978, loss: 0.3962
2023-11-27 03:00:42,175 - mmseg - INFO - Iter [59900/160000]	lr: 3.754e-05, eta: 22:08:40, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2654, decode.acc_seg: 89.2373, aux.loss_ce: 0.1239, aux.acc_seg: 87.9633, loss: 0.3893
2023-11-27 03:01:21,178 - mmseg - INFO - Iter [59950/160000]	lr: 3.752e-05, eta: 22:07:59, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2706, decode.acc_seg: 89.0817, aux.loss_ce: 0.1271, aux.acc_seg: 87.6828, loss: 0.3977
2023-11-27 03:01:59,459 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:01:59,459 - mmseg - INFO - Iter [60000/160000]	lr: 3.750e-05, eta: 22:07:17, time: 0.767, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2893, decode.acc_seg: 88.4224, aux.loss_ce: 0.1348, aux.acc_seg: 86.7658, loss: 0.4242
2023-11-27 03:02:36,719 - mmseg - INFO - Iter [60050/160000]	lr: 3.748e-05, eta: 22:06:33, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2671, decode.acc_seg: 88.9408, aux.loss_ce: 0.1224, aux.acc_seg: 87.9744, loss: 0.3895
2023-11-27 03:03:15,606 - mmseg - INFO - Iter [60100/160000]	lr: 3.746e-05, eta: 22:05:51, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2770, decode.acc_seg: 88.5919, aux.loss_ce: 0.1276, aux.acc_seg: 87.4299, loss: 0.4047
2023-11-27 03:03:55,092 - mmseg - INFO - Iter [60150/160000]	lr: 3.744e-05, eta: 22:05:11, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2638, decode.acc_seg: 89.4118, aux.loss_ce: 0.1222, aux.acc_seg: 88.2987, loss: 0.3860
2023-11-27 03:04:34,892 - mmseg - INFO - Iter [60200/160000]	lr: 3.743e-05, eta: 22:04:31, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2790, decode.acc_seg: 88.9420, aux.loss_ce: 0.1293, aux.acc_seg: 87.5691, loss: 0.4083
2023-11-27 03:05:14,109 - mmseg - INFO - Iter [60250/160000]	lr: 3.741e-05, eta: 22:03:50, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2864, decode.acc_seg: 88.8217, aux.loss_ce: 0.1290, aux.acc_seg: 87.5146, loss: 0.4154
2023-11-27 03:05:54,744 - mmseg - INFO - Iter [60300/160000]	lr: 3.739e-05, eta: 22:03:12, time: 0.812, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2599, decode.acc_seg: 89.2242, aux.loss_ce: 0.1219, aux.acc_seg: 87.9436, loss: 0.3818
2023-11-27 03:06:34,144 - mmseg - INFO - Iter [60350/160000]	lr: 3.737e-05, eta: 22:02:31, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2765, decode.acc_seg: 88.7875, aux.loss_ce: 0.1310, aux.acc_seg: 87.1561, loss: 0.4075
2023-11-27 03:07:14,478 - mmseg - INFO - Iter [60400/160000]	lr: 3.735e-05, eta: 22:01:52, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2921, decode.acc_seg: 88.1906, aux.loss_ce: 0.1322, aux.acc_seg: 87.0044, loss: 0.4244
2023-11-27 03:07:54,674 - mmseg - INFO - Iter [60450/160000]	lr: 3.733e-05, eta: 22:01:13, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2795, decode.acc_seg: 88.8572, aux.loss_ce: 0.1279, aux.acc_seg: 87.7279, loss: 0.4074
2023-11-27 03:08:34,565 - mmseg - INFO - Iter [60500/160000]	lr: 3.731e-05, eta: 22:00:33, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2816, decode.acc_seg: 88.7349, aux.loss_ce: 0.1302, aux.acc_seg: 87.2416, loss: 0.4118
2023-11-27 03:09:13,829 - mmseg - INFO - Iter [60550/160000]	lr: 3.729e-05, eta: 21:59:53, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2875, decode.acc_seg: 88.3530, aux.loss_ce: 0.1341, aux.acc_seg: 86.9978, loss: 0.4217
2023-11-27 03:09:52,746 - mmseg - INFO - Iter [60600/160000]	lr: 3.728e-05, eta: 21:59:11, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2831, decode.acc_seg: 88.2183, aux.loss_ce: 0.1315, aux.acc_seg: 86.8843, loss: 0.4146
2023-11-27 03:10:35,223 - mmseg - INFO - Iter [60650/160000]	lr: 3.726e-05, eta: 21:58:36, time: 0.850, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2748, decode.acc_seg: 88.7332, aux.loss_ce: 0.1258, aux.acc_seg: 87.6545, loss: 0.4006
2023-11-27 03:11:15,324 - mmseg - INFO - Iter [60700/160000]	lr: 3.724e-05, eta: 21:57:57, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2666, decode.acc_seg: 89.0050, aux.loss_ce: 0.1245, aux.acc_seg: 87.6697, loss: 0.3911
2023-11-27 03:11:55,418 - mmseg - INFO - Iter [60750/160000]	lr: 3.722e-05, eta: 21:57:17, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2623, decode.acc_seg: 89.3489, aux.loss_ce: 0.1206, aux.acc_seg: 88.0825, loss: 0.3829
2023-11-27 03:12:34,769 - mmseg - INFO - Iter [60800/160000]	lr: 3.720e-05, eta: 21:56:37, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2673, decode.acc_seg: 89.2190, aux.loss_ce: 0.1221, aux.acc_seg: 88.0502, loss: 0.3894
2023-11-27 03:13:12,276 - mmseg - INFO - Iter [60850/160000]	lr: 3.718e-05, eta: 21:55:53, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2831, decode.acc_seg: 88.6411, aux.loss_ce: 0.1301, aux.acc_seg: 87.4042, loss: 0.4133
2023-11-27 03:13:52,400 - mmseg - INFO - Iter [60900/160000]	lr: 3.716e-05, eta: 21:55:14, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2750, decode.acc_seg: 88.6200, aux.loss_ce: 0.1290, aux.acc_seg: 87.2123, loss: 0.4040
2023-11-27 03:14:32,697 - mmseg - INFO - Iter [60950/160000]	lr: 3.714e-05, eta: 21:54:35, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2721, decode.acc_seg: 88.9700, aux.loss_ce: 0.1249, aux.acc_seg: 87.6900, loss: 0.3970
2023-11-27 03:15:10,158 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:15:10,158 - mmseg - INFO - Iter [61000/160000]	lr: 3.713e-05, eta: 21:53:51, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2634, decode.acc_seg: 89.2617, aux.loss_ce: 0.1220, aux.acc_seg: 88.0686, loss: 0.3854
2023-11-27 03:15:50,121 - mmseg - INFO - Iter [61050/160000]	lr: 3.711e-05, eta: 21:53:12, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2813, decode.acc_seg: 88.5088, aux.loss_ce: 0.1304, aux.acc_seg: 87.0731, loss: 0.4117
2023-11-27 03:16:30,828 - mmseg - INFO - Iter [61100/160000]	lr: 3.709e-05, eta: 21:52:33, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2806, decode.acc_seg: 88.7479, aux.loss_ce: 0.1306, aux.acc_seg: 87.3982, loss: 0.4112
2023-11-27 03:17:09,819 - mmseg - INFO - Iter [61150/160000]	lr: 3.707e-05, eta: 21:51:52, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2633, decode.acc_seg: 89.2857, aux.loss_ce: 0.1252, aux.acc_seg: 87.8336, loss: 0.3885
2023-11-27 03:17:50,526 - mmseg - INFO - Iter [61200/160000]	lr: 3.705e-05, eta: 21:51:14, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2899, decode.acc_seg: 88.4203, aux.loss_ce: 0.1345, aux.acc_seg: 87.0259, loss: 0.4244
2023-11-27 03:18:30,931 - mmseg - INFO - Iter [61250/160000]	lr: 3.703e-05, eta: 21:50:35, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2640, decode.acc_seg: 89.1397, aux.loss_ce: 0.1249, aux.acc_seg: 87.7318, loss: 0.3889
2023-11-27 03:19:11,481 - mmseg - INFO - Iter [61300/160000]	lr: 3.701e-05, eta: 21:49:56, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2596, decode.acc_seg: 89.3113, aux.loss_ce: 0.1212, aux.acc_seg: 87.9279, loss: 0.3809
2023-11-27 03:19:48,416 - mmseg - INFO - Iter [61350/160000]	lr: 3.699e-05, eta: 21:49:12, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2830, decode.acc_seg: 88.6693, aux.loss_ce: 0.1284, aux.acc_seg: 87.4879, loss: 0.4114
2023-11-27 03:20:25,817 - mmseg - INFO - Iter [61400/160000]	lr: 3.698e-05, eta: 21:48:28, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2820, decode.acc_seg: 88.3854, aux.loss_ce: 0.1298, aux.acc_seg: 86.9844, loss: 0.4118
2023-11-27 03:21:05,749 - mmseg - INFO - Iter [61450/160000]	lr: 3.696e-05, eta: 21:47:48, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2561, decode.acc_seg: 89.4262, aux.loss_ce: 0.1175, aux.acc_seg: 88.2537, loss: 0.3735
2023-11-27 03:21:45,740 - mmseg - INFO - Iter [61500/160000]	lr: 3.694e-05, eta: 21:47:09, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2671, decode.acc_seg: 89.1397, aux.loss_ce: 0.1214, aux.acc_seg: 88.0166, loss: 0.3886
2023-11-27 03:22:25,884 - mmseg - INFO - Iter [61550/160000]	lr: 3.692e-05, eta: 21:46:30, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2963, decode.acc_seg: 88.0660, aux.loss_ce: 0.1371, aux.acc_seg: 86.7072, loss: 0.4333
2023-11-27 03:23:05,958 - mmseg - INFO - Iter [61600/160000]	lr: 3.690e-05, eta: 21:45:50, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2677, decode.acc_seg: 89.2377, aux.loss_ce: 0.1234, aux.acc_seg: 87.9282, loss: 0.3910
2023-11-27 03:23:42,882 - mmseg - INFO - Iter [61650/160000]	lr: 3.688e-05, eta: 21:45:06, time: 0.740, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2780, decode.acc_seg: 88.6943, aux.loss_ce: 0.1306, aux.acc_seg: 87.3374, loss: 0.4086
2023-11-27 03:24:21,818 - mmseg - INFO - Iter [61700/160000]	lr: 3.686e-05, eta: 21:44:25, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2696, decode.acc_seg: 89.3042, aux.loss_ce: 0.1235, aux.acc_seg: 87.9191, loss: 0.3930
2023-11-27 03:25:01,640 - mmseg - INFO - Iter [61750/160000]	lr: 3.684e-05, eta: 21:43:45, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2655, decode.acc_seg: 89.1342, aux.loss_ce: 0.1236, aux.acc_seg: 87.8736, loss: 0.3891
2023-11-27 03:25:40,445 - mmseg - INFO - Iter [61800/160000]	lr: 3.683e-05, eta: 21:43:03, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2819, decode.acc_seg: 88.6214, aux.loss_ce: 0.1279, aux.acc_seg: 87.4179, loss: 0.4098
2023-11-27 03:26:18,931 - mmseg - INFO - Iter [61850/160000]	lr: 3.681e-05, eta: 21:42:22, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2728, decode.acc_seg: 88.8117, aux.loss_ce: 0.1238, aux.acc_seg: 87.8567, loss: 0.3966
2023-11-27 03:26:57,625 - mmseg - INFO - Iter [61900/160000]	lr: 3.679e-05, eta: 21:41:40, time: 0.774, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2644, decode.acc_seg: 89.6113, aux.loss_ce: 0.1215, aux.acc_seg: 88.2325, loss: 0.3859
2023-11-27 03:27:36,940 - mmseg - INFO - Iter [61950/160000]	lr: 3.677e-05, eta: 21:40:59, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2726, decode.acc_seg: 88.6573, aux.loss_ce: 0.1261, aux.acc_seg: 87.4088, loss: 0.3987
2023-11-27 03:28:14,884 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:28:14,885 - mmseg - INFO - Iter [62000/160000]	lr: 3.675e-05, eta: 21:40:17, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2880, decode.acc_seg: 88.7734, aux.loss_ce: 0.1336, aux.acc_seg: 87.3288, loss: 0.4215
2023-11-27 03:28:53,182 - mmseg - INFO - Iter [62050/160000]	lr: 3.673e-05, eta: 21:39:34, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2669, decode.acc_seg: 89.2574, aux.loss_ce: 0.1244, aux.acc_seg: 87.9558, loss: 0.3913
2023-11-27 03:29:33,779 - mmseg - INFO - Iter [62100/160000]	lr: 3.671e-05, eta: 21:38:56, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2703, decode.acc_seg: 88.9789, aux.loss_ce: 0.1252, aux.acc_seg: 87.6316, loss: 0.3955
2023-11-27 03:30:12,647 - mmseg - INFO - Iter [62150/160000]	lr: 3.669e-05, eta: 21:38:15, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2614, decode.acc_seg: 89.1145, aux.loss_ce: 0.1219, aux.acc_seg: 87.6637, loss: 0.3833
2023-11-27 03:30:52,629 - mmseg - INFO - Iter [62200/160000]	lr: 3.668e-05, eta: 21:37:35, time: 0.800, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2584, decode.acc_seg: 89.7725, aux.loss_ce: 0.1197, aux.acc_seg: 88.5096, loss: 0.3781
2023-11-27 03:31:32,697 - mmseg - INFO - Iter [62250/160000]	lr: 3.666e-05, eta: 21:36:56, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2567, decode.acc_seg: 89.4463, aux.loss_ce: 0.1195, aux.acc_seg: 88.0559, loss: 0.3762
2023-11-27 03:32:12,517 - mmseg - INFO - Iter [62300/160000]	lr: 3.664e-05, eta: 21:36:16, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2716, decode.acc_seg: 88.8996, aux.loss_ce: 0.1282, aux.acc_seg: 87.5906, loss: 0.3998
2023-11-27 03:32:51,349 - mmseg - INFO - Iter [62350/160000]	lr: 3.662e-05, eta: 21:35:35, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2652, decode.acc_seg: 89.2483, aux.loss_ce: 0.1225, aux.acc_seg: 88.0970, loss: 0.3877
2023-11-27 03:33:29,909 - mmseg - INFO - Iter [62400/160000]	lr: 3.660e-05, eta: 21:34:53, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2736, decode.acc_seg: 88.8713, aux.loss_ce: 0.1251, aux.acc_seg: 87.5968, loss: 0.3987
2023-11-27 03:34:10,507 - mmseg - INFO - Iter [62450/160000]	lr: 3.658e-05, eta: 21:34:14, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2774, decode.acc_seg: 88.5278, aux.loss_ce: 0.1300, aux.acc_seg: 87.0910, loss: 0.4073
2023-11-27 03:34:47,828 - mmseg - INFO - Iter [62500/160000]	lr: 3.656e-05, eta: 21:33:30, time: 0.746, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2555, decode.acc_seg: 89.9326, aux.loss_ce: 0.1183, aux.acc_seg: 88.6959, loss: 0.3737
2023-11-27 03:35:25,138 - mmseg - INFO - Iter [62550/160000]	lr: 3.654e-05, eta: 21:32:47, time: 0.747, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2495, decode.acc_seg: 89.4251, aux.loss_ce: 0.1142, aux.acc_seg: 88.3293, loss: 0.3636
2023-11-27 03:36:05,923 - mmseg - INFO - Iter [62600/160000]	lr: 3.653e-05, eta: 21:32:09, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2788, decode.acc_seg: 88.7214, aux.loss_ce: 0.1260, aux.acc_seg: 87.5801, loss: 0.4048
2023-11-27 03:36:46,051 - mmseg - INFO - Iter [62650/160000]	lr: 3.651e-05, eta: 21:31:29, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.6061, aux.loss_ce: 0.1185, aux.acc_seg: 88.5098, loss: 0.3753
2023-11-27 03:37:25,199 - mmseg - INFO - Iter [62700/160000]	lr: 3.649e-05, eta: 21:30:49, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2760, decode.acc_seg: 88.9699, aux.loss_ce: 0.1258, aux.acc_seg: 87.6429, loss: 0.4018
2023-11-27 03:38:04,232 - mmseg - INFO - Iter [62750/160000]	lr: 3.647e-05, eta: 21:30:07, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2797, decode.acc_seg: 88.3663, aux.loss_ce: 0.1295, aux.acc_seg: 87.1214, loss: 0.4092
2023-11-27 03:38:44,562 - mmseg - INFO - Iter [62800/160000]	lr: 3.645e-05, eta: 21:29:29, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2637, decode.acc_seg: 89.0227, aux.loss_ce: 0.1227, aux.acc_seg: 87.7735, loss: 0.3865
2023-11-27 03:39:25,019 - mmseg - INFO - Iter [62850/160000]	lr: 3.643e-05, eta: 21:28:50, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2799, decode.acc_seg: 88.7475, aux.loss_ce: 0.1288, aux.acc_seg: 87.4368, loss: 0.4086
2023-11-27 03:40:03,717 - mmseg - INFO - Iter [62900/160000]	lr: 3.641e-05, eta: 21:28:08, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2765, decode.acc_seg: 88.6069, aux.loss_ce: 0.1268, aux.acc_seg: 87.2854, loss: 0.4033
2023-11-27 03:40:42,281 - mmseg - INFO - Iter [62950/160000]	lr: 3.639e-05, eta: 21:27:27, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2770, decode.acc_seg: 88.5339, aux.loss_ce: 0.1279, aux.acc_seg: 87.2661, loss: 0.4049
2023-11-27 03:41:24,044 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:41:24,045 - mmseg - INFO - Iter [63000/160000]	lr: 3.638e-05, eta: 21:26:50, time: 0.834, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2939, decode.acc_seg: 88.3019, aux.loss_ce: 0.1361, aux.acc_seg: 86.9323, loss: 0.4299
2023-11-27 03:42:05,566 - mmseg - INFO - Iter [63050/160000]	lr: 3.636e-05, eta: 21:26:13, time: 0.831, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2801, decode.acc_seg: 88.4356, aux.loss_ce: 0.1282, aux.acc_seg: 87.3272, loss: 0.4083
2023-11-27 03:42:44,573 - mmseg - INFO - Iter [63100/160000]	lr: 3.634e-05, eta: 21:25:32, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2540, decode.acc_seg: 89.7224, aux.loss_ce: 0.1175, aux.acc_seg: 88.5046, loss: 0.3715
2023-11-27 03:43:22,860 - mmseg - INFO - Iter [63150/160000]	lr: 3.632e-05, eta: 21:24:50, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2657, decode.acc_seg: 89.0667, aux.loss_ce: 0.1232, aux.acc_seg: 87.8530, loss: 0.3889
2023-11-27 03:44:04,181 - mmseg - INFO - Iter [63200/160000]	lr: 3.630e-05, eta: 21:24:12, time: 0.825, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2544, decode.acc_seg: 89.4557, aux.loss_ce: 0.1186, aux.acc_seg: 88.1626, loss: 0.3730
2023-11-27 03:44:43,907 - mmseg - INFO - Iter [63250/160000]	lr: 3.628e-05, eta: 21:23:32, time: 0.796, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2594, decode.acc_seg: 89.4129, aux.loss_ce: 0.1206, aux.acc_seg: 88.2005, loss: 0.3800
2023-11-27 03:45:23,687 - mmseg - INFO - Iter [63300/160000]	lr: 3.626e-05, eta: 21:22:52, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2854, decode.acc_seg: 88.8393, aux.loss_ce: 0.1314, aux.acc_seg: 87.4778, loss: 0.4168
2023-11-27 03:46:02,279 - mmseg - INFO - Iter [63350/160000]	lr: 3.624e-05, eta: 21:22:11, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2631, decode.acc_seg: 89.4648, aux.loss_ce: 0.1204, aux.acc_seg: 88.3364, loss: 0.3835
2023-11-27 03:46:43,354 - mmseg - INFO - Iter [63400/160000]	lr: 3.623e-05, eta: 21:21:33, time: 0.821, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2596, decode.acc_seg: 89.2527, aux.loss_ce: 0.1202, aux.acc_seg: 88.1094, loss: 0.3797
2023-11-27 03:47:23,996 - mmseg - INFO - Iter [63450/160000]	lr: 3.621e-05, eta: 21:20:54, time: 0.813, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2704, decode.acc_seg: 88.7942, aux.loss_ce: 0.1235, aux.acc_seg: 87.6135, loss: 0.3939
2023-11-27 03:48:04,744 - mmseg - INFO - Iter [63500/160000]	lr: 3.619e-05, eta: 21:20:16, time: 0.815, data_time: 0.013, memory: 21695, decode.loss_ce: 0.2821, decode.acc_seg: 88.6407, aux.loss_ce: 0.1294, aux.acc_seg: 87.4709, loss: 0.4115
2023-11-27 03:48:45,184 - mmseg - INFO - Iter [63550/160000]	lr: 3.617e-05, eta: 21:19:37, time: 0.810, data_time: 0.013, memory: 21695, decode.loss_ce: 0.2724, decode.acc_seg: 88.6993, aux.loss_ce: 0.1261, aux.acc_seg: 87.3068, loss: 0.3985
2023-11-27 03:49:24,654 - mmseg - INFO - Iter [63600/160000]	lr: 3.615e-05, eta: 21:18:57, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2729, decode.acc_seg: 88.7990, aux.loss_ce: 0.1253, aux.acc_seg: 87.5409, loss: 0.3983
2023-11-27 03:50:03,251 - mmseg - INFO - Iter [63650/160000]	lr: 3.613e-05, eta: 21:18:15, time: 0.773, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2651, decode.acc_seg: 89.0880, aux.loss_ce: 0.1226, aux.acc_seg: 87.9186, loss: 0.3876
2023-11-27 03:50:42,492 - mmseg - INFO - Iter [63700/160000]	lr: 3.611e-05, eta: 21:17:35, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2843, decode.acc_seg: 88.5107, aux.loss_ce: 0.1307, aux.acc_seg: 87.2412, loss: 0.4151
2023-11-27 03:51:21,250 - mmseg - INFO - Iter [63750/160000]	lr: 3.609e-05, eta: 21:16:53, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2860, decode.acc_seg: 88.6560, aux.loss_ce: 0.1305, aux.acc_seg: 87.5257, loss: 0.4165
2023-11-27 03:52:01,510 - mmseg - INFO - Iter [63800/160000]	lr: 3.608e-05, eta: 21:16:14, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2630, decode.acc_seg: 89.2704, aux.loss_ce: 0.1233, aux.acc_seg: 87.9323, loss: 0.3863
2023-11-27 03:52:40,685 - mmseg - INFO - Iter [63850/160000]	lr: 3.606e-05, eta: 21:15:33, time: 0.784, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.2819, aux.loss_ce: 0.1183, aux.acc_seg: 87.9480, loss: 0.3728
2023-11-27 03:53:18,447 - mmseg - INFO - Iter [63900/160000]	lr: 3.604e-05, eta: 21:14:50, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2769, decode.acc_seg: 89.1169, aux.loss_ce: 0.1309, aux.acc_seg: 87.7932, loss: 0.4077
2023-11-27 03:53:59,458 - mmseg - INFO - Iter [63950/160000]	lr: 3.602e-05, eta: 21:14:12, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2604, decode.acc_seg: 89.4327, aux.loss_ce: 0.1212, aux.acc_seg: 88.2189, loss: 0.3816
2023-11-27 03:54:39,994 - mmseg - INFO - Saving checkpoint at 64000 iterations
2023-11-27 03:54:45,094 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:54:45,095 - mmseg - INFO - Iter [64000/160000]	lr: 3.600e-05, eta: 21:13:41, time: 0.913, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2491, decode.acc_seg: 89.8683, aux.loss_ce: 0.1166, aux.acc_seg: 88.5918, loss: 0.3658
2023-11-27 03:56:19,342 - mmseg - INFO - per class results:
2023-11-27 03:56:19,357 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.49 | 86.78 |
|       building      |  81.2 | 90.33 |
|         sky         | 94.15 | 97.36 |
|        floor        | 81.44 | 89.76 |
|         tree        | 74.45 | 85.63 |
|       ceiling       | 83.32 | 92.47 |
|         road        | 82.83 | 88.92 |
|         bed         | 86.41 | 94.15 |
|      windowpane     | 61.48 |  80.9 |
|        grass        | 63.44 | 82.85 |
|       cabinet       | 59.55 | 69.09 |
|       sidewalk      |  66.2 | 83.65 |
|        person       | 81.58 | 93.05 |
|        earth        | 33.97 | 44.08 |
|         door        | 53.31 | 70.51 |
|        table        | 56.35 | 73.68 |
|       mountain      | 56.67 | 69.02 |
|        plant        | 52.67 | 68.13 |
|       curtain       |  75.8 | 87.17 |
|        chair        | 54.47 | 66.32 |
|         car         | 85.36 | 92.69 |
|        water        | 65.27 | 78.93 |
|       painting      | 71.89 | 89.24 |
|         sofa        | 64.07 | 78.07 |
|        shelf        | 39.19 | 55.57 |
|        house        | 42.34 | 75.04 |
|         sea         | 67.28 | 74.96 |
|        mirror       | 66.03 | 71.93 |
|         rug         | 68.53 | 76.52 |
|        field        | 33.22 | 57.28 |
|       armchair      | 39.57 | 63.78 |
|         seat        | 57.94 | 83.74 |
|        fence        | 45.47 | 58.97 |
|         desk        | 45.46 | 74.17 |
|         rock        | 44.47 | 68.04 |
|       wardrobe      | 48.02 | 72.96 |
|         lamp        | 62.37 | 76.95 |
|       bathtub       | 71.98 | 83.97 |
|       railing       | 34.94 | 49.46 |
|       cushion       | 59.25 | 72.49 |
|         base        | 43.87 | 55.96 |
|         box         | 28.53 |  38.5 |
|        column       | 44.29 | 56.94 |
|      signboard      | 37.37 | 47.05 |
|   chest of drawers  | 41.91 |  64.5 |
|       counter       | 33.07 | 44.94 |
|         sand        | 35.92 | 60.33 |
|         sink        | 70.87 |  79.4 |
|      skyscraper     | 68.23 | 84.74 |
|      fireplace      | 76.21 | 87.98 |
|     refrigerator    | 74.58 | 88.24 |
|      grandstand     | 47.33 | 66.79 |
|         path        | 24.32 | 37.03 |
|        stairs       |  25.2 | 29.72 |
|        runway       | 72.52 | 97.05 |
|         case        | 41.78 | 44.97 |
|      pool table     |  91.7 | 98.29 |
|        pillow       | 63.01 |  77.1 |
|     screen door     | 60.11 | 81.85 |
|       stairway      | 33.17 | 50.02 |
|        river        | 10.05 | 26.05 |
|        bridge       | 42.34 | 45.83 |
|       bookcase      | 33.33 | 63.81 |
|        blind        | 38.74 | 39.51 |
|     coffee table    | 55.44 |  80.1 |
|        toilet       | 79.53 | 91.54 |
|        flower       |  39.9 | 66.44 |
|         book        | 44.46 | 65.97 |
|         hill        |  7.65 | 11.62 |
|        bench        | 39.33 | 54.85 |
|      countertop     | 52.35 | 73.96 |
|        stove        |  66.7 | 83.28 |
|         palm        | 51.32 | 73.08 |
|    kitchen island   | 39.58 | 74.38 |
|       computer      | 68.15 | 82.37 |
|     swivel chair    | 47.94 | 70.57 |
|         boat        | 42.47 |  56.8 |
|         bar         | 44.69 | 66.75 |
|    arcade machine   | 86.95 | 93.91 |
|        hovel        | 22.94 | 30.81 |
|         bus         | 84.97 | 96.17 |
|        towel        | 63.57 | 77.42 |
|        light        | 54.21 | 60.86 |
|        truck        | 34.52 | 46.09 |
|        tower        |  4.04 |  7.18 |
|      chandelier     | 66.11 | 84.89 |
|        awning       | 27.55 | 31.98 |
|     streetlight     | 25.25 |  32.6 |
|        booth        | 42.83 | 44.06 |
| television receiver | 68.43 | 82.27 |
|       airplane      | 54.94 | 65.01 |
|      dirt track     | 10.05 | 18.29 |
|       apparel       | 42.19 | 53.49 |
|         pole        | 24.05 |  33.8 |
|         land        |  2.15 |  4.0  |
|      bannister      | 16.18 | 21.13 |
|      escalator      | 41.72 | 59.95 |
|       ottoman       | 45.73 | 60.78 |
|        bottle       | 35.63 | 65.44 |
|        buffet       | 51.14 | 63.69 |
|        poster       | 25.38 | 34.29 |
|        stage        | 16.13 | 28.24 |
|         van         | 42.78 |  66.6 |
|         ship        | 14.27 | 23.12 |
|       fountain      | 21.21 | 21.74 |
|    conveyer belt    | 80.92 | 86.95 |
|        canopy       |  12.5 | 19.95 |
|        washer       | 73.37 | 78.02 |
|      plaything      | 25.58 | 45.86 |
|    swimming pool    | 69.42 | 90.83 |
|        stool        | 39.72 | 53.01 |
|        barrel       | 45.67 | 65.12 |
|        basket       | 30.23 | 40.59 |
|      waterfall      |  67.1 | 86.63 |
|         tent        | 94.32 | 98.67 |
|         bag         | 13.79 | 16.83 |
|       minibike      | 70.71 | 85.78 |
|        cradle       |  77.0 | 98.05 |
|         oven        | 32.91 | 35.86 |
|         ball        | 43.43 | 66.37 |
|         food        | 56.29 | 68.84 |
|         step        | 16.76 | 25.73 |
|         tank        | 42.29 |  50.0 |
|      trade name     | 18.93 | 20.62 |
|      microwave      | 81.58 |  93.9 |
|         pot         | 45.84 | 53.17 |
|        animal       |  56.3 | 58.96 |
|       bicycle       | 55.84 | 77.72 |
|         lake        | 50.18 | 56.17 |
|      dishwasher     | 51.29 | 57.66 |
|        screen       | 65.99 | 90.69 |
|       blanket       |  5.3  |  6.57 |
|      sculpture      | 56.57 | 70.59 |
|         hood        | 61.72 | 65.13 |
|        sconce       | 40.94 | 48.12 |
|         vase        | 37.49 | 56.12 |
|    traffic light    | 29.15 | 51.16 |
|         tray        |  8.6  |  15.9 |
|        ashcan       | 36.18 | 47.39 |
|         fan         | 60.66 |  73.1 |
|         pier        | 29.68 | 61.22 |
|      crt screen     |  5.47 | 16.03 |
|        plate        | 53.54 | 69.46 |
|       monitor       |  12.0 | 15.17 |
|    bulletin board   | 53.23 | 58.12 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 64.49 | 75.57 |
|        glass        | 12.14 | 13.02 |
|        clock        | 35.37 | 41.32 |
|         flag        | 54.26 |  63.3 |
+---------------------+-------+-------+
2023-11-27 03:56:19,357 - mmseg - INFO - Summary:
2023-11-27 03:56:19,358 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 82.62 | 48.71 | 61.76 |
+-------+-------+-------+
2023-11-27 03:56:19,390 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 03:56:19,391 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8262, mIoU: 0.4871, mAcc: 0.6176, IoU.wall: 0.7749, IoU.building: 0.8120, IoU.sky: 0.9415, IoU.floor: 0.8144, IoU.tree: 0.7445, IoU.ceiling: 0.8332, IoU.road: 0.8283, IoU.bed : 0.8641, IoU.windowpane: 0.6148, IoU.grass: 0.6344, IoU.cabinet: 0.5955, IoU.sidewalk: 0.6620, IoU.person: 0.8158, IoU.earth: 0.3397, IoU.door: 0.5331, IoU.table: 0.5635, IoU.mountain: 0.5667, IoU.plant: 0.5267, IoU.curtain: 0.7580, IoU.chair: 0.5447, IoU.car: 0.8536, IoU.water: 0.6527, IoU.painting: 0.7189, IoU.sofa: 0.6407, IoU.shelf: 0.3919, IoU.house: 0.4234, IoU.sea: 0.6728, IoU.mirror: 0.6603, IoU.rug: 0.6853, IoU.field: 0.3322, IoU.armchair: 0.3957, IoU.seat: 0.5794, IoU.fence: 0.4547, IoU.desk: 0.4546, IoU.rock: 0.4447, IoU.wardrobe: 0.4802, IoU.lamp: 0.6237, IoU.bathtub: 0.7198, IoU.railing: 0.3494, IoU.cushion: 0.5925, IoU.base: 0.4387, IoU.box: 0.2853, IoU.column: 0.4429, IoU.signboard: 0.3737, IoU.chest of drawers: 0.4191, IoU.counter: 0.3307, IoU.sand: 0.3592, IoU.sink: 0.7087, IoU.skyscraper: 0.6823, IoU.fireplace: 0.7621, IoU.refrigerator: 0.7458, IoU.grandstand: 0.4733, IoU.path: 0.2432, IoU.stairs: 0.2520, IoU.runway: 0.7252, IoU.case: 0.4178, IoU.pool table: 0.9170, IoU.pillow: 0.6301, IoU.screen door: 0.6011, IoU.stairway: 0.3317, IoU.river: 0.1005, IoU.bridge: 0.4234, IoU.bookcase: 0.3333, IoU.blind: 0.3874, IoU.coffee table: 0.5544, IoU.toilet: 0.7953, IoU.flower: 0.3990, IoU.book: 0.4446, IoU.hill: 0.0765, IoU.bench: 0.3933, IoU.countertop: 0.5235, IoU.stove: 0.6670, IoU.palm: 0.5132, IoU.kitchen island: 0.3958, IoU.computer: 0.6815, IoU.swivel chair: 0.4794, IoU.boat: 0.4247, IoU.bar: 0.4469, IoU.arcade machine: 0.8695, IoU.hovel: 0.2294, IoU.bus: 0.8497, IoU.towel: 0.6357, IoU.light: 0.5421, IoU.truck: 0.3452, IoU.tower: 0.0404, IoU.chandelier: 0.6611, IoU.awning: 0.2755, IoU.streetlight: 0.2525, IoU.booth: 0.4283, IoU.television receiver: 0.6843, IoU.airplane: 0.5494, IoU.dirt track: 0.1005, IoU.apparel: 0.4219, IoU.pole: 0.2405, IoU.land: 0.0215, IoU.bannister: 0.1618, IoU.escalator: 0.4172, IoU.ottoman: 0.4573, IoU.bottle: 0.3563, IoU.buffet: 0.5114, IoU.poster: 0.2538, IoU.stage: 0.1613, IoU.van: 0.4278, IoU.ship: 0.1427, IoU.fountain: 0.2121, IoU.conveyer belt: 0.8092, IoU.canopy: 0.1250, IoU.washer: 0.7337, IoU.plaything: 0.2558, IoU.swimming pool: 0.6942, IoU.stool: 0.3972, IoU.barrel: 0.4567, IoU.basket: 0.3023, IoU.waterfall: 0.6710, IoU.tent: 0.9432, IoU.bag: 0.1379, IoU.minibike: 0.7071, IoU.cradle: 0.7700, IoU.oven: 0.3291, IoU.ball: 0.4343, IoU.food: 0.5629, IoU.step: 0.1676, IoU.tank: 0.4229, IoU.trade name: 0.1893, IoU.microwave: 0.8158, IoU.pot: 0.4584, IoU.animal: 0.5630, IoU.bicycle: 0.5584, IoU.lake: 0.5018, IoU.dishwasher: 0.5129, IoU.screen: 0.6599, IoU.blanket: 0.0530, IoU.sculpture: 0.5657, IoU.hood: 0.6172, IoU.sconce: 0.4094, IoU.vase: 0.3749, IoU.traffic light: 0.2915, IoU.tray: 0.0860, IoU.ashcan: 0.3618, IoU.fan: 0.6066, IoU.pier: 0.2968, IoU.crt screen: 0.0547, IoU.plate: 0.5354, IoU.monitor: 0.1200, IoU.bulletin board: 0.5323, IoU.shower: 0.0000, IoU.radiator: 0.6449, IoU.glass: 0.1214, IoU.clock: 0.3537, IoU.flag: 0.5426, Acc.wall: 0.8678, Acc.building: 0.9033, Acc.sky: 0.9736, Acc.floor: 0.8976, Acc.tree: 0.8563, Acc.ceiling: 0.9247, Acc.road: 0.8892, Acc.bed : 0.9415, Acc.windowpane: 0.8090, Acc.grass: 0.8285, Acc.cabinet: 0.6909, Acc.sidewalk: 0.8365, Acc.person: 0.9305, Acc.earth: 0.4408, Acc.door: 0.7051, Acc.table: 0.7368, Acc.mountain: 0.6902, Acc.plant: 0.6813, Acc.curtain: 0.8717, Acc.chair: 0.6632, Acc.car: 0.9269, Acc.water: 0.7893, Acc.painting: 0.8924, Acc.sofa: 0.7807, Acc.shelf: 0.5557, Acc.house: 0.7504, Acc.sea: 0.7496, Acc.mirror: 0.7193, Acc.rug: 0.7652, Acc.field: 0.5728, Acc.armchair: 0.6378, Acc.seat: 0.8374, Acc.fence: 0.5897, Acc.desk: 0.7417, Acc.rock: 0.6804, Acc.wardrobe: 0.7296, Acc.lamp: 0.7695, Acc.bathtub: 0.8397, Acc.railing: 0.4946, Acc.cushion: 0.7249, Acc.base: 0.5596, Acc.box: 0.3850, Acc.column: 0.5694, Acc.signboard: 0.4705, Acc.chest of drawers: 0.6450, Acc.counter: 0.4494, Acc.sand: 0.6033, Acc.sink: 0.7940, Acc.skyscraper: 0.8474, Acc.fireplace: 0.8798, Acc.refrigerator: 0.8824, Acc.grandstand: 0.6679, Acc.path: 0.3703, Acc.stairs: 0.2972, Acc.runway: 0.9705, Acc.case: 0.4497, Acc.pool table: 0.9829, Acc.pillow: 0.7710, Acc.screen door: 0.8185, Acc.stairway: 0.5002, Acc.river: 0.2605, Acc.bridge: 0.4583, Acc.bookcase: 0.6381, Acc.blind: 0.3951, Acc.coffee table: 0.8010, Acc.toilet: 0.9154, Acc.flower: 0.6644, Acc.book: 0.6597, Acc.hill: 0.1162, Acc.bench: 0.5485, Acc.countertop: 0.7396, Acc.stove: 0.8328, Acc.palm: 0.7308, Acc.kitchen island: 0.7438, Acc.computer: 0.8237, Acc.swivel chair: 0.7057, Acc.boat: 0.5680, Acc.bar: 0.6675, Acc.arcade machine: 0.9391, Acc.hovel: 0.3081, Acc.bus: 0.9617, Acc.towel: 0.7742, Acc.light: 0.6086, Acc.truck: 0.4609, Acc.tower: 0.0718, Acc.chandelier: 0.8489, Acc.awning: 0.3198, Acc.streetlight: 0.3260, Acc.booth: 0.4406, Acc.television receiver: 0.8227, Acc.airplane: 0.6501, Acc.dirt track: 0.1829, Acc.apparel: 0.5349, Acc.pole: 0.3380, Acc.land: 0.0400, Acc.bannister: 0.2113, Acc.escalator: 0.5995, Acc.ottoman: 0.6078, Acc.bottle: 0.6544, Acc.buffet: 0.6369, Acc.poster: 0.3429, Acc.stage: 0.2824, Acc.van: 0.6660, Acc.ship: 0.2312, Acc.fountain: 0.2174, Acc.conveyer belt: 0.8695, Acc.canopy: 0.1995, Acc.washer: 0.7802, Acc.plaything: 0.4586, Acc.swimming pool: 0.9083, Acc.stool: 0.5301, Acc.barrel: 0.6512, Acc.basket: 0.4059, Acc.waterfall: 0.8663, Acc.tent: 0.9867, Acc.bag: 0.1683, Acc.minibike: 0.8578, Acc.cradle: 0.9805, Acc.oven: 0.3586, Acc.ball: 0.6637, Acc.food: 0.6884, Acc.step: 0.2573, Acc.tank: 0.5000, Acc.trade name: 0.2062, Acc.microwave: 0.9390, Acc.pot: 0.5317, Acc.animal: 0.5896, Acc.bicycle: 0.7772, Acc.lake: 0.5617, Acc.dishwasher: 0.5766, Acc.screen: 0.9069, Acc.blanket: 0.0657, Acc.sculpture: 0.7059, Acc.hood: 0.6513, Acc.sconce: 0.4812, Acc.vase: 0.5612, Acc.traffic light: 0.5116, Acc.tray: 0.1590, Acc.ashcan: 0.4739, Acc.fan: 0.7310, Acc.pier: 0.6122, Acc.crt screen: 0.1603, Acc.plate: 0.6946, Acc.monitor: 0.1517, Acc.bulletin board: 0.5812, Acc.shower: 0.0000, Acc.radiator: 0.7557, Acc.glass: 0.1302, Acc.clock: 0.4132, Acc.flag: 0.6330
2023-11-27 03:56:56,793 - mmseg - INFO - Iter [64050/160000]	lr: 3.598e-05, eta: 21:15:19, time: 2.634, data_time: 1.896, memory: 21695, decode.loss_ce: 0.2683, decode.acc_seg: 88.9043, aux.loss_ce: 0.1262, aux.acc_seg: 87.4458, loss: 0.3945
2023-11-27 03:57:34,513 - mmseg - INFO - Iter [64100/160000]	lr: 3.596e-05, eta: 21:14:36, time: 0.753, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2831, decode.acc_seg: 88.7434, aux.loss_ce: 0.1311, aux.acc_seg: 87.4255, loss: 0.4142
2023-11-27 03:58:13,969 - mmseg - INFO - Iter [64150/160000]	lr: 3.594e-05, eta: 21:13:56, time: 0.789, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2667, decode.acc_seg: 89.5195, aux.loss_ce: 0.1229, aux.acc_seg: 88.3279, loss: 0.3896
2023-11-27 03:58:54,409 - mmseg - INFO - Iter [64200/160000]	lr: 3.593e-05, eta: 21:13:17, time: 0.810, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2639, decode.acc_seg: 89.1168, aux.loss_ce: 0.1230, aux.acc_seg: 87.7513, loss: 0.3868
2023-11-27 03:59:31,949 - mmseg - INFO - Iter [64250/160000]	lr: 3.591e-05, eta: 21:12:33, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2632, decode.acc_seg: 89.1615, aux.loss_ce: 0.1228, aux.acc_seg: 87.8121, loss: 0.3860
2023-11-27 04:00:10,568 - mmseg - INFO - Iter [64300/160000]	lr: 3.589e-05, eta: 21:11:52, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.5198, aux.loss_ce: 0.1185, aux.acc_seg: 88.1512, loss: 0.3729
2023-11-27 04:00:49,685 - mmseg - INFO - Iter [64350/160000]	lr: 3.587e-05, eta: 21:11:11, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2619, decode.acc_seg: 89.0336, aux.loss_ce: 0.1216, aux.acc_seg: 87.8155, loss: 0.3835
2023-11-27 04:01:29,220 - mmseg - INFO - Iter [64400/160000]	lr: 3.585e-05, eta: 21:10:30, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2685, decode.acc_seg: 88.8930, aux.loss_ce: 0.1272, aux.acc_seg: 87.4720, loss: 0.3957
2023-11-27 04:02:08,655 - mmseg - INFO - Iter [64450/160000]	lr: 3.583e-05, eta: 21:09:50, time: 0.789, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2689, decode.acc_seg: 89.1231, aux.loss_ce: 0.1234, aux.acc_seg: 87.8704, loss: 0.3923
2023-11-27 04:02:48,771 - mmseg - INFO - Iter [64500/160000]	lr: 3.581e-05, eta: 21:09:10, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2570, decode.acc_seg: 89.2155, aux.loss_ce: 0.1196, aux.acc_seg: 88.0236, loss: 0.3767
2023-11-27 04:03:25,905 - mmseg - INFO - Iter [64550/160000]	lr: 3.579e-05, eta: 21:08:26, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2535, decode.acc_seg: 89.6546, aux.loss_ce: 0.1179, aux.acc_seg: 88.3385, loss: 0.3714
2023-11-27 04:04:04,512 - mmseg - INFO - Iter [64600/160000]	lr: 3.578e-05, eta: 21:07:44, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2516, decode.acc_seg: 89.5315, aux.loss_ce: 0.1176, aux.acc_seg: 88.2920, loss: 0.3692
2023-11-27 04:04:44,375 - mmseg - INFO - Iter [64650/160000]	lr: 3.576e-05, eta: 21:07:05, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2487, decode.acc_seg: 89.6650, aux.loss_ce: 0.1166, aux.acc_seg: 88.4241, loss: 0.3653
2023-11-27 04:05:23,427 - mmseg - INFO - Iter [64700/160000]	lr: 3.574e-05, eta: 21:06:24, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2622, decode.acc_seg: 89.2130, aux.loss_ce: 0.1207, aux.acc_seg: 88.1128, loss: 0.3829
2023-11-27 04:06:03,793 - mmseg - INFO - Iter [64750/160000]	lr: 3.572e-05, eta: 21:05:44, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2731, decode.acc_seg: 88.8936, aux.loss_ce: 0.1273, aux.acc_seg: 87.4732, loss: 0.4004
2023-11-27 04:06:43,788 - mmseg - INFO - Iter [64800/160000]	lr: 3.570e-05, eta: 21:05:05, time: 0.800, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2642, decode.acc_seg: 88.8972, aux.loss_ce: 0.1239, aux.acc_seg: 87.3985, loss: 0.3881
2023-11-27 04:07:22,793 - mmseg - INFO - Iter [64850/160000]	lr: 3.568e-05, eta: 21:04:24, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2365, decode.acc_seg: 90.0490, aux.loss_ce: 0.1129, aux.acc_seg: 88.5542, loss: 0.3493
2023-11-27 04:08:00,613 - mmseg - INFO - Iter [64900/160000]	lr: 3.566e-05, eta: 21:03:41, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2630, decode.acc_seg: 89.2614, aux.loss_ce: 0.1195, aux.acc_seg: 88.0917, loss: 0.3826
2023-11-27 04:08:41,546 - mmseg - INFO - Iter [64950/160000]	lr: 3.564e-05, eta: 21:03:02, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2600, decode.acc_seg: 89.5013, aux.loss_ce: 0.1199, aux.acc_seg: 88.3369, loss: 0.3799
2023-11-27 04:09:21,367 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 04:09:21,367 - mmseg - INFO - Iter [65000/160000]	lr: 3.563e-05, eta: 21:02:23, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2553, decode.acc_seg: 89.4018, aux.loss_ce: 0.1194, aux.acc_seg: 88.0709, loss: 0.3747
2023-11-27 04:10:00,186 - mmseg - INFO - Iter [65050/160000]	lr: 3.561e-05, eta: 21:01:41, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2699, decode.acc_seg: 88.8918, aux.loss_ce: 0.1251, aux.acc_seg: 87.6965, loss: 0.3950
2023-11-27 04:10:37,645 - mmseg - INFO - Iter [65100/160000]	lr: 3.559e-05, eta: 21:00:58, time: 0.749, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2532, decode.acc_seg: 89.3147, aux.loss_ce: 0.1162, aux.acc_seg: 88.1963, loss: 0.3694
2023-11-27 04:11:17,471 - mmseg - INFO - Iter [65150/160000]	lr: 3.557e-05, eta: 21:00:18, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2604, decode.acc_seg: 89.4183, aux.loss_ce: 0.1215, aux.acc_seg: 88.0074, loss: 0.3820
2023-11-27 04:11:57,412 - mmseg - INFO - Iter [65200/160000]	lr: 3.555e-05, eta: 20:59:38, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2775, decode.acc_seg: 88.9168, aux.loss_ce: 0.1295, aux.acc_seg: 87.5620, loss: 0.4070
2023-11-27 04:12:37,656 - mmseg - INFO - Iter [65250/160000]	lr: 3.553e-05, eta: 20:58:59, time: 0.805, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2763, decode.acc_seg: 88.6327, aux.loss_ce: 0.1286, aux.acc_seg: 87.2577, loss: 0.4049
2023-11-27 04:13:18,225 - mmseg - INFO - Iter [65300/160000]	lr: 3.551e-05, eta: 20:58:20, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2530, decode.acc_seg: 89.5331, aux.loss_ce: 0.1191, aux.acc_seg: 88.1758, loss: 0.3721
2023-11-27 04:13:58,573 - mmseg - INFO - Iter [65350/160000]	lr: 3.549e-05, eta: 20:57:41, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2491, decode.acc_seg: 90.1133, aux.loss_ce: 0.1166, aux.acc_seg: 88.7579, loss: 0.3657
2023-11-27 04:14:39,092 - mmseg - INFO - Iter [65400/160000]	lr: 3.548e-05, eta: 20:57:02, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2791, decode.acc_seg: 88.6478, aux.loss_ce: 0.1300, aux.acc_seg: 87.4009, loss: 0.4091
2023-11-27 04:15:19,857 - mmseg - INFO - Iter [65450/160000]	lr: 3.546e-05, eta: 20:56:23, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2844, decode.acc_seg: 88.6233, aux.loss_ce: 0.1287, aux.acc_seg: 87.6350, loss: 0.4132
2023-11-27 04:16:00,218 - mmseg - INFO - Iter [65500/160000]	lr: 3.544e-05, eta: 20:55:44, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2569, decode.acc_seg: 89.5401, aux.loss_ce: 0.1190, aux.acc_seg: 88.2074, loss: 0.3759
2023-11-27 04:16:40,419 - mmseg - INFO - Iter [65550/160000]	lr: 3.542e-05, eta: 20:55:05, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2675, decode.acc_seg: 89.2356, aux.loss_ce: 0.1261, aux.acc_seg: 87.8104, loss: 0.3935
2023-11-27 04:17:20,914 - mmseg - INFO - Iter [65600/160000]	lr: 3.540e-05, eta: 20:54:26, time: 0.810, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2620, decode.acc_seg: 89.3358, aux.loss_ce: 0.1219, aux.acc_seg: 88.1015, loss: 0.3838
2023-11-27 04:18:01,297 - mmseg - INFO - Iter [65650/160000]	lr: 3.538e-05, eta: 20:53:47, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2665, decode.acc_seg: 88.7482, aux.loss_ce: 0.1223, aux.acc_seg: 87.4931, loss: 0.3888
2023-11-27 04:18:41,986 - mmseg - INFO - Iter [65700/160000]	lr: 3.536e-05, eta: 20:53:08, time: 0.814, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2469, decode.acc_seg: 89.9667, aux.loss_ce: 0.1153, aux.acc_seg: 88.5268, loss: 0.3622
2023-11-27 04:19:19,483 - mmseg - INFO - Iter [65750/160000]	lr: 3.534e-05, eta: 20:52:25, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2625, decode.acc_seg: 89.2031, aux.loss_ce: 0.1228, aux.acc_seg: 87.8308, loss: 0.3853
2023-11-27 04:19:59,994 - mmseg - INFO - Iter [65800/160000]	lr: 3.533e-05, eta: 20:51:46, time: 0.811, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2706, decode.acc_seg: 89.0120, aux.loss_ce: 0.1243, aux.acc_seg: 87.7284, loss: 0.3949
2023-11-27 04:20:38,806 - mmseg - INFO - Iter [65850/160000]	lr: 3.531e-05, eta: 20:51:04, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2610, decode.acc_seg: 89.2123, aux.loss_ce: 0.1208, aux.acc_seg: 88.0252, loss: 0.3818
2023-11-27 04:21:19,198 - mmseg - INFO - Iter [65900/160000]	lr: 3.529e-05, eta: 20:50:25, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2780, decode.acc_seg: 88.5913, aux.loss_ce: 0.1266, aux.acc_seg: 87.5355, loss: 0.4046
2023-11-27 04:21:59,081 - mmseg - INFO - Iter [65950/160000]	lr: 3.527e-05, eta: 20:49:45, time: 0.798, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2583, decode.acc_seg: 89.2901, aux.loss_ce: 0.1200, aux.acc_seg: 87.9281, loss: 0.3783
2023-11-27 04:22:38,940 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 04:22:38,940 - mmseg - INFO - Iter [66000/160000]	lr: 3.525e-05, eta: 20:49:06, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2598, decode.acc_seg: 89.4726, aux.loss_ce: 0.1218, aux.acc_seg: 88.0966, loss: 0.3816
2023-11-27 04:23:18,793 - mmseg - INFO - Iter [66050/160000]	lr: 3.523e-05, eta: 20:48:26, time: 0.797, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2620, decode.acc_seg: 89.2735, aux.loss_ce: 0.1211, aux.acc_seg: 88.0645, loss: 0.3831
2023-11-27 04:23:57,783 - mmseg - INFO - Iter [66100/160000]	lr: 3.521e-05, eta: 20:47:45, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2660, decode.acc_seg: 89.2263, aux.loss_ce: 0.1216, aux.acc_seg: 88.2128, loss: 0.3876
2023-11-27 04:24:39,031 - mmseg - INFO - Iter [66150/160000]	lr: 3.519e-05, eta: 20:47:07, time: 0.825, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2791, decode.acc_seg: 88.6368, aux.loss_ce: 0.1298, aux.acc_seg: 87.3870, loss: 0.4089
2023-11-27 04:25:17,717 - mmseg - INFO - Iter [66200/160000]	lr: 3.518e-05, eta: 20:46:25, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2658, decode.acc_seg: 89.5013, aux.loss_ce: 0.1212, aux.acc_seg: 88.2410, loss: 0.3871
2023-11-27 04:25:54,941 - mmseg - INFO - Iter [66250/160000]	lr: 3.516e-05, eta: 20:45:42, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2666, decode.acc_seg: 89.2664, aux.loss_ce: 0.1220, aux.acc_seg: 88.0854, loss: 0.3886
2023-11-27 04:26:33,232 - mmseg - INFO - Iter [66300/160000]	lr: 3.514e-05, eta: 20:45:00, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2587, decode.acc_seg: 89.5200, aux.loss_ce: 0.1208, aux.acc_seg: 88.1483, loss: 0.3794
2023-11-27 04:27:11,176 - mmseg - INFO - Iter [66350/160000]	lr: 3.512e-05, eta: 20:44:17, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2690, decode.acc_seg: 89.1661, aux.loss_ce: 0.1264, aux.acc_seg: 87.7680, loss: 0.3955
2023-11-27 04:27:50,525 - mmseg - INFO - Iter [66400/160000]	lr: 3.510e-05, eta: 20:43:36, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2650, decode.acc_seg: 89.3868, aux.loss_ce: 0.1218, aux.acc_seg: 88.1686, loss: 0.3869
2023-11-27 04:28:27,763 - mmseg - INFO - Iter [66450/160000]	lr: 3.508e-05, eta: 20:42:53, time: 0.746, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2646, decode.acc_seg: 88.9368, aux.loss_ce: 0.1230, aux.acc_seg: 87.7370, loss: 0.3876
2023-11-27 04:29:07,893 - mmseg - INFO - Iter [66500/160000]	lr: 3.506e-05, eta: 20:42:13, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2630, decode.acc_seg: 89.0597, aux.loss_ce: 0.1235, aux.acc_seg: 87.7404, loss: 0.3865
2023-11-27 04:29:48,093 - mmseg - INFO - Iter [66550/160000]	lr: 3.504e-05, eta: 20:41:34, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.7128, aux.loss_ce: 0.1172, aux.acc_seg: 88.5430, loss: 0.3717
2023-11-27 04:30:26,273 - mmseg - INFO - Iter [66600/160000]	lr: 3.503e-05, eta: 20:40:52, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2687, decode.acc_seg: 88.6944, aux.loss_ce: 0.1239, aux.acc_seg: 87.4317, loss: 0.3926
2023-11-27 04:31:07,032 - mmseg - INFO - Iter [66650/160000]	lr: 3.501e-05, eta: 20:40:13, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2700, decode.acc_seg: 89.0836, aux.loss_ce: 0.1252, aux.acc_seg: 87.8116, loss: 0.3952
2023-11-27 04:31:47,395 - mmseg - INFO - Iter [66700/160000]	lr: 3.499e-05, eta: 20:39:34, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2705, decode.acc_seg: 89.1402, aux.loss_ce: 0.1238, aux.acc_seg: 87.8733, loss: 0.3943
2023-11-27 04:32:27,250 - mmseg - INFO - Iter [66750/160000]	lr: 3.497e-05, eta: 20:38:54, time: 0.797, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2662, decode.acc_seg: 89.2470, aux.loss_ce: 0.1223, aux.acc_seg: 88.0720, loss: 0.3885
2023-11-27 04:33:07,496 - mmseg - INFO - Iter [66800/160000]	lr: 3.495e-05, eta: 20:38:15, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2654, decode.acc_seg: 88.9141, aux.loss_ce: 0.1240, aux.acc_seg: 87.5800, loss: 0.3894
2023-11-27 04:33:47,626 - mmseg - INFO - Iter [66850/160000]	lr: 3.493e-05, eta: 20:37:35, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2456, decode.acc_seg: 89.6936, aux.loss_ce: 0.1152, aux.acc_seg: 88.5675, loss: 0.3608
2023-11-27 04:34:27,803 - mmseg - INFO - Iter [66900/160000]	lr: 3.491e-05, eta: 20:36:56, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2731, decode.acc_seg: 88.8933, aux.loss_ce: 0.1245, aux.acc_seg: 87.6166, loss: 0.3976
2023-11-27 04:35:10,293 - mmseg - INFO - Iter [66950/160000]	lr: 3.489e-05, eta: 20:36:20, time: 0.850, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2490, decode.acc_seg: 89.6828, aux.loss_ce: 0.1143, aux.acc_seg: 88.5707, loss: 0.3633
2023-11-27 04:35:49,025 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 04:35:49,026 - mmseg - INFO - Iter [67000/160000]	lr: 3.488e-05, eta: 20:35:38, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2558, decode.acc_seg: 89.2747, aux.loss_ce: 0.1209, aux.acc_seg: 87.8687, loss: 0.3767
2023-11-27 04:36:29,794 - mmseg - INFO - Iter [67050/160000]	lr: 3.486e-05, eta: 20:35:00, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2699, decode.acc_seg: 89.2491, aux.loss_ce: 0.1249, aux.acc_seg: 87.8434, loss: 0.3948
2023-11-27 04:37:08,719 - mmseg - INFO - Iter [67100/160000]	lr: 3.484e-05, eta: 20:34:19, time: 0.779, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2579, decode.acc_seg: 89.5786, aux.loss_ce: 0.1176, aux.acc_seg: 88.3459, loss: 0.3756
2023-11-27 04:37:45,891 - mmseg - INFO - Iter [67150/160000]	lr: 3.482e-05, eta: 20:33:35, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2583, decode.acc_seg: 89.5139, aux.loss_ce: 0.1205, aux.acc_seg: 88.2339, loss: 0.3788
2023-11-27 04:38:24,976 - mmseg - INFO - Iter [67200/160000]	lr: 3.480e-05, eta: 20:32:54, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2555, decode.acc_seg: 89.3818, aux.loss_ce: 0.1194, aux.acc_seg: 87.9764, loss: 0.3749
2023-11-27 04:39:01,732 - mmseg - INFO - Iter [67250/160000]	lr: 3.478e-05, eta: 20:32:10, time: 0.735, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2549, decode.acc_seg: 89.2764, aux.loss_ce: 0.1199, aux.acc_seg: 87.7515, loss: 0.3748
2023-11-27 04:39:39,649 - mmseg - INFO - Iter [67300/160000]	lr: 3.476e-05, eta: 20:31:27, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2530, decode.acc_seg: 89.7995, aux.loss_ce: 0.1193, aux.acc_seg: 88.4489, loss: 0.3723
2023-11-27 04:40:17,083 - mmseg - INFO - Iter [67350/160000]	lr: 3.474e-05, eta: 20:30:44, time: 0.749, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2613, decode.acc_seg: 89.1901, aux.loss_ce: 0.1212, aux.acc_seg: 87.9557, loss: 0.3824
2023-11-27 04:40:54,393 - mmseg - INFO - Iter [67400/160000]	lr: 3.473e-05, eta: 20:30:01, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2537, decode.acc_seg: 89.7945, aux.loss_ce: 0.1193, aux.acc_seg: 88.3198, loss: 0.3730
2023-11-27 04:41:32,065 - mmseg - INFO - Iter [67450/160000]	lr: 3.471e-05, eta: 20:29:18, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2653, decode.acc_seg: 89.0876, aux.loss_ce: 0.1244, aux.acc_seg: 87.6746, loss: 0.3897
2023-11-27 04:42:11,523 - mmseg - INFO - Iter [67500/160000]	lr: 3.469e-05, eta: 20:28:38, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2606, decode.acc_seg: 89.2524, aux.loss_ce: 0.1187, aux.acc_seg: 88.0258, loss: 0.3793
2023-11-27 04:42:51,404 - mmseg - INFO - Iter [67550/160000]	lr: 3.467e-05, eta: 20:27:58, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2713, decode.acc_seg: 88.9139, aux.loss_ce: 0.1258, aux.acc_seg: 87.6119, loss: 0.3971
2023-11-27 04:43:30,164 - mmseg - INFO - Iter [67600/160000]	lr: 3.465e-05, eta: 20:27:16, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2479, decode.acc_seg: 89.7172, aux.loss_ce: 0.1162, aux.acc_seg: 88.3924, loss: 0.3641
2023-11-27 04:44:09,006 - mmseg - INFO - Iter [67650/160000]	lr: 3.463e-05, eta: 20:26:35, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2583, decode.acc_seg: 89.1568, aux.loss_ce: 0.1193, aux.acc_seg: 87.9022, loss: 0.3775
2023-11-27 04:44:46,548 - mmseg - INFO - Iter [67700/160000]	lr: 3.461e-05, eta: 20:25:52, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2466, decode.acc_seg: 89.6206, aux.loss_ce: 0.1161, aux.acc_seg: 88.1694, loss: 0.3628
2023-11-27 04:45:26,772 - mmseg - INFO - Iter [67750/160000]	lr: 3.459e-05, eta: 20:25:13, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2618, decode.acc_seg: 89.4326, aux.loss_ce: 0.1219, aux.acc_seg: 88.0473, loss: 0.3837
2023-11-27 04:46:07,087 - mmseg - INFO - Iter [67800/160000]	lr: 3.458e-05, eta: 20:24:34, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2469, decode.acc_seg: 89.8165, aux.loss_ce: 0.1132, aux.acc_seg: 88.6548, loss: 0.3601
2023-11-27 04:46:46,167 - mmseg - INFO - Iter [67850/160000]	lr: 3.456e-05, eta: 20:23:53, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2553, decode.acc_seg: 89.4717, aux.loss_ce: 0.1183, aux.acc_seg: 88.2672, loss: 0.3736
2023-11-27 04:47:25,086 - mmseg - INFO - Iter [67900/160000]	lr: 3.454e-05, eta: 20:23:12, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.6302, aux.loss_ce: 0.1188, aux.acc_seg: 88.3313, loss: 0.3755
2023-11-27 04:48:02,813 - mmseg - INFO - Iter [67950/160000]	lr: 3.452e-05, eta: 20:22:29, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2589, decode.acc_seg: 89.2535, aux.loss_ce: 0.1208, aux.acc_seg: 87.9342, loss: 0.3797
2023-11-27 04:48:43,305 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 04:48:43,305 - mmseg - INFO - Iter [68000/160000]	lr: 3.450e-05, eta: 20:21:50, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2583, decode.acc_seg: 89.5997, aux.loss_ce: 0.1193, aux.acc_seg: 88.4155, loss: 0.3776
2023-11-27 04:49:23,352 - mmseg - INFO - Iter [68050/160000]	lr: 3.448e-05, eta: 20:21:11, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2625, decode.acc_seg: 89.2442, aux.loss_ce: 0.1219, aux.acc_seg: 87.7792, loss: 0.3844
2023-11-27 04:50:01,682 - mmseg - INFO - Iter [68100/160000]	lr: 3.446e-05, eta: 20:20:29, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2604, decode.acc_seg: 89.5198, aux.loss_ce: 0.1223, aux.acc_seg: 88.2391, loss: 0.3827
2023-11-27 04:50:41,791 - mmseg - INFO - Iter [68150/160000]	lr: 3.444e-05, eta: 20:19:49, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2738, decode.acc_seg: 89.2193, aux.loss_ce: 0.1271, aux.acc_seg: 87.7233, loss: 0.4009
2023-11-27 04:51:18,454 - mmseg - INFO - Iter [68200/160000]	lr: 3.443e-05, eta: 20:19:05, time: 0.734, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2762, decode.acc_seg: 88.8924, aux.loss_ce: 0.1293, aux.acc_seg: 87.5824, loss: 0.4056
2023-11-27 04:51:57,491 - mmseg - INFO - Iter [68250/160000]	lr: 3.441e-05, eta: 20:18:24, time: 0.781, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2569, decode.acc_seg: 89.6819, aux.loss_ce: 0.1206, aux.acc_seg: 88.1656, loss: 0.3775
2023-11-27 04:52:36,098 - mmseg - INFO - Iter [68300/160000]	lr: 3.439e-05, eta: 20:17:43, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2504, decode.acc_seg: 89.6547, aux.loss_ce: 0.1179, aux.acc_seg: 88.2611, loss: 0.3682
2023-11-27 04:53:13,607 - mmseg - INFO - Iter [68350/160000]	lr: 3.437e-05, eta: 20:17:00, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2478, decode.acc_seg: 89.9115, aux.loss_ce: 0.1167, aux.acc_seg: 88.4819, loss: 0.3645
2023-11-27 04:53:51,922 - mmseg - INFO - Iter [68400/160000]	lr: 3.435e-05, eta: 20:16:18, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2471, decode.acc_seg: 89.6405, aux.loss_ce: 0.1134, aux.acc_seg: 88.4345, loss: 0.3606
2023-11-27 04:54:31,134 - mmseg - INFO - Iter [68450/160000]	lr: 3.433e-05, eta: 20:15:37, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.3743, aux.loss_ce: 0.1218, aux.acc_seg: 87.9492, loss: 0.3786
2023-11-27 04:55:11,663 - mmseg - INFO - Iter [68500/160000]	lr: 3.431e-05, eta: 20:14:58, time: 0.811, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2471, decode.acc_seg: 89.9893, aux.loss_ce: 0.1142, aux.acc_seg: 88.6283, loss: 0.3613
2023-11-27 04:55:51,033 - mmseg - INFO - Iter [68550/160000]	lr: 3.429e-05, eta: 20:14:18, time: 0.788, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2562, decode.acc_seg: 89.2797, aux.loss_ce: 0.1201, aux.acc_seg: 87.8744, loss: 0.3763
2023-11-27 04:56:30,621 - mmseg - INFO - Iter [68600/160000]	lr: 3.428e-05, eta: 20:13:38, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2473, decode.acc_seg: 89.7218, aux.loss_ce: 0.1159, aux.acc_seg: 88.3112, loss: 0.3632
2023-11-27 04:57:10,190 - mmseg - INFO - Iter [68650/160000]	lr: 3.426e-05, eta: 20:12:57, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2677, decode.acc_seg: 88.9718, aux.loss_ce: 0.1226, aux.acc_seg: 87.8060, loss: 0.3904
2023-11-27 04:57:47,501 - mmseg - INFO - Iter [68700/160000]	lr: 3.424e-05, eta: 20:12:14, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2669, decode.acc_seg: 89.0349, aux.loss_ce: 0.1214, aux.acc_seg: 87.9515, loss: 0.3883
2023-11-27 04:58:24,106 - mmseg - INFO - Iter [68750/160000]	lr: 3.422e-05, eta: 20:11:30, time: 0.732, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2555, decode.acc_seg: 89.5591, aux.loss_ce: 0.1188, aux.acc_seg: 88.3874, loss: 0.3743
2023-11-27 04:59:00,977 - mmseg - INFO - Iter [68800/160000]	lr: 3.420e-05, eta: 20:10:46, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2811, decode.acc_seg: 88.7609, aux.loss_ce: 0.1330, aux.acc_seg: 87.2536, loss: 0.4141
2023-11-27 04:59:41,276 - mmseg - INFO - Iter [68850/160000]	lr: 3.418e-05, eta: 20:10:07, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2627, decode.acc_seg: 89.4639, aux.loss_ce: 0.1204, aux.acc_seg: 88.0610, loss: 0.3831
2023-11-27 05:00:19,410 - mmseg - INFO - Iter [68900/160000]	lr: 3.416e-05, eta: 20:09:25, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2498, decode.acc_seg: 89.6661, aux.loss_ce: 0.1150, aux.acc_seg: 88.6793, loss: 0.3648
2023-11-27 05:00:57,232 - mmseg - INFO - Iter [68950/160000]	lr: 3.414e-05, eta: 20:08:43, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2640, decode.acc_seg: 89.2960, aux.loss_ce: 0.1236, aux.acc_seg: 87.9356, loss: 0.3876
2023-11-27 05:01:35,784 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 05:01:35,784 - mmseg - INFO - Iter [69000/160000]	lr: 3.413e-05, eta: 20:08:01, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2564, decode.acc_seg: 89.4247, aux.loss_ce: 0.1204, aux.acc_seg: 88.1621, loss: 0.3768
2023-11-27 05:02:14,501 - mmseg - INFO - Iter [69050/160000]	lr: 3.411e-05, eta: 20:07:20, time: 0.774, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2618, decode.acc_seg: 89.3729, aux.loss_ce: 0.1209, aux.acc_seg: 88.1852, loss: 0.3827
2023-11-27 05:02:55,301 - mmseg - INFO - Iter [69100/160000]	lr: 3.409e-05, eta: 20:06:41, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2497, decode.acc_seg: 89.6094, aux.loss_ce: 0.1159, aux.acc_seg: 88.3727, loss: 0.3657
2023-11-27 05:03:35,494 - mmseg - INFO - Iter [69150/160000]	lr: 3.407e-05, eta: 20:06:02, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2556, decode.acc_seg: 89.6057, aux.loss_ce: 0.1192, aux.acc_seg: 88.2968, loss: 0.3749
2023-11-27 05:04:15,179 - mmseg - INFO - Iter [69200/160000]	lr: 3.405e-05, eta: 20:05:22, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2644, decode.acc_seg: 89.3028, aux.loss_ce: 0.1242, aux.acc_seg: 87.8967, loss: 0.3885
2023-11-27 05:04:53,543 - mmseg - INFO - Iter [69250/160000]	lr: 3.403e-05, eta: 20:04:40, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2534, decode.acc_seg: 89.8088, aux.loss_ce: 0.1177, aux.acc_seg: 88.5621, loss: 0.3711
2023-11-27 05:05:32,574 - mmseg - INFO - Iter [69300/160000]	lr: 3.401e-05, eta: 20:03:59, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2770, decode.acc_seg: 88.8009, aux.loss_ce: 0.1281, aux.acc_seg: 87.4501, loss: 0.4051
2023-11-27 05:06:13,420 - mmseg - INFO - Iter [69350/160000]	lr: 3.399e-05, eta: 20:03:21, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2433, decode.acc_seg: 89.8395, aux.loss_ce: 0.1142, aux.acc_seg: 88.4909, loss: 0.3575
2023-11-27 05:06:53,754 - mmseg - INFO - Iter [69400/160000]	lr: 3.398e-05, eta: 20:02:42, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2656, decode.acc_seg: 89.3482, aux.loss_ce: 0.1225, aux.acc_seg: 88.1233, loss: 0.3882
2023-11-27 05:07:34,113 - mmseg - INFO - Iter [69450/160000]	lr: 3.396e-05, eta: 20:02:02, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2489, decode.acc_seg: 89.8034, aux.loss_ce: 0.1157, aux.acc_seg: 88.5899, loss: 0.3646
2023-11-27 05:08:15,470 - mmseg - INFO - Iter [69500/160000]	lr: 3.394e-05, eta: 20:01:25, time: 0.828, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2569, decode.acc_seg: 89.3748, aux.loss_ce: 0.1201, aux.acc_seg: 88.1218, loss: 0.3770
2023-11-27 05:08:54,922 - mmseg - INFO - Iter [69550/160000]	lr: 3.392e-05, eta: 20:00:44, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2582, decode.acc_seg: 89.5963, aux.loss_ce: 0.1203, aux.acc_seg: 88.2413, loss: 0.3785
2023-11-27 05:09:34,142 - mmseg - INFO - Iter [69600/160000]	lr: 3.390e-05, eta: 20:00:04, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2482, decode.acc_seg: 90.0861, aux.loss_ce: 0.1148, aux.acc_seg: 88.7716, loss: 0.3630
2023-11-27 05:10:12,133 - mmseg - INFO - Iter [69650/160000]	lr: 3.388e-05, eta: 19:59:22, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2574, decode.acc_seg: 89.4642, aux.loss_ce: 0.1207, aux.acc_seg: 88.2565, loss: 0.3780
2023-11-27 05:10:49,585 - mmseg - INFO - Iter [69700/160000]	lr: 3.386e-05, eta: 19:58:39, time: 0.750, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2549, decode.acc_seg: 89.6111, aux.loss_ce: 0.1175, aux.acc_seg: 88.5707, loss: 0.3723
2023-11-27 05:11:27,181 - mmseg - INFO - Iter [69750/160000]	lr: 3.384e-05, eta: 19:57:56, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2506, decode.acc_seg: 89.6355, aux.loss_ce: 0.1174, aux.acc_seg: 88.4141, loss: 0.3680
2023-11-27 05:12:07,959 - mmseg - INFO - Iter [69800/160000]	lr: 3.383e-05, eta: 19:57:17, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2558, decode.acc_seg: 89.6491, aux.loss_ce: 0.1204, aux.acc_seg: 88.2206, loss: 0.3761
2023-11-27 05:12:46,335 - mmseg - INFO - Iter [69850/160000]	lr: 3.381e-05, eta: 19:56:36, time: 0.769, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2450, decode.acc_seg: 89.8866, aux.loss_ce: 0.1140, aux.acc_seg: 88.5810, loss: 0.3590
2023-11-27 05:13:23,678 - mmseg - INFO - Iter [69900/160000]	lr: 3.379e-05, eta: 19:55:53, time: 0.747, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2671, decode.acc_seg: 89.2907, aux.loss_ce: 0.1225, aux.acc_seg: 88.0890, loss: 0.3896
2023-11-27 05:14:02,959 - mmseg - INFO - Iter [69950/160000]	lr: 3.377e-05, eta: 19:55:12, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.3974, aux.loss_ce: 0.1202, aux.acc_seg: 88.1592, loss: 0.3770
2023-11-27 05:14:41,314 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 05:14:41,314 - mmseg - INFO - Iter [70000/160000]	lr: 3.375e-05, eta: 19:54:31, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2476, decode.acc_seg: 89.6584, aux.loss_ce: 0.1145, aux.acc_seg: 88.2854, loss: 0.3622
2023-11-27 05:15:19,033 - mmseg - INFO - Iter [70050/160000]	lr: 3.373e-05, eta: 19:53:48, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2586, decode.acc_seg: 89.3171, aux.loss_ce: 0.1204, aux.acc_seg: 88.0750, loss: 0.3790
2023-11-27 05:15:58,988 - mmseg - INFO - Iter [70100/160000]	lr: 3.371e-05, eta: 19:53:08, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2421, decode.acc_seg: 89.7940, aux.loss_ce: 0.1104, aux.acc_seg: 88.8283, loss: 0.3525
2023-11-27 05:16:38,803 - mmseg - INFO - Iter [70150/160000]	lr: 3.369e-05, eta: 19:52:29, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2447, decode.acc_seg: 89.9629, aux.loss_ce: 0.1173, aux.acc_seg: 88.5103, loss: 0.3620
2023-11-27 05:17:19,138 - mmseg - INFO - Iter [70200/160000]	lr: 3.368e-05, eta: 19:51:49, time: 0.805, data_time: 0.009, memory: 21695, decode.loss_ce: 0.2616, decode.acc_seg: 89.6491, aux.loss_ce: 0.1223, aux.acc_seg: 88.2037, loss: 0.3840
2023-11-27 05:17:59,005 - mmseg - INFO - Iter [70250/160000]	lr: 3.366e-05, eta: 19:51:10, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2570, decode.acc_seg: 89.7976, aux.loss_ce: 0.1180, aux.acc_seg: 88.5328, loss: 0.3749
2023-11-27 05:18:39,094 - mmseg - INFO - Iter [70300/160000]	lr: 3.364e-05, eta: 19:50:30, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2426, decode.acc_seg: 89.9295, aux.loss_ce: 0.1136, aux.acc_seg: 88.6629, loss: 0.3562
2023-11-27 05:19:19,663 - mmseg - INFO - Iter [70350/160000]	lr: 3.362e-05, eta: 19:49:51, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2682, decode.acc_seg: 89.2177, aux.loss_ce: 0.1229, aux.acc_seg: 87.8744, loss: 0.3911
2023-11-27 05:19:58,914 - mmseg - INFO - Iter [70400/160000]	lr: 3.360e-05, eta: 19:49:11, time: 0.785, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2526, decode.acc_seg: 89.5424, aux.loss_ce: 0.1195, aux.acc_seg: 88.0906, loss: 0.3721
2023-11-27 05:20:39,409 - mmseg - INFO - Iter [70450/160000]	lr: 3.358e-05, eta: 19:48:32, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2702, decode.acc_seg: 89.1823, aux.loss_ce: 0.1242, aux.acc_seg: 87.8229, loss: 0.3944
2023-11-27 05:21:19,799 - mmseg - INFO - Iter [70500/160000]	lr: 3.356e-05, eta: 19:47:53, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2554, decode.acc_seg: 89.2432, aux.loss_ce: 0.1197, aux.acc_seg: 88.1138, loss: 0.3751
2023-11-27 05:22:00,201 - mmseg - INFO - Iter [70550/160000]	lr: 3.354e-05, eta: 19:47:14, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2541, decode.acc_seg: 89.6263, aux.loss_ce: 0.1191, aux.acc_seg: 88.2460, loss: 0.3732
2023-11-27 05:22:39,298 - mmseg - INFO - Iter [70600/160000]	lr: 3.353e-05, eta: 19:46:33, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2408, decode.acc_seg: 89.7718, aux.loss_ce: 0.1132, aux.acc_seg: 88.5333, loss: 0.3540
2023-11-27 05:23:16,155 - mmseg - INFO - Iter [70650/160000]	lr: 3.351e-05, eta: 19:45:49, time: 0.738, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2749, decode.acc_seg: 88.9139, aux.loss_ce: 0.1263, aux.acc_seg: 87.6094, loss: 0.4013
2023-11-27 05:23:54,922 - mmseg - INFO - Iter [70700/160000]	lr: 3.349e-05, eta: 19:45:08, time: 0.774, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2540, decode.acc_seg: 89.5825, aux.loss_ce: 0.1188, aux.acc_seg: 88.3683, loss: 0.3728
2023-11-27 05:24:35,298 - mmseg - INFO - Iter [70750/160000]	lr: 3.347e-05, eta: 19:44:29, time: 0.807, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2601, decode.acc_seg: 89.2884, aux.loss_ce: 0.1215, aux.acc_seg: 88.0137, loss: 0.3816
2023-11-27 05:25:15,392 - mmseg - INFO - Iter [70800/160000]	lr: 3.345e-05, eta: 19:43:50, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2492, decode.acc_seg: 89.7348, aux.loss_ce: 0.1167, aux.acc_seg: 88.3729, loss: 0.3659
2023-11-27 05:25:54,947 - mmseg - INFO - Iter [70850/160000]	lr: 3.343e-05, eta: 19:43:09, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2522, decode.acc_seg: 89.6424, aux.loss_ce: 0.1176, aux.acc_seg: 88.1863, loss: 0.3698
2023-11-27 05:26:32,316 - mmseg - INFO - Iter [70900/160000]	lr: 3.341e-05, eta: 19:42:27, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2584, decode.acc_seg: 89.4850, aux.loss_ce: 0.1182, aux.acc_seg: 88.3818, loss: 0.3766
2023-11-27 05:27:11,471 - mmseg - INFO - Iter [70950/160000]	lr: 3.339e-05, eta: 19:41:46, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2363, decode.acc_seg: 90.3161, aux.loss_ce: 0.1111, aux.acc_seg: 88.9611, loss: 0.3475
2023-11-27 05:27:51,063 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 05:27:51,064 - mmseg - INFO - Iter [71000/160000]	lr: 3.338e-05, eta: 19:41:06, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2334, decode.acc_seg: 90.1683, aux.loss_ce: 0.1107, aux.acc_seg: 88.8566, loss: 0.3441
2023-11-27 05:28:30,402 - mmseg - INFO - Iter [71050/160000]	lr: 3.336e-05, eta: 19:40:25, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2463, decode.acc_seg: 89.6181, aux.loss_ce: 0.1149, aux.acc_seg: 88.3490, loss: 0.3612
2023-11-27 05:29:08,436 - mmseg - INFO - Iter [71100/160000]	lr: 3.334e-05, eta: 19:39:43, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2508, decode.acc_seg: 89.6665, aux.loss_ce: 0.1164, aux.acc_seg: 88.3907, loss: 0.3672
2023-11-27 05:29:49,371 - mmseg - INFO - Iter [71150/160000]	lr: 3.332e-05, eta: 19:39:05, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2471, decode.acc_seg: 89.9220, aux.loss_ce: 0.1149, aux.acc_seg: 88.7249, loss: 0.3620
2023-11-27 05:30:29,899 - mmseg - INFO - Iter [71200/160000]	lr: 3.330e-05, eta: 19:38:26, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2590, decode.acc_seg: 89.7139, aux.loss_ce: 0.1212, aux.acc_seg: 88.3211, loss: 0.3802
2023-11-27 05:31:10,059 - mmseg - INFO - Iter [71250/160000]	lr: 3.328e-05, eta: 19:37:47, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2550, decode.acc_seg: 89.6302, aux.loss_ce: 0.1220, aux.acc_seg: 88.0266, loss: 0.3770
2023-11-27 05:31:50,993 - mmseg - INFO - Iter [71300/160000]	lr: 3.326e-05, eta: 19:37:08, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2329, decode.acc_seg: 90.3931, aux.loss_ce: 0.1106, aux.acc_seg: 88.9893, loss: 0.3435
2023-11-27 05:32:29,889 - mmseg - INFO - Iter [71350/160000]	lr: 3.324e-05, eta: 19:36:27, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2492, decode.acc_seg: 89.8740, aux.loss_ce: 0.1191, aux.acc_seg: 88.3394, loss: 0.3683
2023-11-27 05:33:08,616 - mmseg - INFO - Iter [71400/160000]	lr: 3.323e-05, eta: 19:35:46, time: 0.775, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2586, decode.acc_seg: 89.3896, aux.loss_ce: 0.1202, aux.acc_seg: 88.2402, loss: 0.3788
2023-11-27 05:33:47,931 - mmseg - INFO - Iter [71450/160000]	lr: 3.321e-05, eta: 19:35:06, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2385, decode.acc_seg: 89.8712, aux.loss_ce: 0.1123, aux.acc_seg: 88.6539, loss: 0.3508
2023-11-27 05:34:27,941 - mmseg - INFO - Iter [71500/160000]	lr: 3.319e-05, eta: 19:34:26, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2484, decode.acc_seg: 89.5549, aux.loss_ce: 0.1142, aux.acc_seg: 88.4496, loss: 0.3626
2023-11-27 05:35:08,633 - mmseg - INFO - Iter [71550/160000]	lr: 3.317e-05, eta: 19:33:47, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2420, decode.acc_seg: 89.9717, aux.loss_ce: 0.1134, aux.acc_seg: 88.6259, loss: 0.3554
2023-11-27 05:35:49,512 - mmseg - INFO - Iter [71600/160000]	lr: 3.315e-05, eta: 19:33:09, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2353, decode.acc_seg: 90.4568, aux.loss_ce: 0.1116, aux.acc_seg: 89.0521, loss: 0.3469
2023-11-27 05:36:30,234 - mmseg - INFO - Iter [71650/160000]	lr: 3.313e-05, eta: 19:32:30, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2488, decode.acc_seg: 89.6306, aux.loss_ce: 0.1150, aux.acc_seg: 88.2895, loss: 0.3638
2023-11-27 05:37:09,070 - mmseg - INFO - Iter [71700/160000]	lr: 3.311e-05, eta: 19:31:49, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2558, decode.acc_seg: 89.5082, aux.loss_ce: 0.1198, aux.acc_seg: 88.2215, loss: 0.3756
2023-11-27 05:37:47,138 - mmseg - INFO - Iter [71750/160000]	lr: 3.309e-05, eta: 19:31:07, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2438, decode.acc_seg: 89.9891, aux.loss_ce: 0.1148, aux.acc_seg: 88.7444, loss: 0.3586
2023-11-27 05:38:27,319 - mmseg - INFO - Iter [71800/160000]	lr: 3.308e-05, eta: 19:30:28, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2411, decode.acc_seg: 90.3397, aux.loss_ce: 0.1119, aux.acc_seg: 89.0989, loss: 0.3530
2023-11-27 05:39:08,065 - mmseg - INFO - Iter [71850/160000]	lr: 3.306e-05, eta: 19:29:49, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2690, decode.acc_seg: 88.7367, aux.loss_ce: 0.1221, aux.acc_seg: 87.4934, loss: 0.3911
2023-11-27 05:39:48,383 - mmseg - INFO - Iter [71900/160000]	lr: 3.304e-05, eta: 19:29:10, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2564, decode.acc_seg: 89.4927, aux.loss_ce: 0.1183, aux.acc_seg: 88.4355, loss: 0.3747
2023-11-27 05:40:29,149 - mmseg - INFO - Iter [71950/160000]	lr: 3.302e-05, eta: 19:28:31, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2376, decode.acc_seg: 89.9085, aux.loss_ce: 0.1112, aux.acc_seg: 88.6856, loss: 0.3488
2023-11-27 05:41:10,661 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 05:41:10,661 - mmseg - INFO - Iter [72000/160000]	lr: 3.300e-05, eta: 19:27:54, time: 0.831, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2679, decode.acc_seg: 89.3677, aux.loss_ce: 0.1240, aux.acc_seg: 88.0411, loss: 0.3919
2023-11-27 05:41:49,142 - mmseg - INFO - Iter [72050/160000]	lr: 3.298e-05, eta: 19:27:12, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2383, decode.acc_seg: 89.9212, aux.loss_ce: 0.1124, aux.acc_seg: 88.5278, loss: 0.3506
2023-11-27 05:42:26,489 - mmseg - INFO - Iter [72100/160000]	lr: 3.296e-05, eta: 19:26:29, time: 0.747, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2458, decode.acc_seg: 89.9047, aux.loss_ce: 0.1165, aux.acc_seg: 88.5731, loss: 0.3623
2023-11-27 05:43:06,672 - mmseg - INFO - Iter [72150/160000]	lr: 3.294e-05, eta: 19:25:50, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2448, decode.acc_seg: 89.8783, aux.loss_ce: 0.1163, aux.acc_seg: 88.3359, loss: 0.3611
2023-11-27 05:43:46,809 - mmseg - INFO - Iter [72200/160000]	lr: 3.293e-05, eta: 19:25:11, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.6547, aux.loss_ce: 0.1186, aux.acc_seg: 88.2992, loss: 0.3731
2023-11-27 05:44:25,645 - mmseg - INFO - Iter [72250/160000]	lr: 3.291e-05, eta: 19:24:30, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2420, decode.acc_seg: 90.1069, aux.loss_ce: 0.1122, aux.acc_seg: 88.9192, loss: 0.3542
2023-11-27 05:45:05,243 - mmseg - INFO - Iter [72300/160000]	lr: 3.289e-05, eta: 19:23:50, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2446, decode.acc_seg: 89.8867, aux.loss_ce: 0.1145, aux.acc_seg: 88.5471, loss: 0.3591
2023-11-27 05:45:42,454 - mmseg - INFO - Iter [72350/160000]	lr: 3.287e-05, eta: 19:23:07, time: 0.745, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2457, decode.acc_seg: 90.0796, aux.loss_ce: 0.1151, aux.acc_seg: 88.6762, loss: 0.3609
2023-11-27 05:46:21,214 - mmseg - INFO - Iter [72400/160000]	lr: 3.285e-05, eta: 19:22:25, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2606, decode.acc_seg: 89.4989, aux.loss_ce: 0.1198, aux.acc_seg: 88.2489, loss: 0.3804
2023-11-27 05:46:59,999 - mmseg - INFO - Iter [72450/160000]	lr: 3.283e-05, eta: 19:21:45, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2268, decode.acc_seg: 90.6019, aux.loss_ce: 0.1081, aux.acc_seg: 89.2063, loss: 0.3349
2023-11-27 05:47:39,078 - mmseg - INFO - Iter [72500/160000]	lr: 3.281e-05, eta: 19:21:04, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2396, decode.acc_seg: 89.9251, aux.loss_ce: 0.1137, aux.acc_seg: 88.4953, loss: 0.3533
2023-11-27 05:48:18,357 - mmseg - INFO - Iter [72550/160000]	lr: 3.279e-05, eta: 19:20:23, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2512, decode.acc_seg: 89.6071, aux.loss_ce: 0.1168, aux.acc_seg: 88.4969, loss: 0.3681
2023-11-27 05:48:55,187 - mmseg - INFO - Iter [72600/160000]	lr: 3.278e-05, eta: 19:19:40, time: 0.737, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2471, decode.acc_seg: 89.7559, aux.loss_ce: 0.1170, aux.acc_seg: 88.3496, loss: 0.3641
2023-11-27 05:49:35,598 - mmseg - INFO - Iter [72650/160000]	lr: 3.276e-05, eta: 19:19:01, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2538, decode.acc_seg: 89.4471, aux.loss_ce: 0.1188, aux.acc_seg: 88.2032, loss: 0.3726
2023-11-27 05:50:14,785 - mmseg - INFO - Iter [72700/160000]	lr: 3.274e-05, eta: 19:18:20, time: 0.785, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2406, decode.acc_seg: 90.4503, aux.loss_ce: 0.1115, aux.acc_seg: 89.2227, loss: 0.3521
2023-11-27 05:50:51,698 - mmseg - INFO - Iter [72750/160000]	lr: 3.272e-05, eta: 19:17:37, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2485, decode.acc_seg: 89.6138, aux.loss_ce: 0.1141, aux.acc_seg: 88.4689, loss: 0.3625
2023-11-27 05:51:31,363 - mmseg - INFO - Iter [72800/160000]	lr: 3.270e-05, eta: 19:16:57, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2518, decode.acc_seg: 89.4228, aux.loss_ce: 0.1159, aux.acc_seg: 88.3142, loss: 0.3677
2023-11-27 05:52:11,271 - mmseg - INFO - Iter [72850/160000]	lr: 3.268e-05, eta: 19:16:17, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2578, decode.acc_seg: 89.5606, aux.loss_ce: 0.1202, aux.acc_seg: 88.2018, loss: 0.3780
2023-11-27 05:52:51,700 - mmseg - INFO - Iter [72900/160000]	lr: 3.266e-05, eta: 19:15:38, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2572, decode.acc_seg: 89.5809, aux.loss_ce: 0.1185, aux.acc_seg: 88.2585, loss: 0.3757
2023-11-27 05:53:30,784 - mmseg - INFO - Iter [72950/160000]	lr: 3.264e-05, eta: 19:14:58, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2546, decode.acc_seg: 89.6661, aux.loss_ce: 0.1186, aux.acc_seg: 88.2674, loss: 0.3732
2023-11-27 05:54:10,083 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 05:54:10,083 - mmseg - INFO - Iter [73000/160000]	lr: 3.263e-05, eta: 19:14:17, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.3994, aux.loss_ce: 0.1240, aux.acc_seg: 87.8911, loss: 0.3808
2023-11-27 05:54:51,340 - mmseg - INFO - Iter [73050/160000]	lr: 3.261e-05, eta: 19:13:39, time: 0.826, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2556, decode.acc_seg: 89.8543, aux.loss_ce: 0.1203, aux.acc_seg: 88.3929, loss: 0.3759
2023-11-27 05:55:31,252 - mmseg - INFO - Iter [73100/160000]	lr: 3.259e-05, eta: 19:12:59, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2419, decode.acc_seg: 90.0390, aux.loss_ce: 0.1138, aux.acc_seg: 88.6510, loss: 0.3557
2023-11-27 05:56:10,672 - mmseg - INFO - Iter [73150/160000]	lr: 3.257e-05, eta: 19:12:19, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2493, decode.acc_seg: 89.4824, aux.loss_ce: 0.1161, aux.acc_seg: 88.3109, loss: 0.3654
2023-11-27 05:56:51,496 - mmseg - INFO - Iter [73200/160000]	lr: 3.255e-05, eta: 19:11:41, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2582, decode.acc_seg: 89.6206, aux.loss_ce: 0.1194, aux.acc_seg: 88.3304, loss: 0.3776
2023-11-27 05:57:29,599 - mmseg - INFO - Iter [73250/160000]	lr: 3.253e-05, eta: 19:10:59, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2648, decode.acc_seg: 89.0310, aux.loss_ce: 0.1216, aux.acc_seg: 87.8790, loss: 0.3864
2023-11-27 05:58:08,743 - mmseg - INFO - Iter [73300/160000]	lr: 3.251e-05, eta: 19:10:18, time: 0.784, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2591, decode.acc_seg: 89.6501, aux.loss_ce: 0.1196, aux.acc_seg: 88.2813, loss: 0.3787
2023-11-27 05:58:47,240 - mmseg - INFO - Iter [73350/160000]	lr: 3.249e-05, eta: 19:09:37, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2399, decode.acc_seg: 90.1376, aux.loss_ce: 0.1123, aux.acc_seg: 88.8091, loss: 0.3522
2023-11-27 05:59:25,498 - mmseg - INFO - Iter [73400/160000]	lr: 3.248e-05, eta: 19:08:55, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2479, decode.acc_seg: 89.9074, aux.loss_ce: 0.1163, aux.acc_seg: 88.4508, loss: 0.3642
2023-11-27 06:00:04,406 - mmseg - INFO - Iter [73450/160000]	lr: 3.246e-05, eta: 19:08:14, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2481, decode.acc_seg: 89.7006, aux.loss_ce: 0.1168, aux.acc_seg: 88.3714, loss: 0.3649
2023-11-27 06:00:43,794 - mmseg - INFO - Iter [73500/160000]	lr: 3.244e-05, eta: 19:07:34, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2418, decode.acc_seg: 89.8703, aux.loss_ce: 0.1133, aux.acc_seg: 88.5985, loss: 0.3551
2023-11-27 06:01:20,923 - mmseg - INFO - Iter [73550/160000]	lr: 3.242e-05, eta: 19:06:51, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2423, decode.acc_seg: 89.9973, aux.loss_ce: 0.1132, aux.acc_seg: 88.6925, loss: 0.3555
2023-11-27 06:01:57,414 - mmseg - INFO - Iter [73600/160000]	lr: 3.240e-05, eta: 19:06:08, time: 0.730, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2476, decode.acc_seg: 90.2172, aux.loss_ce: 0.1131, aux.acc_seg: 89.2218, loss: 0.3607
2023-11-27 06:02:36,489 - mmseg - INFO - Iter [73650/160000]	lr: 3.238e-05, eta: 19:05:27, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2378, decode.acc_seg: 90.1030, aux.loss_ce: 0.1118, aux.acc_seg: 88.7741, loss: 0.3496
2023-11-27 06:03:16,892 - mmseg - INFO - Iter [73700/160000]	lr: 3.236e-05, eta: 19:04:48, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2543, decode.acc_seg: 89.8078, aux.loss_ce: 0.1171, aux.acc_seg: 88.6392, loss: 0.3714
2023-11-27 06:03:57,275 - mmseg - INFO - Iter [73750/160000]	lr: 3.234e-05, eta: 19:04:09, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2315, decode.acc_seg: 90.0689, aux.loss_ce: 0.1087, aux.acc_seg: 88.7599, loss: 0.3402
2023-11-27 06:04:38,266 - mmseg - INFO - Iter [73800/160000]	lr: 3.233e-05, eta: 19:03:30, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2517, decode.acc_seg: 89.9394, aux.loss_ce: 0.1163, aux.acc_seg: 88.6784, loss: 0.3680
2023-11-27 06:05:19,446 - mmseg - INFO - Iter [73850/160000]	lr: 3.231e-05, eta: 19:02:52, time: 0.824, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2653, decode.acc_seg: 89.1743, aux.loss_ce: 0.1259, aux.acc_seg: 87.6385, loss: 0.3913
2023-11-27 06:05:59,781 - mmseg - INFO - Iter [73900/160000]	lr: 3.229e-05, eta: 19:02:13, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2561, decode.acc_seg: 89.6818, aux.loss_ce: 0.1188, aux.acc_seg: 88.4492, loss: 0.3749
2023-11-27 06:06:38,227 - mmseg - INFO - Iter [73950/160000]	lr: 3.227e-05, eta: 19:01:32, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2321, decode.acc_seg: 90.2369, aux.loss_ce: 0.1090, aux.acc_seg: 89.1274, loss: 0.3412
2023-11-27 06:07:19,377 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 06:07:19,377 - mmseg - INFO - Iter [74000/160000]	lr: 3.225e-05, eta: 19:00:53, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2630, decode.acc_seg: 89.0812, aux.loss_ce: 0.1212, aux.acc_seg: 87.9416, loss: 0.3842
2023-11-27 06:08:00,190 - mmseg - INFO - Iter [74050/160000]	lr: 3.223e-05, eta: 19:00:15, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2528, decode.acc_seg: 89.6826, aux.loss_ce: 0.1197, aux.acc_seg: 88.4561, loss: 0.3725
2023-11-27 06:08:40,946 - mmseg - INFO - Iter [74100/160000]	lr: 3.221e-05, eta: 18:59:36, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2495, decode.acc_seg: 89.4721, aux.loss_ce: 0.1162, aux.acc_seg: 88.1776, loss: 0.3657
2023-11-27 06:09:21,237 - mmseg - INFO - Iter [74150/160000]	lr: 3.219e-05, eta: 18:58:57, time: 0.806, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2340, decode.acc_seg: 90.3076, aux.loss_ce: 0.1094, aux.acc_seg: 89.1520, loss: 0.3434
2023-11-27 06:10:00,076 - mmseg - INFO - Iter [74200/160000]	lr: 3.218e-05, eta: 18:58:16, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2425, decode.acc_seg: 90.0282, aux.loss_ce: 0.1130, aux.acc_seg: 88.6269, loss: 0.3555
2023-11-27 06:10:40,183 - mmseg - INFO - Iter [74250/160000]	lr: 3.216e-05, eta: 18:57:36, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2516, decode.acc_seg: 89.8074, aux.loss_ce: 0.1165, aux.acc_seg: 88.4441, loss: 0.3681
2023-11-27 06:11:17,070 - mmseg - INFO - Iter [74300/160000]	lr: 3.214e-05, eta: 18:56:53, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2392, decode.acc_seg: 90.0120, aux.loss_ce: 0.1119, aux.acc_seg: 88.7138, loss: 0.3511
2023-11-27 06:11:56,708 - mmseg - INFO - Iter [74350/160000]	lr: 3.212e-05, eta: 18:56:13, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2570, decode.acc_seg: 89.4365, aux.loss_ce: 0.1216, aux.acc_seg: 87.9540, loss: 0.3787
2023-11-27 06:12:37,141 - mmseg - INFO - Iter [74400/160000]	lr: 3.210e-05, eta: 18:55:34, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2636, decode.acc_seg: 89.4227, aux.loss_ce: 0.1214, aux.acc_seg: 88.1525, loss: 0.3849
2023-11-27 06:13:16,916 - mmseg - INFO - Iter [74450/160000]	lr: 3.208e-05, eta: 18:54:54, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2601, decode.acc_seg: 89.4389, aux.loss_ce: 0.1227, aux.acc_seg: 87.9403, loss: 0.3828
2023-11-27 06:13:57,316 - mmseg - INFO - Iter [74500/160000]	lr: 3.206e-05, eta: 18:54:15, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2504, decode.acc_seg: 89.7912, aux.loss_ce: 0.1156, aux.acc_seg: 88.8142, loss: 0.3660
2023-11-27 06:14:38,478 - mmseg - INFO - Iter [74550/160000]	lr: 3.204e-05, eta: 18:53:37, time: 0.823, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2402, decode.acc_seg: 90.0092, aux.loss_ce: 0.1122, aux.acc_seg: 88.7410, loss: 0.3524
2023-11-27 06:15:16,725 - mmseg - INFO - Iter [74600/160000]	lr: 3.203e-05, eta: 18:52:55, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2385, decode.acc_seg: 90.1945, aux.loss_ce: 0.1140, aux.acc_seg: 88.6934, loss: 0.3525
2023-11-27 06:15:54,371 - mmseg - INFO - Iter [74650/160000]	lr: 3.201e-05, eta: 18:52:13, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2443, decode.acc_seg: 89.9424, aux.loss_ce: 0.1159, aux.acc_seg: 88.5319, loss: 0.3602
2023-11-27 06:16:34,659 - mmseg - INFO - Iter [74700/160000]	lr: 3.199e-05, eta: 18:51:34, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2472, decode.acc_seg: 89.7643, aux.loss_ce: 0.1150, aux.acc_seg: 88.6789, loss: 0.3622
2023-11-27 06:17:11,383 - mmseg - INFO - Iter [74750/160000]	lr: 3.197e-05, eta: 18:50:51, time: 0.735, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2457, decode.acc_seg: 89.4970, aux.loss_ce: 0.1153, aux.acc_seg: 88.2647, loss: 0.3610
2023-11-27 06:17:48,086 - mmseg - INFO - Iter [74800/160000]	lr: 3.195e-05, eta: 18:50:07, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2340, decode.acc_seg: 90.4825, aux.loss_ce: 0.1104, aux.acc_seg: 88.9580, loss: 0.3444
2023-11-27 06:18:25,107 - mmseg - INFO - Iter [74850/160000]	lr: 3.193e-05, eta: 18:49:24, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2498, decode.acc_seg: 89.5322, aux.loss_ce: 0.1171, aux.acc_seg: 88.1654, loss: 0.3669
2023-11-27 06:19:02,471 - mmseg - INFO - Iter [74900/160000]	lr: 3.191e-05, eta: 18:48:42, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2496, decode.acc_seg: 89.9745, aux.loss_ce: 0.1187, aux.acc_seg: 88.4968, loss: 0.3683
2023-11-27 06:19:41,273 - mmseg - INFO - Iter [74950/160000]	lr: 3.189e-05, eta: 18:48:01, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2508, decode.acc_seg: 89.8149, aux.loss_ce: 0.1164, aux.acc_seg: 88.5824, loss: 0.3672
2023-11-27 06:20:19,651 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 06:20:19,651 - mmseg - INFO - Iter [75000/160000]	lr: 3.188e-05, eta: 18:47:20, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2487, decode.acc_seg: 89.9171, aux.loss_ce: 0.1158, aux.acc_seg: 88.6273, loss: 0.3646
2023-11-27 06:20:56,532 - mmseg - INFO - Iter [75050/160000]	lr: 3.186e-05, eta: 18:46:36, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2357, decode.acc_seg: 90.2516, aux.loss_ce: 0.1106, aux.acc_seg: 88.9142, loss: 0.3463
2023-11-27 06:21:32,988 - mmseg - INFO - Iter [75100/160000]	lr: 3.184e-05, eta: 18:45:53, time: 0.729, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2356, decode.acc_seg: 90.3672, aux.loss_ce: 0.1104, aux.acc_seg: 89.1565, loss: 0.3460
2023-11-27 06:22:13,270 - mmseg - INFO - Iter [75150/160000]	lr: 3.182e-05, eta: 18:45:14, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2427, decode.acc_seg: 89.8238, aux.loss_ce: 0.1132, aux.acc_seg: 88.7957, loss: 0.3559
2023-11-27 06:22:54,247 - mmseg - INFO - Iter [75200/160000]	lr: 3.180e-05, eta: 18:44:35, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2379, decode.acc_seg: 90.3780, aux.loss_ce: 0.1110, aux.acc_seg: 89.0775, loss: 0.3489
2023-11-27 06:23:34,375 - mmseg - INFO - Iter [75250/160000]	lr: 3.178e-05, eta: 18:43:56, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2402, decode.acc_seg: 89.8715, aux.loss_ce: 0.1124, aux.acc_seg: 88.7451, loss: 0.3526
2023-11-27 06:24:14,226 - mmseg - INFO - Iter [75300/160000]	lr: 3.176e-05, eta: 18:43:16, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2266, decode.acc_seg: 90.7121, aux.loss_ce: 0.1084, aux.acc_seg: 89.3387, loss: 0.3351
2023-11-27 06:24:54,569 - mmseg - INFO - Iter [75350/160000]	lr: 3.174e-05, eta: 18:42:37, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2416, decode.acc_seg: 89.8258, aux.loss_ce: 0.1118, aux.acc_seg: 88.6002, loss: 0.3534
2023-11-27 06:25:34,852 - mmseg - INFO - Iter [75400/160000]	lr: 3.173e-05, eta: 18:41:58, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2483, decode.acc_seg: 89.7204, aux.loss_ce: 0.1151, aux.acc_seg: 88.5544, loss: 0.3634
2023-11-27 06:26:14,869 - mmseg - INFO - Iter [75450/160000]	lr: 3.171e-05, eta: 18:41:18, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2443, decode.acc_seg: 90.0439, aux.loss_ce: 0.1124, aux.acc_seg: 88.9567, loss: 0.3567
2023-11-27 06:26:54,072 - mmseg - INFO - Iter [75500/160000]	lr: 3.169e-05, eta: 18:40:38, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2454, decode.acc_seg: 89.9664, aux.loss_ce: 0.1162, aux.acc_seg: 88.5538, loss: 0.3616
2023-11-27 06:27:34,014 - mmseg - INFO - Iter [75550/160000]	lr: 3.167e-05, eta: 18:39:58, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2488, decode.acc_seg: 89.5930, aux.loss_ce: 0.1172, aux.acc_seg: 88.3114, loss: 0.3660
2023-11-27 06:28:14,070 - mmseg - INFO - Iter [75600/160000]	lr: 3.165e-05, eta: 18:39:19, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.7801, aux.loss_ce: 0.1184, aux.acc_seg: 88.6221, loss: 0.3729
2023-11-27 06:28:52,464 - mmseg - INFO - Iter [75650/160000]	lr: 3.163e-05, eta: 18:38:37, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2494, decode.acc_seg: 89.9062, aux.loss_ce: 0.1165, aux.acc_seg: 88.6290, loss: 0.3658
2023-11-27 06:29:31,419 - mmseg - INFO - Iter [75700/160000]	lr: 3.161e-05, eta: 18:37:57, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2415, decode.acc_seg: 89.9553, aux.loss_ce: 0.1125, aux.acc_seg: 88.7412, loss: 0.3540
2023-11-27 06:30:11,892 - mmseg - INFO - Iter [75750/160000]	lr: 3.159e-05, eta: 18:37:18, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2389, decode.acc_seg: 90.3497, aux.loss_ce: 0.1120, aux.acc_seg: 88.9823, loss: 0.3509
2023-11-27 06:30:53,080 - mmseg - INFO - Iter [75800/160000]	lr: 3.158e-05, eta: 18:36:39, time: 0.823, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2476, decode.acc_seg: 90.0252, aux.loss_ce: 0.1178, aux.acc_seg: 88.4793, loss: 0.3655
2023-11-27 06:31:34,027 - mmseg - INFO - Iter [75850/160000]	lr: 3.156e-05, eta: 18:36:01, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2358, decode.acc_seg: 90.0075, aux.loss_ce: 0.1116, aux.acc_seg: 88.6714, loss: 0.3474
2023-11-27 06:32:14,857 - mmseg - INFO - Iter [75900/160000]	lr: 3.154e-05, eta: 18:35:22, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2499, decode.acc_seg: 89.7976, aux.loss_ce: 0.1183, aux.acc_seg: 88.4727, loss: 0.3681
2023-11-27 06:32:52,789 - mmseg - INFO - Iter [75950/160000]	lr: 3.152e-05, eta: 18:34:40, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2356, decode.acc_seg: 90.1019, aux.loss_ce: 0.1085, aux.acc_seg: 88.9434, loss: 0.3441
2023-11-27 06:33:32,607 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 06:33:32,608 - mmseg - INFO - Iter [76000/160000]	lr: 3.150e-05, eta: 18:34:01, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2352, decode.acc_seg: 90.3347, aux.loss_ce: 0.1089, aux.acc_seg: 89.1118, loss: 0.3441
2023-11-27 06:34:10,131 - mmseg - INFO - Iter [76050/160000]	lr: 3.148e-05, eta: 18:33:18, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2533, decode.acc_seg: 89.6404, aux.loss_ce: 0.1210, aux.acc_seg: 88.2243, loss: 0.3743
2023-11-27 06:34:47,168 - mmseg - INFO - Iter [76100/160000]	lr: 3.146e-05, eta: 18:32:36, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2283, decode.acc_seg: 90.3778, aux.loss_ce: 0.1043, aux.acc_seg: 89.3897, loss: 0.3326
2023-11-27 06:35:25,218 - mmseg - INFO - Iter [76150/160000]	lr: 3.144e-05, eta: 18:31:54, time: 0.760, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2501, decode.acc_seg: 89.7815, aux.loss_ce: 0.1170, aux.acc_seg: 88.4136, loss: 0.3671
2023-11-27 06:36:04,154 - mmseg - INFO - Iter [76200/160000]	lr: 3.143e-05, eta: 18:31:13, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2327, decode.acc_seg: 90.2555, aux.loss_ce: 0.1103, aux.acc_seg: 88.8742, loss: 0.3430
2023-11-27 06:36:44,812 - mmseg - INFO - Iter [76250/160000]	lr: 3.141e-05, eta: 18:30:34, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2395, decode.acc_seg: 90.0243, aux.loss_ce: 0.1120, aux.acc_seg: 88.8779, loss: 0.3516
2023-11-27 06:37:23,757 - mmseg - INFO - Iter [76300/160000]	lr: 3.139e-05, eta: 18:29:54, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2461, decode.acc_seg: 89.9015, aux.loss_ce: 0.1168, aux.acc_seg: 88.4419, loss: 0.3629
2023-11-27 06:38:03,344 - mmseg - INFO - Iter [76350/160000]	lr: 3.137e-05, eta: 18:29:14, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2322, decode.acc_seg: 90.4143, aux.loss_ce: 0.1085, aux.acc_seg: 89.1155, loss: 0.3406
2023-11-27 06:38:41,216 - mmseg - INFO - Iter [76400/160000]	lr: 3.135e-05, eta: 18:28:32, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2344, decode.acc_seg: 90.2423, aux.loss_ce: 0.1100, aux.acc_seg: 88.7569, loss: 0.3444
2023-11-27 06:39:20,913 - mmseg - INFO - Iter [76450/160000]	lr: 3.133e-05, eta: 18:27:52, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2474, decode.acc_seg: 89.7911, aux.loss_ce: 0.1133, aux.acc_seg: 88.6376, loss: 0.3607
2023-11-27 06:39:57,708 - mmseg - INFO - Iter [76500/160000]	lr: 3.131e-05, eta: 18:27:09, time: 0.737, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2589, decode.acc_seg: 89.5604, aux.loss_ce: 0.1198, aux.acc_seg: 88.3549, loss: 0.3787
2023-11-27 06:40:36,100 - mmseg - INFO - Iter [76550/160000]	lr: 3.129e-05, eta: 18:26:28, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2690, decode.acc_seg: 89.1813, aux.loss_ce: 0.1237, aux.acc_seg: 87.9791, loss: 0.3927
2023-11-27 06:41:14,022 - mmseg - INFO - Iter [76600/160000]	lr: 3.128e-05, eta: 18:25:46, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2543, decode.acc_seg: 89.6220, aux.loss_ce: 0.1196, aux.acc_seg: 88.0832, loss: 0.3739
2023-11-27 06:41:50,907 - mmseg - INFO - Iter [76650/160000]	lr: 3.126e-05, eta: 18:25:03, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2436, decode.acc_seg: 89.9535, aux.loss_ce: 0.1152, aux.acc_seg: 88.6364, loss: 0.3588
2023-11-27 06:42:29,112 - mmseg - INFO - Iter [76700/160000]	lr: 3.124e-05, eta: 18:24:21, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2434, decode.acc_seg: 90.3253, aux.loss_ce: 0.1137, aux.acc_seg: 89.0321, loss: 0.3571
2023-11-27 06:43:09,637 - mmseg - INFO - Iter [76750/160000]	lr: 3.122e-05, eta: 18:23:42, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2452, decode.acc_seg: 89.9824, aux.loss_ce: 0.1143, aux.acc_seg: 88.6969, loss: 0.3595
2023-11-27 06:43:49,415 - mmseg - INFO - Iter [76800/160000]	lr: 3.120e-05, eta: 18:23:03, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2369, decode.acc_seg: 90.1836, aux.loss_ce: 0.1110, aux.acc_seg: 88.9444, loss: 0.3478
2023-11-27 06:44:30,143 - mmseg - INFO - Iter [76850/160000]	lr: 3.118e-05, eta: 18:22:24, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2407, decode.acc_seg: 90.0488, aux.loss_ce: 0.1118, aux.acc_seg: 88.6752, loss: 0.3524
2023-11-27 06:45:10,299 - mmseg - INFO - Iter [76900/160000]	lr: 3.116e-05, eta: 18:21:45, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2474, decode.acc_seg: 89.8359, aux.loss_ce: 0.1148, aux.acc_seg: 88.5831, loss: 0.3622
2023-11-27 06:45:49,959 - mmseg - INFO - Iter [76950/160000]	lr: 3.114e-05, eta: 18:21:05, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2375, decode.acc_seg: 89.8969, aux.loss_ce: 0.1103, aux.acc_seg: 88.7224, loss: 0.3478
2023-11-27 06:46:27,274 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 06:46:27,274 - mmseg - INFO - Iter [77000/160000]	lr: 3.113e-05, eta: 18:20:22, time: 0.747, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2283, decode.acc_seg: 90.2251, aux.loss_ce: 0.1075, aux.acc_seg: 88.8526, loss: 0.3358
2023-11-27 06:47:07,719 - mmseg - INFO - Iter [77050/160000]	lr: 3.111e-05, eta: 18:19:43, time: 0.809, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2473, decode.acc_seg: 89.9241, aux.loss_ce: 0.1182, aux.acc_seg: 88.5277, loss: 0.3656
2023-11-27 06:47:44,905 - mmseg - INFO - Iter [77100/160000]	lr: 3.109e-05, eta: 18:19:01, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2535, decode.acc_seg: 89.6077, aux.loss_ce: 0.1187, aux.acc_seg: 88.2129, loss: 0.3722
2023-11-27 06:48:24,736 - mmseg - INFO - Iter [77150/160000]	lr: 3.107e-05, eta: 18:18:21, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2500, decode.acc_seg: 89.6176, aux.loss_ce: 0.1172, aux.acc_seg: 88.3367, loss: 0.3672
2023-11-27 06:49:05,246 - mmseg - INFO - Iter [77200/160000]	lr: 3.105e-05, eta: 18:17:42, time: 0.810, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2300, decode.acc_seg: 90.3959, aux.loss_ce: 0.1077, aux.acc_seg: 89.1342, loss: 0.3377
2023-11-27 06:49:44,705 - mmseg - INFO - Iter [77250/160000]	lr: 3.103e-05, eta: 18:17:02, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2252, decode.acc_seg: 90.5932, aux.loss_ce: 0.1064, aux.acc_seg: 89.3170, loss: 0.3316
2023-11-27 06:50:24,667 - mmseg - INFO - Iter [77300/160000]	lr: 3.101e-05, eta: 18:16:22, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2344, decode.acc_seg: 90.3641, aux.loss_ce: 0.1127, aux.acc_seg: 88.7226, loss: 0.3471
2023-11-27 06:51:03,178 - mmseg - INFO - Iter [77350/160000]	lr: 3.099e-05, eta: 18:15:41, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2503, decode.acc_seg: 89.8397, aux.loss_ce: 0.1175, aux.acc_seg: 88.4455, loss: 0.3678
2023-11-27 06:51:42,009 - mmseg - INFO - Iter [77400/160000]	lr: 3.098e-05, eta: 18:15:00, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2277, decode.acc_seg: 90.2990, aux.loss_ce: 0.1077, aux.acc_seg: 88.9836, loss: 0.3354
2023-11-27 06:52:21,311 - mmseg - INFO - Iter [77450/160000]	lr: 3.096e-05, eta: 18:14:20, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2259, decode.acc_seg: 90.4261, aux.loss_ce: 0.1055, aux.acc_seg: 89.2231, loss: 0.3313
2023-11-27 06:53:01,904 - mmseg - INFO - Iter [77500/160000]	lr: 3.094e-05, eta: 18:13:41, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2399, decode.acc_seg: 90.0217, aux.loss_ce: 0.1138, aux.acc_seg: 88.6463, loss: 0.3537
2023-11-27 06:53:41,877 - mmseg - INFO - Iter [77550/160000]	lr: 3.092e-05, eta: 18:13:02, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2417, decode.acc_seg: 90.0733, aux.loss_ce: 0.1128, aux.acc_seg: 88.7484, loss: 0.3545
2023-11-27 06:54:21,767 - mmseg - INFO - Iter [77600/160000]	lr: 3.090e-05, eta: 18:12:22, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2609, decode.acc_seg: 89.3195, aux.loss_ce: 0.1213, aux.acc_seg: 87.9941, loss: 0.3822
2023-11-27 06:55:00,922 - mmseg - INFO - Iter [77650/160000]	lr: 3.088e-05, eta: 18:11:42, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2276, decode.acc_seg: 90.3982, aux.loss_ce: 0.1074, aux.acc_seg: 89.1514, loss: 0.3350
2023-11-27 06:55:40,068 - mmseg - INFO - Iter [77700/160000]	lr: 3.086e-05, eta: 18:11:01, time: 0.784, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2488, decode.acc_seg: 89.8909, aux.loss_ce: 0.1164, aux.acc_seg: 88.7062, loss: 0.3652
2023-11-27 06:56:19,953 - mmseg - INFO - Iter [77750/160000]	lr: 3.084e-05, eta: 18:10:21, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2434, decode.acc_seg: 89.9712, aux.loss_ce: 0.1143, aux.acc_seg: 88.7354, loss: 0.3576
2023-11-27 06:57:00,807 - mmseg - INFO - Iter [77800/160000]	lr: 3.083e-05, eta: 18:09:43, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2566, decode.acc_seg: 89.8493, aux.loss_ce: 0.1185, aux.acc_seg: 88.5493, loss: 0.3751
2023-11-27 06:57:41,376 - mmseg - INFO - Iter [77850/160000]	lr: 3.081e-05, eta: 18:09:04, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2614, decode.acc_seg: 89.5697, aux.loss_ce: 0.1229, aux.acc_seg: 88.0934, loss: 0.3844
2023-11-27 06:58:21,789 - mmseg - INFO - Iter [77900/160000]	lr: 3.079e-05, eta: 18:08:25, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2517, decode.acc_seg: 89.5885, aux.loss_ce: 0.1182, aux.acc_seg: 88.1672, loss: 0.3699
2023-11-27 06:59:02,102 - mmseg - INFO - Iter [77950/160000]	lr: 3.077e-05, eta: 18:07:46, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2305, decode.acc_seg: 90.1927, aux.loss_ce: 0.1073, aux.acc_seg: 89.1084, loss: 0.3378
2023-11-27 06:59:42,888 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 06:59:42,889 - mmseg - INFO - Iter [78000/160000]	lr: 3.075e-05, eta: 18:07:07, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2350, decode.acc_seg: 89.9433, aux.loss_ce: 0.1105, aux.acc_seg: 88.7002, loss: 0.3455
2023-11-27 07:00:20,650 - mmseg - INFO - Iter [78050/160000]	lr: 3.073e-05, eta: 18:06:25, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2467, decode.acc_seg: 90.1739, aux.loss_ce: 0.1147, aux.acc_seg: 88.9569, loss: 0.3614
2023-11-27 07:00:59,792 - mmseg - INFO - Iter [78100/160000]	lr: 3.071e-05, eta: 18:05:45, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2362, decode.acc_seg: 90.0785, aux.loss_ce: 0.1109, aux.acc_seg: 88.5732, loss: 0.3471
2023-11-27 07:01:40,634 - mmseg - INFO - Iter [78150/160000]	lr: 3.069e-05, eta: 18:05:06, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2304, decode.acc_seg: 90.5792, aux.loss_ce: 0.1071, aux.acc_seg: 89.4505, loss: 0.3375
2023-11-27 07:02:19,241 - mmseg - INFO - Iter [78200/160000]	lr: 3.068e-05, eta: 18:04:25, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2331, decode.acc_seg: 90.2957, aux.loss_ce: 0.1100, aux.acc_seg: 88.8213, loss: 0.3431
2023-11-27 07:02:56,578 - mmseg - INFO - Iter [78250/160000]	lr: 3.066e-05, eta: 18:03:43, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2408, decode.acc_seg: 90.0957, aux.loss_ce: 0.1103, aux.acc_seg: 89.0200, loss: 0.3512
2023-11-27 07:03:36,787 - mmseg - INFO - Iter [78300/160000]	lr: 3.064e-05, eta: 18:03:03, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2343, decode.acc_seg: 90.3181, aux.loss_ce: 0.1092, aux.acc_seg: 89.1218, loss: 0.3435
2023-11-27 07:04:19,591 - mmseg - INFO - Iter [78350/160000]	lr: 3.062e-05, eta: 18:02:27, time: 0.856, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2420, decode.acc_seg: 90.0772, aux.loss_ce: 0.1143, aux.acc_seg: 88.7607, loss: 0.3563
2023-11-27 07:04:59,814 - mmseg - INFO - Iter [78400/160000]	lr: 3.060e-05, eta: 18:01:47, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2281, decode.acc_seg: 90.6833, aux.loss_ce: 0.1081, aux.acc_seg: 89.2806, loss: 0.3362
2023-11-27 07:05:39,482 - mmseg - INFO - Iter [78450/160000]	lr: 3.058e-05, eta: 18:01:08, time: 0.794, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2419, decode.acc_seg: 90.0822, aux.loss_ce: 0.1138, aux.acc_seg: 88.6903, loss: 0.3557
2023-11-27 07:06:20,913 - mmseg - INFO - Iter [78500/160000]	lr: 3.056e-05, eta: 18:00:29, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2596, decode.acc_seg: 89.4184, aux.loss_ce: 0.1180, aux.acc_seg: 88.2053, loss: 0.3776
2023-11-27 07:07:01,777 - mmseg - INFO - Iter [78550/160000]	lr: 3.054e-05, eta: 17:59:51, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2406, decode.acc_seg: 89.9503, aux.loss_ce: 0.1102, aux.acc_seg: 88.7551, loss: 0.3508
2023-11-27 07:07:41,730 - mmseg - INFO - Iter [78600/160000]	lr: 3.053e-05, eta: 17:59:11, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2284, decode.acc_seg: 90.3011, aux.loss_ce: 0.1069, aux.acc_seg: 89.0425, loss: 0.3353
2023-11-27 07:08:19,371 - mmseg - INFO - Iter [78650/160000]	lr: 3.051e-05, eta: 17:58:29, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2333, decode.acc_seg: 90.3362, aux.loss_ce: 0.1103, aux.acc_seg: 89.0442, loss: 0.3436
2023-11-27 07:08:58,298 - mmseg - INFO - Iter [78700/160000]	lr: 3.049e-05, eta: 17:57:49, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2294, decode.acc_seg: 90.3088, aux.loss_ce: 0.1104, aux.acc_seg: 89.0089, loss: 0.3398
2023-11-27 07:09:38,402 - mmseg - INFO - Iter [78750/160000]	lr: 3.047e-05, eta: 17:57:09, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2400, decode.acc_seg: 90.0248, aux.loss_ce: 0.1108, aux.acc_seg: 88.9395, loss: 0.3508
2023-11-27 07:10:18,945 - mmseg - INFO - Iter [78800/160000]	lr: 3.045e-05, eta: 17:56:30, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2518, decode.acc_seg: 89.7767, aux.loss_ce: 0.1185, aux.acc_seg: 88.4993, loss: 0.3703
2023-11-27 07:10:58,305 - mmseg - INFO - Iter [78850/160000]	lr: 3.043e-05, eta: 17:55:50, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2589, decode.acc_seg: 89.5280, aux.loss_ce: 0.1201, aux.acc_seg: 88.1838, loss: 0.3789
2023-11-27 07:11:38,562 - mmseg - INFO - Iter [78900/160000]	lr: 3.041e-05, eta: 17:55:11, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2413, decode.acc_seg: 90.2014, aux.loss_ce: 0.1129, aux.acc_seg: 88.7979, loss: 0.3542
2023-11-27 07:12:18,802 - mmseg - INFO - Iter [78950/160000]	lr: 3.039e-05, eta: 17:54:31, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2415, decode.acc_seg: 89.9886, aux.loss_ce: 0.1143, aux.acc_seg: 88.6206, loss: 0.3558
2023-11-27 07:12:58,998 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 07:12:58,998 - mmseg - INFO - Iter [79000/160000]	lr: 3.038e-05, eta: 17:53:52, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2383, decode.acc_seg: 89.9536, aux.loss_ce: 0.1106, aux.acc_seg: 88.7868, loss: 0.3489
2023-11-27 07:13:37,625 - mmseg - INFO - Iter [79050/160000]	lr: 3.036e-05, eta: 17:53:11, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2279, decode.acc_seg: 90.5791, aux.loss_ce: 0.1057, aux.acc_seg: 89.1650, loss: 0.3335
2023-11-27 07:14:17,876 - mmseg - INFO - Iter [79100/160000]	lr: 3.034e-05, eta: 17:52:32, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2371, decode.acc_seg: 90.3268, aux.loss_ce: 0.1112, aux.acc_seg: 88.9881, loss: 0.3484
2023-11-27 07:14:57,473 - mmseg - INFO - Iter [79150/160000]	lr: 3.032e-05, eta: 17:51:52, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2290, decode.acc_seg: 90.4938, aux.loss_ce: 0.1075, aux.acc_seg: 89.2131, loss: 0.3365
2023-11-27 07:15:35,362 - mmseg - INFO - Iter [79200/160000]	lr: 3.030e-05, eta: 17:51:10, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2341, decode.acc_seg: 90.2469, aux.loss_ce: 0.1093, aux.acc_seg: 88.8637, loss: 0.3434
2023-11-27 07:16:12,719 - mmseg - INFO - Iter [79250/160000]	lr: 3.028e-05, eta: 17:50:28, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2459, decode.acc_seg: 90.1271, aux.loss_ce: 0.1171, aux.acc_seg: 88.8128, loss: 0.3630
2023-11-27 07:16:52,417 - mmseg - INFO - Iter [79300/160000]	lr: 3.026e-05, eta: 17:49:48, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2346, decode.acc_seg: 90.3053, aux.loss_ce: 0.1105, aux.acc_seg: 88.9084, loss: 0.3451
2023-11-27 07:17:32,333 - mmseg - INFO - Iter [79350/160000]	lr: 3.024e-05, eta: 17:49:09, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2224, decode.acc_seg: 90.8650, aux.loss_ce: 0.1041, aux.acc_seg: 89.6931, loss: 0.3265
2023-11-27 07:18:12,365 - mmseg - INFO - Iter [79400/160000]	lr: 3.023e-05, eta: 17:48:29, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2511, decode.acc_seg: 90.0732, aux.loss_ce: 0.1184, aux.acc_seg: 88.6646, loss: 0.3695
2023-11-27 07:18:49,873 - mmseg - INFO - Iter [79450/160000]	lr: 3.021e-05, eta: 17:47:47, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2236, decode.acc_seg: 90.8480, aux.loss_ce: 0.1050, aux.acc_seg: 89.5590, loss: 0.3286
2023-11-27 07:19:29,883 - mmseg - INFO - Iter [79500/160000]	lr: 3.019e-05, eta: 17:47:07, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2292, decode.acc_seg: 90.4508, aux.loss_ce: 0.1088, aux.acc_seg: 88.8951, loss: 0.3380
2023-11-27 07:20:10,267 - mmseg - INFO - Iter [79550/160000]	lr: 3.017e-05, eta: 17:46:28, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2363, decode.acc_seg: 90.2247, aux.loss_ce: 0.1099, aux.acc_seg: 88.9956, loss: 0.3463
2023-11-27 07:20:52,823 - mmseg - INFO - Iter [79600/160000]	lr: 3.015e-05, eta: 17:45:51, time: 0.851, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2356, decode.acc_seg: 90.3465, aux.loss_ce: 0.1119, aux.acc_seg: 88.8886, loss: 0.3475
2023-11-27 07:21:33,278 - mmseg - INFO - Iter [79650/160000]	lr: 3.013e-05, eta: 17:45:12, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2425, decode.acc_seg: 90.2072, aux.loss_ce: 0.1127, aux.acc_seg: 89.0029, loss: 0.3552
2023-11-27 07:22:12,886 - mmseg - INFO - Iter [79700/160000]	lr: 3.011e-05, eta: 17:44:32, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2345, decode.acc_seg: 90.5050, aux.loss_ce: 0.1103, aux.acc_seg: 89.1839, loss: 0.3448
2023-11-27 07:22:49,536 - mmseg - INFO - Iter [79750/160000]	lr: 3.009e-05, eta: 17:43:49, time: 0.734, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2191, decode.acc_seg: 90.9147, aux.loss_ce: 0.1034, aux.acc_seg: 89.7150, loss: 0.3225
2023-11-27 07:23:26,510 - mmseg - INFO - Iter [79800/160000]	lr: 3.008e-05, eta: 17:43:07, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2340, decode.acc_seg: 90.4495, aux.loss_ce: 0.1108, aux.acc_seg: 89.2070, loss: 0.3448
2023-11-27 07:24:06,686 - mmseg - INFO - Iter [79850/160000]	lr: 3.006e-05, eta: 17:42:28, time: 0.805, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2397, decode.acc_seg: 90.0946, aux.loss_ce: 0.1116, aux.acc_seg: 88.8924, loss: 0.3513
2023-11-27 07:24:43,765 - mmseg - INFO - Iter [79900/160000]	lr: 3.004e-05, eta: 17:41:45, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2262, decode.acc_seg: 90.3530, aux.loss_ce: 0.1058, aux.acc_seg: 89.1167, loss: 0.3321
2023-11-27 07:25:21,048 - mmseg - INFO - Iter [79950/160000]	lr: 3.002e-05, eta: 17:41:03, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2295, decode.acc_seg: 90.4157, aux.loss_ce: 0.1081, aux.acc_seg: 89.1590, loss: 0.3376
2023-11-27 07:26:01,291 - mmseg - INFO - Saving checkpoint at 80000 iterations
2023-11-27 07:26:06,326 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 07:26:06,327 - mmseg - INFO - Iter [80000/160000]	lr: 3.000e-05, eta: 17:40:29, time: 0.906, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2284, decode.acc_seg: 90.5823, aux.loss_ce: 0.1064, aux.acc_seg: 89.5085, loss: 0.3348
2023-11-27 07:27:38,548 - mmseg - INFO - per class results:
2023-11-27 07:27:38,562 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.74 | 88.01 |
|       building      | 81.07 | 89.69 |
|         sky         | 94.59 | 97.39 |
|        floor        | 82.89 | 90.42 |
|         tree        | 75.13 | 88.29 |
|       ceiling       | 84.02 | 91.67 |
|         road        | 84.03 | 90.44 |
|         bed         | 87.59 | 95.09 |
|      windowpane     | 61.98 | 78.95 |
|        grass        | 64.18 | 84.29 |
|       cabinet       | 62.42 | 73.99 |
|       sidewalk      | 67.34 | 81.12 |
|        person       | 81.05 | 93.35 |
|        earth        | 31.66 |  42.8 |
|         door        | 52.65 | 71.85 |
|        table        | 58.88 | 76.21 |
|       mountain      | 55.86 | 72.58 |
|        plant        |  54.7 | 65.61 |
|       curtain       | 76.21 | 85.93 |
|        chair        |  56.0 | 67.49 |
|         car         | 85.16 |  92.4 |
|        water        | 62.23 | 74.13 |
|       painting      | 74.01 | 87.16 |
|         sofa        | 61.97 |  77.0 |
|        shelf        | 43.53 | 63.94 |
|        house        | 41.51 | 62.61 |
|         sea         | 63.51 | 83.97 |
|        mirror       | 64.62 | 76.56 |
|         rug         | 71.11 | 80.08 |
|        field        | 30.38 | 47.55 |
|       armchair      | 38.81 | 62.07 |
|         seat        | 57.31 | 82.64 |
|        fence        | 46.09 | 62.73 |
|         desk        | 48.77 | 70.78 |
|         rock        | 44.67 | 70.08 |
|       wardrobe      | 47.54 | 61.95 |
|         lamp        | 64.58 | 76.69 |
|       bathtub       | 77.31 | 83.58 |
|       railing       | 32.83 | 51.15 |
|       cushion       | 58.58 | 71.67 |
|         base        | 36.38 | 50.08 |
|         box         | 28.89 |  34.8 |
|        column       | 43.68 | 53.78 |
|      signboard      | 40.32 | 52.63 |
|   chest of drawers  | 46.21 | 61.83 |
|       counter       | 35.03 | 45.51 |
|         sand        | 31.27 | 50.11 |
|         sink        | 71.22 | 79.19 |
|      skyscraper     | 43.69 | 52.83 |
|      fireplace      | 72.37 | 90.53 |
|     refrigerator    | 79.99 | 90.39 |
|      grandstand     | 47.88 | 64.75 |
|         path        | 16.14 |  28.6 |
|        stairs       | 34.71 | 45.46 |
|        runway       | 70.76 | 92.69 |
|         case        |  56.5 |  64.6 |
|      pool table     | 92.45 | 96.67 |
|        pillow       | 61.58 | 73.08 |
|     screen door     |  47.8 | 63.06 |
|       stairway      | 30.13 | 39.11 |
|        river        | 12.79 | 23.37 |
|        bridge       | 74.79 | 87.21 |
|       bookcase      | 36.06 | 60.48 |
|        blind        | 43.27 | 48.54 |
|     coffee table    | 56.58 | 82.79 |
|        toilet       | 82.52 | 88.76 |
|        flower       | 39.47 | 54.24 |
|         book        |  44.3 | 63.79 |
|         hill        |  9.25 | 15.09 |
|        bench        | 40.59 | 51.27 |
|      countertop     | 48.04 | 77.58 |
|        stove        | 70.84 | 80.88 |
|         palm        | 52.73 | 74.82 |
|    kitchen island   | 44.05 | 86.06 |
|       computer      | 69.15 | 81.48 |
|     swivel chair    | 50.02 | 72.08 |
|         boat        | 47.92 | 54.32 |
|         bar         |  46.1 |  65.5 |
|    arcade machine   | 62.83 | 69.88 |
|        hovel        | 35.61 | 57.69 |
|         bus         | 85.04 | 96.79 |
|        towel        | 57.17 | 77.43 |
|        light        | 57.06 | 63.06 |
|        truck        |  35.7 |  53.3 |
|        tower        | 22.06 | 41.37 |
|      chandelier     | 66.53 | 81.94 |
|        awning       | 24.63 | 29.69 |
|     streetlight     | 26.83 |  34.6 |
|        booth        | 48.17 | 50.19 |
| television receiver | 68.85 | 78.23 |
|       airplane      | 56.71 | 66.46 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       | 51.61 | 70.77 |
|         pole        | 27.44 |  39.9 |
|         land        |  3.64 |  6.9  |
|      bannister      | 14.78 | 20.15 |
|      escalator      | 29.69 |  41.7 |
|       ottoman       |  46.5 | 59.85 |
|        bottle       | 35.07 | 58.88 |
|        buffet       | 45.64 | 59.55 |
|        poster       | 30.49 | 39.47 |
|        stage        | 19.75 | 29.36 |
|         van         | 45.81 | 64.14 |
|         ship        | 22.52 | 37.31 |
|       fountain      | 21.42 | 21.71 |
|    conveyer belt    | 65.63 | 90.77 |
|        canopy       | 23.98 | 42.19 |
|        washer       | 74.07 |  78.9 |
|      plaything      |  20.3 | 46.07 |
|    swimming pool    | 70.09 | 89.77 |
|        stool        | 37.94 |  48.5 |
|        barrel       | 49.83 | 65.07 |
|        basket       | 31.09 | 39.49 |
|      waterfall      |  70.8 | 82.99 |
|         tent        | 90.54 | 98.67 |
|         bag         | 15.62 | 21.16 |
|       minibike      | 72.09 | 85.57 |
|        cradle       | 84.18 | 97.35 |
|         oven        |  46.7 | 57.07 |
|         ball        | 40.67 | 49.75 |
|         food        |  29.3 | 32.59 |
|         step        | 12.36 | 14.16 |
|         tank        | 35.71 | 41.43 |
|      trade name     | 27.74 | 33.58 |
|      microwave      | 81.36 |  91.8 |
|         pot         | 47.65 | 54.75 |
|        animal       | 60.88 | 66.42 |
|       bicycle       | 58.23 | 76.29 |
|         lake        | 59.44 | 71.85 |
|      dishwasher     | 66.86 | 71.13 |
|        screen       | 68.58 | 88.99 |
|       blanket       | 11.83 | 13.46 |
|      sculpture      |  48.9 |  77.3 |
|         hood        | 63.67 | 69.34 |
|        sconce       | 40.87 | 47.34 |
|         vase        | 39.77 | 55.36 |
|    traffic light    | 33.45 | 55.79 |
|         tray        | 10.56 | 15.25 |
|        ashcan       |  35.3 | 49.56 |
|         fan         | 62.58 | 78.21 |
|         pier        |  53.1 | 88.33 |
|      crt screen     |  6.84 | 20.94 |
|        plate        | 54.48 | 65.16 |
|       monitor       |  8.77 |  12.2 |
|    bulletin board   | 50.12 | 71.22 |
|        shower       |  0.36 |  0.49 |
|       radiator      | 64.93 | 70.97 |
|        glass        | 13.91 | 14.72 |
|        clock        | 39.16 | 44.87 |
|         flag        | 37.93 | 43.73 |
+---------------------+-------+-------+
2023-11-27 07:27:38,562 - mmseg - INFO - Summary:
2023-11-27 07:27:38,563 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 82.97 | 49.46 | 62.29 |
+-------+-------+-------+
2023-11-27 07:27:38,588 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 07:27:38,589 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8297, mIoU: 0.4946, mAcc: 0.6229, IoU.wall: 0.7774, IoU.building: 0.8107, IoU.sky: 0.9459, IoU.floor: 0.8289, IoU.tree: 0.7513, IoU.ceiling: 0.8402, IoU.road: 0.8403, IoU.bed : 0.8759, IoU.windowpane: 0.6198, IoU.grass: 0.6418, IoU.cabinet: 0.6242, IoU.sidewalk: 0.6734, IoU.person: 0.8105, IoU.earth: 0.3166, IoU.door: 0.5265, IoU.table: 0.5888, IoU.mountain: 0.5586, IoU.plant: 0.5470, IoU.curtain: 0.7621, IoU.chair: 0.5600, IoU.car: 0.8516, IoU.water: 0.6223, IoU.painting: 0.7401, IoU.sofa: 0.6197, IoU.shelf: 0.4353, IoU.house: 0.4151, IoU.sea: 0.6351, IoU.mirror: 0.6462, IoU.rug: 0.7111, IoU.field: 0.3038, IoU.armchair: 0.3881, IoU.seat: 0.5731, IoU.fence: 0.4609, IoU.desk: 0.4877, IoU.rock: 0.4467, IoU.wardrobe: 0.4754, IoU.lamp: 0.6458, IoU.bathtub: 0.7731, IoU.railing: 0.3283, IoU.cushion: 0.5858, IoU.base: 0.3638, IoU.box: 0.2889, IoU.column: 0.4368, IoU.signboard: 0.4032, IoU.chest of drawers: 0.4621, IoU.counter: 0.3503, IoU.sand: 0.3127, IoU.sink: 0.7122, IoU.skyscraper: 0.4369, IoU.fireplace: 0.7237, IoU.refrigerator: 0.7999, IoU.grandstand: 0.4788, IoU.path: 0.1614, IoU.stairs: 0.3471, IoU.runway: 0.7076, IoU.case: 0.5650, IoU.pool table: 0.9245, IoU.pillow: 0.6158, IoU.screen door: 0.4780, IoU.stairway: 0.3013, IoU.river: 0.1279, IoU.bridge: 0.7479, IoU.bookcase: 0.3606, IoU.blind: 0.4327, IoU.coffee table: 0.5658, IoU.toilet: 0.8252, IoU.flower: 0.3947, IoU.book: 0.4430, IoU.hill: 0.0925, IoU.bench: 0.4059, IoU.countertop: 0.4804, IoU.stove: 0.7084, IoU.palm: 0.5273, IoU.kitchen island: 0.4405, IoU.computer: 0.6915, IoU.swivel chair: 0.5002, IoU.boat: 0.4792, IoU.bar: 0.4610, IoU.arcade machine: 0.6283, IoU.hovel: 0.3561, IoU.bus: 0.8504, IoU.towel: 0.5717, IoU.light: 0.5706, IoU.truck: 0.3570, IoU.tower: 0.2206, IoU.chandelier: 0.6653, IoU.awning: 0.2463, IoU.streetlight: 0.2683, IoU.booth: 0.4817, IoU.television receiver: 0.6885, IoU.airplane: 0.5671, IoU.dirt track: 0.0000, IoU.apparel: 0.5161, IoU.pole: 0.2744, IoU.land: 0.0364, IoU.bannister: 0.1478, IoU.escalator: 0.2969, IoU.ottoman: 0.4650, IoU.bottle: 0.3507, IoU.buffet: 0.4564, IoU.poster: 0.3049, IoU.stage: 0.1975, IoU.van: 0.4581, IoU.ship: 0.2252, IoU.fountain: 0.2142, IoU.conveyer belt: 0.6563, IoU.canopy: 0.2398, IoU.washer: 0.7407, IoU.plaything: 0.2030, IoU.swimming pool: 0.7009, IoU.stool: 0.3794, IoU.barrel: 0.4983, IoU.basket: 0.3109, IoU.waterfall: 0.7080, IoU.tent: 0.9054, IoU.bag: 0.1562, IoU.minibike: 0.7209, IoU.cradle: 0.8418, IoU.oven: 0.4670, IoU.ball: 0.4067, IoU.food: 0.2930, IoU.step: 0.1236, IoU.tank: 0.3571, IoU.trade name: 0.2774, IoU.microwave: 0.8136, IoU.pot: 0.4765, IoU.animal: 0.6088, IoU.bicycle: 0.5823, IoU.lake: 0.5944, IoU.dishwasher: 0.6686, IoU.screen: 0.6858, IoU.blanket: 0.1183, IoU.sculpture: 0.4890, IoU.hood: 0.6367, IoU.sconce: 0.4087, IoU.vase: 0.3977, IoU.traffic light: 0.3345, IoU.tray: 0.1056, IoU.ashcan: 0.3530, IoU.fan: 0.6258, IoU.pier: 0.5310, IoU.crt screen: 0.0684, IoU.plate: 0.5448, IoU.monitor: 0.0877, IoU.bulletin board: 0.5012, IoU.shower: 0.0036, IoU.radiator: 0.6493, IoU.glass: 0.1391, IoU.clock: 0.3916, IoU.flag: 0.3793, Acc.wall: 0.8801, Acc.building: 0.8969, Acc.sky: 0.9739, Acc.floor: 0.9042, Acc.tree: 0.8829, Acc.ceiling: 0.9167, Acc.road: 0.9044, Acc.bed : 0.9509, Acc.windowpane: 0.7895, Acc.grass: 0.8429, Acc.cabinet: 0.7399, Acc.sidewalk: 0.8112, Acc.person: 0.9335, Acc.earth: 0.4280, Acc.door: 0.7185, Acc.table: 0.7621, Acc.mountain: 0.7258, Acc.plant: 0.6561, Acc.curtain: 0.8593, Acc.chair: 0.6749, Acc.car: 0.9240, Acc.water: 0.7413, Acc.painting: 0.8716, Acc.sofa: 0.7700, Acc.shelf: 0.6394, Acc.house: 0.6261, Acc.sea: 0.8397, Acc.mirror: 0.7656, Acc.rug: 0.8008, Acc.field: 0.4755, Acc.armchair: 0.6207, Acc.seat: 0.8264, Acc.fence: 0.6273, Acc.desk: 0.7078, Acc.rock: 0.7008, Acc.wardrobe: 0.6195, Acc.lamp: 0.7669, Acc.bathtub: 0.8358, Acc.railing: 0.5115, Acc.cushion: 0.7167, Acc.base: 0.5008, Acc.box: 0.3480, Acc.column: 0.5378, Acc.signboard: 0.5263, Acc.chest of drawers: 0.6183, Acc.counter: 0.4551, Acc.sand: 0.5011, Acc.sink: 0.7919, Acc.skyscraper: 0.5283, Acc.fireplace: 0.9053, Acc.refrigerator: 0.9039, Acc.grandstand: 0.6475, Acc.path: 0.2860, Acc.stairs: 0.4546, Acc.runway: 0.9269, Acc.case: 0.6460, Acc.pool table: 0.9667, Acc.pillow: 0.7308, Acc.screen door: 0.6306, Acc.stairway: 0.3911, Acc.river: 0.2337, Acc.bridge: 0.8721, Acc.bookcase: 0.6048, Acc.blind: 0.4854, Acc.coffee table: 0.8279, Acc.toilet: 0.8876, Acc.flower: 0.5424, Acc.book: 0.6379, Acc.hill: 0.1509, Acc.bench: 0.5127, Acc.countertop: 0.7758, Acc.stove: 0.8088, Acc.palm: 0.7482, Acc.kitchen island: 0.8606, Acc.computer: 0.8148, Acc.swivel chair: 0.7208, Acc.boat: 0.5432, Acc.bar: 0.6550, Acc.arcade machine: 0.6988, Acc.hovel: 0.5769, Acc.bus: 0.9679, Acc.towel: 0.7743, Acc.light: 0.6306, Acc.truck: 0.5330, Acc.tower: 0.4137, Acc.chandelier: 0.8194, Acc.awning: 0.2969, Acc.streetlight: 0.3460, Acc.booth: 0.5019, Acc.television receiver: 0.7823, Acc.airplane: 0.6646, Acc.dirt track: 0.0000, Acc.apparel: 0.7077, Acc.pole: 0.3990, Acc.land: 0.0690, Acc.bannister: 0.2015, Acc.escalator: 0.4170, Acc.ottoman: 0.5985, Acc.bottle: 0.5888, Acc.buffet: 0.5955, Acc.poster: 0.3947, Acc.stage: 0.2936, Acc.van: 0.6414, Acc.ship: 0.3731, Acc.fountain: 0.2171, Acc.conveyer belt: 0.9077, Acc.canopy: 0.4219, Acc.washer: 0.7890, Acc.plaything: 0.4607, Acc.swimming pool: 0.8977, Acc.stool: 0.4850, Acc.barrel: 0.6507, Acc.basket: 0.3949, Acc.waterfall: 0.8299, Acc.tent: 0.9867, Acc.bag: 0.2116, Acc.minibike: 0.8557, Acc.cradle: 0.9735, Acc.oven: 0.5707, Acc.ball: 0.4975, Acc.food: 0.3259, Acc.step: 0.1416, Acc.tank: 0.4143, Acc.trade name: 0.3358, Acc.microwave: 0.9180, Acc.pot: 0.5475, Acc.animal: 0.6642, Acc.bicycle: 0.7629, Acc.lake: 0.7185, Acc.dishwasher: 0.7113, Acc.screen: 0.8899, Acc.blanket: 0.1346, Acc.sculpture: 0.7730, Acc.hood: 0.6934, Acc.sconce: 0.4734, Acc.vase: 0.5536, Acc.traffic light: 0.5579, Acc.tray: 0.1525, Acc.ashcan: 0.4956, Acc.fan: 0.7821, Acc.pier: 0.8833, Acc.crt screen: 0.2094, Acc.plate: 0.6516, Acc.monitor: 0.1220, Acc.bulletin board: 0.7122, Acc.shower: 0.0049, Acc.radiator: 0.7097, Acc.glass: 0.1472, Acc.clock: 0.4487, Acc.flag: 0.4373
2023-11-27 07:28:16,492 - mmseg - INFO - Iter [80050/160000]	lr: 2.998e-05, eta: 17:41:19, time: 2.602, data_time: 1.856, memory: 21695, decode.loss_ce: 0.2212, decode.acc_seg: 91.0680, aux.loss_ce: 0.1040, aux.acc_seg: 89.6247, loss: 0.3251
2023-11-27 07:28:56,552 - mmseg - INFO - Iter [80100/160000]	lr: 2.996e-05, eta: 17:40:39, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2335, decode.acc_seg: 90.5406, aux.loss_ce: 0.1104, aux.acc_seg: 89.1815, loss: 0.3439
2023-11-27 07:29:34,904 - mmseg - INFO - Iter [80150/160000]	lr: 2.994e-05, eta: 17:39:58, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2180, decode.acc_seg: 90.8214, aux.loss_ce: 0.1030, aux.acc_seg: 89.7387, loss: 0.3211
2023-11-27 07:30:14,685 - mmseg - INFO - Iter [80200/160000]	lr: 2.993e-05, eta: 17:39:18, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2228, decode.acc_seg: 90.5821, aux.loss_ce: 0.1051, aux.acc_seg: 89.4147, loss: 0.3279
2023-11-27 07:30:54,513 - mmseg - INFO - Iter [80250/160000]	lr: 2.991e-05, eta: 17:38:38, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2568, decode.acc_seg: 89.5791, aux.loss_ce: 0.1204, aux.acc_seg: 88.2967, loss: 0.3771
2023-11-27 07:31:34,760 - mmseg - INFO - Iter [80300/160000]	lr: 2.989e-05, eta: 17:37:59, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2350, decode.acc_seg: 89.9835, aux.loss_ce: 0.1092, aux.acc_seg: 88.8524, loss: 0.3442
2023-11-27 07:32:14,184 - mmseg - INFO - Iter [80350/160000]	lr: 2.987e-05, eta: 17:37:19, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2255, decode.acc_seg: 90.5903, aux.loss_ce: 0.1058, aux.acc_seg: 89.4377, loss: 0.3313
2023-11-27 07:32:52,621 - mmseg - INFO - Iter [80400/160000]	lr: 2.985e-05, eta: 17:36:38, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2273, decode.acc_seg: 90.9252, aux.loss_ce: 0.1102, aux.acc_seg: 89.3021, loss: 0.3375
2023-11-27 07:33:31,404 - mmseg - INFO - Iter [80450/160000]	lr: 2.983e-05, eta: 17:35:57, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2202, decode.acc_seg: 90.9054, aux.loss_ce: 0.1036, aux.acc_seg: 89.7563, loss: 0.3238
2023-11-27 07:34:12,565 - mmseg - INFO - Iter [80500/160000]	lr: 2.981e-05, eta: 17:35:18, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2336, decode.acc_seg: 90.2653, aux.loss_ce: 0.1125, aux.acc_seg: 88.9425, loss: 0.3460
2023-11-27 07:34:53,727 - mmseg - INFO - Iter [80550/160000]	lr: 2.979e-05, eta: 17:34:40, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2468, decode.acc_seg: 89.6383, aux.loss_ce: 0.1180, aux.acc_seg: 88.1487, loss: 0.3648
2023-11-27 07:35:33,844 - mmseg - INFO - Iter [80600/160000]	lr: 2.978e-05, eta: 17:34:00, time: 0.804, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2287, decode.acc_seg: 90.3517, aux.loss_ce: 0.1055, aux.acc_seg: 89.3320, loss: 0.3342
2023-11-27 07:36:13,106 - mmseg - INFO - Iter [80650/160000]	lr: 2.976e-05, eta: 17:33:20, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2370, decode.acc_seg: 90.3416, aux.loss_ce: 0.1125, aux.acc_seg: 89.0526, loss: 0.3495
2023-11-27 07:36:54,082 - mmseg - INFO - Iter [80700/160000]	lr: 2.974e-05, eta: 17:32:41, time: 0.820, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2301, decode.acc_seg: 90.3802, aux.loss_ce: 0.1085, aux.acc_seg: 89.0444, loss: 0.3386
2023-11-27 07:37:31,018 - mmseg - INFO - Iter [80750/160000]	lr: 2.972e-05, eta: 17:31:59, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2302, decode.acc_seg: 90.5249, aux.loss_ce: 0.1091, aux.acc_seg: 89.2771, loss: 0.3393
2023-11-27 07:38:07,757 - mmseg - INFO - Iter [80800/160000]	lr: 2.970e-05, eta: 17:31:16, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2392, decode.acc_seg: 90.2528, aux.loss_ce: 0.1118, aux.acc_seg: 88.9366, loss: 0.3510
2023-11-27 07:38:46,797 - mmseg - INFO - Iter [80850/160000]	lr: 2.968e-05, eta: 17:30:35, time: 0.781, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2351, decode.acc_seg: 90.2890, aux.loss_ce: 0.1129, aux.acc_seg: 88.7096, loss: 0.3480
2023-11-27 07:39:26,413 - mmseg - INFO - Iter [80900/160000]	lr: 2.966e-05, eta: 17:29:55, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2280, decode.acc_seg: 90.7620, aux.loss_ce: 0.1066, aux.acc_seg: 89.3976, loss: 0.3345
2023-11-27 07:40:04,419 - mmseg - INFO - Iter [80950/160000]	lr: 2.964e-05, eta: 17:29:14, time: 0.760, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2315, decode.acc_seg: 90.4487, aux.loss_ce: 0.1093, aux.acc_seg: 89.1937, loss: 0.3408
2023-11-27 07:40:43,654 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 07:40:43,654 - mmseg - INFO - Iter [81000/160000]	lr: 2.963e-05, eta: 17:28:33, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2332, decode.acc_seg: 90.4336, aux.loss_ce: 0.1096, aux.acc_seg: 89.1637, loss: 0.3428
2023-11-27 07:41:21,108 - mmseg - INFO - Iter [81050/160000]	lr: 2.961e-05, eta: 17:27:51, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2337, decode.acc_seg: 90.6381, aux.loss_ce: 0.1111, aux.acc_seg: 89.1263, loss: 0.3448
2023-11-27 07:41:58,414 - mmseg - INFO - Iter [81100/160000]	lr: 2.959e-05, eta: 17:27:09, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2163, decode.acc_seg: 90.9589, aux.loss_ce: 0.1038, aux.acc_seg: 89.6798, loss: 0.3201
2023-11-27 07:42:38,494 - mmseg - INFO - Iter [81150/160000]	lr: 2.957e-05, eta: 17:26:29, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2324, decode.acc_seg: 90.4474, aux.loss_ce: 0.1114, aux.acc_seg: 88.8123, loss: 0.3439
2023-11-27 07:43:18,475 - mmseg - INFO - Iter [81200/160000]	lr: 2.955e-05, eta: 17:25:49, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2298, decode.acc_seg: 90.1378, aux.loss_ce: 0.1104, aux.acc_seg: 88.6784, loss: 0.3402
2023-11-27 07:43:56,774 - mmseg - INFO - Iter [81250/160000]	lr: 2.953e-05, eta: 17:25:08, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2344, decode.acc_seg: 90.5015, aux.loss_ce: 0.1114, aux.acc_seg: 89.1248, loss: 0.3459
2023-11-27 07:44:34,794 - mmseg - INFO - Iter [81300/160000]	lr: 2.951e-05, eta: 17:24:27, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2395, decode.acc_seg: 90.0994, aux.loss_ce: 0.1096, aux.acc_seg: 88.9204, loss: 0.3491
2023-11-27 07:45:15,492 - mmseg - INFO - Iter [81350/160000]	lr: 2.949e-05, eta: 17:23:48, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2268, decode.acc_seg: 90.5583, aux.loss_ce: 0.1081, aux.acc_seg: 89.0625, loss: 0.3350
2023-11-27 07:45:56,095 - mmseg - INFO - Iter [81400/160000]	lr: 2.948e-05, eta: 17:23:09, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2402, decode.acc_seg: 90.3959, aux.loss_ce: 0.1090, aux.acc_seg: 89.2538, loss: 0.3492
2023-11-27 07:46:36,102 - mmseg - INFO - Iter [81450/160000]	lr: 2.946e-05, eta: 17:22:29, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2347, decode.acc_seg: 90.1890, aux.loss_ce: 0.1106, aux.acc_seg: 88.8795, loss: 0.3453
2023-11-27 07:47:16,472 - mmseg - INFO - Iter [81500/160000]	lr: 2.944e-05, eta: 17:21:50, time: 0.807, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2286, decode.acc_seg: 90.6545, aux.loss_ce: 0.1068, aux.acc_seg: 89.3113, loss: 0.3354
2023-11-27 07:47:56,871 - mmseg - INFO - Iter [81550/160000]	lr: 2.942e-05, eta: 17:21:10, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2322, decode.acc_seg: 90.4359, aux.loss_ce: 0.1086, aux.acc_seg: 89.4004, loss: 0.3408
2023-11-27 07:48:34,821 - mmseg - INFO - Iter [81600/160000]	lr: 2.940e-05, eta: 17:20:29, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2249, decode.acc_seg: 90.7701, aux.loss_ce: 0.1047, aux.acc_seg: 89.3564, loss: 0.3296
2023-11-27 07:49:11,928 - mmseg - INFO - Iter [81650/160000]	lr: 2.938e-05, eta: 17:19:46, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2235, decode.acc_seg: 90.7554, aux.loss_ce: 0.1077, aux.acc_seg: 89.1954, loss: 0.3312
2023-11-27 07:49:50,159 - mmseg - INFO - Iter [81700/160000]	lr: 2.936e-05, eta: 17:19:05, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2329, decode.acc_seg: 90.0557, aux.loss_ce: 0.1106, aux.acc_seg: 88.6910, loss: 0.3436
2023-11-27 07:50:28,189 - mmseg - INFO - Iter [81750/160000]	lr: 2.934e-05, eta: 17:18:24, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2366, decode.acc_seg: 89.9091, aux.loss_ce: 0.1125, aux.acc_seg: 88.4915, loss: 0.3491
2023-11-27 07:51:06,486 - mmseg - INFO - Iter [81800/160000]	lr: 2.933e-05, eta: 17:17:42, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2265, decode.acc_seg: 90.6444, aux.loss_ce: 0.1051, aux.acc_seg: 89.4165, loss: 0.3316
2023-11-27 07:51:46,568 - mmseg - INFO - Iter [81850/160000]	lr: 2.931e-05, eta: 17:17:03, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2220, decode.acc_seg: 90.8707, aux.loss_ce: 0.1040, aux.acc_seg: 89.5057, loss: 0.3260
2023-11-27 07:52:26,888 - mmseg - INFO - Iter [81900/160000]	lr: 2.929e-05, eta: 17:16:23, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2384, decode.acc_seg: 90.0961, aux.loss_ce: 0.1103, aux.acc_seg: 88.8275, loss: 0.3486
2023-11-27 07:53:07,925 - mmseg - INFO - Iter [81950/160000]	lr: 2.927e-05, eta: 17:15:45, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2467, decode.acc_seg: 89.9779, aux.loss_ce: 0.1136, aux.acc_seg: 88.9001, loss: 0.3603
2023-11-27 07:53:49,039 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 07:53:49,039 - mmseg - INFO - Iter [82000/160000]	lr: 2.925e-05, eta: 17:15:06, time: 0.823, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2380, decode.acc_seg: 90.1547, aux.loss_ce: 0.1113, aux.acc_seg: 88.8078, loss: 0.3493
2023-11-27 07:54:28,548 - mmseg - INFO - Iter [82050/160000]	lr: 2.923e-05, eta: 17:14:26, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2390, decode.acc_seg: 90.3005, aux.loss_ce: 0.1132, aux.acc_seg: 89.0808, loss: 0.3522
2023-11-27 07:55:08,402 - mmseg - INFO - Iter [82100/160000]	lr: 2.921e-05, eta: 17:13:46, time: 0.797, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2366, decode.acc_seg: 90.1965, aux.loss_ce: 0.1138, aux.acc_seg: 88.7026, loss: 0.3504
2023-11-27 07:55:49,394 - mmseg - INFO - Iter [82150/160000]	lr: 2.919e-05, eta: 17:13:08, time: 0.819, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2253, decode.acc_seg: 90.5415, aux.loss_ce: 0.1059, aux.acc_seg: 89.3209, loss: 0.3312
2023-11-27 07:56:29,866 - mmseg - INFO - Iter [82200/160000]	lr: 2.918e-05, eta: 17:12:28, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2205, decode.acc_seg: 90.6110, aux.loss_ce: 0.1038, aux.acc_seg: 89.4231, loss: 0.3243
2023-11-27 07:57:09,822 - mmseg - INFO - Iter [82250/160000]	lr: 2.916e-05, eta: 17:11:49, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2412, decode.acc_seg: 90.1302, aux.loss_ce: 0.1144, aux.acc_seg: 88.8147, loss: 0.3557
2023-11-27 07:57:50,329 - mmseg - INFO - Iter [82300/160000]	lr: 2.914e-05, eta: 17:11:10, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2177, decode.acc_seg: 90.7220, aux.loss_ce: 0.1043, aux.acc_seg: 89.3697, loss: 0.3220
2023-11-27 07:58:30,319 - mmseg - INFO - Iter [82350/160000]	lr: 2.912e-05, eta: 17:10:30, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2134, decode.acc_seg: 90.9624, aux.loss_ce: 0.1012, aux.acc_seg: 89.6056, loss: 0.3146
2023-11-27 07:59:10,656 - mmseg - INFO - Iter [82400/160000]	lr: 2.910e-05, eta: 17:09:51, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2450, decode.acc_seg: 90.1239, aux.loss_ce: 0.1154, aux.acc_seg: 88.8115, loss: 0.3604
2023-11-27 07:59:49,838 - mmseg - INFO - Iter [82450/160000]	lr: 2.908e-05, eta: 17:09:10, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2326, decode.acc_seg: 90.1923, aux.loss_ce: 0.1094, aux.acc_seg: 89.0579, loss: 0.3420
2023-11-27 08:00:30,143 - mmseg - INFO - Iter [82500/160000]	lr: 2.906e-05, eta: 17:08:31, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2320, decode.acc_seg: 90.7263, aux.loss_ce: 0.1096, aux.acc_seg: 89.3505, loss: 0.3416
2023-11-27 08:01:09,516 - mmseg - INFO - Iter [82550/160000]	lr: 2.904e-05, eta: 17:07:51, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2352, decode.acc_seg: 90.2607, aux.loss_ce: 0.1106, aux.acc_seg: 89.0228, loss: 0.3459
2023-11-27 08:01:49,510 - mmseg - INFO - Iter [82600/160000]	lr: 2.903e-05, eta: 17:07:11, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2305, decode.acc_seg: 90.3770, aux.loss_ce: 0.1077, aux.acc_seg: 89.1400, loss: 0.3381
2023-11-27 08:02:30,251 - mmseg - INFO - Iter [82650/160000]	lr: 2.901e-05, eta: 17:06:32, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2289, decode.acc_seg: 90.6219, aux.loss_ce: 0.1073, aux.acc_seg: 89.4304, loss: 0.3362
2023-11-27 08:03:11,061 - mmseg - INFO - Iter [82700/160000]	lr: 2.899e-05, eta: 17:05:53, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2410, decode.acc_seg: 89.9831, aux.loss_ce: 0.1144, aux.acc_seg: 88.5705, loss: 0.3554
2023-11-27 08:03:50,051 - mmseg - INFO - Iter [82750/160000]	lr: 2.897e-05, eta: 17:05:13, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2313, decode.acc_seg: 90.4908, aux.loss_ce: 0.1081, aux.acc_seg: 89.1477, loss: 0.3394
2023-11-27 08:04:28,630 - mmseg - INFO - Iter [82800/160000]	lr: 2.895e-05, eta: 17:04:32, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2290, decode.acc_seg: 90.4006, aux.loss_ce: 0.1088, aux.acc_seg: 88.9865, loss: 0.3379
2023-11-27 08:05:09,309 - mmseg - INFO - Iter [82850/160000]	lr: 2.893e-05, eta: 17:03:53, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2266, decode.acc_seg: 90.5726, aux.loss_ce: 0.1069, aux.acc_seg: 89.3674, loss: 0.3335
2023-11-27 08:05:49,480 - mmseg - INFO - Iter [82900/160000]	lr: 2.891e-05, eta: 17:03:13, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2381, decode.acc_seg: 90.1189, aux.loss_ce: 0.1101, aux.acc_seg: 89.0871, loss: 0.3481
2023-11-27 08:06:29,362 - mmseg - INFO - Iter [82950/160000]	lr: 2.889e-05, eta: 17:02:33, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2249, decode.acc_seg: 90.8073, aux.loss_ce: 0.1065, aux.acc_seg: 89.5891, loss: 0.3314
2023-11-27 08:07:09,477 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 08:07:09,477 - mmseg - INFO - Iter [83000/160000]	lr: 2.888e-05, eta: 17:01:54, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2383, decode.acc_seg: 90.0584, aux.loss_ce: 0.1106, aux.acc_seg: 88.8211, loss: 0.3489
2023-11-27 08:07:49,347 - mmseg - INFO - Iter [83050/160000]	lr: 2.886e-05, eta: 17:01:14, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2251, decode.acc_seg: 90.6246, aux.loss_ce: 0.1050, aux.acc_seg: 89.4245, loss: 0.3301
2023-11-27 08:08:29,265 - mmseg - INFO - Iter [83100/160000]	lr: 2.884e-05, eta: 17:00:34, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2261, decode.acc_seg: 90.8999, aux.loss_ce: 0.1071, aux.acc_seg: 89.5413, loss: 0.3332
2023-11-27 08:09:08,626 - mmseg - INFO - Iter [83150/160000]	lr: 2.882e-05, eta: 16:59:54, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2231, decode.acc_seg: 90.6080, aux.loss_ce: 0.1057, aux.acc_seg: 89.0206, loss: 0.3288
2023-11-27 08:09:48,748 - mmseg - INFO - Iter [83200/160000]	lr: 2.880e-05, eta: 16:59:15, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2243, decode.acc_seg: 90.7911, aux.loss_ce: 0.1068, aux.acc_seg: 89.3950, loss: 0.3311
2023-11-27 08:10:28,894 - mmseg - INFO - Iter [83250/160000]	lr: 2.878e-05, eta: 16:58:35, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2337, decode.acc_seg: 90.3527, aux.loss_ce: 0.1102, aux.acc_seg: 89.1037, loss: 0.3439
2023-11-27 08:11:09,798 - mmseg - INFO - Iter [83300/160000]	lr: 2.876e-05, eta: 16:57:56, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2234, decode.acc_seg: 90.5941, aux.loss_ce: 0.1055, aux.acc_seg: 89.4657, loss: 0.3289
2023-11-27 08:11:49,221 - mmseg - INFO - Iter [83350/160000]	lr: 2.874e-05, eta: 16:57:16, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2278, decode.acc_seg: 90.1968, aux.loss_ce: 0.1073, aux.acc_seg: 88.9636, loss: 0.3350
2023-11-27 08:12:29,291 - mmseg - INFO - Iter [83400/160000]	lr: 2.873e-05, eta: 16:56:37, time: 0.800, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2211, decode.acc_seg: 90.8077, aux.loss_ce: 0.1067, aux.acc_seg: 89.4327, loss: 0.3278
2023-11-27 08:13:09,551 - mmseg - INFO - Iter [83450/160000]	lr: 2.871e-05, eta: 16:55:57, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 90.3935, aux.loss_ce: 0.1041, aux.acc_seg: 88.9626, loss: 0.3208
2023-11-27 08:13:46,702 - mmseg - INFO - Iter [83500/160000]	lr: 2.869e-05, eta: 16:55:15, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2153, decode.acc_seg: 91.0316, aux.loss_ce: 0.1022, aux.acc_seg: 89.9042, loss: 0.3175
2023-11-27 08:14:24,931 - mmseg - INFO - Iter [83550/160000]	lr: 2.867e-05, eta: 16:54:34, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2351, decode.acc_seg: 90.0567, aux.loss_ce: 0.1121, aux.acc_seg: 88.6639, loss: 0.3472
2023-11-27 08:15:05,881 - mmseg - INFO - Iter [83600/160000]	lr: 2.865e-05, eta: 16:53:55, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2429, decode.acc_seg: 89.8817, aux.loss_ce: 0.1137, aux.acc_seg: 88.5763, loss: 0.3566
2023-11-27 08:15:47,101 - mmseg - INFO - Iter [83650/160000]	lr: 2.863e-05, eta: 16:53:16, time: 0.825, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2300, decode.acc_seg: 90.5020, aux.loss_ce: 0.1065, aux.acc_seg: 89.3762, loss: 0.3366
2023-11-27 08:16:27,312 - mmseg - INFO - Iter [83700/160000]	lr: 2.861e-05, eta: 16:52:37, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2242, decode.acc_seg: 90.6344, aux.loss_ce: 0.1068, aux.acc_seg: 89.4876, loss: 0.3310
2023-11-27 08:17:07,532 - mmseg - INFO - Iter [83750/160000]	lr: 2.859e-05, eta: 16:51:57, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2228, decode.acc_seg: 90.5732, aux.loss_ce: 0.1061, aux.acc_seg: 89.0759, loss: 0.3288
2023-11-27 08:17:47,916 - mmseg - INFO - Iter [83800/160000]	lr: 2.858e-05, eta: 16:51:18, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2297, decode.acc_seg: 90.1631, aux.loss_ce: 0.1089, aux.acc_seg: 88.8325, loss: 0.3386
2023-11-27 08:18:28,125 - mmseg - INFO - Iter [83850/160000]	lr: 2.856e-05, eta: 16:50:39, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2367, decode.acc_seg: 90.4194, aux.loss_ce: 0.1101, aux.acc_seg: 89.1113, loss: 0.3468
2023-11-27 08:19:08,387 - mmseg - INFO - Iter [83900/160000]	lr: 2.854e-05, eta: 16:49:59, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2263, decode.acc_seg: 90.4249, aux.loss_ce: 0.1062, aux.acc_seg: 89.2823, loss: 0.3326
2023-11-27 08:19:47,511 - mmseg - INFO - Iter [83950/160000]	lr: 2.852e-05, eta: 16:49:19, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2270, decode.acc_seg: 90.6500, aux.loss_ce: 0.1056, aux.acc_seg: 89.4704, loss: 0.3326
2023-11-27 08:20:25,658 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 08:20:25,658 - mmseg - INFO - Iter [84000/160000]	lr: 2.850e-05, eta: 16:48:37, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2258, decode.acc_seg: 90.7233, aux.loss_ce: 0.1070, aux.acc_seg: 89.4147, loss: 0.3328
2023-11-27 08:21:05,493 - mmseg - INFO - Iter [84050/160000]	lr: 2.848e-05, eta: 16:47:58, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2299, decode.acc_seg: 90.5137, aux.loss_ce: 0.1083, aux.acc_seg: 89.1638, loss: 0.3382
2023-11-27 08:21:44,535 - mmseg - INFO - Iter [84100/160000]	lr: 2.846e-05, eta: 16:47:17, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2319, decode.acc_seg: 90.3840, aux.loss_ce: 0.1061, aux.acc_seg: 89.3035, loss: 0.3380
2023-11-27 08:22:24,940 - mmseg - INFO - Iter [84150/160000]	lr: 2.844e-05, eta: 16:46:38, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2343, decode.acc_seg: 90.4245, aux.loss_ce: 0.1090, aux.acc_seg: 89.1991, loss: 0.3432
2023-11-27 08:23:05,401 - mmseg - INFO - Iter [84200/160000]	lr: 2.843e-05, eta: 16:45:59, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2437, decode.acc_seg: 89.9126, aux.loss_ce: 0.1165, aux.acc_seg: 88.3858, loss: 0.3603
2023-11-27 08:23:44,266 - mmseg - INFO - Iter [84250/160000]	lr: 2.841e-05, eta: 16:45:18, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2341, decode.acc_seg: 90.3333, aux.loss_ce: 0.1116, aux.acc_seg: 89.0039, loss: 0.3456
2023-11-27 08:24:21,648 - mmseg - INFO - Iter [84300/160000]	lr: 2.839e-05, eta: 16:44:36, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2307, decode.acc_seg: 90.2635, aux.loss_ce: 0.1102, aux.acc_seg: 88.8760, loss: 0.3409
2023-11-27 08:24:58,643 - mmseg - INFO - Iter [84350/160000]	lr: 2.837e-05, eta: 16:43:54, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2245, decode.acc_seg: 90.7636, aux.loss_ce: 0.1045, aux.acc_seg: 89.6227, loss: 0.3290
2023-11-27 08:25:36,209 - mmseg - INFO - Iter [84400/160000]	lr: 2.835e-05, eta: 16:43:12, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2378, decode.acc_seg: 90.5432, aux.loss_ce: 0.1115, aux.acc_seg: 89.1106, loss: 0.3493
2023-11-27 08:26:16,255 - mmseg - INFO - Iter [84450/160000]	lr: 2.833e-05, eta: 16:42:32, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2158, decode.acc_seg: 90.8071, aux.loss_ce: 0.1033, aux.acc_seg: 89.4727, loss: 0.3191
2023-11-27 08:26:56,201 - mmseg - INFO - Iter [84500/160000]	lr: 2.831e-05, eta: 16:41:53, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2395, decode.acc_seg: 90.0830, aux.loss_ce: 0.1118, aux.acc_seg: 88.8758, loss: 0.3512
2023-11-27 08:27:32,830 - mmseg - INFO - Iter [84550/160000]	lr: 2.829e-05, eta: 16:41:10, time: 0.732, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2360, decode.acc_seg: 90.3246, aux.loss_ce: 0.1120, aux.acc_seg: 88.9634, loss: 0.3479
2023-11-27 08:28:12,221 - mmseg - INFO - Iter [84600/160000]	lr: 2.828e-05, eta: 16:40:30, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2327, decode.acc_seg: 90.0948, aux.loss_ce: 0.1103, aux.acc_seg: 88.9057, loss: 0.3430
2023-11-27 08:28:54,156 - mmseg - INFO - Iter [84650/160000]	lr: 2.826e-05, eta: 16:39:52, time: 0.839, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2419, decode.acc_seg: 90.0177, aux.loss_ce: 0.1134, aux.acc_seg: 88.7392, loss: 0.3553
2023-11-27 08:29:34,052 - mmseg - INFO - Iter [84700/160000]	lr: 2.824e-05, eta: 16:39:12, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2187, decode.acc_seg: 90.8288, aux.loss_ce: 0.1037, aux.acc_seg: 89.5893, loss: 0.3224
2023-11-27 08:30:10,605 - mmseg - INFO - Iter [84750/160000]	lr: 2.822e-05, eta: 16:38:29, time: 0.731, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2298, decode.acc_seg: 90.5691, aux.loss_ce: 0.1069, aux.acc_seg: 89.4814, loss: 0.3366
2023-11-27 08:30:47,674 - mmseg - INFO - Iter [84800/160000]	lr: 2.820e-05, eta: 16:37:47, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2369, decode.acc_seg: 90.1501, aux.loss_ce: 0.1127, aux.acc_seg: 88.7345, loss: 0.3496
2023-11-27 08:31:25,599 - mmseg - INFO - Iter [84850/160000]	lr: 2.818e-05, eta: 16:37:06, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2338, decode.acc_seg: 90.5447, aux.loss_ce: 0.1100, aux.acc_seg: 89.3895, loss: 0.3438
2023-11-27 08:32:04,112 - mmseg - INFO - Iter [84900/160000]	lr: 2.816e-05, eta: 16:36:25, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2140, decode.acc_seg: 90.9512, aux.loss_ce: 0.1021, aux.acc_seg: 89.6270, loss: 0.3161
2023-11-27 08:32:41,847 - mmseg - INFO - Iter [84950/160000]	lr: 2.814e-05, eta: 16:35:43, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2260, decode.acc_seg: 90.7949, aux.loss_ce: 0.1068, aux.acc_seg: 89.5717, loss: 0.3328
2023-11-27 08:33:20,104 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 08:33:20,104 - mmseg - INFO - Iter [85000/160000]	lr: 2.813e-05, eta: 16:35:02, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2425, decode.acc_seg: 90.2765, aux.loss_ce: 0.1140, aux.acc_seg: 88.9968, loss: 0.3565
2023-11-27 08:33:58,107 - mmseg - INFO - Iter [85050/160000]	lr: 2.811e-05, eta: 16:34:21, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2297, decode.acc_seg: 90.2462, aux.loss_ce: 0.1092, aux.acc_seg: 88.7677, loss: 0.3389
2023-11-27 08:34:39,911 - mmseg - INFO - Iter [85100/160000]	lr: 2.809e-05, eta: 16:33:42, time: 0.836, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2320, decode.acc_seg: 90.4542, aux.loss_ce: 0.1090, aux.acc_seg: 89.2285, loss: 0.3410
2023-11-27 08:35:19,648 - mmseg - INFO - Iter [85150/160000]	lr: 2.807e-05, eta: 16:33:03, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2148, decode.acc_seg: 90.8833, aux.loss_ce: 0.1025, aux.acc_seg: 89.5593, loss: 0.3173
2023-11-27 08:35:59,979 - mmseg - INFO - Iter [85200/160000]	lr: 2.805e-05, eta: 16:32:23, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2274, decode.acc_seg: 90.5395, aux.loss_ce: 0.1095, aux.acc_seg: 89.1216, loss: 0.3369
2023-11-27 08:36:39,884 - mmseg - INFO - Iter [85250/160000]	lr: 2.803e-05, eta: 16:31:44, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2267, decode.acc_seg: 90.4241, aux.loss_ce: 0.1082, aux.acc_seg: 89.0859, loss: 0.3349
2023-11-27 08:37:19,969 - mmseg - INFO - Iter [85300/160000]	lr: 2.801e-05, eta: 16:31:04, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2379, decode.acc_seg: 90.5046, aux.loss_ce: 0.1096, aux.acc_seg: 89.3529, loss: 0.3475
2023-11-27 08:38:00,074 - mmseg - INFO - Iter [85350/160000]	lr: 2.799e-05, eta: 16:30:24, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2175, decode.acc_seg: 90.7021, aux.loss_ce: 0.1050, aux.acc_seg: 89.2746, loss: 0.3226
2023-11-27 08:38:40,357 - mmseg - INFO - Iter [85400/160000]	lr: 2.798e-05, eta: 16:29:45, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2252, decode.acc_seg: 90.5164, aux.loss_ce: 0.1075, aux.acc_seg: 89.1248, loss: 0.3327
2023-11-27 08:39:17,315 - mmseg - INFO - Iter [85450/160000]	lr: 2.796e-05, eta: 16:29:03, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2420, decode.acc_seg: 90.1159, aux.loss_ce: 0.1136, aux.acc_seg: 88.8209, loss: 0.3556
2023-11-27 08:39:55,733 - mmseg - INFO - Iter [85500/160000]	lr: 2.794e-05, eta: 16:28:22, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2247, decode.acc_seg: 90.6322, aux.loss_ce: 0.1068, aux.acc_seg: 89.3457, loss: 0.3315
2023-11-27 08:40:35,263 - mmseg - INFO - Iter [85550/160000]	lr: 2.792e-05, eta: 16:27:42, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2241, decode.acc_seg: 90.7809, aux.loss_ce: 0.1067, aux.acc_seg: 89.3640, loss: 0.3309
2023-11-27 08:41:12,370 - mmseg - INFO - Iter [85600/160000]	lr: 2.790e-05, eta: 16:27:00, time: 0.742, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2329, decode.acc_seg: 90.1756, aux.loss_ce: 0.1097, aux.acc_seg: 88.8845, loss: 0.3425
2023-11-27 08:41:52,860 - mmseg - INFO - Iter [85650/160000]	lr: 2.788e-05, eta: 16:26:20, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2267, decode.acc_seg: 90.6089, aux.loss_ce: 0.1078, aux.acc_seg: 89.1871, loss: 0.3345
2023-11-27 08:42:31,167 - mmseg - INFO - Iter [85700/160000]	lr: 2.786e-05, eta: 16:25:39, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 90.7186, aux.loss_ce: 0.1051, aux.acc_seg: 89.0688, loss: 0.3219
2023-11-27 08:43:10,419 - mmseg - INFO - Iter [85750/160000]	lr: 2.784e-05, eta: 16:24:59, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2545, decode.acc_seg: 89.5933, aux.loss_ce: 0.1185, aux.acc_seg: 88.1985, loss: 0.3730
2023-11-27 08:43:48,059 - mmseg - INFO - Iter [85800/160000]	lr: 2.783e-05, eta: 16:24:17, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2357, decode.acc_seg: 90.3364, aux.loss_ce: 0.1120, aux.acc_seg: 89.1142, loss: 0.3477
2023-11-27 08:44:25,308 - mmseg - INFO - Iter [85850/160000]	lr: 2.781e-05, eta: 16:23:35, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2106, decode.acc_seg: 91.1392, aux.loss_ce: 0.1011, aux.acc_seg: 89.8330, loss: 0.3117
2023-11-27 08:45:07,372 - mmseg - INFO - Iter [85900/160000]	lr: 2.779e-05, eta: 16:22:58, time: 0.842, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2283, decode.acc_seg: 90.5804, aux.loss_ce: 0.1097, aux.acc_seg: 89.1377, loss: 0.3379
2023-11-27 08:45:48,068 - mmseg - INFO - Iter [85950/160000]	lr: 2.777e-05, eta: 16:22:19, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2283, decode.acc_seg: 90.3323, aux.loss_ce: 0.1077, aux.acc_seg: 89.0640, loss: 0.3360
2023-11-27 08:46:28,707 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 08:46:28,707 - mmseg - INFO - Iter [86000/160000]	lr: 2.775e-05, eta: 16:21:39, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2429, decode.acc_seg: 90.2222, aux.loss_ce: 0.1157, aux.acc_seg: 88.9063, loss: 0.3585
2023-11-27 08:47:08,061 - mmseg - INFO - Iter [86050/160000]	lr: 2.773e-05, eta: 16:20:59, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2294, decode.acc_seg: 90.6270, aux.loss_ce: 0.1089, aux.acc_seg: 89.6104, loss: 0.3383
2023-11-27 08:47:46,098 - mmseg - INFO - Iter [86100/160000]	lr: 2.771e-05, eta: 16:20:18, time: 0.760, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2183, decode.acc_seg: 90.9270, aux.loss_ce: 0.1029, aux.acc_seg: 89.7120, loss: 0.3212
2023-11-27 08:48:23,981 - mmseg - INFO - Iter [86150/160000]	lr: 2.769e-05, eta: 16:19:37, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2327, decode.acc_seg: 90.2738, aux.loss_ce: 0.1096, aux.acc_seg: 89.0662, loss: 0.3423
2023-11-27 08:49:02,111 - mmseg - INFO - Iter [86200/160000]	lr: 2.768e-05, eta: 16:18:55, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2236, decode.acc_seg: 90.8108, aux.loss_ce: 0.1061, aux.acc_seg: 89.4446, loss: 0.3298
2023-11-27 08:49:41,375 - mmseg - INFO - Iter [86250/160000]	lr: 2.766e-05, eta: 16:18:15, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2163, decode.acc_seg: 90.8921, aux.loss_ce: 0.1018, aux.acc_seg: 89.5698, loss: 0.3180
2023-11-27 08:50:20,112 - mmseg - INFO - Iter [86300/160000]	lr: 2.764e-05, eta: 16:17:34, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2181, decode.acc_seg: 91.0401, aux.loss_ce: 0.1033, aux.acc_seg: 89.7809, loss: 0.3214
2023-11-27 08:50:57,413 - mmseg - INFO - Iter [86350/160000]	lr: 2.762e-05, eta: 16:16:53, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2252, decode.acc_seg: 90.6614, aux.loss_ce: 0.1065, aux.acc_seg: 89.3155, loss: 0.3318
2023-11-27 08:51:36,848 - mmseg - INFO - Iter [86400/160000]	lr: 2.760e-05, eta: 16:16:12, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2335, decode.acc_seg: 90.2103, aux.loss_ce: 0.1110, aux.acc_seg: 88.8766, loss: 0.3445
2023-11-27 08:52:17,527 - mmseg - INFO - Iter [86450/160000]	lr: 2.758e-05, eta: 16:15:33, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2351, decode.acc_seg: 90.3420, aux.loss_ce: 0.1106, aux.acc_seg: 89.0919, loss: 0.3458
2023-11-27 08:52:55,188 - mmseg - INFO - Iter [86500/160000]	lr: 2.756e-05, eta: 16:14:52, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2333, decode.acc_seg: 89.9347, aux.loss_ce: 0.1122, aux.acc_seg: 88.4233, loss: 0.3455
2023-11-27 08:53:32,336 - mmseg - INFO - Iter [86550/160000]	lr: 2.754e-05, eta: 16:14:10, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2309, decode.acc_seg: 90.4050, aux.loss_ce: 0.1084, aux.acc_seg: 89.1570, loss: 0.3393
2023-11-27 08:54:11,872 - mmseg - INFO - Iter [86600/160000]	lr: 2.753e-05, eta: 16:13:30, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2195, decode.acc_seg: 90.8272, aux.loss_ce: 0.1053, aux.acc_seg: 89.4534, loss: 0.3248
2023-11-27 08:54:51,191 - mmseg - INFO - Iter [86650/160000]	lr: 2.751e-05, eta: 16:12:50, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2273, decode.acc_seg: 90.2716, aux.loss_ce: 0.1061, aux.acc_seg: 88.9339, loss: 0.3334
2023-11-27 08:55:31,258 - mmseg - INFO - Iter [86700/160000]	lr: 2.749e-05, eta: 16:12:10, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2239, decode.acc_seg: 90.7702, aux.loss_ce: 0.1090, aux.acc_seg: 89.2910, loss: 0.3329
2023-11-27 08:56:10,857 - mmseg - INFO - Iter [86750/160000]	lr: 2.747e-05, eta: 16:11:30, time: 0.793, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 90.7395, aux.loss_ce: 0.1028, aux.acc_seg: 89.4431, loss: 0.3196
2023-11-27 08:56:49,262 - mmseg - INFO - Iter [86800/160000]	lr: 2.745e-05, eta: 16:10:49, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2299, decode.acc_seg: 90.4664, aux.loss_ce: 0.1059, aux.acc_seg: 89.4023, loss: 0.3358
2023-11-27 08:57:28,546 - mmseg - INFO - Iter [86850/160000]	lr: 2.743e-05, eta: 16:10:09, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2196, decode.acc_seg: 90.8006, aux.loss_ce: 0.1037, aux.acc_seg: 89.5318, loss: 0.3233
2023-11-27 08:58:07,635 - mmseg - INFO - Iter [86900/160000]	lr: 2.741e-05, eta: 16:09:29, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2246, decode.acc_seg: 90.5376, aux.loss_ce: 0.1069, aux.acc_seg: 89.1391, loss: 0.3315
2023-11-27 08:58:45,153 - mmseg - INFO - Iter [86950/160000]	lr: 2.739e-05, eta: 16:08:47, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2247, decode.acc_seg: 90.5100, aux.loss_ce: 0.1044, aux.acc_seg: 89.5447, loss: 0.3291
2023-11-27 08:59:23,943 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 08:59:23,943 - mmseg - INFO - Iter [87000/160000]	lr: 2.738e-05, eta: 16:08:06, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2231, decode.acc_seg: 90.7345, aux.loss_ce: 0.1075, aux.acc_seg: 89.4027, loss: 0.3306
2023-11-27 09:00:00,568 - mmseg - INFO - Iter [87050/160000]	lr: 2.736e-05, eta: 16:07:24, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2159, decode.acc_seg: 90.9826, aux.loss_ce: 0.1039, aux.acc_seg: 89.5808, loss: 0.3198
2023-11-27 09:00:37,869 - mmseg - INFO - Iter [87100/160000]	lr: 2.734e-05, eta: 16:06:42, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2273, decode.acc_seg: 90.3224, aux.loss_ce: 0.1090, aux.acc_seg: 89.0236, loss: 0.3363
2023-11-27 09:01:16,584 - mmseg - INFO - Iter [87150/160000]	lr: 2.732e-05, eta: 16:06:01, time: 0.774, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2278, decode.acc_seg: 90.4159, aux.loss_ce: 0.1081, aux.acc_seg: 89.1076, loss: 0.3359
2023-11-27 09:01:55,322 - mmseg - INFO - Iter [87200/160000]	lr: 2.730e-05, eta: 16:05:21, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2208, decode.acc_seg: 90.6721, aux.loss_ce: 0.1063, aux.acc_seg: 89.1925, loss: 0.3271
2023-11-27 09:02:35,743 - mmseg - INFO - Iter [87250/160000]	lr: 2.728e-05, eta: 16:04:41, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2223, decode.acc_seg: 90.7052, aux.loss_ce: 0.1037, aux.acc_seg: 89.5142, loss: 0.3260
2023-11-27 09:03:14,943 - mmseg - INFO - Iter [87300/160000]	lr: 2.726e-05, eta: 16:04:01, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2154, decode.acc_seg: 91.0524, aux.loss_ce: 0.1017, aux.acc_seg: 89.7761, loss: 0.3171
2023-11-27 09:03:51,817 - mmseg - INFO - Iter [87350/160000]	lr: 2.724e-05, eta: 16:03:19, time: 0.737, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2129, decode.acc_seg: 91.1143, aux.loss_ce: 0.1018, aux.acc_seg: 89.8633, loss: 0.3147
2023-11-27 09:04:29,744 - mmseg - INFO - Iter [87400/160000]	lr: 2.723e-05, eta: 16:02:37, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2429, decode.acc_seg: 90.0200, aux.loss_ce: 0.1145, aux.acc_seg: 88.7207, loss: 0.3574
2023-11-27 09:05:10,767 - mmseg - INFO - Iter [87450/160000]	lr: 2.721e-05, eta: 16:01:59, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2347, decode.acc_seg: 90.2311, aux.loss_ce: 0.1099, aux.acc_seg: 89.1283, loss: 0.3446
2023-11-27 09:05:52,062 - mmseg - INFO - Iter [87500/160000]	lr: 2.719e-05, eta: 16:01:20, time: 0.827, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2161, decode.acc_seg: 91.0984, aux.loss_ce: 0.1047, aux.acc_seg: 89.7397, loss: 0.3208
2023-11-27 09:06:32,327 - mmseg - INFO - Iter [87550/160000]	lr: 2.717e-05, eta: 16:00:41, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2320, decode.acc_seg: 90.3640, aux.loss_ce: 0.1098, aux.acc_seg: 89.0901, loss: 0.3417
2023-11-27 09:07:12,286 - mmseg - INFO - Iter [87600/160000]	lr: 2.715e-05, eta: 16:00:01, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2138, decode.acc_seg: 90.9833, aux.loss_ce: 0.1014, aux.acc_seg: 89.6160, loss: 0.3153
2023-11-27 09:07:53,514 - mmseg - INFO - Iter [87650/160000]	lr: 2.713e-05, eta: 15:59:23, time: 0.825, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2096, decode.acc_seg: 91.1787, aux.loss_ce: 0.1008, aux.acc_seg: 89.7414, loss: 0.3103
2023-11-27 09:08:34,147 - mmseg - INFO - Iter [87700/160000]	lr: 2.711e-05, eta: 15:58:44, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2223, decode.acc_seg: 90.6856, aux.loss_ce: 0.1054, aux.acc_seg: 89.3411, loss: 0.3277
2023-11-27 09:09:13,850 - mmseg - INFO - Iter [87750/160000]	lr: 2.709e-05, eta: 15:58:04, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2256, decode.acc_seg: 90.4739, aux.loss_ce: 0.1084, aux.acc_seg: 89.0536, loss: 0.3339
2023-11-27 09:09:54,950 - mmseg - INFO - Iter [87800/160000]	lr: 2.708e-05, eta: 15:57:25, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2250, decode.acc_seg: 90.8073, aux.loss_ce: 0.1063, aux.acc_seg: 89.5697, loss: 0.3313
2023-11-27 09:10:36,550 - mmseg - INFO - Iter [87850/160000]	lr: 2.706e-05, eta: 15:56:47, time: 0.832, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2453, decode.acc_seg: 90.2925, aux.loss_ce: 0.1145, aux.acc_seg: 89.0829, loss: 0.3598
2023-11-27 09:11:17,645 - mmseg - INFO - Iter [87900/160000]	lr: 2.704e-05, eta: 15:56:08, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2338, decode.acc_seg: 90.0992, aux.loss_ce: 0.1099, aux.acc_seg: 88.8868, loss: 0.3437
2023-11-27 09:11:59,001 - mmseg - INFO - Iter [87950/160000]	lr: 2.702e-05, eta: 15:55:29, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2372, decode.acc_seg: 90.2904, aux.loss_ce: 0.1113, aux.acc_seg: 89.0651, loss: 0.3485
2023-11-27 09:12:40,025 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 09:12:40,025 - mmseg - INFO - Iter [88000/160000]	lr: 2.700e-05, eta: 15:54:51, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2150, decode.acc_seg: 91.1151, aux.loss_ce: 0.1061, aux.acc_seg: 89.5840, loss: 0.3212
2023-11-27 09:13:20,006 - mmseg - INFO - Iter [88050/160000]	lr: 2.698e-05, eta: 15:54:11, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2221, decode.acc_seg: 90.6490, aux.loss_ce: 0.1049, aux.acc_seg: 89.4828, loss: 0.3270
2023-11-27 09:13:58,480 - mmseg - INFO - Iter [88100/160000]	lr: 2.696e-05, eta: 15:53:30, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2200, decode.acc_seg: 90.7504, aux.loss_ce: 0.1047, aux.acc_seg: 89.3580, loss: 0.3248
2023-11-27 09:14:38,203 - mmseg - INFO - Iter [88150/160000]	lr: 2.694e-05, eta: 15:52:50, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2271, decode.acc_seg: 90.5337, aux.loss_ce: 0.1094, aux.acc_seg: 89.0705, loss: 0.3365
2023-11-27 09:15:16,916 - mmseg - INFO - Iter [88200/160000]	lr: 2.693e-05, eta: 15:52:10, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2178, decode.acc_seg: 91.0393, aux.loss_ce: 0.1025, aux.acc_seg: 89.7483, loss: 0.3203
2023-11-27 09:15:57,440 - mmseg - INFO - Iter [88250/160000]	lr: 2.691e-05, eta: 15:51:31, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2145, decode.acc_seg: 90.9293, aux.loss_ce: 0.1027, aux.acc_seg: 89.6242, loss: 0.3173
2023-11-27 09:16:34,653 - mmseg - INFO - Iter [88300/160000]	lr: 2.689e-05, eta: 15:50:49, time: 0.745, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2248, decode.acc_seg: 90.6482, aux.loss_ce: 0.1045, aux.acc_seg: 89.5566, loss: 0.3293
2023-11-27 09:17:14,202 - mmseg - INFO - Iter [88350/160000]	lr: 2.687e-05, eta: 15:50:09, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2184, decode.acc_seg: 90.7568, aux.loss_ce: 0.1052, aux.acc_seg: 89.3816, loss: 0.3236
2023-11-27 09:17:54,172 - mmseg - INFO - Iter [88400/160000]	lr: 2.685e-05, eta: 15:49:29, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2125, decode.acc_seg: 91.0566, aux.loss_ce: 0.0994, aux.acc_seg: 89.9348, loss: 0.3119
2023-11-27 09:18:33,773 - mmseg - INFO - Iter [88450/160000]	lr: 2.683e-05, eta: 15:48:49, time: 0.793, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2061, decode.acc_seg: 91.4991, aux.loss_ce: 0.0986, aux.acc_seg: 90.1186, loss: 0.3048
2023-11-27 09:19:12,156 - mmseg - INFO - Iter [88500/160000]	lr: 2.681e-05, eta: 15:48:08, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2205, decode.acc_seg: 90.7232, aux.loss_ce: 0.1040, aux.acc_seg: 89.4685, loss: 0.3245
2023-11-27 09:19:52,892 - mmseg - INFO - Iter [88550/160000]	lr: 2.679e-05, eta: 15:47:29, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2300, decode.acc_seg: 90.6582, aux.loss_ce: 0.1103, aux.acc_seg: 89.1467, loss: 0.3404
2023-11-27 09:20:33,194 - mmseg - INFO - Iter [88600/160000]	lr: 2.678e-05, eta: 15:46:50, time: 0.806, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2184, decode.acc_seg: 91.1387, aux.loss_ce: 0.1023, aux.acc_seg: 89.9181, loss: 0.3207
2023-11-27 09:21:13,602 - mmseg - INFO - Iter [88650/160000]	lr: 2.676e-05, eta: 15:46:11, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2245, decode.acc_seg: 90.7470, aux.loss_ce: 0.1068, aux.acc_seg: 89.3078, loss: 0.3312
2023-11-27 09:21:54,417 - mmseg - INFO - Iter [88700/160000]	lr: 2.674e-05, eta: 15:45:32, time: 0.817, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2327, decode.acc_seg: 90.5193, aux.loss_ce: 0.1100, aux.acc_seg: 89.0365, loss: 0.3427
2023-11-27 09:22:35,448 - mmseg - INFO - Iter [88750/160000]	lr: 2.672e-05, eta: 15:44:53, time: 0.821, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2161, decode.acc_seg: 91.0422, aux.loss_ce: 0.1039, aux.acc_seg: 89.8630, loss: 0.3200
2023-11-27 09:23:16,197 - mmseg - INFO - Iter [88800/160000]	lr: 2.670e-05, eta: 15:44:14, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2110, decode.acc_seg: 91.3700, aux.loss_ce: 0.1004, aux.acc_seg: 89.9987, loss: 0.3114
2023-11-27 09:23:56,908 - mmseg - INFO - Iter [88850/160000]	lr: 2.668e-05, eta: 15:43:35, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 91.0190, aux.loss_ce: 0.1031, aux.acc_seg: 89.7838, loss: 0.3198
2023-11-27 09:24:36,610 - mmseg - INFO - Iter [88900/160000]	lr: 2.666e-05, eta: 15:42:55, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2125, decode.acc_seg: 90.9790, aux.loss_ce: 0.1012, aux.acc_seg: 89.7323, loss: 0.3137
2023-11-27 09:25:14,693 - mmseg - INFO - Iter [88950/160000]	lr: 2.664e-05, eta: 15:42:14, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2150, decode.acc_seg: 90.8535, aux.loss_ce: 0.1024, aux.acc_seg: 89.5541, loss: 0.3174
2023-11-27 09:25:54,500 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 09:25:54,500 - mmseg - INFO - Iter [89000/160000]	lr: 2.663e-05, eta: 15:41:34, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2302, decode.acc_seg: 90.2734, aux.loss_ce: 0.1079, aux.acc_seg: 89.0878, loss: 0.3381
2023-11-27 09:26:34,672 - mmseg - INFO - Iter [89050/160000]	lr: 2.661e-05, eta: 15:40:55, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2262, decode.acc_seg: 90.6389, aux.loss_ce: 0.1071, aux.acc_seg: 89.3060, loss: 0.3333
2023-11-27 09:27:14,566 - mmseg - INFO - Iter [89100/160000]	lr: 2.659e-05, eta: 15:40:15, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2221, decode.acc_seg: 90.6974, aux.loss_ce: 0.1057, aux.acc_seg: 89.5376, loss: 0.3277
2023-11-27 09:27:53,360 - mmseg - INFO - Iter [89150/160000]	lr: 2.657e-05, eta: 15:39:34, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2302, decode.acc_seg: 90.3084, aux.loss_ce: 0.1087, aux.acc_seg: 88.9632, loss: 0.3389
2023-11-27 09:28:30,873 - mmseg - INFO - Iter [89200/160000]	lr: 2.655e-05, eta: 15:38:53, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2179, decode.acc_seg: 90.7445, aux.loss_ce: 0.1034, aux.acc_seg: 89.3636, loss: 0.3212
2023-11-27 09:29:10,428 - mmseg - INFO - Iter [89250/160000]	lr: 2.653e-05, eta: 15:38:13, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2087, decode.acc_seg: 91.1718, aux.loss_ce: 0.0989, aux.acc_seg: 89.9543, loss: 0.3077
2023-11-27 09:29:48,184 - mmseg - INFO - Iter [89300/160000]	lr: 2.651e-05, eta: 15:37:31, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2119, decode.acc_seg: 91.2075, aux.loss_ce: 0.1012, aux.acc_seg: 89.6543, loss: 0.3132
2023-11-27 09:30:28,332 - mmseg - INFO - Iter [89350/160000]	lr: 2.649e-05, eta: 15:36:52, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2071, decode.acc_seg: 91.3206, aux.loss_ce: 0.0985, aux.acc_seg: 89.9660, loss: 0.3055
2023-11-27 09:31:08,055 - mmseg - INFO - Iter [89400/160000]	lr: 2.648e-05, eta: 15:36:12, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2122, decode.acc_seg: 90.8560, aux.loss_ce: 0.1006, aux.acc_seg: 89.7312, loss: 0.3127
2023-11-27 09:31:48,248 - mmseg - INFO - Iter [89450/160000]	lr: 2.646e-05, eta: 15:35:33, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2435, decode.acc_seg: 90.2031, aux.loss_ce: 0.1147, aux.acc_seg: 88.7330, loss: 0.3583
2023-11-27 09:32:28,120 - mmseg - INFO - Iter [89500/160000]	lr: 2.644e-05, eta: 15:34:53, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2191, decode.acc_seg: 90.7910, aux.loss_ce: 0.1027, aux.acc_seg: 89.4853, loss: 0.3219
2023-11-27 09:33:06,523 - mmseg - INFO - Iter [89550/160000]	lr: 2.642e-05, eta: 15:34:12, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2161, decode.acc_seg: 90.9125, aux.loss_ce: 0.1036, aux.acc_seg: 89.6462, loss: 0.3196
2023-11-27 09:33:45,812 - mmseg - INFO - Iter [89600/160000]	lr: 2.640e-05, eta: 15:33:32, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 90.7384, aux.loss_ce: 0.1024, aux.acc_seg: 89.4768, loss: 0.3191
2023-11-27 09:34:23,857 - mmseg - INFO - Iter [89650/160000]	lr: 2.638e-05, eta: 15:32:51, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2241, decode.acc_seg: 90.7373, aux.loss_ce: 0.1064, aux.acc_seg: 89.4915, loss: 0.3305
2023-11-27 09:35:05,529 - mmseg - INFO - Iter [89700/160000]	lr: 2.636e-05, eta: 15:32:12, time: 0.833, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2036, decode.acc_seg: 91.2094, aux.loss_ce: 0.0969, aux.acc_seg: 90.0071, loss: 0.3005
2023-11-27 09:35:46,133 - mmseg - INFO - Iter [89750/160000]	lr: 2.634e-05, eta: 15:31:33, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2155, decode.acc_seg: 90.8999, aux.loss_ce: 0.1040, aux.acc_seg: 89.4941, loss: 0.3195
2023-11-27 09:36:26,580 - mmseg - INFO - Iter [89800/160000]	lr: 2.633e-05, eta: 15:30:54, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2144, decode.acc_seg: 91.0386, aux.loss_ce: 0.1024, aux.acc_seg: 89.7727, loss: 0.3167
2023-11-27 09:37:06,885 - mmseg - INFO - Iter [89850/160000]	lr: 2.631e-05, eta: 15:30:15, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2099, decode.acc_seg: 90.9067, aux.loss_ce: 0.1005, aux.acc_seg: 89.6046, loss: 0.3104
2023-11-27 09:37:47,484 - mmseg - INFO - Iter [89900/160000]	lr: 2.629e-05, eta: 15:29:35, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2315, decode.acc_seg: 90.7253, aux.loss_ce: 0.1089, aux.acc_seg: 89.3148, loss: 0.3405
2023-11-27 09:38:24,644 - mmseg - INFO - Iter [89950/160000]	lr: 2.627e-05, eta: 15:28:54, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2152, decode.acc_seg: 91.1536, aux.loss_ce: 0.1016, aux.acc_seg: 89.9491, loss: 0.3168
2023-11-27 09:39:03,688 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 09:39:03,688 - mmseg - INFO - Iter [90000/160000]	lr: 2.625e-05, eta: 15:28:13, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2143, decode.acc_seg: 90.9840, aux.loss_ce: 0.1026, aux.acc_seg: 89.6244, loss: 0.3169
2023-11-27 09:39:40,942 - mmseg - INFO - Iter [90050/160000]	lr: 2.623e-05, eta: 15:27:32, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2270, decode.acc_seg: 90.6615, aux.loss_ce: 0.1084, aux.acc_seg: 89.1887, loss: 0.3354
2023-11-27 09:40:21,289 - mmseg - INFO - Iter [90100/160000]	lr: 2.621e-05, eta: 15:26:52, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2242, decode.acc_seg: 90.8021, aux.loss_ce: 0.1054, aux.acc_seg: 89.6532, loss: 0.3296
2023-11-27 09:41:02,454 - mmseg - INFO - Iter [90150/160000]	lr: 2.619e-05, eta: 15:26:13, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2241, decode.acc_seg: 90.7312, aux.loss_ce: 0.1047, aux.acc_seg: 89.5161, loss: 0.3287
2023-11-27 09:41:43,214 - mmseg - INFO - Iter [90200/160000]	lr: 2.618e-05, eta: 15:25:34, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2229, decode.acc_seg: 90.5979, aux.loss_ce: 0.1051, aux.acc_seg: 89.3344, loss: 0.3281
2023-11-27 09:42:24,024 - mmseg - INFO - Iter [90250/160000]	lr: 2.616e-05, eta: 15:24:55, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2105, decode.acc_seg: 91.0361, aux.loss_ce: 0.1000, aux.acc_seg: 89.7311, loss: 0.3105
2023-11-27 09:43:02,124 - mmseg - INFO - Iter [90300/160000]	lr: 2.614e-05, eta: 15:24:14, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2103, decode.acc_seg: 91.1457, aux.loss_ce: 0.0994, aux.acc_seg: 90.0644, loss: 0.3097
2023-11-27 09:43:39,773 - mmseg - INFO - Iter [90350/160000]	lr: 2.612e-05, eta: 15:23:33, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2281, decode.acc_seg: 90.5913, aux.loss_ce: 0.1079, aux.acc_seg: 89.3739, loss: 0.3359
2023-11-27 09:44:19,758 - mmseg - INFO - Iter [90400/160000]	lr: 2.610e-05, eta: 15:22:53, time: 0.799, data_time: 0.009, memory: 21695, decode.loss_ce: 0.2320, decode.acc_seg: 90.3707, aux.loss_ce: 0.1083, aux.acc_seg: 89.0704, loss: 0.3403
2023-11-27 09:45:01,289 - mmseg - INFO - Iter [90450/160000]	lr: 2.608e-05, eta: 15:22:15, time: 0.831, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2083, decode.acc_seg: 91.4672, aux.loss_ce: 0.0996, aux.acc_seg: 90.1791, loss: 0.3078
2023-11-27 09:45:42,685 - mmseg - INFO - Iter [90500/160000]	lr: 2.606e-05, eta: 15:21:36, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2213, decode.acc_seg: 90.8503, aux.loss_ce: 0.1050, aux.acc_seg: 89.4678, loss: 0.3264
2023-11-27 09:46:23,172 - mmseg - INFO - Iter [90550/160000]	lr: 2.604e-05, eta: 15:20:57, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2240, decode.acc_seg: 90.6898, aux.loss_ce: 0.1056, aux.acc_seg: 89.5729, loss: 0.3297
2023-11-27 09:47:03,605 - mmseg - INFO - Iter [90600/160000]	lr: 2.603e-05, eta: 15:20:18, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2248, decode.acc_seg: 90.6114, aux.loss_ce: 0.1072, aux.acc_seg: 89.2067, loss: 0.3320
2023-11-27 09:47:43,846 - mmseg - INFO - Iter [90650/160000]	lr: 2.601e-05, eta: 15:19:38, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2233, decode.acc_seg: 90.7383, aux.loss_ce: 0.1059, aux.acc_seg: 89.4083, loss: 0.3292
2023-11-27 09:48:24,516 - mmseg - INFO - Iter [90700/160000]	lr: 2.599e-05, eta: 15:18:59, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2272, decode.acc_seg: 90.6285, aux.loss_ce: 0.1056, aux.acc_seg: 89.2896, loss: 0.3328
2023-11-27 09:49:04,580 - mmseg - INFO - Iter [90750/160000]	lr: 2.597e-05, eta: 15:18:20, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2230, decode.acc_seg: 90.6533, aux.loss_ce: 0.1046, aux.acc_seg: 89.3195, loss: 0.3276
2023-11-27 09:49:43,392 - mmseg - INFO - Iter [90800/160000]	lr: 2.595e-05, eta: 15:17:39, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2317, decode.acc_seg: 90.3329, aux.loss_ce: 0.1085, aux.acc_seg: 89.0925, loss: 0.3402
2023-11-27 09:50:21,048 - mmseg - INFO - Iter [90850/160000]	lr: 2.593e-05, eta: 15:16:58, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2301, decode.acc_seg: 90.4788, aux.loss_ce: 0.1094, aux.acc_seg: 89.0527, loss: 0.3395
2023-11-27 09:51:01,752 - mmseg - INFO - Iter [90900/160000]	lr: 2.591e-05, eta: 15:16:19, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2173, decode.acc_seg: 90.9270, aux.loss_ce: 0.1032, aux.acc_seg: 89.6499, loss: 0.3204
2023-11-27 09:51:42,513 - mmseg - INFO - Iter [90950/160000]	lr: 2.589e-05, eta: 15:15:40, time: 0.815, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2052, decode.acc_seg: 91.4371, aux.loss_ce: 0.0972, aux.acc_seg: 90.1941, loss: 0.3024
2023-11-27 09:52:22,815 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 09:52:22,816 - mmseg - INFO - Iter [91000/160000]	lr: 2.588e-05, eta: 15:15:00, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2295, decode.acc_seg: 90.3600, aux.loss_ce: 0.1089, aux.acc_seg: 88.9674, loss: 0.3384
2023-11-27 09:53:00,446 - mmseg - INFO - Iter [91050/160000]	lr: 2.586e-05, eta: 15:14:19, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2205, decode.acc_seg: 90.7289, aux.loss_ce: 0.1042, aux.acc_seg: 89.4673, loss: 0.3247
2023-11-27 09:53:39,397 - mmseg - INFO - Iter [91100/160000]	lr: 2.584e-05, eta: 15:13:39, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2253, decode.acc_seg: 90.9741, aux.loss_ce: 0.1058, aux.acc_seg: 89.6205, loss: 0.3312
2023-11-27 09:54:16,433 - mmseg - INFO - Iter [91150/160000]	lr: 2.582e-05, eta: 15:12:57, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2217, decode.acc_seg: 90.7468, aux.loss_ce: 0.1036, aux.acc_seg: 89.5664, loss: 0.3253
2023-11-27 09:54:54,909 - mmseg - INFO - Iter [91200/160000]	lr: 2.580e-05, eta: 15:12:16, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2187, decode.acc_seg: 90.9429, aux.loss_ce: 0.1052, aux.acc_seg: 89.4796, loss: 0.3239
2023-11-27 09:55:33,806 - mmseg - INFO - Iter [91250/160000]	lr: 2.578e-05, eta: 15:11:35, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2088, decode.acc_seg: 91.0382, aux.loss_ce: 0.0999, aux.acc_seg: 89.7574, loss: 0.3087
2023-11-27 09:56:10,631 - mmseg - INFO - Iter [91300/160000]	lr: 2.576e-05, eta: 15:10:53, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2141, decode.acc_seg: 91.0876, aux.loss_ce: 0.1013, aux.acc_seg: 89.8855, loss: 0.3153
2023-11-27 09:56:47,327 - mmseg - INFO - Iter [91350/160000]	lr: 2.574e-05, eta: 15:10:11, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2197, decode.acc_seg: 90.9623, aux.loss_ce: 0.1045, aux.acc_seg: 89.6623, loss: 0.3242
2023-11-27 09:57:24,592 - mmseg - INFO - Iter [91400/160000]	lr: 2.573e-05, eta: 15:09:30, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2287, decode.acc_seg: 90.3776, aux.loss_ce: 0.1097, aux.acc_seg: 88.8991, loss: 0.3384
2023-11-27 09:58:02,116 - mmseg - INFO - Iter [91450/160000]	lr: 2.571e-05, eta: 15:08:48, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2139, decode.acc_seg: 90.8848, aux.loss_ce: 0.1024, aux.acc_seg: 89.5452, loss: 0.3164
2023-11-27 09:58:41,030 - mmseg - INFO - Iter [91500/160000]	lr: 2.569e-05, eta: 15:08:08, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2161, decode.acc_seg: 91.0841, aux.loss_ce: 0.1026, aux.acc_seg: 89.6541, loss: 0.3187
2023-11-27 09:59:17,766 - mmseg - INFO - Iter [91550/160000]	lr: 2.567e-05, eta: 15:07:26, time: 0.735, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2241, decode.acc_seg: 90.7062, aux.loss_ce: 0.1061, aux.acc_seg: 89.4702, loss: 0.3302
2023-11-27 09:59:56,391 - mmseg - INFO - Iter [91600/160000]	lr: 2.565e-05, eta: 15:06:45, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2299, decode.acc_seg: 90.5741, aux.loss_ce: 0.1093, aux.acc_seg: 89.2519, loss: 0.3392
2023-11-27 10:00:35,247 - mmseg - INFO - Iter [91650/160000]	lr: 2.563e-05, eta: 15:06:05, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2222, decode.acc_seg: 90.6590, aux.loss_ce: 0.1055, aux.acc_seg: 89.2183, loss: 0.3277
2023-11-27 10:01:14,756 - mmseg - INFO - Iter [91700/160000]	lr: 2.561e-05, eta: 15:05:25, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2078, decode.acc_seg: 91.0712, aux.loss_ce: 0.0965, aux.acc_seg: 90.0656, loss: 0.3043
2023-11-27 10:01:52,927 - mmseg - INFO - Iter [91750/160000]	lr: 2.559e-05, eta: 15:04:44, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2165, decode.acc_seg: 90.8956, aux.loss_ce: 0.1001, aux.acc_seg: 89.8180, loss: 0.3166
2023-11-27 10:02:29,820 - mmseg - INFO - Iter [91800/160000]	lr: 2.558e-05, eta: 15:04:02, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2135, decode.acc_seg: 90.8360, aux.loss_ce: 0.1025, aux.acc_seg: 89.5419, loss: 0.3161
2023-11-27 10:03:07,987 - mmseg - INFO - Iter [91850/160000]	lr: 2.556e-05, eta: 15:03:21, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2187, decode.acc_seg: 90.8097, aux.loss_ce: 0.1071, aux.acc_seg: 89.2254, loss: 0.3258
2023-11-27 10:03:48,753 - mmseg - INFO - Iter [91900/160000]	lr: 2.554e-05, eta: 15:02:42, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2277, decode.acc_seg: 90.7997, aux.loss_ce: 0.1092, aux.acc_seg: 89.3402, loss: 0.3369
2023-11-27 10:04:29,426 - mmseg - INFO - Iter [91950/160000]	lr: 2.552e-05, eta: 15:02:03, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2145, decode.acc_seg: 91.0344, aux.loss_ce: 0.1044, aux.acc_seg: 89.4852, loss: 0.3188
2023-11-27 10:05:08,609 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:05:08,609 - mmseg - INFO - Iter [92000/160000]	lr: 2.550e-05, eta: 15:01:23, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2086, decode.acc_seg: 91.3734, aux.loss_ce: 0.0983, aux.acc_seg: 90.1339, loss: 0.3069
2023-11-27 10:05:46,142 - mmseg - INFO - Iter [92050/160000]	lr: 2.548e-05, eta: 15:00:41, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2223, decode.acc_seg: 90.6181, aux.loss_ce: 0.1054, aux.acc_seg: 89.4337, loss: 0.3277
2023-11-27 10:06:24,673 - mmseg - INFO - Iter [92100/160000]	lr: 2.546e-05, eta: 15:00:00, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2151, decode.acc_seg: 90.8030, aux.loss_ce: 0.1038, aux.acc_seg: 89.3747, loss: 0.3189
2023-11-27 10:07:03,867 - mmseg - INFO - Iter [92150/160000]	lr: 2.544e-05, eta: 14:59:20, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2164, decode.acc_seg: 90.9119, aux.loss_ce: 0.1010, aux.acc_seg: 89.8100, loss: 0.3173
2023-11-27 10:07:42,837 - mmseg - INFO - Iter [92200/160000]	lr: 2.543e-05, eta: 14:58:40, time: 0.779, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2212, decode.acc_seg: 90.7959, aux.loss_ce: 0.1072, aux.acc_seg: 89.4636, loss: 0.3284
2023-11-27 10:08:21,268 - mmseg - INFO - Iter [92250/160000]	lr: 2.541e-05, eta: 14:57:59, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2077, decode.acc_seg: 91.4124, aux.loss_ce: 0.1005, aux.acc_seg: 90.0062, loss: 0.3082
2023-11-27 10:09:01,766 - mmseg - INFO - Iter [92300/160000]	lr: 2.539e-05, eta: 14:57:20, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2039, decode.acc_seg: 91.4297, aux.loss_ce: 0.0982, aux.acc_seg: 90.1542, loss: 0.3022
2023-11-27 10:09:41,098 - mmseg - INFO - Iter [92350/160000]	lr: 2.537e-05, eta: 14:56:40, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2090, decode.acc_seg: 91.2098, aux.loss_ce: 0.1007, aux.acc_seg: 89.7021, loss: 0.3097
2023-11-27 10:10:18,259 - mmseg - INFO - Iter [92400/160000]	lr: 2.535e-05, eta: 14:55:58, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2247, decode.acc_seg: 90.8376, aux.loss_ce: 0.1065, aux.acc_seg: 89.5304, loss: 0.3312
2023-11-27 10:10:56,909 - mmseg - INFO - Iter [92450/160000]	lr: 2.533e-05, eta: 14:55:18, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2215, decode.acc_seg: 90.8648, aux.loss_ce: 0.1041, aux.acc_seg: 89.5436, loss: 0.3256
2023-11-27 10:11:37,397 - mmseg - INFO - Iter [92500/160000]	lr: 2.531e-05, eta: 14:54:38, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2086, decode.acc_seg: 91.4593, aux.loss_ce: 0.1005, aux.acc_seg: 90.1391, loss: 0.3091
2023-11-27 10:12:17,476 - mmseg - INFO - Iter [92550/160000]	lr: 2.529e-05, eta: 14:53:59, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2177, decode.acc_seg: 90.9110, aux.loss_ce: 0.1047, aux.acc_seg: 89.5231, loss: 0.3224
2023-11-27 10:12:57,259 - mmseg - INFO - Iter [92600/160000]	lr: 2.528e-05, eta: 14:53:19, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2164, decode.acc_seg: 90.9090, aux.loss_ce: 0.1042, aux.acc_seg: 89.5030, loss: 0.3207
2023-11-27 10:13:34,296 - mmseg - INFO - Iter [92650/160000]	lr: 2.526e-05, eta: 14:52:37, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2205, decode.acc_seg: 90.9904, aux.loss_ce: 0.1048, aux.acc_seg: 89.5672, loss: 0.3252
2023-11-27 10:14:14,182 - mmseg - INFO - Iter [92700/160000]	lr: 2.524e-05, eta: 14:51:58, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2109, decode.acc_seg: 91.0685, aux.loss_ce: 0.1011, aux.acc_seg: 89.6621, loss: 0.3120
2023-11-27 10:14:52,962 - mmseg - INFO - Iter [92750/160000]	lr: 2.522e-05, eta: 14:51:17, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2161, decode.acc_seg: 90.9585, aux.loss_ce: 0.1062, aux.acc_seg: 89.4513, loss: 0.3224
2023-11-27 10:15:32,457 - mmseg - INFO - Iter [92800/160000]	lr: 2.520e-05, eta: 14:50:37, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2064, decode.acc_seg: 91.0809, aux.loss_ce: 0.0989, aux.acc_seg: 89.7442, loss: 0.3053
2023-11-27 10:16:12,684 - mmseg - INFO - Iter [92850/160000]	lr: 2.518e-05, eta: 14:49:58, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2216, decode.acc_seg: 90.9017, aux.loss_ce: 0.1037, aux.acc_seg: 89.7140, loss: 0.3253
2023-11-27 10:16:52,565 - mmseg - INFO - Iter [92900/160000]	lr: 2.516e-05, eta: 14:49:18, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2182, decode.acc_seg: 90.9390, aux.loss_ce: 0.1037, aux.acc_seg: 89.7110, loss: 0.3220
2023-11-27 10:17:30,953 - mmseg - INFO - Iter [92950/160000]	lr: 2.514e-05, eta: 14:48:37, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2199, decode.acc_seg: 90.7231, aux.loss_ce: 0.1055, aux.acc_seg: 89.4293, loss: 0.3254
2023-11-27 10:18:11,552 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:18:11,553 - mmseg - INFO - Iter [93000/160000]	lr: 2.513e-05, eta: 14:47:58, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2108, decode.acc_seg: 91.1224, aux.loss_ce: 0.1002, aux.acc_seg: 89.8158, loss: 0.3110
2023-11-27 10:18:52,458 - mmseg - INFO - Iter [93050/160000]	lr: 2.511e-05, eta: 14:47:19, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2236, decode.acc_seg: 90.7958, aux.loss_ce: 0.1069, aux.acc_seg: 89.4756, loss: 0.3305
2023-11-27 10:19:33,122 - mmseg - INFO - Iter [93100/160000]	lr: 2.509e-05, eta: 14:46:40, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2121, decode.acc_seg: 91.1086, aux.loss_ce: 0.1017, aux.acc_seg: 89.6788, loss: 0.3137
2023-11-27 10:20:13,366 - mmseg - INFO - Iter [93150/160000]	lr: 2.507e-05, eta: 14:46:01, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2145, decode.acc_seg: 91.1069, aux.loss_ce: 0.1019, aux.acc_seg: 89.8749, loss: 0.3164
2023-11-27 10:20:53,357 - mmseg - INFO - Iter [93200/160000]	lr: 2.505e-05, eta: 14:45:21, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2176, decode.acc_seg: 91.0968, aux.loss_ce: 0.1033, aux.acc_seg: 89.9122, loss: 0.3208
2023-11-27 10:21:33,590 - mmseg - INFO - Iter [93250/160000]	lr: 2.503e-05, eta: 14:44:42, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2017, decode.acc_seg: 91.3920, aux.loss_ce: 0.0972, aux.acc_seg: 90.0761, loss: 0.2988
2023-11-27 10:22:13,318 - mmseg - INFO - Iter [93300/160000]	lr: 2.501e-05, eta: 14:44:02, time: 0.794, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2230, decode.acc_seg: 90.8448, aux.loss_ce: 0.1054, aux.acc_seg: 89.6059, loss: 0.3285
2023-11-27 10:22:53,491 - mmseg - INFO - Iter [93350/160000]	lr: 2.499e-05, eta: 14:43:23, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2380, decode.acc_seg: 90.1692, aux.loss_ce: 0.1115, aux.acc_seg: 89.0408, loss: 0.3495
2023-11-27 10:23:31,014 - mmseg - INFO - Iter [93400/160000]	lr: 2.498e-05, eta: 14:42:41, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2147, decode.acc_seg: 90.9765, aux.loss_ce: 0.1023, aux.acc_seg: 89.5829, loss: 0.3170
2023-11-27 10:24:10,718 - mmseg - INFO - Iter [93450/160000]	lr: 2.496e-05, eta: 14:42:01, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2193, decode.acc_seg: 90.7214, aux.loss_ce: 0.1021, aux.acc_seg: 89.7468, loss: 0.3213
2023-11-27 10:24:52,835 - mmseg - INFO - Iter [93500/160000]	lr: 2.494e-05, eta: 14:41:23, time: 0.842, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2224, decode.acc_seg: 90.9223, aux.loss_ce: 0.1056, aux.acc_seg: 89.5578, loss: 0.3280
2023-11-27 10:25:31,605 - mmseg - INFO - Iter [93550/160000]	lr: 2.492e-05, eta: 14:40:43, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2226, decode.acc_seg: 90.7846, aux.loss_ce: 0.1047, aux.acc_seg: 89.4769, loss: 0.3273
2023-11-27 10:26:10,936 - mmseg - INFO - Iter [93600/160000]	lr: 2.490e-05, eta: 14:40:03, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2227, decode.acc_seg: 90.4715, aux.loss_ce: 0.1047, aux.acc_seg: 89.2771, loss: 0.3274
2023-11-27 10:26:47,882 - mmseg - INFO - Iter [93650/160000]	lr: 2.488e-05, eta: 14:39:21, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2105, decode.acc_seg: 91.0321, aux.loss_ce: 0.1008, aux.acc_seg: 89.6391, loss: 0.3113
2023-11-27 10:27:24,685 - mmseg - INFO - Iter [93700/160000]	lr: 2.486e-05, eta: 14:38:39, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2213, decode.acc_seg: 91.1384, aux.loss_ce: 0.1068, aux.acc_seg: 89.8059, loss: 0.3280
2023-11-27 10:28:02,146 - mmseg - INFO - Iter [93750/160000]	lr: 2.484e-05, eta: 14:37:58, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2109, decode.acc_seg: 91.2004, aux.loss_ce: 0.1024, aux.acc_seg: 89.8320, loss: 0.3133
2023-11-27 10:28:42,086 - mmseg - INFO - Iter [93800/160000]	lr: 2.483e-05, eta: 14:37:18, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2146, decode.acc_seg: 90.9150, aux.loss_ce: 0.1018, aux.acc_seg: 89.7279, loss: 0.3164
2023-11-27 10:29:21,079 - mmseg - INFO - Iter [93850/160000]	lr: 2.481e-05, eta: 14:36:38, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2018, decode.acc_seg: 91.4409, aux.loss_ce: 0.0960, aux.acc_seg: 90.1627, loss: 0.2979
2023-11-27 10:30:00,204 - mmseg - INFO - Iter [93900/160000]	lr: 2.479e-05, eta: 14:35:58, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2151, decode.acc_seg: 91.0404, aux.loss_ce: 0.1020, aux.acc_seg: 89.7880, loss: 0.3171
2023-11-27 10:30:40,574 - mmseg - INFO - Iter [93950/160000]	lr: 2.477e-05, eta: 14:35:18, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2067, decode.acc_seg: 91.4094, aux.loss_ce: 0.0979, aux.acc_seg: 90.2003, loss: 0.3047
2023-11-27 10:31:20,660 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:31:20,661 - mmseg - INFO - Iter [94000/160000]	lr: 2.475e-05, eta: 14:34:39, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2177, decode.acc_seg: 90.9294, aux.loss_ce: 0.1027, aux.acc_seg: 89.5958, loss: 0.3204
2023-11-27 10:32:00,637 - mmseg - INFO - Iter [94050/160000]	lr: 2.473e-05, eta: 14:33:59, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2043, decode.acc_seg: 91.3439, aux.loss_ce: 0.0979, aux.acc_seg: 90.0261, loss: 0.3022
2023-11-27 10:32:41,598 - mmseg - INFO - Iter [94100/160000]	lr: 2.471e-05, eta: 14:33:20, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2228, decode.acc_seg: 90.6699, aux.loss_ce: 0.1053, aux.acc_seg: 89.3072, loss: 0.3281
2023-11-27 10:33:21,591 - mmseg - INFO - Iter [94150/160000]	lr: 2.469e-05, eta: 14:32:41, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2141, decode.acc_seg: 90.8668, aux.loss_ce: 0.1020, aux.acc_seg: 89.6828, loss: 0.3161
2023-11-27 10:34:01,512 - mmseg - INFO - Iter [94200/160000]	lr: 2.468e-05, eta: 14:32:01, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2155, decode.acc_seg: 90.9677, aux.loss_ce: 0.1025, aux.acc_seg: 89.7357, loss: 0.3181
2023-11-27 10:34:41,170 - mmseg - INFO - Iter [94250/160000]	lr: 2.466e-05, eta: 14:31:21, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2104, decode.acc_seg: 91.1712, aux.loss_ce: 0.1005, aux.acc_seg: 89.8479, loss: 0.3109
2023-11-27 10:35:18,403 - mmseg - INFO - Iter [94300/160000]	lr: 2.464e-05, eta: 14:30:40, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2172, decode.acc_seg: 90.6872, aux.loss_ce: 0.1040, aux.acc_seg: 89.2863, loss: 0.3212
2023-11-27 10:35:55,153 - mmseg - INFO - Iter [94350/160000]	lr: 2.462e-05, eta: 14:29:58, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2246, decode.acc_seg: 90.7011, aux.loss_ce: 0.1041, aux.acc_seg: 89.6448, loss: 0.3287
2023-11-27 10:36:35,631 - mmseg - INFO - Iter [94400/160000]	lr: 2.460e-05, eta: 14:29:19, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2195, decode.acc_seg: 91.0582, aux.loss_ce: 0.1036, aux.acc_seg: 89.8413, loss: 0.3231
2023-11-27 10:37:15,958 - mmseg - INFO - Iter [94450/160000]	lr: 2.458e-05, eta: 14:28:39, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2206, decode.acc_seg: 90.7564, aux.loss_ce: 0.1036, aux.acc_seg: 89.4888, loss: 0.3243
2023-11-27 10:37:56,053 - mmseg - INFO - Iter [94500/160000]	lr: 2.456e-05, eta: 14:28:00, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2065, decode.acc_seg: 91.2628, aux.loss_ce: 0.0995, aux.acc_seg: 89.8722, loss: 0.3060
2023-11-27 10:38:35,573 - mmseg - INFO - Iter [94550/160000]	lr: 2.454e-05, eta: 14:27:20, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2215, decode.acc_seg: 90.6956, aux.loss_ce: 0.1084, aux.acc_seg: 89.2438, loss: 0.3298
2023-11-27 10:39:13,891 - mmseg - INFO - Iter [94600/160000]	lr: 2.453e-05, eta: 14:26:39, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2066, decode.acc_seg: 91.0613, aux.loss_ce: 0.0998, aux.acc_seg: 89.6615, loss: 0.3063
2023-11-27 10:39:53,439 - mmseg - INFO - Iter [94650/160000]	lr: 2.451e-05, eta: 14:25:59, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 91.3430, aux.loss_ce: 0.0997, aux.acc_seg: 89.9743, loss: 0.3067
2023-11-27 10:40:32,068 - mmseg - INFO - Iter [94700/160000]	lr: 2.449e-05, eta: 14:25:19, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2022, decode.acc_seg: 91.5884, aux.loss_ce: 0.0966, aux.acc_seg: 90.4310, loss: 0.2988
2023-11-27 10:41:12,874 - mmseg - INFO - Iter [94750/160000]	lr: 2.447e-05, eta: 14:24:40, time: 0.815, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2187, decode.acc_seg: 91.0141, aux.loss_ce: 0.1037, aux.acc_seg: 89.7134, loss: 0.3224
2023-11-27 10:41:53,529 - mmseg - INFO - Iter [94800/160000]	lr: 2.445e-05, eta: 14:24:00, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2211, decode.acc_seg: 90.6345, aux.loss_ce: 0.1040, aux.acc_seg: 89.3031, loss: 0.3251
2023-11-27 10:42:32,687 - mmseg - INFO - Iter [94850/160000]	lr: 2.443e-05, eta: 14:23:20, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2146, decode.acc_seg: 91.0847, aux.loss_ce: 0.1000, aux.acc_seg: 89.8647, loss: 0.3146
2023-11-27 10:43:12,911 - mmseg - INFO - Iter [94900/160000]	lr: 2.441e-05, eta: 14:22:41, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2115, decode.acc_seg: 91.0977, aux.loss_ce: 0.0990, aux.acc_seg: 89.9941, loss: 0.3105
2023-11-27 10:43:53,092 - mmseg - INFO - Iter [94950/160000]	lr: 2.439e-05, eta: 14:22:01, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2062, decode.acc_seg: 91.3181, aux.loss_ce: 0.0978, aux.acc_seg: 89.8663, loss: 0.3040
2023-11-27 10:44:33,657 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:44:33,657 - mmseg - INFO - Iter [95000/160000]	lr: 2.438e-05, eta: 14:21:22, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2182, decode.acc_seg: 90.9394, aux.loss_ce: 0.1022, aux.acc_seg: 89.8183, loss: 0.3204
2023-11-27 10:45:14,289 - mmseg - INFO - Iter [95050/160000]	lr: 2.436e-05, eta: 14:20:43, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2077, decode.acc_seg: 91.3626, aux.loss_ce: 0.0991, aux.acc_seg: 90.1480, loss: 0.3068
2023-11-27 10:45:54,934 - mmseg - INFO - Iter [95100/160000]	lr: 2.434e-05, eta: 14:20:04, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2104, decode.acc_seg: 91.2342, aux.loss_ce: 0.1016, aux.acc_seg: 89.8279, loss: 0.3120
2023-11-27 10:46:35,641 - mmseg - INFO - Iter [95150/160000]	lr: 2.432e-05, eta: 14:19:25, time: 0.814, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2077, decode.acc_seg: 91.1739, aux.loss_ce: 0.0995, aux.acc_seg: 89.8223, loss: 0.3072
2023-11-27 10:47:15,987 - mmseg - INFO - Iter [95200/160000]	lr: 2.430e-05, eta: 14:18:45, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1909, decode.acc_seg: 92.0504, aux.loss_ce: 0.0914, aux.acc_seg: 90.7656, loss: 0.2823
2023-11-27 10:47:56,317 - mmseg - INFO - Iter [95250/160000]	lr: 2.428e-05, eta: 14:18:06, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2047, decode.acc_seg: 91.4801, aux.loss_ce: 0.0980, aux.acc_seg: 90.2566, loss: 0.3028
2023-11-27 10:48:35,224 - mmseg - INFO - Iter [95300/160000]	lr: 2.426e-05, eta: 14:17:26, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2044, decode.acc_seg: 91.5140, aux.loss_ce: 0.0979, aux.acc_seg: 90.2493, loss: 0.3022
2023-11-27 10:49:15,016 - mmseg - INFO - Iter [95350/160000]	lr: 2.424e-05, eta: 14:16:46, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2082, decode.acc_seg: 91.1373, aux.loss_ce: 0.1008, aux.acc_seg: 89.6410, loss: 0.3090
2023-11-27 10:49:55,397 - mmseg - INFO - Iter [95400/160000]	lr: 2.423e-05, eta: 14:16:07, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2083, decode.acc_seg: 91.0262, aux.loss_ce: 0.1017, aux.acc_seg: 89.5506, loss: 0.3100
2023-11-27 10:50:35,740 - mmseg - INFO - Iter [95450/160000]	lr: 2.421e-05, eta: 14:15:27, time: 0.806, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2128, decode.acc_seg: 91.0137, aux.loss_ce: 0.1012, aux.acc_seg: 89.8278, loss: 0.3140
2023-11-27 10:51:12,875 - mmseg - INFO - Iter [95500/160000]	lr: 2.419e-05, eta: 14:14:46, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2132, decode.acc_seg: 91.3028, aux.loss_ce: 0.1009, aux.acc_seg: 90.0940, loss: 0.3141
2023-11-27 10:51:53,583 - mmseg - INFO - Iter [95550/160000]	lr: 2.417e-05, eta: 14:14:07, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2082, decode.acc_seg: 91.1719, aux.loss_ce: 0.0983, aux.acc_seg: 89.8688, loss: 0.3065
2023-11-27 10:52:33,198 - mmseg - INFO - Iter [95600/160000]	lr: 2.415e-05, eta: 14:13:27, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2125, decode.acc_seg: 91.1646, aux.loss_ce: 0.1006, aux.acc_seg: 89.8685, loss: 0.3131
2023-11-27 10:53:14,058 - mmseg - INFO - Iter [95650/160000]	lr: 2.413e-05, eta: 14:12:48, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2300, decode.acc_seg: 90.5351, aux.loss_ce: 0.1097, aux.acc_seg: 89.0151, loss: 0.3397
2023-11-27 10:53:52,086 - mmseg - INFO - Iter [95700/160000]	lr: 2.411e-05, eta: 14:12:07, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2094, decode.acc_seg: 91.1593, aux.loss_ce: 0.0987, aux.acc_seg: 90.0604, loss: 0.3081
2023-11-27 10:54:29,457 - mmseg - INFO - Iter [95750/160000]	lr: 2.409e-05, eta: 14:11:25, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2313, decode.acc_seg: 90.3770, aux.loss_ce: 0.1109, aux.acc_seg: 88.9192, loss: 0.3422
2023-11-27 10:55:06,978 - mmseg - INFO - Iter [95800/160000]	lr: 2.408e-05, eta: 14:10:44, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2200, decode.acc_seg: 90.7278, aux.loss_ce: 0.1048, aux.acc_seg: 89.2293, loss: 0.3248
2023-11-27 10:55:44,218 - mmseg - INFO - Iter [95850/160000]	lr: 2.406e-05, eta: 14:10:03, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2145, decode.acc_seg: 90.8707, aux.loss_ce: 0.1011, aux.acc_seg: 89.5601, loss: 0.3156
2023-11-27 10:56:24,492 - mmseg - INFO - Iter [95900/160000]	lr: 2.404e-05, eta: 14:09:23, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2114, decode.acc_seg: 91.0726, aux.loss_ce: 0.1017, aux.acc_seg: 89.7582, loss: 0.3130
2023-11-27 10:57:02,620 - mmseg - INFO - Iter [95950/160000]	lr: 2.402e-05, eta: 14:08:43, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2005, decode.acc_seg: 91.4666, aux.loss_ce: 0.0954, aux.acc_seg: 90.1927, loss: 0.2958
2023-11-27 10:57:44,857 - mmseg - INFO - Saving checkpoint at 96000 iterations
2023-11-27 10:57:49,953 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:57:49,954 - mmseg - INFO - Iter [96000/160000]	lr: 2.400e-05, eta: 14:08:08, time: 0.948, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2167, decode.acc_seg: 90.8893, aux.loss_ce: 0.1022, aux.acc_seg: 89.7915, loss: 0.3189
2023-11-27 10:59:25,992 - mmseg - INFO - per class results:
2023-11-27 10:59:26,006 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  77.9 | 88.01 |
|       building      | 80.62 | 90.88 |
|         sky         | 94.47 | 97.61 |
|        floor        | 82.44 | 90.56 |
|         tree        | 75.23 | 86.92 |
|       ceiling       | 84.77 | 91.82 |
|         road        | 82.75 | 90.01 |
|         bed         | 89.59 | 95.34 |
|      windowpane     | 61.46 | 80.17 |
|        grass        | 67.92 | 86.61 |
|       cabinet       | 62.18 | 74.44 |
|       sidewalk      |  66.3 | 81.35 |
|        person       | 80.92 | 93.47 |
|        earth        | 37.07 | 49.62 |
|         door        | 49.27 | 59.58 |
|        table        | 59.85 | 73.45 |
|       mountain      | 56.52 |  74.7 |
|        plant        | 53.42 | 67.65 |
|       curtain       | 73.88 |  87.5 |
|        chair        | 57.19 | 70.87 |
|         car         | 84.16 | 94.06 |
|        water        |  62.0 | 78.92 |
|       painting      | 73.95 | 88.87 |
|         sofa        | 64.52 | 78.64 |
|        shelf        |  44.5 | 64.31 |
|        house        | 26.09 | 32.62 |
|         sea         | 60.24 |  75.8 |
|        mirror       | 64.68 | 72.58 |
|         rug         | 64.63 |  77.1 |
|        field        | 30.98 |  45.0 |
|       armchair      |  41.8 | 65.36 |
|         seat        | 59.35 | 83.28 |
|        fence        | 48.56 | 59.56 |
|         desk        | 48.36 | 73.71 |
|         rock        | 47.27 | 71.09 |
|       wardrobe      | 47.19 | 56.65 |
|         lamp        | 65.46 | 74.48 |
|       bathtub       | 79.46 | 87.07 |
|       railing       | 34.69 | 51.55 |
|       cushion       | 59.29 | 71.79 |
|         base        | 35.58 |  48.0 |
|         box         | 28.57 | 38.29 |
|        column       | 43.86 | 51.44 |
|      signboard      | 37.73 | 56.81 |
|   chest of drawers  | 38.22 | 72.38 |
|       counter       | 37.19 | 42.98 |
|         sand        | 33.87 | 47.97 |
|         sink        | 71.29 | 79.47 |
|      skyscraper     | 43.96 |  54.0 |
|      fireplace      | 73.63 | 91.08 |
|     refrigerator    | 77.35 | 87.08 |
|      grandstand     | 53.56 | 69.12 |
|         path        | 21.91 | 32.12 |
|        stairs       |  8.37 |  9.97 |
|        runway       | 69.43 | 93.46 |
|         case        | 69.24 | 82.47 |
|      pool table     | 92.95 | 97.49 |
|        pillow       |  61.3 | 75.44 |
|     screen door     | 70.12 | 73.96 |
|       stairway      | 25.05 | 51.24 |
|        river        |  9.97 | 16.42 |
|        bridge       | 76.15 | 85.37 |
|       bookcase      | 39.54 | 59.83 |
|        blind        | 42.57 | 48.36 |
|     coffee table    | 52.75 | 84.25 |
|        toilet       | 78.56 | 90.85 |
|        flower       | 37.75 | 56.55 |
|         book        | 45.16 | 65.14 |
|         hill        | 13.38 | 20.75 |
|        bench        | 41.91 | 54.02 |
|      countertop     | 50.77 | 76.66 |
|        stove        | 71.71 | 75.97 |
|         palm        | 52.19 | 74.43 |
|    kitchen island   | 44.46 | 77.72 |
|       computer      | 72.22 |  85.7 |
|     swivel chair    | 47.01 | 72.44 |
|         boat        | 45.34 | 53.09 |
|         bar         | 43.14 | 62.19 |
|    arcade machine   | 83.74 | 92.51 |
|        hovel        | 44.91 | 64.93 |
|         bus         | 83.67 | 97.28 |
|        towel        | 62.29 | 77.34 |
|        light        | 57.77 | 68.27 |
|        truck        | 33.18 | 47.38 |
|        tower        | 19.74 | 37.03 |
|      chandelier     | 67.13 | 87.39 |
|        awning       | 32.36 | 44.09 |
|     streetlight     | 27.76 |  37.2 |
|        booth        | 39.79 | 48.44 |
| television receiver | 71.14 | 82.19 |
|       airplane      | 55.23 | 65.78 |
|      dirt track     |  0.02 |  0.03 |
|       apparel       | 41.82 | 75.88 |
|         pole        | 22.83 | 30.44 |
|         land        |  5.74 |  6.91 |
|      bannister      | 15.22 | 19.79 |
|      escalator      | 32.42 | 46.58 |
|       ottoman       | 47.75 |  61.0 |
|        bottle       | 35.92 | 62.68 |
|        buffet       | 50.66 | 63.07 |
|        poster       |  30.4 | 45.72 |
|        stage        | 15.96 | 29.78 |
|         van         | 39.44 | 56.26 |
|         ship        | 22.04 | 34.99 |
|       fountain      | 21.42 | 21.65 |
|    conveyer belt    | 59.13 | 65.32 |
|        canopy       | 14.71 |  24.0 |
|        washer       | 72.51 | 76.19 |
|      plaything      | 31.11 | 45.81 |
|    swimming pool    | 71.79 | 91.42 |
|        stool        | 43.73 | 52.67 |
|        barrel       | 38.37 | 66.92 |
|        basket       | 38.14 |  52.9 |
|      waterfall      | 69.59 | 96.92 |
|         tent        | 93.36 | 98.67 |
|         bag         | 13.24 | 17.13 |
|       minibike      | 72.51 | 83.05 |
|        cradle       | 85.16 | 96.19 |
|         oven        | 42.97 | 51.81 |
|         ball        | 35.22 | 67.86 |
|         food        | 56.74 | 64.11 |
|         step        | 15.37 | 21.56 |
|         tank        | 34.12 | 38.39 |
|      trade name     | 23.13 | 28.98 |
|      microwave      | 78.31 | 91.12 |
|         pot         | 48.77 | 55.67 |
|        animal       | 60.53 | 62.92 |
|       bicycle       | 57.97 | 79.02 |
|         lake        | 62.96 | 68.14 |
|      dishwasher     | 64.12 | 75.45 |
|        screen       | 68.06 | 89.94 |
|       blanket       | 13.73 | 15.93 |
|      sculpture      | 56.64 | 82.05 |
|         hood        | 64.82 | 70.65 |
|        sconce       | 48.36 | 61.88 |
|         vase        | 40.03 | 53.26 |
|    traffic light    |  31.4 | 61.78 |
|         tray        | 10.15 |  13.8 |
|        ashcan       | 35.08 | 51.38 |
|         fan         | 59.83 | 74.52 |
|         pier        | 25.65 | 33.15 |
|      crt screen     |  5.68 | 16.46 |
|        plate        | 55.17 | 67.27 |
|       monitor       |  8.95 | 11.73 |
|    bulletin board   |  48.5 | 60.69 |
|        shower       |  0.41 |  0.67 |
|       radiator      | 69.66 | 78.11 |
|        glass        | 14.52 |  15.2 |
|        clock        | 35.12 | 50.33 |
|         flag        | 56.94 | 63.38 |
+---------------------+-------+-------+
2023-11-27 10:59:26,006 - mmseg - INFO - Summary:
2023-11-27 10:59:26,006 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.09 | 49.68 | 62.64 |
+-------+-------+-------+
2023-11-27 10:59:26,038 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 10:59:26,038 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8309, mIoU: 0.4968, mAcc: 0.6264, IoU.wall: 0.7790, IoU.building: 0.8062, IoU.sky: 0.9447, IoU.floor: 0.8244, IoU.tree: 0.7523, IoU.ceiling: 0.8477, IoU.road: 0.8275, IoU.bed : 0.8959, IoU.windowpane: 0.6146, IoU.grass: 0.6792, IoU.cabinet: 0.6218, IoU.sidewalk: 0.6630, IoU.person: 0.8092, IoU.earth: 0.3707, IoU.door: 0.4927, IoU.table: 0.5985, IoU.mountain: 0.5652, IoU.plant: 0.5342, IoU.curtain: 0.7388, IoU.chair: 0.5719, IoU.car: 0.8416, IoU.water: 0.6200, IoU.painting: 0.7395, IoU.sofa: 0.6452, IoU.shelf: 0.4450, IoU.house: 0.2609, IoU.sea: 0.6024, IoU.mirror: 0.6468, IoU.rug: 0.6463, IoU.field: 0.3098, IoU.armchair: 0.4180, IoU.seat: 0.5935, IoU.fence: 0.4856, IoU.desk: 0.4836, IoU.rock: 0.4727, IoU.wardrobe: 0.4719, IoU.lamp: 0.6546, IoU.bathtub: 0.7946, IoU.railing: 0.3469, IoU.cushion: 0.5929, IoU.base: 0.3558, IoU.box: 0.2857, IoU.column: 0.4386, IoU.signboard: 0.3773, IoU.chest of drawers: 0.3822, IoU.counter: 0.3719, IoU.sand: 0.3387, IoU.sink: 0.7129, IoU.skyscraper: 0.4396, IoU.fireplace: 0.7363, IoU.refrigerator: 0.7735, IoU.grandstand: 0.5356, IoU.path: 0.2191, IoU.stairs: 0.0837, IoU.runway: 0.6943, IoU.case: 0.6924, IoU.pool table: 0.9295, IoU.pillow: 0.6130, IoU.screen door: 0.7012, IoU.stairway: 0.2505, IoU.river: 0.0997, IoU.bridge: 0.7615, IoU.bookcase: 0.3954, IoU.blind: 0.4257, IoU.coffee table: 0.5275, IoU.toilet: 0.7856, IoU.flower: 0.3775, IoU.book: 0.4516, IoU.hill: 0.1338, IoU.bench: 0.4191, IoU.countertop: 0.5077, IoU.stove: 0.7171, IoU.palm: 0.5219, IoU.kitchen island: 0.4446, IoU.computer: 0.7222, IoU.swivel chair: 0.4701, IoU.boat: 0.4534, IoU.bar: 0.4314, IoU.arcade machine: 0.8374, IoU.hovel: 0.4491, IoU.bus: 0.8367, IoU.towel: 0.6229, IoU.light: 0.5777, IoU.truck: 0.3318, IoU.tower: 0.1974, IoU.chandelier: 0.6713, IoU.awning: 0.3236, IoU.streetlight: 0.2776, IoU.booth: 0.3979, IoU.television receiver: 0.7114, IoU.airplane: 0.5523, IoU.dirt track: 0.0002, IoU.apparel: 0.4182, IoU.pole: 0.2283, IoU.land: 0.0574, IoU.bannister: 0.1522, IoU.escalator: 0.3242, IoU.ottoman: 0.4775, IoU.bottle: 0.3592, IoU.buffet: 0.5066, IoU.poster: 0.3040, IoU.stage: 0.1596, IoU.van: 0.3944, IoU.ship: 0.2204, IoU.fountain: 0.2142, IoU.conveyer belt: 0.5913, IoU.canopy: 0.1471, IoU.washer: 0.7251, IoU.plaything: 0.3111, IoU.swimming pool: 0.7179, IoU.stool: 0.4373, IoU.barrel: 0.3837, IoU.basket: 0.3814, IoU.waterfall: 0.6959, IoU.tent: 0.9336, IoU.bag: 0.1324, IoU.minibike: 0.7251, IoU.cradle: 0.8516, IoU.oven: 0.4297, IoU.ball: 0.3522, IoU.food: 0.5674, IoU.step: 0.1537, IoU.tank: 0.3412, IoU.trade name: 0.2313, IoU.microwave: 0.7831, IoU.pot: 0.4877, IoU.animal: 0.6053, IoU.bicycle: 0.5797, IoU.lake: 0.6296, IoU.dishwasher: 0.6412, IoU.screen: 0.6806, IoU.blanket: 0.1373, IoU.sculpture: 0.5664, IoU.hood: 0.6482, IoU.sconce: 0.4836, IoU.vase: 0.4003, IoU.traffic light: 0.3140, IoU.tray: 0.1015, IoU.ashcan: 0.3508, IoU.fan: 0.5983, IoU.pier: 0.2565, IoU.crt screen: 0.0568, IoU.plate: 0.5517, IoU.monitor: 0.0895, IoU.bulletin board: 0.4850, IoU.shower: 0.0041, IoU.radiator: 0.6966, IoU.glass: 0.1452, IoU.clock: 0.3512, IoU.flag: 0.5694, Acc.wall: 0.8801, Acc.building: 0.9088, Acc.sky: 0.9761, Acc.floor: 0.9056, Acc.tree: 0.8692, Acc.ceiling: 0.9182, Acc.road: 0.9001, Acc.bed : 0.9534, Acc.windowpane: 0.8017, Acc.grass: 0.8661, Acc.cabinet: 0.7444, Acc.sidewalk: 0.8135, Acc.person: 0.9347, Acc.earth: 0.4962, Acc.door: 0.5958, Acc.table: 0.7345, Acc.mountain: 0.7470, Acc.plant: 0.6765, Acc.curtain: 0.8750, Acc.chair: 0.7087, Acc.car: 0.9406, Acc.water: 0.7892, Acc.painting: 0.8887, Acc.sofa: 0.7864, Acc.shelf: 0.6431, Acc.house: 0.3262, Acc.sea: 0.7580, Acc.mirror: 0.7258, Acc.rug: 0.7710, Acc.field: 0.4500, Acc.armchair: 0.6536, Acc.seat: 0.8328, Acc.fence: 0.5956, Acc.desk: 0.7371, Acc.rock: 0.7109, Acc.wardrobe: 0.5665, Acc.lamp: 0.7448, Acc.bathtub: 0.8707, Acc.railing: 0.5155, Acc.cushion: 0.7179, Acc.base: 0.4800, Acc.box: 0.3829, Acc.column: 0.5144, Acc.signboard: 0.5681, Acc.chest of drawers: 0.7238, Acc.counter: 0.4298, Acc.sand: 0.4797, Acc.sink: 0.7947, Acc.skyscraper: 0.5400, Acc.fireplace: 0.9108, Acc.refrigerator: 0.8708, Acc.grandstand: 0.6912, Acc.path: 0.3212, Acc.stairs: 0.0997, Acc.runway: 0.9346, Acc.case: 0.8247, Acc.pool table: 0.9749, Acc.pillow: 0.7544, Acc.screen door: 0.7396, Acc.stairway: 0.5124, Acc.river: 0.1642, Acc.bridge: 0.8537, Acc.bookcase: 0.5983, Acc.blind: 0.4836, Acc.coffee table: 0.8425, Acc.toilet: 0.9085, Acc.flower: 0.5655, Acc.book: 0.6514, Acc.hill: 0.2075, Acc.bench: 0.5402, Acc.countertop: 0.7666, Acc.stove: 0.7597, Acc.palm: 0.7443, Acc.kitchen island: 0.7772, Acc.computer: 0.8570, Acc.swivel chair: 0.7244, Acc.boat: 0.5309, Acc.bar: 0.6219, Acc.arcade machine: 0.9251, Acc.hovel: 0.6493, Acc.bus: 0.9728, Acc.towel: 0.7734, Acc.light: 0.6827, Acc.truck: 0.4738, Acc.tower: 0.3703, Acc.chandelier: 0.8739, Acc.awning: 0.4409, Acc.streetlight: 0.3720, Acc.booth: 0.4844, Acc.television receiver: 0.8219, Acc.airplane: 0.6578, Acc.dirt track: 0.0003, Acc.apparel: 0.7588, Acc.pole: 0.3044, Acc.land: 0.0691, Acc.bannister: 0.1979, Acc.escalator: 0.4658, Acc.ottoman: 0.6100, Acc.bottle: 0.6268, Acc.buffet: 0.6307, Acc.poster: 0.4572, Acc.stage: 0.2978, Acc.van: 0.5626, Acc.ship: 0.3499, Acc.fountain: 0.2165, Acc.conveyer belt: 0.6532, Acc.canopy: 0.2400, Acc.washer: 0.7619, Acc.plaything: 0.4581, Acc.swimming pool: 0.9142, Acc.stool: 0.5267, Acc.barrel: 0.6692, Acc.basket: 0.5290, Acc.waterfall: 0.9692, Acc.tent: 0.9867, Acc.bag: 0.1713, Acc.minibike: 0.8305, Acc.cradle: 0.9619, Acc.oven: 0.5181, Acc.ball: 0.6786, Acc.food: 0.6411, Acc.step: 0.2156, Acc.tank: 0.3839, Acc.trade name: 0.2898, Acc.microwave: 0.9112, Acc.pot: 0.5567, Acc.animal: 0.6292, Acc.bicycle: 0.7902, Acc.lake: 0.6814, Acc.dishwasher: 0.7545, Acc.screen: 0.8994, Acc.blanket: 0.1593, Acc.sculpture: 0.8205, Acc.hood: 0.7065, Acc.sconce: 0.6188, Acc.vase: 0.5326, Acc.traffic light: 0.6178, Acc.tray: 0.1380, Acc.ashcan: 0.5138, Acc.fan: 0.7452, Acc.pier: 0.3315, Acc.crt screen: 0.1646, Acc.plate: 0.6727, Acc.monitor: 0.1173, Acc.bulletin board: 0.6069, Acc.shower: 0.0067, Acc.radiator: 0.7811, Acc.glass: 0.1520, Acc.clock: 0.5033, Acc.flag: 0.6338
2023-11-27 11:00:03,711 - mmseg - INFO - Iter [96050/160000]	lr: 2.398e-05, eta: 14:08:31, time: 2.675, data_time: 1.932, memory: 21695, decode.loss_ce: 0.2024, decode.acc_seg: 91.4958, aux.loss_ce: 0.0954, aux.acc_seg: 90.3419, loss: 0.2978
2023-11-27 11:00:41,822 - mmseg - INFO - Iter [96100/160000]	lr: 2.396e-05, eta: 14:07:50, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1940, decode.acc_seg: 91.7093, aux.loss_ce: 0.0934, aux.acc_seg: 90.4638, loss: 0.2874
2023-11-27 11:01:22,226 - mmseg - INFO - Iter [96150/160000]	lr: 2.394e-05, eta: 14:07:10, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2001, decode.acc_seg: 91.5711, aux.loss_ce: 0.0960, aux.acc_seg: 90.2903, loss: 0.2961
2023-11-27 11:02:03,255 - mmseg - INFO - Iter [96200/160000]	lr: 2.393e-05, eta: 14:06:31, time: 0.821, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2087, decode.acc_seg: 91.2299, aux.loss_ce: 0.1006, aux.acc_seg: 89.9400, loss: 0.3093
2023-11-27 11:02:41,198 - mmseg - INFO - Iter [96250/160000]	lr: 2.391e-05, eta: 14:05:50, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2107, decode.acc_seg: 91.0897, aux.loss_ce: 0.1012, aux.acc_seg: 89.7645, loss: 0.3119
2023-11-27 11:03:18,060 - mmseg - INFO - Iter [96300/160000]	lr: 2.389e-05, eta: 14:05:09, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2096, decode.acc_seg: 91.1485, aux.loss_ce: 0.1009, aux.acc_seg: 89.7307, loss: 0.3105
2023-11-27 11:03:58,210 - mmseg - INFO - Iter [96350/160000]	lr: 2.387e-05, eta: 14:04:29, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2160, decode.acc_seg: 90.8759, aux.loss_ce: 0.1036, aux.acc_seg: 89.4966, loss: 0.3196
2023-11-27 11:04:38,624 - mmseg - INFO - Iter [96400/160000]	lr: 2.385e-05, eta: 14:03:50, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2068, decode.acc_seg: 91.6049, aux.loss_ce: 0.0987, aux.acc_seg: 90.3127, loss: 0.3055
2023-11-27 11:05:19,460 - mmseg - INFO - Iter [96450/160000]	lr: 2.383e-05, eta: 14:03:10, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2090, decode.acc_seg: 91.1398, aux.loss_ce: 0.1008, aux.acc_seg: 89.8150, loss: 0.3098
2023-11-27 11:06:00,290 - mmseg - INFO - Iter [96500/160000]	lr: 2.381e-05, eta: 14:02:31, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1986, decode.acc_seg: 91.7631, aux.loss_ce: 0.0950, aux.acc_seg: 90.5605, loss: 0.2935
2023-11-27 11:06:38,183 - mmseg - INFO - Iter [96550/160000]	lr: 2.379e-05, eta: 14:01:50, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2198, decode.acc_seg: 90.7486, aux.loss_ce: 0.1034, aux.acc_seg: 89.5628, loss: 0.3232
2023-11-27 11:07:17,901 - mmseg - INFO - Iter [96600/160000]	lr: 2.378e-05, eta: 14:01:10, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2090, decode.acc_seg: 91.2949, aux.loss_ce: 0.1001, aux.acc_seg: 89.9684, loss: 0.3091
2023-11-27 11:07:58,223 - mmseg - INFO - Iter [96650/160000]	lr: 2.376e-05, eta: 14:00:31, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2081, decode.acc_seg: 91.3416, aux.loss_ce: 0.0989, aux.acc_seg: 90.0889, loss: 0.3070
2023-11-27 11:08:38,698 - mmseg - INFO - Iter [96700/160000]	lr: 2.374e-05, eta: 13:59:52, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2060, decode.acc_seg: 91.4366, aux.loss_ce: 0.0982, aux.acc_seg: 90.1422, loss: 0.3042
2023-11-27 11:09:19,078 - mmseg - INFO - Iter [96750/160000]	lr: 2.372e-05, eta: 13:59:12, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2121, decode.acc_seg: 90.9642, aux.loss_ce: 0.0999, aux.acc_seg: 89.8250, loss: 0.3120
2023-11-27 11:09:58,824 - mmseg - INFO - Iter [96800/160000]	lr: 2.370e-05, eta: 13:58:32, time: 0.794, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1955, decode.acc_seg: 91.6916, aux.loss_ce: 0.0951, aux.acc_seg: 90.2428, loss: 0.2906
2023-11-27 11:10:39,785 - mmseg - INFO - Iter [96850/160000]	lr: 2.368e-05, eta: 13:57:53, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1992, decode.acc_seg: 91.6009, aux.loss_ce: 0.0955, aux.acc_seg: 90.3394, loss: 0.2947
2023-11-27 11:11:20,051 - mmseg - INFO - Iter [96900/160000]	lr: 2.366e-05, eta: 13:57:14, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2233, decode.acc_seg: 90.8615, aux.loss_ce: 0.1051, aux.acc_seg: 89.6683, loss: 0.3285
2023-11-27 11:12:00,333 - mmseg - INFO - Iter [96950/160000]	lr: 2.364e-05, eta: 13:56:34, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2100, decode.acc_seg: 91.2476, aux.loss_ce: 0.0992, aux.acc_seg: 89.9575, loss: 0.3092
2023-11-27 11:12:39,673 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 11:12:39,674 - mmseg - INFO - Iter [97000/160000]	lr: 2.363e-05, eta: 13:55:54, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2128, decode.acc_seg: 90.9790, aux.loss_ce: 0.1032, aux.acc_seg: 89.4479, loss: 0.3160
2023-11-27 11:13:18,762 - mmseg - INFO - Iter [97050/160000]	lr: 2.361e-05, eta: 13:55:14, time: 0.783, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2180, decode.acc_seg: 90.9566, aux.loss_ce: 0.1042, aux.acc_seg: 89.6788, loss: 0.3223
2023-11-27 11:13:56,663 - mmseg - INFO - Iter [97100/160000]	lr: 2.359e-05, eta: 13:54:33, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2104, decode.acc_seg: 91.1001, aux.loss_ce: 0.0988, aux.acc_seg: 89.9443, loss: 0.3092
2023-11-27 11:14:37,042 - mmseg - INFO - Iter [97150/160000]	lr: 2.357e-05, eta: 13:53:53, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2277, decode.acc_seg: 90.9965, aux.loss_ce: 0.1105, aux.acc_seg: 89.4539, loss: 0.3382
2023-11-27 11:15:15,738 - mmseg - INFO - Iter [97200/160000]	lr: 2.355e-05, eta: 13:53:13, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2218, decode.acc_seg: 90.9117, aux.loss_ce: 0.1042, aux.acc_seg: 89.5578, loss: 0.3260
2023-11-27 11:15:52,523 - mmseg - INFO - Iter [97250/160000]	lr: 2.353e-05, eta: 13:52:31, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2119, decode.acc_seg: 90.8059, aux.loss_ce: 0.1016, aux.acc_seg: 89.3960, loss: 0.3135
2023-11-27 11:16:34,637 - mmseg - INFO - Iter [97300/160000]	lr: 2.351e-05, eta: 13:51:53, time: 0.841, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2111, decode.acc_seg: 91.0984, aux.loss_ce: 0.1017, aux.acc_seg: 89.6664, loss: 0.3128
2023-11-27 11:17:14,578 - mmseg - INFO - Iter [97350/160000]	lr: 2.349e-05, eta: 13:51:13, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2209, decode.acc_seg: 91.0354, aux.loss_ce: 0.1062, aux.acc_seg: 89.5907, loss: 0.3272
2023-11-27 11:17:51,896 - mmseg - INFO - Iter [97400/160000]	lr: 2.348e-05, eta: 13:50:32, time: 0.746, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2009, decode.acc_seg: 91.5483, aux.loss_ce: 0.0964, aux.acc_seg: 90.2588, loss: 0.2973
2023-11-27 11:18:31,978 - mmseg - INFO - Iter [97450/160000]	lr: 2.346e-05, eta: 13:49:52, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2139, decode.acc_seg: 90.8837, aux.loss_ce: 0.1045, aux.acc_seg: 89.3599, loss: 0.3185
2023-11-27 11:19:12,614 - mmseg - INFO - Iter [97500/160000]	lr: 2.344e-05, eta: 13:49:13, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1985, decode.acc_seg: 91.7751, aux.loss_ce: 0.0953, aux.acc_seg: 90.3965, loss: 0.2938
2023-11-27 11:19:52,491 - mmseg - INFO - Iter [97550/160000]	lr: 2.342e-05, eta: 13:48:33, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2101, decode.acc_seg: 91.3018, aux.loss_ce: 0.0995, aux.acc_seg: 90.1509, loss: 0.3096
2023-11-27 11:20:32,921 - mmseg - INFO - Iter [97600/160000]	lr: 2.340e-05, eta: 13:47:54, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2062, decode.acc_seg: 91.5553, aux.loss_ce: 0.0968, aux.acc_seg: 90.3882, loss: 0.3030
2023-11-27 11:21:12,854 - mmseg - INFO - Iter [97650/160000]	lr: 2.338e-05, eta: 13:47:14, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2137, decode.acc_seg: 90.9743, aux.loss_ce: 0.1029, aux.acc_seg: 89.6154, loss: 0.3166
2023-11-27 11:21:51,301 - mmseg - INFO - Iter [97700/160000]	lr: 2.336e-05, eta: 13:46:33, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1967, decode.acc_seg: 91.6664, aux.loss_ce: 0.0941, aux.acc_seg: 90.4493, loss: 0.2908
2023-11-27 11:22:28,597 - mmseg - INFO - Iter [97750/160000]	lr: 2.334e-05, eta: 13:45:52, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2124, decode.acc_seg: 91.1776, aux.loss_ce: 0.1016, aux.acc_seg: 89.9169, loss: 0.3140
2023-11-27 11:23:09,324 - mmseg - INFO - Iter [97800/160000]	lr: 2.333e-05, eta: 13:45:13, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1971, decode.acc_seg: 91.7430, aux.loss_ce: 0.0953, aux.acc_seg: 90.3231, loss: 0.2924
2023-11-27 11:23:49,311 - mmseg - INFO - Iter [97850/160000]	lr: 2.331e-05, eta: 13:44:33, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2112, decode.acc_seg: 91.2997, aux.loss_ce: 0.1008, aux.acc_seg: 89.9134, loss: 0.3120
2023-11-27 11:24:28,454 - mmseg - INFO - Iter [97900/160000]	lr: 2.329e-05, eta: 13:43:53, time: 0.784, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2120, decode.acc_seg: 90.8896, aux.loss_ce: 0.1031, aux.acc_seg: 89.3938, loss: 0.3151
2023-11-27 11:25:08,522 - mmseg - INFO - Iter [97950/160000]	lr: 2.327e-05, eta: 13:43:13, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2116, decode.acc_seg: 91.1507, aux.loss_ce: 0.1018, aux.acc_seg: 89.8794, loss: 0.3134
2023-11-27 11:25:47,602 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 11:25:47,602 - mmseg - INFO - Iter [98000/160000]	lr: 2.325e-05, eta: 13:42:33, time: 0.783, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2050, decode.acc_seg: 91.3552, aux.loss_ce: 0.0959, aux.acc_seg: 90.2336, loss: 0.3009
2023-11-27 11:26:24,940 - mmseg - INFO - Iter [98050/160000]	lr: 2.323e-05, eta: 13:41:51, time: 0.746, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1953, decode.acc_seg: 91.6955, aux.loss_ce: 0.0924, aux.acc_seg: 90.5688, loss: 0.2877
2023-11-27 11:27:03,005 - mmseg - INFO - Iter [98100/160000]	lr: 2.321e-05, eta: 13:41:11, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2079, decode.acc_seg: 90.8286, aux.loss_ce: 0.0997, aux.acc_seg: 89.5391, loss: 0.3075
2023-11-27 11:27:43,039 - mmseg - INFO - Iter [98150/160000]	lr: 2.319e-05, eta: 13:40:31, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2091, decode.acc_seg: 90.8398, aux.loss_ce: 0.1002, aux.acc_seg: 89.4566, loss: 0.3092
2023-11-27 11:28:19,866 - mmseg - INFO - Iter [98200/160000]	lr: 2.318e-05, eta: 13:39:49, time: 0.737, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2051, decode.acc_seg: 91.4226, aux.loss_ce: 0.0979, aux.acc_seg: 90.0666, loss: 0.3030
2023-11-27 11:28:56,675 - mmseg - INFO - Iter [98250/160000]	lr: 2.316e-05, eta: 13:39:08, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2145, decode.acc_seg: 90.9826, aux.loss_ce: 0.1031, aux.acc_seg: 89.6482, loss: 0.3176
2023-11-27 11:29:34,224 - mmseg - INFO - Iter [98300/160000]	lr: 2.314e-05, eta: 13:38:26, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2019, decode.acc_seg: 91.5249, aux.loss_ce: 0.0975, aux.acc_seg: 90.2323, loss: 0.2993
2023-11-27 11:30:14,541 - mmseg - INFO - Iter [98350/160000]	lr: 2.312e-05, eta: 13:37:47, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2182, decode.acc_seg: 90.8578, aux.loss_ce: 0.1018, aux.acc_seg: 89.6796, loss: 0.3200
2023-11-27 11:30:52,012 - mmseg - INFO - Iter [98400/160000]	lr: 2.310e-05, eta: 13:37:06, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2029, decode.acc_seg: 91.4774, aux.loss_ce: 0.0976, aux.acc_seg: 90.1703, loss: 0.3005
2023-11-27 11:31:29,827 - mmseg - INFO - Iter [98450/160000]	lr: 2.308e-05, eta: 13:36:25, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2106, decode.acc_seg: 91.3442, aux.loss_ce: 0.1003, aux.acc_seg: 90.0328, loss: 0.3109
2023-11-27 11:32:08,321 - mmseg - INFO - Iter [98500/160000]	lr: 2.306e-05, eta: 13:35:44, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2266, decode.acc_seg: 90.7471, aux.loss_ce: 0.1062, aux.acc_seg: 89.4877, loss: 0.3328
2023-11-27 11:32:48,148 - mmseg - INFO - Iter [98550/160000]	lr: 2.304e-05, eta: 13:35:04, time: 0.796, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2074, decode.acc_seg: 91.4198, aux.loss_ce: 0.0983, aux.acc_seg: 90.1661, loss: 0.3057
2023-11-27 11:33:27,673 - mmseg - INFO - Iter [98600/160000]	lr: 2.303e-05, eta: 13:34:24, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2040, decode.acc_seg: 91.3939, aux.loss_ce: 0.0984, aux.acc_seg: 90.0229, loss: 0.3024
2023-11-27 11:34:06,626 - mmseg - INFO - Iter [98650/160000]	lr: 2.301e-05, eta: 13:33:44, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2092, decode.acc_seg: 91.3377, aux.loss_ce: 0.1009, aux.acc_seg: 89.9861, loss: 0.3102
2023-11-27 11:34:47,492 - mmseg - INFO - Iter [98700/160000]	lr: 2.299e-05, eta: 13:33:05, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2264, decode.acc_seg: 90.7109, aux.loss_ce: 0.1087, aux.acc_seg: 89.2938, loss: 0.3351
2023-11-27 11:35:25,391 - mmseg - INFO - Iter [98750/160000]	lr: 2.297e-05, eta: 13:32:24, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2076, decode.acc_seg: 91.5069, aux.loss_ce: 0.0995, aux.acc_seg: 90.0902, loss: 0.3071
2023-11-27 11:36:04,186 - mmseg - INFO - Iter [98800/160000]	lr: 2.295e-05, eta: 13:31:43, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2049, decode.acc_seg: 91.2779, aux.loss_ce: 0.0984, aux.acc_seg: 90.0235, loss: 0.3033
2023-11-27 11:36:44,382 - mmseg - INFO - Iter [98850/160000]	lr: 2.293e-05, eta: 13:31:04, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2117, decode.acc_seg: 91.7367, aux.loss_ce: 0.1019, aux.acc_seg: 90.2664, loss: 0.3135
2023-11-27 11:37:23,783 - mmseg - INFO - Iter [98900/160000]	lr: 2.291e-05, eta: 13:30:24, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2262, decode.acc_seg: 90.8260, aux.loss_ce: 0.1066, aux.acc_seg: 89.4652, loss: 0.3328
2023-11-27 11:38:03,332 - mmseg - INFO - Iter [98950/160000]	lr: 2.289e-05, eta: 13:29:44, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2039, decode.acc_seg: 91.3486, aux.loss_ce: 0.0981, aux.acc_seg: 89.9984, loss: 0.3020
2023-11-27 11:38:41,780 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 11:38:41,780 - mmseg - INFO - Iter [99000/160000]	lr: 2.288e-05, eta: 13:29:03, time: 0.770, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2193, decode.acc_seg: 91.0681, aux.loss_ce: 0.1054, aux.acc_seg: 89.6401, loss: 0.3248
2023-11-27 11:39:19,291 - mmseg - INFO - Iter [99050/160000]	lr: 2.286e-05, eta: 13:28:22, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2143, decode.acc_seg: 90.8494, aux.loss_ce: 0.1018, aux.acc_seg: 89.5167, loss: 0.3161
2023-11-27 11:39:57,781 - mmseg - INFO - Iter [99100/160000]	lr: 2.284e-05, eta: 13:27:42, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2106, decode.acc_seg: 91.4912, aux.loss_ce: 0.0996, aux.acc_seg: 90.1650, loss: 0.3102
2023-11-27 11:40:38,298 - mmseg - INFO - Iter [99150/160000]	lr: 2.282e-05, eta: 13:27:02, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2185, decode.acc_seg: 90.8076, aux.loss_ce: 0.1067, aux.acc_seg: 89.2303, loss: 0.3252
2023-11-27 11:41:16,476 - mmseg - INFO - Iter [99200/160000]	lr: 2.280e-05, eta: 13:26:21, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 91.2896, aux.loss_ce: 0.0984, aux.acc_seg: 89.9832, loss: 0.3054
2023-11-27 11:41:54,239 - mmseg - INFO - Iter [99250/160000]	lr: 2.278e-05, eta: 13:25:40, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2069, decode.acc_seg: 91.2516, aux.loss_ce: 0.0984, aux.acc_seg: 90.0609, loss: 0.3052
2023-11-27 11:42:33,062 - mmseg - INFO - Iter [99300/160000]	lr: 2.276e-05, eta: 13:25:00, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1958, decode.acc_seg: 91.8008, aux.loss_ce: 0.0955, aux.acc_seg: 90.4746, loss: 0.2913
2023-11-27 11:43:11,444 - mmseg - INFO - Iter [99350/160000]	lr: 2.274e-05, eta: 13:24:19, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2255, decode.acc_seg: 90.7611, aux.loss_ce: 0.1076, aux.acc_seg: 89.3317, loss: 0.3332
2023-11-27 11:43:51,579 - mmseg - INFO - Iter [99400/160000]	lr: 2.273e-05, eta: 13:23:40, time: 0.802, data_time: 0.009, memory: 21695, decode.loss_ce: 0.2092, decode.acc_seg: 91.3191, aux.loss_ce: 0.0987, aux.acc_seg: 89.9712, loss: 0.3078
2023-11-27 11:44:31,786 - mmseg - INFO - Iter [99450/160000]	lr: 2.271e-05, eta: 13:23:00, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2001, decode.acc_seg: 91.5306, aux.loss_ce: 0.0947, aux.acc_seg: 90.3199, loss: 0.2948
2023-11-27 11:45:12,146 - mmseg - INFO - Iter [99500/160000]	lr: 2.269e-05, eta: 13:22:21, time: 0.807, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2006, decode.acc_seg: 91.5299, aux.loss_ce: 0.0960, aux.acc_seg: 90.2085, loss: 0.2966
2023-11-27 11:45:50,844 - mmseg - INFO - Iter [99550/160000]	lr: 2.267e-05, eta: 13:21:40, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2175, decode.acc_seg: 91.1575, aux.loss_ce: 0.1032, aux.acc_seg: 89.8998, loss: 0.3207
2023-11-27 11:46:30,281 - mmseg - INFO - Iter [99600/160000]	lr: 2.265e-05, eta: 13:21:00, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1897, decode.acc_seg: 92.1082, aux.loss_ce: 0.0917, aux.acc_seg: 90.8089, loss: 0.2814
2023-11-27 11:47:08,865 - mmseg - INFO - Iter [99650/160000]	lr: 2.263e-05, eta: 13:20:20, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2088, decode.acc_seg: 91.1810, aux.loss_ce: 0.1004, aux.acc_seg: 89.8422, loss: 0.3091
2023-11-27 11:47:45,568 - mmseg - INFO - Iter [99700/160000]	lr: 2.261e-05, eta: 13:19:38, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2014, decode.acc_seg: 91.5542, aux.loss_ce: 0.0976, aux.acc_seg: 90.1048, loss: 0.2990
2023-11-27 11:48:21,901 - mmseg - INFO - Iter [99750/160000]	lr: 2.259e-05, eta: 13:18:56, time: 0.726, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2155, decode.acc_seg: 90.9951, aux.loss_ce: 0.1026, aux.acc_seg: 89.5577, loss: 0.3181
2023-11-27 11:49:03,503 - mmseg - INFO - Iter [99800/160000]	lr: 2.258e-05, eta: 13:18:18, time: 0.831, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2059, decode.acc_seg: 91.3161, aux.loss_ce: 0.1011, aux.acc_seg: 89.8218, loss: 0.3071
2023-11-27 11:49:44,027 - mmseg - INFO - Iter [99850/160000]	lr: 2.256e-05, eta: 13:17:38, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 91.3289, aux.loss_ce: 0.0995, aux.acc_seg: 89.8896, loss: 0.3065
2023-11-27 11:50:24,866 - mmseg - INFO - Iter [99900/160000]	lr: 2.254e-05, eta: 13:16:59, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2065, decode.acc_seg: 91.1429, aux.loss_ce: 0.1011, aux.acc_seg: 89.7344, loss: 0.3076
2023-11-27 11:51:03,933 - mmseg - INFO - Iter [99950/160000]	lr: 2.252e-05, eta: 13:16:19, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2065, decode.acc_seg: 91.3818, aux.loss_ce: 0.0987, aux.acc_seg: 89.9882, loss: 0.3053
2023-11-27 11:51:41,949 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 11:51:41,949 - mmseg - INFO - Iter [100000/160000]	lr: 2.250e-05, eta: 13:15:38, time: 0.760, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1989, decode.acc_seg: 91.7125, aux.loss_ce: 0.0939, aux.acc_seg: 90.4872, loss: 0.2928
2023-11-27 11:52:22,375 - mmseg - INFO - Iter [100050/160000]	lr: 2.248e-05, eta: 13:14:59, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2034, decode.acc_seg: 91.3173, aux.loss_ce: 0.0980, aux.acc_seg: 89.9907, loss: 0.3015
2023-11-27 11:53:00,739 - mmseg - INFO - Iter [100100/160000]	lr: 2.246e-05, eta: 13:14:18, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2083, decode.acc_seg: 91.3399, aux.loss_ce: 0.0998, aux.acc_seg: 89.9598, loss: 0.3081
2023-11-27 11:53:40,374 - mmseg - INFO - Iter [100150/160000]	lr: 2.244e-05, eta: 13:13:38, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2189, decode.acc_seg: 91.2470, aux.loss_ce: 0.1031, aux.acc_seg: 89.8809, loss: 0.3220
2023-11-27 11:54:20,527 - mmseg - INFO - Iter [100200/160000]	lr: 2.243e-05, eta: 13:12:59, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1993, decode.acc_seg: 91.4020, aux.loss_ce: 0.0946, aux.acc_seg: 90.1821, loss: 0.2939
2023-11-27 11:55:00,568 - mmseg - INFO - Iter [100250/160000]	lr: 2.241e-05, eta: 13:12:19, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2030, decode.acc_seg: 91.5891, aux.loss_ce: 0.0974, aux.acc_seg: 90.2284, loss: 0.3004
2023-11-27 11:55:39,268 - mmseg - INFO - Iter [100300/160000]	lr: 2.239e-05, eta: 13:11:39, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2122, decode.acc_seg: 91.0754, aux.loss_ce: 0.1011, aux.acc_seg: 89.9092, loss: 0.3133
2023-11-27 11:56:20,488 - mmseg - INFO - Iter [100350/160000]	lr: 2.237e-05, eta: 13:11:00, time: 0.824, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2089, decode.acc_seg: 91.1903, aux.loss_ce: 0.0999, aux.acc_seg: 89.9615, loss: 0.3088
2023-11-27 11:57:01,297 - mmseg - INFO - Iter [100400/160000]	lr: 2.235e-05, eta: 13:10:21, time: 0.816, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1958, decode.acc_seg: 91.8497, aux.loss_ce: 0.0932, aux.acc_seg: 90.7408, loss: 0.2890
2023-11-27 11:57:41,611 - mmseg - INFO - Iter [100450/160000]	lr: 2.233e-05, eta: 13:09:41, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 90.9954, aux.loss_ce: 0.0974, aux.acc_seg: 89.8384, loss: 0.3044
2023-11-27 11:58:22,430 - mmseg - INFO - Iter [100500/160000]	lr: 2.231e-05, eta: 13:09:02, time: 0.816, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2199, decode.acc_seg: 90.9066, aux.loss_ce: 0.1049, aux.acc_seg: 89.6032, loss: 0.3248
2023-11-27 11:59:03,831 - mmseg - INFO - Iter [100550/160000]	lr: 2.229e-05, eta: 13:08:23, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2083, decode.acc_seg: 91.3773, aux.loss_ce: 0.0984, aux.acc_seg: 90.1833, loss: 0.3067
2023-11-27 11:59:45,120 - mmseg - INFO - Iter [100600/160000]	lr: 2.228e-05, eta: 13:07:44, time: 0.826, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2030, decode.acc_seg: 91.5187, aux.loss_ce: 0.0985, aux.acc_seg: 90.0202, loss: 0.3015
2023-11-27 12:00:23,502 - mmseg - INFO - Iter [100650/160000]	lr: 2.226e-05, eta: 13:07:04, time: 0.768, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2011, decode.acc_seg: 91.3052, aux.loss_ce: 0.0968, aux.acc_seg: 89.9790, loss: 0.2979
2023-11-27 12:01:04,553 - mmseg - INFO - Iter [100700/160000]	lr: 2.224e-05, eta: 13:06:25, time: 0.821, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1951, decode.acc_seg: 92.0279, aux.loss_ce: 0.0954, aux.acc_seg: 90.7118, loss: 0.2905
2023-11-27 12:01:43,072 - mmseg - INFO - Iter [100750/160000]	lr: 2.222e-05, eta: 13:05:44, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2068, decode.acc_seg: 91.1159, aux.loss_ce: 0.0990, aux.acc_seg: 89.7942, loss: 0.3058
2023-11-27 12:02:23,498 - mmseg - INFO - Iter [100800/160000]	lr: 2.220e-05, eta: 13:05:05, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1886, decode.acc_seg: 91.8558, aux.loss_ce: 0.0905, aux.acc_seg: 90.4534, loss: 0.2791
2023-11-27 12:03:03,565 - mmseg - INFO - Iter [100850/160000]	lr: 2.218e-05, eta: 13:04:25, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2033, decode.acc_seg: 91.5116, aux.loss_ce: 0.0964, aux.acc_seg: 90.2352, loss: 0.2997
2023-11-27 12:03:43,372 - mmseg - INFO - Iter [100900/160000]	lr: 2.216e-05, eta: 13:03:45, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2005, decode.acc_seg: 91.4410, aux.loss_ce: 0.0972, aux.acc_seg: 90.0724, loss: 0.2977
2023-11-27 12:04:24,571 - mmseg - INFO - Iter [100950/160000]	lr: 2.214e-05, eta: 13:03:06, time: 0.824, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2055, decode.acc_seg: 91.2139, aux.loss_ce: 0.0983, aux.acc_seg: 89.8622, loss: 0.3038
2023-11-27 12:05:05,467 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 12:05:05,468 - mmseg - INFO - Iter [101000/160000]	lr: 2.213e-05, eta: 13:02:27, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1978, decode.acc_seg: 91.6498, aux.loss_ce: 0.0947, aux.acc_seg: 90.2751, loss: 0.2925
2023-11-27 12:05:46,953 - mmseg - INFO - Iter [101050/160000]	lr: 2.211e-05, eta: 13:01:48, time: 0.830, data_time: 0.052, memory: 21695, decode.loss_ce: 0.2180, decode.acc_seg: 90.8438, aux.loss_ce: 0.1040, aux.acc_seg: 89.4391, loss: 0.3220
2023-11-27 12:06:27,729 - mmseg - INFO - Iter [101100/160000]	lr: 2.209e-05, eta: 13:01:09, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2129, decode.acc_seg: 91.0717, aux.loss_ce: 0.1011, aux.acc_seg: 89.6615, loss: 0.3140
2023-11-27 12:07:05,257 - mmseg - INFO - Iter [101150/160000]	lr: 2.207e-05, eta: 13:00:28, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2192, decode.acc_seg: 90.5694, aux.loss_ce: 0.1037, aux.acc_seg: 89.3882, loss: 0.3229
2023-11-27 12:07:43,625 - mmseg - INFO - Iter [101200/160000]	lr: 2.205e-05, eta: 12:59:47, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2012, decode.acc_seg: 91.2792, aux.loss_ce: 0.0945, aux.acc_seg: 90.0884, loss: 0.2957
2023-11-27 12:08:23,615 - mmseg - INFO - Iter [101250/160000]	lr: 2.203e-05, eta: 12:59:08, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2054, decode.acc_seg: 91.4960, aux.loss_ce: 0.0985, aux.acc_seg: 90.1539, loss: 0.3039
2023-11-27 12:09:02,867 - mmseg - INFO - Iter [101300/160000]	lr: 2.201e-05, eta: 12:58:28, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2041, decode.acc_seg: 91.5851, aux.loss_ce: 0.0988, aux.acc_seg: 90.2071, loss: 0.3029
2023-11-27 12:09:40,282 - mmseg - INFO - Iter [101350/160000]	lr: 2.199e-05, eta: 12:57:47, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2147, decode.acc_seg: 91.1243, aux.loss_ce: 0.1022, aux.acc_seg: 89.7211, loss: 0.3169
2023-11-27 12:10:17,698 - mmseg - INFO - Iter [101400/160000]	lr: 2.198e-05, eta: 12:57:05, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2176, decode.acc_seg: 91.1466, aux.loss_ce: 0.1032, aux.acc_seg: 89.8190, loss: 0.3208
2023-11-27 12:10:56,966 - mmseg - INFO - Iter [101450/160000]	lr: 2.196e-05, eta: 12:56:25, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1946, decode.acc_seg: 91.8356, aux.loss_ce: 0.0924, aux.acc_seg: 90.6289, loss: 0.2870
2023-11-27 12:11:36,384 - mmseg - INFO - Iter [101500/160000]	lr: 2.194e-05, eta: 12:55:45, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2067, decode.acc_seg: 91.3433, aux.loss_ce: 0.1020, aux.acc_seg: 89.8723, loss: 0.3087
2023-11-27 12:12:14,337 - mmseg - INFO - Iter [101550/160000]	lr: 2.192e-05, eta: 12:55:04, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1939, decode.acc_seg: 91.7854, aux.loss_ce: 0.0951, aux.acc_seg: 90.2735, loss: 0.2890
2023-11-27 12:12:55,190 - mmseg - INFO - Iter [101600/160000]	lr: 2.190e-05, eta: 12:54:25, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2030, decode.acc_seg: 91.3230, aux.loss_ce: 0.0993, aux.acc_seg: 89.7561, loss: 0.3023
2023-11-27 12:13:33,235 - mmseg - INFO - Iter [101650/160000]	lr: 2.188e-05, eta: 12:53:44, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 92.0448, aux.loss_ce: 0.0913, aux.acc_seg: 90.8547, loss: 0.2835
2023-11-27 12:14:13,892 - mmseg - INFO - Iter [101700/160000]	lr: 2.186e-05, eta: 12:53:05, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2034, decode.acc_seg: 91.4883, aux.loss_ce: 0.0973, aux.acc_seg: 90.2458, loss: 0.3007
2023-11-27 12:14:54,823 - mmseg - INFO - Iter [101750/160000]	lr: 2.184e-05, eta: 12:52:26, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1970, decode.acc_seg: 91.5283, aux.loss_ce: 0.0949, aux.acc_seg: 90.1596, loss: 0.2919
2023-11-27 12:15:35,497 - mmseg - INFO - Iter [101800/160000]	lr: 2.183e-05, eta: 12:51:47, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1934, decode.acc_seg: 91.9954, aux.loss_ce: 0.0927, aux.acc_seg: 90.7156, loss: 0.2860
2023-11-27 12:16:15,434 - mmseg - INFO - Iter [101850/160000]	lr: 2.181e-05, eta: 12:51:07, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2169, decode.acc_seg: 90.8160, aux.loss_ce: 0.1013, aux.acc_seg: 89.6958, loss: 0.3183
2023-11-27 12:16:54,253 - mmseg - INFO - Iter [101900/160000]	lr: 2.179e-05, eta: 12:50:27, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2000, decode.acc_seg: 91.2917, aux.loss_ce: 0.0968, aux.acc_seg: 90.0041, loss: 0.2968
2023-11-27 12:17:31,946 - mmseg - INFO - Iter [101950/160000]	lr: 2.177e-05, eta: 12:49:46, time: 0.753, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2238, decode.acc_seg: 90.8298, aux.loss_ce: 0.1060, aux.acc_seg: 89.4577, loss: 0.3298
2023-11-27 12:18:11,222 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 12:18:11,222 - mmseg - INFO - Iter [102000/160000]	lr: 2.175e-05, eta: 12:49:06, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2062, decode.acc_seg: 91.5202, aux.loss_ce: 0.0996, aux.acc_seg: 90.1981, loss: 0.3057
2023-11-27 12:18:51,490 - mmseg - INFO - Iter [102050/160000]	lr: 2.173e-05, eta: 12:48:26, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2034, decode.acc_seg: 91.4408, aux.loss_ce: 0.0964, aux.acc_seg: 90.2027, loss: 0.2998
2023-11-27 12:19:30,540 - mmseg - INFO - Iter [102100/160000]	lr: 2.171e-05, eta: 12:47:46, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2179, decode.acc_seg: 90.9448, aux.loss_ce: 0.1048, aux.acc_seg: 89.6676, loss: 0.3227
2023-11-27 12:20:11,251 - mmseg - INFO - Iter [102150/160000]	lr: 2.169e-05, eta: 12:47:07, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2288, decode.acc_seg: 90.6559, aux.loss_ce: 0.1082, aux.acc_seg: 89.2935, loss: 0.3370
2023-11-27 12:20:51,721 - mmseg - INFO - Iter [102200/160000]	lr: 2.168e-05, eta: 12:46:27, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2035, decode.acc_seg: 91.3497, aux.loss_ce: 0.0974, aux.acc_seg: 90.0876, loss: 0.3009
2023-11-27 12:21:32,559 - mmseg - INFO - Iter [102250/160000]	lr: 2.166e-05, eta: 12:45:48, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2079, decode.acc_seg: 91.2913, aux.loss_ce: 0.1017, aux.acc_seg: 90.0083, loss: 0.3096
2023-11-27 12:22:13,024 - mmseg - INFO - Iter [102300/160000]	lr: 2.164e-05, eta: 12:45:09, time: 0.810, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2039, decode.acc_seg: 91.3755, aux.loss_ce: 0.0979, aux.acc_seg: 90.0645, loss: 0.3019
2023-11-27 12:22:55,107 - mmseg - INFO - Iter [102350/160000]	lr: 2.162e-05, eta: 12:44:30, time: 0.841, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2040, decode.acc_seg: 91.4160, aux.loss_ce: 0.0971, aux.acc_seg: 90.2290, loss: 0.3012
2023-11-27 12:23:35,620 - mmseg - INFO - Iter [102400/160000]	lr: 2.160e-05, eta: 12:43:51, time: 0.810, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1906, decode.acc_seg: 91.9507, aux.loss_ce: 0.0915, aux.acc_seg: 90.6112, loss: 0.2821
2023-11-27 12:24:15,458 - mmseg - INFO - Iter [102450/160000]	lr: 2.158e-05, eta: 12:43:11, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2005, decode.acc_seg: 91.5369, aux.loss_ce: 0.0969, aux.acc_seg: 90.3401, loss: 0.2973
2023-11-27 12:24:53,614 - mmseg - INFO - Iter [102500/160000]	lr: 2.156e-05, eta: 12:42:31, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1966, decode.acc_seg: 91.4834, aux.loss_ce: 0.0943, aux.acc_seg: 90.3162, loss: 0.2908
2023-11-27 12:25:31,956 - mmseg - INFO - Iter [102550/160000]	lr: 2.154e-05, eta: 12:41:50, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2039, decode.acc_seg: 91.5237, aux.loss_ce: 0.0982, aux.acc_seg: 90.1321, loss: 0.3021
2023-11-27 12:26:08,787 - mmseg - INFO - Iter [102600/160000]	lr: 2.153e-05, eta: 12:41:08, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1966, decode.acc_seg: 91.6766, aux.loss_ce: 0.0968, aux.acc_seg: 90.1814, loss: 0.2935
2023-11-27 12:26:49,177 - mmseg - INFO - Iter [102650/160000]	lr: 2.151e-05, eta: 12:40:29, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2023, decode.acc_seg: 91.3714, aux.loss_ce: 0.0956, aux.acc_seg: 90.2366, loss: 0.2979
2023-11-27 12:27:29,514 - mmseg - INFO - Iter [102700/160000]	lr: 2.149e-05, eta: 12:39:50, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2092, decode.acc_seg: 91.1113, aux.loss_ce: 0.1014, aux.acc_seg: 89.7497, loss: 0.3106
2023-11-27 12:28:09,845 - mmseg - INFO - Iter [102750/160000]	lr: 2.147e-05, eta: 12:39:10, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.8035, aux.loss_ce: 0.0953, aux.acc_seg: 90.4569, loss: 0.2934
2023-11-27 12:28:50,318 - mmseg - INFO - Iter [102800/160000]	lr: 2.145e-05, eta: 12:38:31, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1991, decode.acc_seg: 91.4341, aux.loss_ce: 0.0953, aux.acc_seg: 90.1318, loss: 0.2944
2023-11-27 12:29:31,098 - mmseg - INFO - Iter [102850/160000]	lr: 2.143e-05, eta: 12:37:51, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2135, decode.acc_seg: 91.0786, aux.loss_ce: 0.1003, aux.acc_seg: 89.8021, loss: 0.3138
2023-11-27 12:30:12,460 - mmseg - INFO - Iter [102900/160000]	lr: 2.141e-05, eta: 12:37:13, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1958, decode.acc_seg: 91.8293, aux.loss_ce: 0.0932, aux.acc_seg: 90.6062, loss: 0.2890
2023-11-27 12:30:51,291 - mmseg - INFO - Iter [102950/160000]	lr: 2.139e-05, eta: 12:36:32, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2150, decode.acc_seg: 91.0276, aux.loss_ce: 0.1038, aux.acc_seg: 89.5492, loss: 0.3187
2023-11-27 12:31:31,385 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 12:31:31,385 - mmseg - INFO - Iter [103000/160000]	lr: 2.138e-05, eta: 12:35:53, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2017, decode.acc_seg: 91.5724, aux.loss_ce: 0.0965, aux.acc_seg: 90.2165, loss: 0.2982
2023-11-27 12:32:11,607 - mmseg - INFO - Iter [103050/160000]	lr: 2.136e-05, eta: 12:35:13, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1993, decode.acc_seg: 91.5208, aux.loss_ce: 0.0948, aux.acc_seg: 90.3671, loss: 0.2941
2023-11-27 12:32:52,246 - mmseg - INFO - Iter [103100/160000]	lr: 2.134e-05, eta: 12:34:34, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2009, decode.acc_seg: 91.4105, aux.loss_ce: 0.0949, aux.acc_seg: 90.3155, loss: 0.2959
2023-11-27 12:33:31,889 - mmseg - INFO - Iter [103150/160000]	lr: 2.132e-05, eta: 12:33:54, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1942, decode.acc_seg: 91.6030, aux.loss_ce: 0.0930, aux.acc_seg: 90.2739, loss: 0.2871
2023-11-27 12:34:11,596 - mmseg - INFO - Iter [103200/160000]	lr: 2.130e-05, eta: 12:33:14, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2035, decode.acc_seg: 91.1176, aux.loss_ce: 0.0977, aux.acc_seg: 89.8464, loss: 0.3012
2023-11-27 12:34:48,879 - mmseg - INFO - Iter [103250/160000]	lr: 2.128e-05, eta: 12:32:33, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2062, decode.acc_seg: 91.2790, aux.loss_ce: 0.0965, aux.acc_seg: 90.1606, loss: 0.3028
2023-11-27 12:35:28,647 - mmseg - INFO - Iter [103300/160000]	lr: 2.126e-05, eta: 12:31:53, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1994, decode.acc_seg: 91.6979, aux.loss_ce: 0.0945, aux.acc_seg: 90.5283, loss: 0.2939
2023-11-27 12:36:09,585 - mmseg - INFO - Iter [103350/160000]	lr: 2.124e-05, eta: 12:31:14, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2022, decode.acc_seg: 91.4560, aux.loss_ce: 0.0970, aux.acc_seg: 90.1280, loss: 0.2992
2023-11-27 12:36:47,989 - mmseg - INFO - Iter [103400/160000]	lr: 2.123e-05, eta: 12:30:33, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2302, decode.acc_seg: 90.6474, aux.loss_ce: 0.1079, aux.acc_seg: 89.3905, loss: 0.3381
2023-11-27 12:37:27,813 - mmseg - INFO - Iter [103450/160000]	lr: 2.121e-05, eta: 12:29:54, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2217, decode.acc_seg: 90.6881, aux.loss_ce: 0.1058, aux.acc_seg: 89.3976, loss: 0.3275
2023-11-27 12:38:07,538 - mmseg - INFO - Iter [103500/160000]	lr: 2.119e-05, eta: 12:29:14, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2051, decode.acc_seg: 91.3538, aux.loss_ce: 0.0984, aux.acc_seg: 90.2055, loss: 0.3034
2023-11-27 12:38:47,456 - mmseg - INFO - Iter [103550/160000]	lr: 2.117e-05, eta: 12:28:34, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1977, decode.acc_seg: 91.6058, aux.loss_ce: 0.0938, aux.acc_seg: 90.3424, loss: 0.2914
2023-11-27 12:39:28,630 - mmseg - INFO - Iter [103600/160000]	lr: 2.115e-05, eta: 12:27:55, time: 0.824, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2046, decode.acc_seg: 91.4160, aux.loss_ce: 0.0977, aux.acc_seg: 89.9881, loss: 0.3023
2023-11-27 12:40:08,866 - mmseg - INFO - Iter [103650/160000]	lr: 2.113e-05, eta: 12:27:16, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2060, decode.acc_seg: 91.3048, aux.loss_ce: 0.0981, aux.acc_seg: 89.9532, loss: 0.3041
2023-11-27 12:40:46,845 - mmseg - INFO - Iter [103700/160000]	lr: 2.111e-05, eta: 12:26:35, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2022, decode.acc_seg: 91.4265, aux.loss_ce: 0.0980, aux.acc_seg: 89.9497, loss: 0.3002
2023-11-27 12:41:26,511 - mmseg - INFO - Iter [103750/160000]	lr: 2.109e-05, eta: 12:25:55, time: 0.794, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1956, decode.acc_seg: 91.8275, aux.loss_ce: 0.0948, aux.acc_seg: 90.5235, loss: 0.2904
2023-11-27 12:42:05,680 - mmseg - INFO - Iter [103800/160000]	lr: 2.108e-05, eta: 12:25:15, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2116, decode.acc_seg: 91.3461, aux.loss_ce: 0.0996, aux.acc_seg: 90.0735, loss: 0.3112
2023-11-27 12:42:45,411 - mmseg - INFO - Iter [103850/160000]	lr: 2.106e-05, eta: 12:24:35, time: 0.794, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1850, decode.acc_seg: 92.3721, aux.loss_ce: 0.0888, aux.acc_seg: 91.0542, loss: 0.2738
2023-11-27 12:43:25,152 - mmseg - INFO - Iter [103900/160000]	lr: 2.104e-05, eta: 12:23:55, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2050, decode.acc_seg: 91.5285, aux.loss_ce: 0.0983, aux.acc_seg: 90.2102, loss: 0.3034
2023-11-27 12:44:05,711 - mmseg - INFO - Iter [103950/160000]	lr: 2.102e-05, eta: 12:23:16, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2068, decode.acc_seg: 91.3642, aux.loss_ce: 0.0969, aux.acc_seg: 90.0121, loss: 0.3036
2023-11-27 12:44:44,194 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 12:44:44,194 - mmseg - INFO - Iter [104000/160000]	lr: 2.100e-05, eta: 12:22:35, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 90.9676, aux.loss_ce: 0.0994, aux.acc_seg: 89.6880, loss: 0.3064
2023-11-27 12:45:24,839 - mmseg - INFO - Iter [104050/160000]	lr: 2.098e-05, eta: 12:21:56, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1972, decode.acc_seg: 91.7495, aux.loss_ce: 0.0934, aux.acc_seg: 90.5482, loss: 0.2906
2023-11-27 12:46:05,308 - mmseg - INFO - Iter [104100/160000]	lr: 2.096e-05, eta: 12:21:17, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1894, decode.acc_seg: 91.8530, aux.loss_ce: 0.0921, aux.acc_seg: 90.5658, loss: 0.2816
2023-11-27 12:46:45,370 - mmseg - INFO - Iter [104150/160000]	lr: 2.094e-05, eta: 12:20:37, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1927, decode.acc_seg: 91.9839, aux.loss_ce: 0.0922, aux.acc_seg: 90.7908, loss: 0.2849
2023-11-27 12:47:25,362 - mmseg - INFO - Iter [104200/160000]	lr: 2.093e-05, eta: 12:19:57, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1999, decode.acc_seg: 91.7290, aux.loss_ce: 0.0966, aux.acc_seg: 90.2433, loss: 0.2965
2023-11-27 12:48:03,829 - mmseg - INFO - Iter [104250/160000]	lr: 2.091e-05, eta: 12:19:17, time: 0.770, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1992, decode.acc_seg: 91.2800, aux.loss_ce: 0.0962, aux.acc_seg: 89.9865, loss: 0.2954
2023-11-27 12:48:43,693 - mmseg - INFO - Iter [104300/160000]	lr: 2.089e-05, eta: 12:18:37, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1945, decode.acc_seg: 91.6747, aux.loss_ce: 0.0933, aux.acc_seg: 90.4065, loss: 0.2877
2023-11-27 12:49:22,712 - mmseg - INFO - Iter [104350/160000]	lr: 2.087e-05, eta: 12:17:57, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1946, decode.acc_seg: 91.5638, aux.loss_ce: 0.0954, aux.acc_seg: 90.0773, loss: 0.2901
2023-11-27 12:50:02,941 - mmseg - INFO - Iter [104400/160000]	lr: 2.085e-05, eta: 12:17:17, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2023, decode.acc_seg: 91.3183, aux.loss_ce: 0.0960, aux.acc_seg: 89.9314, loss: 0.2983
2023-11-27 12:50:42,700 - mmseg - INFO - Iter [104450/160000]	lr: 2.083e-05, eta: 12:16:38, time: 0.796, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1983, decode.acc_seg: 91.6371, aux.loss_ce: 0.0959, aux.acc_seg: 90.3062, loss: 0.2942
2023-11-27 12:51:23,062 - mmseg - INFO - Iter [104500/160000]	lr: 2.081e-05, eta: 12:15:58, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1985, decode.acc_seg: 91.4288, aux.loss_ce: 0.0963, aux.acc_seg: 89.9680, loss: 0.2948
2023-11-27 12:52:00,096 - mmseg - INFO - Iter [104550/160000]	lr: 2.079e-05, eta: 12:15:17, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2003, decode.acc_seg: 91.2651, aux.loss_ce: 0.0964, aux.acc_seg: 90.0780, loss: 0.2967
2023-11-27 12:52:39,574 - mmseg - INFO - Iter [104600/160000]	lr: 2.078e-05, eta: 12:14:37, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2026, decode.acc_seg: 91.3864, aux.loss_ce: 0.0979, aux.acc_seg: 89.9403, loss: 0.3005
2023-11-27 12:53:18,938 - mmseg - INFO - Iter [104650/160000]	lr: 2.076e-05, eta: 12:13:57, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1977, decode.acc_seg: 91.6320, aux.loss_ce: 0.0975, aux.acc_seg: 90.2409, loss: 0.2952
2023-11-27 12:53:57,167 - mmseg - INFO - Iter [104700/160000]	lr: 2.074e-05, eta: 12:13:16, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1997, decode.acc_seg: 91.3684, aux.loss_ce: 0.0971, aux.acc_seg: 89.9332, loss: 0.2968
2023-11-27 12:54:36,497 - mmseg - INFO - Iter [104750/160000]	lr: 2.072e-05, eta: 12:12:36, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2010, decode.acc_seg: 91.4448, aux.loss_ce: 0.0987, aux.acc_seg: 89.9124, loss: 0.2997
2023-11-27 12:55:17,959 - mmseg - INFO - Iter [104800/160000]	lr: 2.070e-05, eta: 12:11:57, time: 0.829, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2057, decode.acc_seg: 91.2683, aux.loss_ce: 0.0970, aux.acc_seg: 90.1508, loss: 0.3027
2023-11-27 12:55:59,360 - mmseg - INFO - Iter [104850/160000]	lr: 2.068e-05, eta: 12:11:19, time: 0.829, data_time: 0.054, memory: 21695, decode.loss_ce: 0.2061, decode.acc_seg: 91.4241, aux.loss_ce: 0.0981, aux.acc_seg: 90.1679, loss: 0.3042
2023-11-27 12:56:36,776 - mmseg - INFO - Iter [104900/160000]	lr: 2.066e-05, eta: 12:10:38, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2055, decode.acc_seg: 91.3615, aux.loss_ce: 0.0983, aux.acc_seg: 90.0739, loss: 0.3038
2023-11-27 12:57:16,884 - mmseg - INFO - Iter [104950/160000]	lr: 2.064e-05, eta: 12:09:58, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2058, decode.acc_seg: 91.6631, aux.loss_ce: 0.0999, aux.acc_seg: 90.2389, loss: 0.3057
2023-11-27 12:57:57,842 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 12:57:57,842 - mmseg - INFO - Iter [105000/160000]	lr: 2.063e-05, eta: 12:09:19, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1922, decode.acc_seg: 91.6727, aux.loss_ce: 0.0943, aux.acc_seg: 90.2164, loss: 0.2864
2023-11-27 12:58:39,126 - mmseg - INFO - Iter [105050/160000]	lr: 2.061e-05, eta: 12:08:40, time: 0.826, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.6391, aux.loss_ce: 0.0958, aux.acc_seg: 90.2540, loss: 0.2939
2023-11-27 12:59:19,508 - mmseg - INFO - Iter [105100/160000]	lr: 2.059e-05, eta: 12:08:00, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1932, decode.acc_seg: 91.9722, aux.loss_ce: 0.0925, aux.acc_seg: 90.7628, loss: 0.2857
2023-11-27 13:00:01,218 - mmseg - INFO - Iter [105150/160000]	lr: 2.057e-05, eta: 12:07:21, time: 0.834, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1870, decode.acc_seg: 92.2173, aux.loss_ce: 0.0902, aux.acc_seg: 90.9349, loss: 0.2772
2023-11-27 13:00:43,352 - mmseg - INFO - Iter [105200/160000]	lr: 2.055e-05, eta: 12:06:43, time: 0.843, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1997, decode.acc_seg: 91.6427, aux.loss_ce: 0.0970, aux.acc_seg: 90.3141, loss: 0.2967
2023-11-27 13:01:25,234 - mmseg - INFO - Iter [105250/160000]	lr: 2.053e-05, eta: 12:06:04, time: 0.838, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.7165, aux.loss_ce: 0.0961, aux.acc_seg: 90.2794, loss: 0.2943
2023-11-27 13:02:06,907 - mmseg - INFO - Iter [105300/160000]	lr: 2.051e-05, eta: 12:05:25, time: 0.834, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2120, decode.acc_seg: 91.1972, aux.loss_ce: 0.1024, aux.acc_seg: 89.7627, loss: 0.3144
2023-11-27 13:02:48,911 - mmseg - INFO - Iter [105350/160000]	lr: 2.049e-05, eta: 12:04:47, time: 0.840, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1997, decode.acc_seg: 91.4432, aux.loss_ce: 0.0951, aux.acc_seg: 90.1573, loss: 0.2948
2023-11-27 13:03:30,612 - mmseg - INFO - Iter [105400/160000]	lr: 2.048e-05, eta: 12:04:08, time: 0.834, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2023, decode.acc_seg: 91.3012, aux.loss_ce: 0.0965, aux.acc_seg: 90.0981, loss: 0.2988
2023-11-27 13:04:10,618 - mmseg - INFO - Iter [105450/160000]	lr: 2.046e-05, eta: 12:03:28, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2002, decode.acc_seg: 91.5718, aux.loss_ce: 0.0966, aux.acc_seg: 90.3072, loss: 0.2968
2023-11-27 13:04:50,205 - mmseg - INFO - Iter [105500/160000]	lr: 2.044e-05, eta: 12:02:48, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2140, decode.acc_seg: 90.8903, aux.loss_ce: 0.1011, aux.acc_seg: 89.6220, loss: 0.3151
2023-11-27 13:05:29,823 - mmseg - INFO - Iter [105550/160000]	lr: 2.042e-05, eta: 12:02:09, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1987, decode.acc_seg: 91.5349, aux.loss_ce: 0.0973, aux.acc_seg: 89.9758, loss: 0.2960
2023-11-27 13:06:09,148 - mmseg - INFO - Iter [105600/160000]	lr: 2.040e-05, eta: 12:01:29, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1985, decode.acc_seg: 91.7276, aux.loss_ce: 0.0935, aux.acc_seg: 90.5095, loss: 0.2920
2023-11-27 13:06:47,834 - mmseg - INFO - Iter [105650/160000]	lr: 2.038e-05, eta: 12:00:48, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1899, decode.acc_seg: 91.9051, aux.loss_ce: 0.0899, aux.acc_seg: 90.6890, loss: 0.2798
2023-11-27 13:07:26,565 - mmseg - INFO - Iter [105700/160000]	lr: 2.036e-05, eta: 12:00:08, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1943, decode.acc_seg: 91.6766, aux.loss_ce: 0.0932, aux.acc_seg: 90.4588, loss: 0.2875
2023-11-27 13:08:07,076 - mmseg - INFO - Iter [105750/160000]	lr: 2.034e-05, eta: 11:59:28, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2024, decode.acc_seg: 91.5496, aux.loss_ce: 0.0969, aux.acc_seg: 90.2160, loss: 0.2994
2023-11-27 13:08:47,532 - mmseg - INFO - Iter [105800/160000]	lr: 2.033e-05, eta: 11:58:49, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2041, decode.acc_seg: 91.3415, aux.loss_ce: 0.0983, aux.acc_seg: 89.9800, loss: 0.3024
2023-11-27 13:09:28,281 - mmseg - INFO - Iter [105850/160000]	lr: 2.031e-05, eta: 11:58:10, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2038, decode.acc_seg: 91.2739, aux.loss_ce: 0.0978, aux.acc_seg: 89.9154, loss: 0.3016
2023-11-27 13:10:05,639 - mmseg - INFO - Iter [105900/160000]	lr: 2.029e-05, eta: 11:57:29, time: 0.749, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1974, decode.acc_seg: 91.5867, aux.loss_ce: 0.0944, aux.acc_seg: 90.2886, loss: 0.2917
2023-11-27 13:10:44,029 - mmseg - INFO - Iter [105950/160000]	lr: 2.027e-05, eta: 11:56:48, time: 0.767, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 91.3891, aux.loss_ce: 0.0974, aux.acc_seg: 90.1995, loss: 0.3045
2023-11-27 13:11:21,615 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 13:11:21,615 - mmseg - INFO - Iter [106000/160000]	lr: 2.025e-05, eta: 11:56:07, time: 0.753, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1910, decode.acc_seg: 91.4751, aux.loss_ce: 0.0932, aux.acc_seg: 90.0084, loss: 0.2842
2023-11-27 13:12:01,508 - mmseg - INFO - Iter [106050/160000]	lr: 2.023e-05, eta: 11:55:28, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2070, decode.acc_seg: 91.4781, aux.loss_ce: 0.0986, aux.acc_seg: 90.2789, loss: 0.3056
2023-11-27 13:12:43,475 - mmseg - INFO - Iter [106100/160000]	lr: 2.021e-05, eta: 11:54:49, time: 0.839, data_time: 0.053, memory: 21695, decode.loss_ce: 0.2008, decode.acc_seg: 91.3323, aux.loss_ce: 0.0953, aux.acc_seg: 90.0893, loss: 0.2962
2023-11-27 13:13:23,658 - mmseg - INFO - Iter [106150/160000]	lr: 2.019e-05, eta: 11:54:09, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1863, decode.acc_seg: 92.1455, aux.loss_ce: 0.0913, aux.acc_seg: 90.7789, loss: 0.2776
2023-11-27 13:14:03,806 - mmseg - INFO - Iter [106200/160000]	lr: 2.018e-05, eta: 11:53:30, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1862, decode.acc_seg: 92.0898, aux.loss_ce: 0.0896, aux.acc_seg: 90.8564, loss: 0.2758
2023-11-27 13:14:44,267 - mmseg - INFO - Iter [106250/160000]	lr: 2.016e-05, eta: 11:52:50, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2008, decode.acc_seg: 91.3526, aux.loss_ce: 0.0981, aux.acc_seg: 89.8212, loss: 0.2989
2023-11-27 13:15:23,563 - mmseg - INFO - Iter [106300/160000]	lr: 2.014e-05, eta: 11:52:10, time: 0.786, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1993, decode.acc_seg: 91.4551, aux.loss_ce: 0.0955, aux.acc_seg: 90.1896, loss: 0.2948
2023-11-27 13:16:03,022 - mmseg - INFO - Iter [106350/160000]	lr: 2.012e-05, eta: 11:51:30, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2009, decode.acc_seg: 91.4346, aux.loss_ce: 0.0961, aux.acc_seg: 90.1219, loss: 0.2970
2023-11-27 13:16:41,971 - mmseg - INFO - Iter [106400/160000]	lr: 2.010e-05, eta: 11:50:50, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2004, decode.acc_seg: 91.6156, aux.loss_ce: 0.0994, aux.acc_seg: 90.0803, loss: 0.2999
2023-11-27 13:17:20,634 - mmseg - INFO - Iter [106450/160000]	lr: 2.008e-05, eta: 11:50:10, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1907, decode.acc_seg: 91.8432, aux.loss_ce: 0.0923, aux.acc_seg: 90.5745, loss: 0.2830
2023-11-27 13:17:57,614 - mmseg - INFO - Iter [106500/160000]	lr: 2.006e-05, eta: 11:49:28, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1944, decode.acc_seg: 91.7964, aux.loss_ce: 0.0950, aux.acc_seg: 90.2817, loss: 0.2894
2023-11-27 13:18:34,748 - mmseg - INFO - Iter [106550/160000]	lr: 2.004e-05, eta: 11:48:47, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1974, decode.acc_seg: 91.7177, aux.loss_ce: 0.0955, aux.acc_seg: 90.3086, loss: 0.2929
2023-11-27 13:19:14,951 - mmseg - INFO - Iter [106600/160000]	lr: 2.003e-05, eta: 11:48:08, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2081, decode.acc_seg: 91.3498, aux.loss_ce: 0.0979, aux.acc_seg: 90.0492, loss: 0.3060
2023-11-27 13:19:56,094 - mmseg - INFO - Iter [106650/160000]	lr: 2.001e-05, eta: 11:47:29, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1917, decode.acc_seg: 91.9472, aux.loss_ce: 0.0941, aux.acc_seg: 90.5326, loss: 0.2857
2023-11-27 13:20:35,349 - mmseg - INFO - Iter [106700/160000]	lr: 1.999e-05, eta: 11:46:49, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1894, decode.acc_seg: 91.9822, aux.loss_ce: 0.0917, aux.acc_seg: 90.7407, loss: 0.2811
2023-11-27 13:21:12,938 - mmseg - INFO - Iter [106750/160000]	lr: 1.997e-05, eta: 11:46:08, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2007, decode.acc_seg: 91.4971, aux.loss_ce: 0.0971, aux.acc_seg: 90.1047, loss: 0.2978
2023-11-27 13:21:49,958 - mmseg - INFO - Iter [106800/160000]	lr: 1.995e-05, eta: 11:45:27, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1978, decode.acc_seg: 91.8336, aux.loss_ce: 0.0950, aux.acc_seg: 90.5611, loss: 0.2929
2023-11-27 13:22:29,148 - mmseg - INFO - Iter [106850/160000]	lr: 1.993e-05, eta: 11:44:47, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1934, decode.acc_seg: 91.7116, aux.loss_ce: 0.0932, aux.acc_seg: 90.3489, loss: 0.2866
2023-11-27 13:23:06,552 - mmseg - INFO - Iter [106900/160000]	lr: 1.991e-05, eta: 11:44:06, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2012, decode.acc_seg: 91.4688, aux.loss_ce: 0.0978, aux.acc_seg: 90.0342, loss: 0.2990
2023-11-27 13:23:46,625 - mmseg - INFO - Iter [106950/160000]	lr: 1.989e-05, eta: 11:43:26, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1893, decode.acc_seg: 92.0836, aux.loss_ce: 0.0914, aux.acc_seg: 90.7362, loss: 0.2807
2023-11-27 13:24:26,720 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 13:24:26,721 - mmseg - INFO - Iter [107000/160000]	lr: 1.988e-05, eta: 11:42:46, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2026, decode.acc_seg: 91.7799, aux.loss_ce: 0.0956, aux.acc_seg: 90.5838, loss: 0.2981
2023-11-27 13:25:07,039 - mmseg - INFO - Iter [107050/160000]	lr: 1.986e-05, eta: 11:42:07, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2033, decode.acc_seg: 91.3059, aux.loss_ce: 0.0970, aux.acc_seg: 90.0194, loss: 0.3003
2023-11-27 13:25:46,158 - mmseg - INFO - Iter [107100/160000]	lr: 1.984e-05, eta: 11:41:27, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2016, decode.acc_seg: 91.8011, aux.loss_ce: 0.0948, aux.acc_seg: 90.5134, loss: 0.2963
2023-11-27 13:26:23,558 - mmseg - INFO - Iter [107150/160000]	lr: 1.982e-05, eta: 11:40:46, time: 0.749, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2057, decode.acc_seg: 91.4208, aux.loss_ce: 0.0978, aux.acc_seg: 90.2553, loss: 0.3036
2023-11-27 13:27:01,813 - mmseg - INFO - Iter [107200/160000]	lr: 1.980e-05, eta: 11:40:05, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2025, decode.acc_seg: 91.4812, aux.loss_ce: 0.0994, aux.acc_seg: 89.9548, loss: 0.3019
2023-11-27 13:27:41,724 - mmseg - INFO - Iter [107250/160000]	lr: 1.978e-05, eta: 11:39:25, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1973, decode.acc_seg: 91.6054, aux.loss_ce: 0.0967, aux.acc_seg: 90.1318, loss: 0.2940
2023-11-27 13:28:21,878 - mmseg - INFO - Iter [107300/160000]	lr: 1.976e-05, eta: 11:38:46, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1921, decode.acc_seg: 91.7150, aux.loss_ce: 0.0931, aux.acc_seg: 90.3862, loss: 0.2852
2023-11-27 13:29:01,846 - mmseg - INFO - Iter [107350/160000]	lr: 1.974e-05, eta: 11:38:06, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2073, decode.acc_seg: 91.4581, aux.loss_ce: 0.0994, aux.acc_seg: 90.0555, loss: 0.3067
2023-11-27 13:29:42,818 - mmseg - INFO - Iter [107400/160000]	lr: 1.973e-05, eta: 11:37:27, time: 0.819, data_time: 0.054, memory: 21695, decode.loss_ce: 0.1934, decode.acc_seg: 91.8109, aux.loss_ce: 0.0931, aux.acc_seg: 90.6200, loss: 0.2865
2023-11-27 13:30:20,297 - mmseg - INFO - Iter [107450/160000]	lr: 1.971e-05, eta: 11:36:46, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1951, decode.acc_seg: 91.6928, aux.loss_ce: 0.0944, aux.acc_seg: 90.2897, loss: 0.2896
2023-11-27 13:30:58,772 - mmseg - INFO - Iter [107500/160000]	lr: 1.969e-05, eta: 11:36:06, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1974, decode.acc_seg: 91.8619, aux.loss_ce: 0.0964, aux.acc_seg: 90.2782, loss: 0.2938
2023-11-27 13:31:38,722 - mmseg - INFO - Iter [107550/160000]	lr: 1.967e-05, eta: 11:35:26, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1888, decode.acc_seg: 91.9396, aux.loss_ce: 0.0903, aux.acc_seg: 90.8414, loss: 0.2791
2023-11-27 13:32:18,633 - mmseg - INFO - Iter [107600/160000]	lr: 1.965e-05, eta: 11:34:46, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1994, decode.acc_seg: 91.4957, aux.loss_ce: 0.0983, aux.acc_seg: 90.0112, loss: 0.2977
2023-11-27 13:32:58,601 - mmseg - INFO - Iter [107650/160000]	lr: 1.963e-05, eta: 11:34:07, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1957, decode.acc_seg: 91.8615, aux.loss_ce: 0.0964, aux.acc_seg: 90.3002, loss: 0.2921
2023-11-27 13:33:37,269 - mmseg - INFO - Iter [107700/160000]	lr: 1.961e-05, eta: 11:33:26, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1952, decode.acc_seg: 91.6199, aux.loss_ce: 0.0946, aux.acc_seg: 90.2578, loss: 0.2898
2023-11-27 13:34:15,423 - mmseg - INFO - Iter [107750/160000]	lr: 1.959e-05, eta: 11:32:46, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1994, decode.acc_seg: 91.7096, aux.loss_ce: 0.0964, aux.acc_seg: 90.2635, loss: 0.2957
2023-11-27 13:34:52,952 - mmseg - INFO - Iter [107800/160000]	lr: 1.958e-05, eta: 11:32:05, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2001, decode.acc_seg: 91.7661, aux.loss_ce: 0.0967, aux.acc_seg: 90.4239, loss: 0.2968
2023-11-27 13:35:33,450 - mmseg - INFO - Iter [107850/160000]	lr: 1.956e-05, eta: 11:31:25, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1918, decode.acc_seg: 91.8817, aux.loss_ce: 0.0927, aux.acc_seg: 90.4923, loss: 0.2845
2023-11-27 13:36:12,717 - mmseg - INFO - Iter [107900/160000]	lr: 1.954e-05, eta: 11:30:45, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1958, decode.acc_seg: 91.7053, aux.loss_ce: 0.0940, aux.acc_seg: 90.5086, loss: 0.2898
2023-11-27 13:36:51,548 - mmseg - INFO - Iter [107950/160000]	lr: 1.952e-05, eta: 11:30:05, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2019, decode.acc_seg: 91.4576, aux.loss_ce: 0.0980, aux.acc_seg: 90.0006, loss: 0.2999
2023-11-27 13:37:32,300 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 13:37:32,301 - mmseg - INFO - Iter [108000/160000]	lr: 1.950e-05, eta: 11:29:26, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1920, decode.acc_seg: 91.6875, aux.loss_ce: 0.0920, aux.acc_seg: 90.5536, loss: 0.2841
2023-11-27 13:38:12,093 - mmseg - INFO - Iter [108050/160000]	lr: 1.948e-05, eta: 11:28:46, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1989, decode.acc_seg: 91.5830, aux.loss_ce: 0.0973, aux.acc_seg: 90.0018, loss: 0.2962
2023-11-27 13:38:52,625 - mmseg - INFO - Iter [108100/160000]	lr: 1.946e-05, eta: 11:28:07, time: 0.811, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1947, decode.acc_seg: 91.6218, aux.loss_ce: 0.0921, aux.acc_seg: 90.4252, loss: 0.2867
2023-11-27 13:39:32,586 - mmseg - INFO - Iter [108150/160000]	lr: 1.944e-05, eta: 11:27:27, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1956, decode.acc_seg: 91.6934, aux.loss_ce: 0.0936, aux.acc_seg: 90.2920, loss: 0.2891
2023-11-27 13:40:12,789 - mmseg - INFO - Iter [108200/160000]	lr: 1.943e-05, eta: 11:26:47, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2139, decode.acc_seg: 90.9218, aux.loss_ce: 0.1002, aux.acc_seg: 89.7160, loss: 0.3140
2023-11-27 13:40:51,045 - mmseg - INFO - Iter [108250/160000]	lr: 1.941e-05, eta: 11:26:07, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1963, decode.acc_seg: 91.9600, aux.loss_ce: 0.0943, aux.acc_seg: 90.7116, loss: 0.2906
2023-11-27 13:41:29,059 - mmseg - INFO - Iter [108300/160000]	lr: 1.939e-05, eta: 11:25:26, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2060, decode.acc_seg: 91.2331, aux.loss_ce: 0.0984, aux.acc_seg: 89.9560, loss: 0.3044
2023-11-27 13:42:09,340 - mmseg - INFO - Iter [108350/160000]	lr: 1.937e-05, eta: 11:24:47, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2155, decode.acc_seg: 90.9788, aux.loss_ce: 0.1025, aux.acc_seg: 89.8064, loss: 0.3180
2023-11-27 13:42:48,745 - mmseg - INFO - Iter [108400/160000]	lr: 1.935e-05, eta: 11:24:07, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2056, decode.acc_seg: 91.4353, aux.loss_ce: 0.0986, aux.acc_seg: 90.1577, loss: 0.3042
2023-11-27 13:43:26,653 - mmseg - INFO - Iter [108450/160000]	lr: 1.933e-05, eta: 11:23:26, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2033, decode.acc_seg: 91.4312, aux.loss_ce: 0.0965, aux.acc_seg: 90.0887, loss: 0.2998
2023-11-27 13:44:03,769 - mmseg - INFO - Iter [108500/160000]	lr: 1.931e-05, eta: 11:22:45, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1915, decode.acc_seg: 92.1177, aux.loss_ce: 0.0925, aux.acc_seg: 90.7681, loss: 0.2840
2023-11-27 13:44:44,089 - mmseg - INFO - Iter [108550/160000]	lr: 1.929e-05, eta: 11:22:06, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1992, decode.acc_seg: 91.7582, aux.loss_ce: 0.0951, aux.acc_seg: 90.5354, loss: 0.2943
2023-11-27 13:45:24,968 - mmseg - INFO - Iter [108600/160000]	lr: 1.928e-05, eta: 11:21:26, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1913, decode.acc_seg: 91.9316, aux.loss_ce: 0.0927, aux.acc_seg: 90.6391, loss: 0.2839
2023-11-27 13:46:06,326 - mmseg - INFO - Iter [108650/160000]	lr: 1.926e-05, eta: 11:20:47, time: 0.828, data_time: 0.054, memory: 21695, decode.loss_ce: 0.1891, decode.acc_seg: 91.7215, aux.loss_ce: 0.0929, aux.acc_seg: 90.2637, loss: 0.2821
2023-11-27 13:46:46,719 - mmseg - INFO - Iter [108700/160000]	lr: 1.924e-05, eta: 11:20:08, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1921, decode.acc_seg: 91.8794, aux.loss_ce: 0.0924, aux.acc_seg: 90.6217, loss: 0.2845
2023-11-27 13:47:26,964 - mmseg - INFO - Iter [108750/160000]	lr: 1.922e-05, eta: 11:19:28, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1990, decode.acc_seg: 91.7758, aux.loss_ce: 0.0972, aux.acc_seg: 90.2504, loss: 0.2962
2023-11-27 13:48:04,038 - mmseg - INFO - Iter [108800/160000]	lr: 1.920e-05, eta: 11:18:47, time: 0.743, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1929, decode.acc_seg: 91.9339, aux.loss_ce: 0.0929, aux.acc_seg: 90.6128, loss: 0.2858
2023-11-27 13:48:40,657 - mmseg - INFO - Iter [108850/160000]	lr: 1.918e-05, eta: 11:18:06, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2024, decode.acc_seg: 91.5991, aux.loss_ce: 0.0968, aux.acc_seg: 90.4296, loss: 0.2993
2023-11-27 13:49:19,832 - mmseg - INFO - Iter [108900/160000]	lr: 1.916e-05, eta: 11:17:26, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2010, decode.acc_seg: 91.4640, aux.loss_ce: 0.0974, aux.acc_seg: 90.0878, loss: 0.2984
2023-11-27 13:50:00,276 - mmseg - INFO - Iter [108950/160000]	lr: 1.914e-05, eta: 11:16:46, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1906, decode.acc_seg: 91.8825, aux.loss_ce: 0.0922, aux.acc_seg: 90.5219, loss: 0.2829
2023-11-27 13:50:38,156 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 13:50:38,156 - mmseg - INFO - Iter [109000/160000]	lr: 1.913e-05, eta: 11:16:06, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1951, decode.acc_seg: 91.7101, aux.loss_ce: 0.0935, aux.acc_seg: 90.5150, loss: 0.2885
2023-11-27 13:51:18,187 - mmseg - INFO - Iter [109050/160000]	lr: 1.911e-05, eta: 11:15:26, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 91.9699, aux.loss_ce: 0.0904, aux.acc_seg: 90.5439, loss: 0.2735
2023-11-27 13:51:56,813 - mmseg - INFO - Iter [109100/160000]	lr: 1.909e-05, eta: 11:14:46, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1874, decode.acc_seg: 91.7307, aux.loss_ce: 0.0900, aux.acc_seg: 90.5318, loss: 0.2773
2023-11-27 13:52:35,448 - mmseg - INFO - Iter [109150/160000]	lr: 1.907e-05, eta: 11:14:06, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2022, decode.acc_seg: 91.5357, aux.loss_ce: 0.0968, aux.acc_seg: 90.2201, loss: 0.2991
2023-11-27 13:53:14,935 - mmseg - INFO - Iter [109200/160000]	lr: 1.905e-05, eta: 11:13:26, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1942, decode.acc_seg: 91.9163, aux.loss_ce: 0.0933, aux.acc_seg: 90.6632, loss: 0.2875
2023-11-27 13:53:54,852 - mmseg - INFO - Iter [109250/160000]	lr: 1.903e-05, eta: 11:12:46, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1863, decode.acc_seg: 92.0930, aux.loss_ce: 0.0901, aux.acc_seg: 90.7982, loss: 0.2765
2023-11-27 13:54:34,891 - mmseg - INFO - Iter [109300/160000]	lr: 1.901e-05, eta: 11:12:06, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1922, decode.acc_seg: 92.0019, aux.loss_ce: 0.0944, aux.acc_seg: 90.6505, loss: 0.2866
2023-11-27 13:55:14,669 - mmseg - INFO - Iter [109350/160000]	lr: 1.899e-05, eta: 11:11:27, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1918, decode.acc_seg: 91.6165, aux.loss_ce: 0.0943, aux.acc_seg: 90.2642, loss: 0.2861
2023-11-27 13:55:55,255 - mmseg - INFO - Iter [109400/160000]	lr: 1.898e-05, eta: 11:10:47, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2010, decode.acc_seg: 91.3168, aux.loss_ce: 0.0964, aux.acc_seg: 90.0146, loss: 0.2974
2023-11-27 13:56:36,396 - mmseg - INFO - Iter [109450/160000]	lr: 1.896e-05, eta: 11:10:08, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1878, decode.acc_seg: 91.9453, aux.loss_ce: 0.0900, aux.acc_seg: 90.6236, loss: 0.2779
2023-11-27 13:57:16,687 - mmseg - INFO - Iter [109500/160000]	lr: 1.894e-05, eta: 11:09:29, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2011, decode.acc_seg: 91.5728, aux.loss_ce: 0.0968, aux.acc_seg: 90.1130, loss: 0.2979
2023-11-27 13:57:55,140 - mmseg - INFO - Iter [109550/160000]	lr: 1.892e-05, eta: 11:08:48, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2018, decode.acc_seg: 91.5827, aux.loss_ce: 0.0977, aux.acc_seg: 90.2163, loss: 0.2995
2023-11-27 13:58:34,610 - mmseg - INFO - Iter [109600/160000]	lr: 1.890e-05, eta: 11:08:08, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2009, decode.acc_seg: 91.3689, aux.loss_ce: 0.0980, aux.acc_seg: 89.9918, loss: 0.2989
2023-11-27 13:59:14,424 - mmseg - INFO - Iter [109650/160000]	lr: 1.888e-05, eta: 11:07:28, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2023, decode.acc_seg: 91.1720, aux.loss_ce: 0.0953, aux.acc_seg: 90.0074, loss: 0.2976
2023-11-27 13:59:54,353 - mmseg - INFO - Iter [109700/160000]	lr: 1.886e-05, eta: 11:06:49, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2051, decode.acc_seg: 91.1104, aux.loss_ce: 0.0997, aux.acc_seg: 89.6281, loss: 0.3049
2023-11-27 14:00:35,434 - mmseg - INFO - Iter [109750/160000]	lr: 1.884e-05, eta: 11:06:10, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1911, decode.acc_seg: 91.6895, aux.loss_ce: 0.0930, aux.acc_seg: 90.3588, loss: 0.2841
2023-11-27 14:01:16,236 - mmseg - INFO - Iter [109800/160000]	lr: 1.883e-05, eta: 11:05:30, time: 0.817, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1953, decode.acc_seg: 91.5252, aux.loss_ce: 0.0939, aux.acc_seg: 90.2821, loss: 0.2892
2023-11-27 14:01:53,549 - mmseg - INFO - Iter [109850/160000]	lr: 1.881e-05, eta: 11:04:49, time: 0.746, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1857, decode.acc_seg: 91.9293, aux.loss_ce: 0.0906, aux.acc_seg: 90.5715, loss: 0.2763
2023-11-27 14:02:34,119 - mmseg - INFO - Iter [109900/160000]	lr: 1.879e-05, eta: 11:04:10, time: 0.812, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1937, decode.acc_seg: 91.7143, aux.loss_ce: 0.0957, aux.acc_seg: 90.2214, loss: 0.2894
2023-11-27 14:03:11,635 - mmseg - INFO - Iter [109950/160000]	lr: 1.877e-05, eta: 11:03:29, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.4582, aux.loss_ce: 0.0980, aux.acc_seg: 90.0296, loss: 0.2961
2023-11-27 14:03:50,201 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:03:50,201 - mmseg - INFO - Iter [110000/160000]	lr: 1.875e-05, eta: 11:02:49, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1810, decode.acc_seg: 92.1478, aux.loss_ce: 0.0884, aux.acc_seg: 90.7054, loss: 0.2695
2023-11-27 14:04:30,597 - mmseg - INFO - Iter [110050/160000]	lr: 1.873e-05, eta: 11:02:09, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1962, decode.acc_seg: 91.6182, aux.loss_ce: 0.0938, aux.acc_seg: 90.3862, loss: 0.2899
2023-11-27 14:05:09,713 - mmseg - INFO - Iter [110100/160000]	lr: 1.871e-05, eta: 11:01:29, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1902, decode.acc_seg: 91.9892, aux.loss_ce: 0.0918, aux.acc_seg: 90.7796, loss: 0.2820
2023-11-27 14:05:49,972 - mmseg - INFO - Iter [110150/160000]	lr: 1.869e-05, eta: 11:00:50, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2154, decode.acc_seg: 91.0432, aux.loss_ce: 0.1015, aux.acc_seg: 89.6970, loss: 0.3169
2023-11-27 14:06:29,080 - mmseg - INFO - Iter [110200/160000]	lr: 1.868e-05, eta: 11:00:10, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1889, decode.acc_seg: 91.9882, aux.loss_ce: 0.0893, aux.acc_seg: 90.8489, loss: 0.2782
2023-11-27 14:07:06,349 - mmseg - INFO - Iter [110250/160000]	lr: 1.866e-05, eta: 10:59:29, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2050, decode.acc_seg: 91.3360, aux.loss_ce: 0.0985, aux.acc_seg: 90.0305, loss: 0.3034
2023-11-27 14:07:44,011 - mmseg - INFO - Iter [110300/160000]	lr: 1.864e-05, eta: 10:58:48, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1917, decode.acc_seg: 91.8979, aux.loss_ce: 0.0922, aux.acc_seg: 90.6814, loss: 0.2840
2023-11-27 14:08:23,040 - mmseg - INFO - Iter [110350/160000]	lr: 1.862e-05, eta: 10:58:08, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1931, decode.acc_seg: 91.7398, aux.loss_ce: 0.0949, aux.acc_seg: 90.2823, loss: 0.2880
2023-11-27 14:09:03,116 - mmseg - INFO - Iter [110400/160000]	lr: 1.860e-05, eta: 10:57:28, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1850, decode.acc_seg: 92.1235, aux.loss_ce: 0.0901, aux.acc_seg: 90.7086, loss: 0.2751
2023-11-27 14:09:43,110 - mmseg - INFO - Iter [110450/160000]	lr: 1.858e-05, eta: 10:56:49, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2001, decode.acc_seg: 91.5377, aux.loss_ce: 0.0972, aux.acc_seg: 90.1910, loss: 0.2973
2023-11-27 14:10:23,288 - mmseg - INFO - Iter [110500/160000]	lr: 1.856e-05, eta: 10:56:09, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2024, decode.acc_seg: 91.3389, aux.loss_ce: 0.0971, aux.acc_seg: 90.0097, loss: 0.2995
2023-11-27 14:11:03,542 - mmseg - INFO - Iter [110550/160000]	lr: 1.854e-05, eta: 10:55:30, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1980, decode.acc_seg: 91.5969, aux.loss_ce: 0.0966, aux.acc_seg: 90.2281, loss: 0.2945
2023-11-27 14:11:44,185 - mmseg - INFO - Iter [110600/160000]	lr: 1.853e-05, eta: 10:54:50, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1795, decode.acc_seg: 92.1680, aux.loss_ce: 0.0857, aux.acc_seg: 91.0074, loss: 0.2652
2023-11-27 14:12:24,940 - mmseg - INFO - Iter [110650/160000]	lr: 1.851e-05, eta: 10:54:11, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2097, decode.acc_seg: 91.3656, aux.loss_ce: 0.1012, aux.acc_seg: 89.9308, loss: 0.3109
2023-11-27 14:13:05,198 - mmseg - INFO - Iter [110700/160000]	lr: 1.849e-05, eta: 10:53:31, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2000, decode.acc_seg: 91.7800, aux.loss_ce: 0.0948, aux.acc_seg: 90.7145, loss: 0.2948
2023-11-27 14:13:45,580 - mmseg - INFO - Iter [110750/160000]	lr: 1.847e-05, eta: 10:52:52, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1917, decode.acc_seg: 91.8693, aux.loss_ce: 0.0925, aux.acc_seg: 90.6319, loss: 0.2842
2023-11-27 14:14:22,735 - mmseg - INFO - Iter [110800/160000]	lr: 1.845e-05, eta: 10:52:11, time: 0.743, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.5904, aux.loss_ce: 0.0945, aux.acc_seg: 90.3732, loss: 0.2926
2023-11-27 14:15:02,048 - mmseg - INFO - Iter [110850/160000]	lr: 1.843e-05, eta: 10:51:31, time: 0.788, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1980, decode.acc_seg: 91.8116, aux.loss_ce: 0.0949, aux.acc_seg: 90.4650, loss: 0.2929
2023-11-27 14:15:38,834 - mmseg - INFO - Iter [110900/160000]	lr: 1.841e-05, eta: 10:50:50, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1915, decode.acc_seg: 91.7861, aux.loss_ce: 0.0925, aux.acc_seg: 90.4657, loss: 0.2840
2023-11-27 14:16:18,176 - mmseg - INFO - Iter [110950/160000]	lr: 1.839e-05, eta: 10:50:10, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1979, decode.acc_seg: 91.7950, aux.loss_ce: 0.0950, aux.acc_seg: 90.4307, loss: 0.2929
2023-11-27 14:16:58,040 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:16:58,041 - mmseg - INFO - Iter [111000/160000]	lr: 1.838e-05, eta: 10:49:30, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2050, decode.acc_seg: 91.4486, aux.loss_ce: 0.0969, aux.acc_seg: 90.0761, loss: 0.3019
2023-11-27 14:17:35,157 - mmseg - INFO - Iter [111050/160000]	lr: 1.836e-05, eta: 10:48:49, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1896, decode.acc_seg: 91.9575, aux.loss_ce: 0.0953, aux.acc_seg: 90.2996, loss: 0.2849
2023-11-27 14:18:12,652 - mmseg - INFO - Iter [111100/160000]	lr: 1.834e-05, eta: 10:48:08, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1940, decode.acc_seg: 91.8007, aux.loss_ce: 0.0939, aux.acc_seg: 90.5832, loss: 0.2879
2023-11-27 14:18:51,684 - mmseg - INFO - Iter [111150/160000]	lr: 1.832e-05, eta: 10:47:28, time: 0.780, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1828, decode.acc_seg: 92.2373, aux.loss_ce: 0.0893, aux.acc_seg: 90.7954, loss: 0.2721
2023-11-27 14:19:31,798 - mmseg - INFO - Iter [111200/160000]	lr: 1.830e-05, eta: 10:46:49, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 92.0213, aux.loss_ce: 0.0934, aux.acc_seg: 90.6343, loss: 0.2857
2023-11-27 14:20:10,885 - mmseg - INFO - Iter [111250/160000]	lr: 1.828e-05, eta: 10:46:09, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1898, decode.acc_seg: 91.7419, aux.loss_ce: 0.0915, aux.acc_seg: 90.6182, loss: 0.2813
2023-11-27 14:20:48,570 - mmseg - INFO - Iter [111300/160000]	lr: 1.826e-05, eta: 10:45:28, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1958, decode.acc_seg: 91.7097, aux.loss_ce: 0.0942, aux.acc_seg: 90.4415, loss: 0.2900
2023-11-27 14:21:26,715 - mmseg - INFO - Iter [111350/160000]	lr: 1.824e-05, eta: 10:44:48, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1951, decode.acc_seg: 91.6714, aux.loss_ce: 0.0954, aux.acc_seg: 90.2586, loss: 0.2904
2023-11-27 14:22:06,249 - mmseg - INFO - Iter [111400/160000]	lr: 1.823e-05, eta: 10:44:08, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1943, decode.acc_seg: 91.9234, aux.loss_ce: 0.0939, aux.acc_seg: 90.5761, loss: 0.2882
2023-11-27 14:22:42,814 - mmseg - INFO - Iter [111450/160000]	lr: 1.821e-05, eta: 10:43:27, time: 0.731, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1885, decode.acc_seg: 92.0858, aux.loss_ce: 0.0903, aux.acc_seg: 90.8380, loss: 0.2787
2023-11-27 14:23:19,651 - mmseg - INFO - Iter [111500/160000]	lr: 1.819e-05, eta: 10:42:46, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1955, decode.acc_seg: 91.5894, aux.loss_ce: 0.0937, aux.acc_seg: 90.2774, loss: 0.2892
2023-11-27 14:23:59,815 - mmseg - INFO - Iter [111550/160000]	lr: 1.817e-05, eta: 10:42:06, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1804, decode.acc_seg: 92.3274, aux.loss_ce: 0.0879, aux.acc_seg: 90.9457, loss: 0.2683
2023-11-27 14:24:38,713 - mmseg - INFO - Iter [111600/160000]	lr: 1.815e-05, eta: 10:41:26, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1868, decode.acc_seg: 92.0306, aux.loss_ce: 0.0904, aux.acc_seg: 90.8151, loss: 0.2772
2023-11-27 14:25:17,872 - mmseg - INFO - Iter [111650/160000]	lr: 1.813e-05, eta: 10:40:46, time: 0.784, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1956, decode.acc_seg: 91.8062, aux.loss_ce: 0.0952, aux.acc_seg: 90.4792, loss: 0.2908
2023-11-27 14:25:55,806 - mmseg - INFO - Iter [111700/160000]	lr: 1.811e-05, eta: 10:40:05, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2066, decode.acc_seg: 91.4213, aux.loss_ce: 0.0989, aux.acc_seg: 90.1333, loss: 0.3055
2023-11-27 14:26:34,588 - mmseg - INFO - Iter [111750/160000]	lr: 1.809e-05, eta: 10:39:25, time: 0.776, data_time: 0.009, memory: 21695, decode.loss_ce: 0.2087, decode.acc_seg: 91.6692, aux.loss_ce: 0.0986, aux.acc_seg: 90.2671, loss: 0.3072
2023-11-27 14:27:13,399 - mmseg - INFO - Iter [111800/160000]	lr: 1.808e-05, eta: 10:38:45, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1981, decode.acc_seg: 91.4798, aux.loss_ce: 0.0963, aux.acc_seg: 90.0798, loss: 0.2944
2023-11-27 14:27:54,246 - mmseg - INFO - Iter [111850/160000]	lr: 1.806e-05, eta: 10:38:06, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2009, decode.acc_seg: 91.5048, aux.loss_ce: 0.0953, aux.acc_seg: 90.2030, loss: 0.2962
2023-11-27 14:28:35,061 - mmseg - INFO - Iter [111900/160000]	lr: 1.804e-05, eta: 10:37:26, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2024, decode.acc_seg: 91.4973, aux.loss_ce: 0.0960, aux.acc_seg: 90.3756, loss: 0.2984
2023-11-27 14:29:15,453 - mmseg - INFO - Iter [111950/160000]	lr: 1.802e-05, eta: 10:36:47, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1930, decode.acc_seg: 91.8918, aux.loss_ce: 0.0933, aux.acc_seg: 90.4534, loss: 0.2863
2023-11-27 14:29:54,623 - mmseg - INFO - Saving checkpoint at 112000 iterations
2023-11-27 14:29:59,708 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:29:59,708 - mmseg - INFO - Iter [112000/160000]	lr: 1.800e-05, eta: 10:36:09, time: 0.886, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2057, decode.acc_seg: 91.4354, aux.loss_ce: 0.0977, aux.acc_seg: 90.2282, loss: 0.3034
2023-11-27 14:31:33,531 - mmseg - INFO - per class results:
2023-11-27 14:31:33,544 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 78.36 | 88.25 |
|       building      | 80.83 | 89.86 |
|         sky         | 94.11 | 97.73 |
|        floor        | 82.84 | 90.25 |
|         tree        | 73.88 | 87.39 |
|       ceiling       | 84.88 | 92.23 |
|         road        |  85.7 | 91.41 |
|         bed         | 89.21 | 95.38 |
|      windowpane     |  61.5 | 79.43 |
|        grass        | 66.39 | 81.83 |
|       cabinet       | 63.57 | 76.48 |
|       sidewalk      |  67.6 |  79.6 |
|        person       | 81.58 | 93.47 |
|        earth        | 38.25 | 53.72 |
|         door        | 50.75 | 63.69 |
|        table        | 58.83 | 74.82 |
|       mountain      | 56.67 | 73.09 |
|        plant        | 51.14 | 60.68 |
|       curtain       | 75.38 | 88.44 |
|        chair        | 58.46 | 72.41 |
|         car         | 85.37 | 92.87 |
|        water        | 60.72 | 77.74 |
|       painting      | 74.02 | 88.67 |
|         sofa        | 67.41 | 85.64 |
|        shelf        | 44.36 | 64.66 |
|        house        | 35.57 | 61.32 |
|         sea         |  63.7 | 77.03 |
|        mirror       | 66.36 |  71.6 |
|         rug         | 62.86 | 76.72 |
|        field        | 25.45 | 40.73 |
|       armchair      |  39.9 | 54.01 |
|         seat        | 60.39 | 83.16 |
|        fence        | 49.12 | 62.53 |
|         desk        |  44.0 | 71.25 |
|         rock        |  44.2 | 64.36 |
|       wardrobe      | 50.03 | 64.23 |
|         lamp        | 64.86 | 79.27 |
|       bathtub       | 81.74 | 90.66 |
|       railing       | 37.52 | 52.84 |
|       cushion       | 60.33 | 74.75 |
|         base        | 35.57 | 42.38 |
|         box         | 30.29 | 42.38 |
|        column       | 43.23 | 52.93 |
|      signboard      | 41.28 | 54.84 |
|   chest of drawers  | 43.84 | 55.37 |
|       counter       | 34.47 |  45.8 |
|         sand        | 37.03 | 50.61 |
|         sink        | 70.74 | 81.36 |
|      skyscraper     | 38.06 | 45.81 |
|      fireplace      | 72.31 | 92.97 |
|     refrigerator    | 78.38 | 86.42 |
|      grandstand     | 39.13 | 72.32 |
|         path        | 26.05 | 42.57 |
|        stairs       | 33.32 | 44.72 |
|        runway       | 71.18 | 94.83 |
|         case        | 61.25 | 70.59 |
|      pool table     | 92.82 | 97.11 |
|        pillow       | 61.47 | 72.68 |
|     screen door     | 69.83 | 75.43 |
|       stairway      | 33.86 | 40.46 |
|        river        | 10.78 | 21.43 |
|        bridge       | 72.55 | 81.89 |
|       bookcase      |  39.3 | 64.12 |
|        blind        | 38.94 | 42.31 |
|     coffee table    | 54.28 | 84.84 |
|        toilet       | 80.78 | 90.41 |
|        flower       | 37.95 | 54.03 |
|         book        | 44.49 | 65.45 |
|         hill        | 12.74 | 20.26 |
|        bench        | 45.93 | 52.24 |
|      countertop     | 51.75 | 76.17 |
|        stove        | 70.76 | 81.92 |
|         palm        | 53.01 | 70.07 |
|    kitchen island   | 46.45 | 90.15 |
|       computer      | 61.69 | 72.72 |
|     swivel chair    |  49.1 | 67.61 |
|         boat        | 36.46 | 56.19 |
|         bar         | 46.12 | 68.54 |
|    arcade machine   | 63.95 | 67.51 |
|        hovel        | 35.67 | 71.91 |
|         bus         |  85.7 | 96.58 |
|        towel        | 64.99 | 78.32 |
|        light        | 56.37 | 62.63 |
|        truck        | 39.83 | 47.97 |
|        tower        | 20.52 | 37.89 |
|      chandelier     | 67.18 | 85.23 |
|        awning       | 29.15 |  37.0 |
|     streetlight     |  27.9 | 37.22 |
|        booth        | 45.12 | 51.83 |
| television receiver | 67.97 | 81.32 |
|       airplane      | 53.84 | 68.97 |
|      dirt track     |  4.95 |  8.29 |
|       apparel       | 43.67 | 55.87 |
|         pole        | 24.83 | 36.99 |
|         land        |  3.45 |  4.69 |
|      bannister      | 14.82 | 19.35 |
|      escalator      | 47.63 | 70.78 |
|       ottoman       | 48.53 | 57.11 |
|        bottle       |  33.7 | 54.49 |
|        buffet       | 52.52 | 65.24 |
|        poster       | 31.85 | 39.01 |
|        stage        | 18.61 |  28.9 |
|         van         | 44.97 | 66.44 |
|         ship        | 60.02 | 95.75 |
|       fountain      | 22.69 | 23.17 |
|    conveyer belt    | 79.88 | 88.01 |
|        canopy       |  10.8 | 14.97 |
|        washer       | 71.72 |  77.0 |
|      plaything      | 30.36 | 45.18 |
|    swimming pool    | 75.71 | 86.14 |
|        stool        | 45.92 |  58.5 |
|        barrel       |  52.4 | 68.88 |
|        basket       |  39.0 | 50.97 |
|      waterfall      | 75.53 | 87.13 |
|         tent        | 93.24 | 98.69 |
|         bag         | 13.14 | 15.47 |
|       minibike      | 72.91 | 84.55 |
|        cradle       | 73.25 | 84.74 |
|         oven        |  46.2 | 60.73 |
|         ball        | 49.49 | 58.66 |
|         food        | 49.14 | 53.49 |
|         step        | 21.17 | 26.12 |
|         tank        | 43.74 | 51.23 |
|      trade name     | 28.63 | 32.69 |
|      microwave      | 79.66 | 89.92 |
|         pot         | 47.24 | 53.55 |
|        animal       | 62.77 | 65.57 |
|       bicycle       | 60.43 | 77.07 |
|         lake        | 55.05 | 68.88 |
|      dishwasher     | 58.12 | 62.94 |
|        screen       | 61.21 | 89.45 |
|       blanket       | 15.08 | 18.57 |
|      sculpture      | 50.41 | 77.43 |
|         hood        | 65.15 | 72.83 |
|        sconce       | 46.32 | 54.77 |
|         vase        | 40.87 | 59.34 |
|    traffic light    | 35.32 | 50.01 |
|         tray        |  7.47 | 10.77 |
|        ashcan       | 36.24 | 49.58 |
|         fan         |  64.3 | 75.99 |
|         pier        | 40.87 | 66.42 |
|      crt screen     |  3.74 | 12.07 |
|        plate        | 53.33 | 70.33 |
|       monitor       |  6.4  |  9.5  |
|    bulletin board   | 44.88 |  57.5 |
|        shower       |  3.07 |  3.2  |
|       radiator      | 67.48 | 72.63 |
|        glass        | 15.98 | 17.03 |
|        clock        | 35.34 | 46.01 |
|         flag        | 55.64 | 61.52 |
+---------------------+-------+-------+
2023-11-27 14:31:33,544 - mmseg - INFO - Summary:
2023-11-27 14:31:33,545 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.26 | 50.53 | 63.15 |
+-------+-------+-------+
2023-11-27 14:31:33,560 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:31:33,561 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8326, mIoU: 0.5053, mAcc: 0.6315, IoU.wall: 0.7836, IoU.building: 0.8083, IoU.sky: 0.9411, IoU.floor: 0.8284, IoU.tree: 0.7388, IoU.ceiling: 0.8488, IoU.road: 0.8570, IoU.bed : 0.8921, IoU.windowpane: 0.6150, IoU.grass: 0.6639, IoU.cabinet: 0.6357, IoU.sidewalk: 0.6760, IoU.person: 0.8158, IoU.earth: 0.3825, IoU.door: 0.5075, IoU.table: 0.5883, IoU.mountain: 0.5667, IoU.plant: 0.5114, IoU.curtain: 0.7538, IoU.chair: 0.5846, IoU.car: 0.8537, IoU.water: 0.6072, IoU.painting: 0.7402, IoU.sofa: 0.6741, IoU.shelf: 0.4436, IoU.house: 0.3557, IoU.sea: 0.6370, IoU.mirror: 0.6636, IoU.rug: 0.6286, IoU.field: 0.2545, IoU.armchair: 0.3990, IoU.seat: 0.6039, IoU.fence: 0.4912, IoU.desk: 0.4400, IoU.rock: 0.4420, IoU.wardrobe: 0.5003, IoU.lamp: 0.6486, IoU.bathtub: 0.8174, IoU.railing: 0.3752, IoU.cushion: 0.6033, IoU.base: 0.3557, IoU.box: 0.3029, IoU.column: 0.4323, IoU.signboard: 0.4128, IoU.chest of drawers: 0.4384, IoU.counter: 0.3447, IoU.sand: 0.3703, IoU.sink: 0.7074, IoU.skyscraper: 0.3806, IoU.fireplace: 0.7231, IoU.refrigerator: 0.7838, IoU.grandstand: 0.3913, IoU.path: 0.2605, IoU.stairs: 0.3332, IoU.runway: 0.7118, IoU.case: 0.6125, IoU.pool table: 0.9282, IoU.pillow: 0.6147, IoU.screen door: 0.6983, IoU.stairway: 0.3386, IoU.river: 0.1078, IoU.bridge: 0.7255, IoU.bookcase: 0.3930, IoU.blind: 0.3894, IoU.coffee table: 0.5428, IoU.toilet: 0.8078, IoU.flower: 0.3795, IoU.book: 0.4449, IoU.hill: 0.1274, IoU.bench: 0.4593, IoU.countertop: 0.5175, IoU.stove: 0.7076, IoU.palm: 0.5301, IoU.kitchen island: 0.4645, IoU.computer: 0.6169, IoU.swivel chair: 0.4910, IoU.boat: 0.3646, IoU.bar: 0.4612, IoU.arcade machine: 0.6395, IoU.hovel: 0.3567, IoU.bus: 0.8570, IoU.towel: 0.6499, IoU.light: 0.5637, IoU.truck: 0.3983, IoU.tower: 0.2052, IoU.chandelier: 0.6718, IoU.awning: 0.2915, IoU.streetlight: 0.2790, IoU.booth: 0.4512, IoU.television receiver: 0.6797, IoU.airplane: 0.5384, IoU.dirt track: 0.0495, IoU.apparel: 0.4367, IoU.pole: 0.2483, IoU.land: 0.0345, IoU.bannister: 0.1482, IoU.escalator: 0.4763, IoU.ottoman: 0.4853, IoU.bottle: 0.3370, IoU.buffet: 0.5252, IoU.poster: 0.3185, IoU.stage: 0.1861, IoU.van: 0.4497, IoU.ship: 0.6002, IoU.fountain: 0.2269, IoU.conveyer belt: 0.7988, IoU.canopy: 0.1080, IoU.washer: 0.7172, IoU.plaything: 0.3036, IoU.swimming pool: 0.7571, IoU.stool: 0.4592, IoU.barrel: 0.5240, IoU.basket: 0.3900, IoU.waterfall: 0.7553, IoU.tent: 0.9324, IoU.bag: 0.1314, IoU.minibike: 0.7291, IoU.cradle: 0.7325, IoU.oven: 0.4620, IoU.ball: 0.4949, IoU.food: 0.4914, IoU.step: 0.2117, IoU.tank: 0.4374, IoU.trade name: 0.2863, IoU.microwave: 0.7966, IoU.pot: 0.4724, IoU.animal: 0.6277, IoU.bicycle: 0.6043, IoU.lake: 0.5505, IoU.dishwasher: 0.5812, IoU.screen: 0.6121, IoU.blanket: 0.1508, IoU.sculpture: 0.5041, IoU.hood: 0.6515, IoU.sconce: 0.4632, IoU.vase: 0.4087, IoU.traffic light: 0.3532, IoU.tray: 0.0747, IoU.ashcan: 0.3624, IoU.fan: 0.6430, IoU.pier: 0.4087, IoU.crt screen: 0.0374, IoU.plate: 0.5333, IoU.monitor: 0.0640, IoU.bulletin board: 0.4488, IoU.shower: 0.0307, IoU.radiator: 0.6748, IoU.glass: 0.1598, IoU.clock: 0.3534, IoU.flag: 0.5564, Acc.wall: 0.8825, Acc.building: 0.8986, Acc.sky: 0.9773, Acc.floor: 0.9025, Acc.tree: 0.8739, Acc.ceiling: 0.9223, Acc.road: 0.9141, Acc.bed : 0.9538, Acc.windowpane: 0.7943, Acc.grass: 0.8183, Acc.cabinet: 0.7648, Acc.sidewalk: 0.7960, Acc.person: 0.9347, Acc.earth: 0.5372, Acc.door: 0.6369, Acc.table: 0.7482, Acc.mountain: 0.7309, Acc.plant: 0.6068, Acc.curtain: 0.8844, Acc.chair: 0.7241, Acc.car: 0.9287, Acc.water: 0.7774, Acc.painting: 0.8867, Acc.sofa: 0.8564, Acc.shelf: 0.6466, Acc.house: 0.6132, Acc.sea: 0.7703, Acc.mirror: 0.7160, Acc.rug: 0.7672, Acc.field: 0.4073, Acc.armchair: 0.5401, Acc.seat: 0.8316, Acc.fence: 0.6253, Acc.desk: 0.7125, Acc.rock: 0.6436, Acc.wardrobe: 0.6423, Acc.lamp: 0.7927, Acc.bathtub: 0.9066, Acc.railing: 0.5284, Acc.cushion: 0.7475, Acc.base: 0.4238, Acc.box: 0.4238, Acc.column: 0.5293, Acc.signboard: 0.5484, Acc.chest of drawers: 0.5537, Acc.counter: 0.4580, Acc.sand: 0.5061, Acc.sink: 0.8136, Acc.skyscraper: 0.4581, Acc.fireplace: 0.9297, Acc.refrigerator: 0.8642, Acc.grandstand: 0.7232, Acc.path: 0.4257, Acc.stairs: 0.4472, Acc.runway: 0.9483, Acc.case: 0.7059, Acc.pool table: 0.9711, Acc.pillow: 0.7268, Acc.screen door: 0.7543, Acc.stairway: 0.4046, Acc.river: 0.2143, Acc.bridge: 0.8189, Acc.bookcase: 0.6412, Acc.blind: 0.4231, Acc.coffee table: 0.8484, Acc.toilet: 0.9041, Acc.flower: 0.5403, Acc.book: 0.6545, Acc.hill: 0.2026, Acc.bench: 0.5224, Acc.countertop: 0.7617, Acc.stove: 0.8192, Acc.palm: 0.7007, Acc.kitchen island: 0.9015, Acc.computer: 0.7272, Acc.swivel chair: 0.6761, Acc.boat: 0.5619, Acc.bar: 0.6854, Acc.arcade machine: 0.6751, Acc.hovel: 0.7191, Acc.bus: 0.9658, Acc.towel: 0.7832, Acc.light: 0.6263, Acc.truck: 0.4797, Acc.tower: 0.3789, Acc.chandelier: 0.8523, Acc.awning: 0.3700, Acc.streetlight: 0.3722, Acc.booth: 0.5183, Acc.television receiver: 0.8132, Acc.airplane: 0.6897, Acc.dirt track: 0.0829, Acc.apparel: 0.5587, Acc.pole: 0.3699, Acc.land: 0.0469, Acc.bannister: 0.1935, Acc.escalator: 0.7078, Acc.ottoman: 0.5711, Acc.bottle: 0.5449, Acc.buffet: 0.6524, Acc.poster: 0.3901, Acc.stage: 0.2890, Acc.van: 0.6644, Acc.ship: 0.9575, Acc.fountain: 0.2317, Acc.conveyer belt: 0.8801, Acc.canopy: 0.1497, Acc.washer: 0.7700, Acc.plaything: 0.4518, Acc.swimming pool: 0.8614, Acc.stool: 0.5850, Acc.barrel: 0.6888, Acc.basket: 0.5097, Acc.waterfall: 0.8713, Acc.tent: 0.9869, Acc.bag: 0.1547, Acc.minibike: 0.8455, Acc.cradle: 0.8474, Acc.oven: 0.6073, Acc.ball: 0.5866, Acc.food: 0.5349, Acc.step: 0.2612, Acc.tank: 0.5123, Acc.trade name: 0.3269, Acc.microwave: 0.8992, Acc.pot: 0.5355, Acc.animal: 0.6557, Acc.bicycle: 0.7707, Acc.lake: 0.6888, Acc.dishwasher: 0.6294, Acc.screen: 0.8945, Acc.blanket: 0.1857, Acc.sculpture: 0.7743, Acc.hood: 0.7283, Acc.sconce: 0.5477, Acc.vase: 0.5934, Acc.traffic light: 0.5001, Acc.tray: 0.1077, Acc.ashcan: 0.4958, Acc.fan: 0.7599, Acc.pier: 0.6642, Acc.crt screen: 0.1207, Acc.plate: 0.7033, Acc.monitor: 0.0950, Acc.bulletin board: 0.5750, Acc.shower: 0.0320, Acc.radiator: 0.7263, Acc.glass: 0.1703, Acc.clock: 0.4601, Acc.flag: 0.6152
2023-11-27 14:32:10,220 - mmseg - INFO - Iter [112050/160000]	lr: 1.798e-05, eta: 10:36:08, time: 2.610, data_time: 1.887, memory: 21695, decode.loss_ce: 0.1892, decode.acc_seg: 91.9919, aux.loss_ce: 0.0916, aux.acc_seg: 90.7091, loss: 0.2808
2023-11-27 14:32:46,944 - mmseg - INFO - Iter [112100/160000]	lr: 1.796e-05, eta: 10:35:27, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1915, decode.acc_seg: 91.7855, aux.loss_ce: 0.0934, aux.acc_seg: 90.3946, loss: 0.2849
2023-11-27 14:33:25,849 - mmseg - INFO - Iter [112150/160000]	lr: 1.794e-05, eta: 10:34:47, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1792, decode.acc_seg: 92.3619, aux.loss_ce: 0.0867, aux.acc_seg: 91.2473, loss: 0.2659
2023-11-27 14:34:05,886 - mmseg - INFO - Iter [112200/160000]	lr: 1.793e-05, eta: 10:34:07, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1949, decode.acc_seg: 91.8009, aux.loss_ce: 0.0945, aux.acc_seg: 90.4307, loss: 0.2894
2023-11-27 14:34:43,473 - mmseg - INFO - Iter [112250/160000]	lr: 1.791e-05, eta: 10:33:26, time: 0.753, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1984, decode.acc_seg: 91.5146, aux.loss_ce: 0.0959, aux.acc_seg: 90.0796, loss: 0.2942
2023-11-27 14:35:20,891 - mmseg - INFO - Iter [112300/160000]	lr: 1.789e-05, eta: 10:32:46, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1985, decode.acc_seg: 91.5009, aux.loss_ce: 0.0957, aux.acc_seg: 90.1400, loss: 0.2942
2023-11-27 14:35:58,378 - mmseg - INFO - Iter [112350/160000]	lr: 1.787e-05, eta: 10:32:05, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1933, decode.acc_seg: 91.7411, aux.loss_ce: 0.0938, aux.acc_seg: 90.3030, loss: 0.2870
2023-11-27 14:36:38,348 - mmseg - INFO - Iter [112400/160000]	lr: 1.785e-05, eta: 10:31:25, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1991, decode.acc_seg: 91.5390, aux.loss_ce: 0.0956, aux.acc_seg: 90.1986, loss: 0.2947
2023-11-27 14:37:19,732 - mmseg - INFO - Iter [112450/160000]	lr: 1.783e-05, eta: 10:30:46, time: 0.828, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1924, decode.acc_seg: 91.9265, aux.loss_ce: 0.0923, aux.acc_seg: 90.6755, loss: 0.2847
2023-11-27 14:38:00,150 - mmseg - INFO - Iter [112500/160000]	lr: 1.781e-05, eta: 10:30:06, time: 0.808, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1866, decode.acc_seg: 92.2235, aux.loss_ce: 0.0913, aux.acc_seg: 90.9007, loss: 0.2779
2023-11-27 14:38:40,563 - mmseg - INFO - Iter [112550/160000]	lr: 1.779e-05, eta: 10:29:27, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1903, decode.acc_seg: 91.9938, aux.loss_ce: 0.0920, aux.acc_seg: 90.6567, loss: 0.2823
2023-11-27 14:39:21,353 - mmseg - INFO - Iter [112600/160000]	lr: 1.778e-05, eta: 10:28:47, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2061, decode.acc_seg: 91.3076, aux.loss_ce: 0.0999, aux.acc_seg: 89.9443, loss: 0.3060
2023-11-27 14:39:59,720 - mmseg - INFO - Iter [112650/160000]	lr: 1.776e-05, eta: 10:28:07, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2023, decode.acc_seg: 91.5113, aux.loss_ce: 0.1001, aux.acc_seg: 90.0301, loss: 0.3024
2023-11-27 14:40:40,111 - mmseg - INFO - Iter [112700/160000]	lr: 1.774e-05, eta: 10:27:27, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1895, decode.acc_seg: 91.9602, aux.loss_ce: 0.0912, aux.acc_seg: 90.6394, loss: 0.2806
2023-11-27 14:41:20,374 - mmseg - INFO - Iter [112750/160000]	lr: 1.772e-05, eta: 10:26:48, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1819, decode.acc_seg: 92.1319, aux.loss_ce: 0.0888, aux.acc_seg: 90.7687, loss: 0.2706
2023-11-27 14:42:00,610 - mmseg - INFO - Iter [112800/160000]	lr: 1.770e-05, eta: 10:26:08, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1881, decode.acc_seg: 91.9295, aux.loss_ce: 0.0926, aux.acc_seg: 90.5006, loss: 0.2807
2023-11-27 14:42:40,564 - mmseg - INFO - Iter [112850/160000]	lr: 1.768e-05, eta: 10:25:29, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1907, decode.acc_seg: 92.0173, aux.loss_ce: 0.0922, aux.acc_seg: 90.7319, loss: 0.2829
2023-11-27 14:43:20,489 - mmseg - INFO - Iter [112900/160000]	lr: 1.766e-05, eta: 10:24:49, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2046, decode.acc_seg: 91.6784, aux.loss_ce: 0.0997, aux.acc_seg: 90.2675, loss: 0.3043
2023-11-27 14:44:00,684 - mmseg - INFO - Iter [112950/160000]	lr: 1.764e-05, eta: 10:24:09, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1818, decode.acc_seg: 92.3366, aux.loss_ce: 0.0887, aux.acc_seg: 91.0761, loss: 0.2705
2023-11-27 14:44:41,195 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:44:41,195 - mmseg - INFO - Iter [113000/160000]	lr: 1.763e-05, eta: 10:23:30, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.1368, aux.loss_ce: 0.0887, aux.acc_seg: 90.9796, loss: 0.2699
2023-11-27 14:45:21,122 - mmseg - INFO - Iter [113050/160000]	lr: 1.761e-05, eta: 10:22:50, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1884, decode.acc_seg: 92.1198, aux.loss_ce: 0.0929, aux.acc_seg: 90.7130, loss: 0.2813
2023-11-27 14:46:01,445 - mmseg - INFO - Iter [113100/160000]	lr: 1.759e-05, eta: 10:22:10, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 91.9499, aux.loss_ce: 0.0929, aux.acc_seg: 90.6039, loss: 0.2852
2023-11-27 14:46:40,811 - mmseg - INFO - Iter [113150/160000]	lr: 1.757e-05, eta: 10:21:30, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 92.0671, aux.loss_ce: 0.0893, aux.acc_seg: 90.7269, loss: 0.2724
2023-11-27 14:47:20,076 - mmseg - INFO - Iter [113200/160000]	lr: 1.755e-05, eta: 10:20:50, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1927, decode.acc_seg: 91.8975, aux.loss_ce: 0.0949, aux.acc_seg: 90.4558, loss: 0.2876
2023-11-27 14:48:00,151 - mmseg - INFO - Iter [113250/160000]	lr: 1.753e-05, eta: 10:20:11, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1754, decode.acc_seg: 92.5649, aux.loss_ce: 0.0864, aux.acc_seg: 91.2210, loss: 0.2618
2023-11-27 14:48:39,767 - mmseg - INFO - Iter [113300/160000]	lr: 1.751e-05, eta: 10:19:31, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1915, decode.acc_seg: 92.0172, aux.loss_ce: 0.0933, aux.acc_seg: 90.6679, loss: 0.2849
2023-11-27 14:49:17,380 - mmseg - INFO - Iter [113350/160000]	lr: 1.749e-05, eta: 10:18:50, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1856, decode.acc_seg: 92.0649, aux.loss_ce: 0.0892, aux.acc_seg: 90.8521, loss: 0.2748
2023-11-27 14:49:58,497 - mmseg - INFO - Iter [113400/160000]	lr: 1.748e-05, eta: 10:18:11, time: 0.822, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1970, decode.acc_seg: 91.6307, aux.loss_ce: 0.0950, aux.acc_seg: 90.3885, loss: 0.2920
2023-11-27 14:50:38,153 - mmseg - INFO - Iter [113450/160000]	lr: 1.746e-05, eta: 10:17:31, time: 0.795, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2081, decode.acc_seg: 91.3937, aux.loss_ce: 0.1003, aux.acc_seg: 90.0187, loss: 0.3084
2023-11-27 14:51:16,466 - mmseg - INFO - Iter [113500/160000]	lr: 1.744e-05, eta: 10:16:51, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1867, decode.acc_seg: 92.0257, aux.loss_ce: 0.0898, aux.acc_seg: 90.7779, loss: 0.2765
2023-11-27 14:51:56,335 - mmseg - INFO - Iter [113550/160000]	lr: 1.742e-05, eta: 10:16:11, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2066, decode.acc_seg: 91.6476, aux.loss_ce: 0.0982, aux.acc_seg: 90.3694, loss: 0.3048
2023-11-27 14:52:36,481 - mmseg - INFO - Iter [113600/160000]	lr: 1.740e-05, eta: 10:15:31, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1959, decode.acc_seg: 91.6408, aux.loss_ce: 0.0934, aux.acc_seg: 90.3662, loss: 0.2892
2023-11-27 14:53:16,877 - mmseg - INFO - Iter [113650/160000]	lr: 1.738e-05, eta: 10:14:52, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2108, decode.acc_seg: 91.3300, aux.loss_ce: 0.1010, aux.acc_seg: 89.8741, loss: 0.3118
2023-11-27 14:53:58,789 - mmseg - INFO - Iter [113700/160000]	lr: 1.736e-05, eta: 10:14:13, time: 0.839, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1956, decode.acc_seg: 91.7856, aux.loss_ce: 0.0935, aux.acc_seg: 90.4939, loss: 0.2891
2023-11-27 14:54:37,376 - mmseg - INFO - Iter [113750/160000]	lr: 1.734e-05, eta: 10:13:32, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1879, decode.acc_seg: 92.1410, aux.loss_ce: 0.0907, aux.acc_seg: 90.9157, loss: 0.2786
2023-11-27 14:55:14,325 - mmseg - INFO - Iter [113800/160000]	lr: 1.733e-05, eta: 10:12:51, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1901, decode.acc_seg: 92.0823, aux.loss_ce: 0.0928, aux.acc_seg: 90.7351, loss: 0.2828
2023-11-27 14:55:51,635 - mmseg - INFO - Iter [113850/160000]	lr: 1.731e-05, eta: 10:12:11, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1990, decode.acc_seg: 91.5551, aux.loss_ce: 0.0963, aux.acc_seg: 90.1961, loss: 0.2953
2023-11-27 14:56:31,623 - mmseg - INFO - Iter [113900/160000]	lr: 1.729e-05, eta: 10:11:31, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1787, decode.acc_seg: 92.3949, aux.loss_ce: 0.0880, aux.acc_seg: 91.1079, loss: 0.2667
2023-11-27 14:57:11,546 - mmseg - INFO - Iter [113950/160000]	lr: 1.727e-05, eta: 10:10:51, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1846, decode.acc_seg: 92.2427, aux.loss_ce: 0.0895, aux.acc_seg: 91.0373, loss: 0.2741
2023-11-27 14:57:51,817 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 14:57:51,817 - mmseg - INFO - Iter [114000/160000]	lr: 1.725e-05, eta: 10:10:12, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1869, decode.acc_seg: 91.9500, aux.loss_ce: 0.0909, aux.acc_seg: 90.6870, loss: 0.2778
2023-11-27 14:58:31,779 - mmseg - INFO - Iter [114050/160000]	lr: 1.723e-05, eta: 10:09:32, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1896, decode.acc_seg: 92.0261, aux.loss_ce: 0.0921, aux.acc_seg: 90.7518, loss: 0.2817
2023-11-27 14:59:12,482 - mmseg - INFO - Iter [114100/160000]	lr: 1.721e-05, eta: 10:08:52, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1877, decode.acc_seg: 92.0909, aux.loss_ce: 0.0908, aux.acc_seg: 90.6400, loss: 0.2786
2023-11-27 14:59:53,390 - mmseg - INFO - Iter [114150/160000]	lr: 1.719e-05, eta: 10:08:13, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1821, decode.acc_seg: 92.2505, aux.loss_ce: 0.0895, aux.acc_seg: 90.7845, loss: 0.2716
2023-11-27 15:00:30,246 - mmseg - INFO - Iter [114200/160000]	lr: 1.718e-05, eta: 10:07:32, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1926, decode.acc_seg: 91.7794, aux.loss_ce: 0.0939, aux.acc_seg: 90.4489, loss: 0.2864
2023-11-27 15:01:08,019 - mmseg - INFO - Iter [114250/160000]	lr: 1.716e-05, eta: 10:06:51, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1820, decode.acc_seg: 92.1309, aux.loss_ce: 0.0903, aux.acc_seg: 90.6511, loss: 0.2723
2023-11-27 15:01:45,577 - mmseg - INFO - Iter [114300/160000]	lr: 1.714e-05, eta: 10:06:11, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1883, decode.acc_seg: 91.9477, aux.loss_ce: 0.0903, aux.acc_seg: 90.6388, loss: 0.2786
2023-11-27 15:02:25,652 - mmseg - INFO - Iter [114350/160000]	lr: 1.712e-05, eta: 10:05:31, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1918, decode.acc_seg: 91.8359, aux.loss_ce: 0.0929, aux.acc_seg: 90.5130, loss: 0.2847
2023-11-27 15:03:05,583 - mmseg - INFO - Iter [114400/160000]	lr: 1.710e-05, eta: 10:04:51, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2044, decode.acc_seg: 91.2180, aux.loss_ce: 0.0968, aux.acc_seg: 90.0153, loss: 0.3012
2023-11-27 15:03:46,065 - mmseg - INFO - Iter [114450/160000]	lr: 1.708e-05, eta: 10:04:12, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1830, decode.acc_seg: 92.3405, aux.loss_ce: 0.0890, aux.acc_seg: 91.0001, loss: 0.2720
2023-11-27 15:04:26,308 - mmseg - INFO - Iter [114500/160000]	lr: 1.706e-05, eta: 10:03:32, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1840, decode.acc_seg: 92.2642, aux.loss_ce: 0.0909, aux.acc_seg: 90.9016, loss: 0.2749
2023-11-27 15:05:05,541 - mmseg - INFO - Iter [114550/160000]	lr: 1.704e-05, eta: 10:02:52, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1968, decode.acc_seg: 92.0171, aux.loss_ce: 0.0952, aux.acc_seg: 90.6270, loss: 0.2921
2023-11-27 15:05:46,100 - mmseg - INFO - Iter [114600/160000]	lr: 1.703e-05, eta: 10:02:13, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1913, decode.acc_seg: 91.8106, aux.loss_ce: 0.0924, aux.acc_seg: 90.5086, loss: 0.2837
2023-11-27 15:06:23,489 - mmseg - INFO - Iter [114650/160000]	lr: 1.701e-05, eta: 10:01:32, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1971, decode.acc_seg: 91.6619, aux.loss_ce: 0.0936, aux.acc_seg: 90.4766, loss: 0.2908
2023-11-27 15:07:03,723 - mmseg - INFO - Iter [114700/160000]	lr: 1.699e-05, eta: 10:00:52, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1978, decode.acc_seg: 91.5477, aux.loss_ce: 0.0964, aux.acc_seg: 90.1718, loss: 0.2942
2023-11-27 15:07:43,748 - mmseg - INFO - Iter [114750/160000]	lr: 1.697e-05, eta: 10:00:13, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1926, decode.acc_seg: 91.8273, aux.loss_ce: 0.0928, aux.acc_seg: 90.7549, loss: 0.2854
2023-11-27 15:08:20,816 - mmseg - INFO - Iter [114800/160000]	lr: 1.695e-05, eta: 9:59:32, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2060, decode.acc_seg: 91.5401, aux.loss_ce: 0.0997, aux.acc_seg: 90.0804, loss: 0.3057
2023-11-27 15:09:01,881 - mmseg - INFO - Iter [114850/160000]	lr: 1.693e-05, eta: 9:58:52, time: 0.820, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1786, decode.acc_seg: 92.1971, aux.loss_ce: 0.0872, aux.acc_seg: 90.9030, loss: 0.2658
2023-11-27 15:09:40,734 - mmseg - INFO - Iter [114900/160000]	lr: 1.691e-05, eta: 9:58:12, time: 0.779, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1897, decode.acc_seg: 91.9437, aux.loss_ce: 0.0939, aux.acc_seg: 90.2986, loss: 0.2836
2023-11-27 15:10:21,460 - mmseg - INFO - Iter [114950/160000]	lr: 1.689e-05, eta: 9:57:33, time: 0.814, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1853, decode.acc_seg: 91.9667, aux.loss_ce: 0.0888, aux.acc_seg: 90.5953, loss: 0.2741
2023-11-27 15:11:01,514 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 15:11:01,514 - mmseg - INFO - Iter [115000/160000]	lr: 1.688e-05, eta: 9:56:53, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1840, decode.acc_seg: 92.0559, aux.loss_ce: 0.0879, aux.acc_seg: 90.8151, loss: 0.2719
2023-11-27 15:11:41,621 - mmseg - INFO - Iter [115050/160000]	lr: 1.686e-05, eta: 9:56:14, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1914, decode.acc_seg: 91.8793, aux.loss_ce: 0.0940, aux.acc_seg: 90.5461, loss: 0.2854
2023-11-27 15:12:21,652 - mmseg - INFO - Iter [115100/160000]	lr: 1.684e-05, eta: 9:55:34, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1865, decode.acc_seg: 92.1377, aux.loss_ce: 0.0904, aux.acc_seg: 90.6724, loss: 0.2769
2023-11-27 15:13:01,930 - mmseg - INFO - Iter [115150/160000]	lr: 1.682e-05, eta: 9:54:54, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1800, decode.acc_seg: 92.2567, aux.loss_ce: 0.0875, aux.acc_seg: 90.9320, loss: 0.2675
2023-11-27 15:13:42,677 - mmseg - INFO - Iter [115200/160000]	lr: 1.680e-05, eta: 9:54:15, time: 0.815, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1868, decode.acc_seg: 91.9528, aux.loss_ce: 0.0907, aux.acc_seg: 90.4534, loss: 0.2775
2023-11-27 15:14:22,647 - mmseg - INFO - Iter [115250/160000]	lr: 1.678e-05, eta: 9:53:35, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2017, decode.acc_seg: 91.4656, aux.loss_ce: 0.0971, aux.acc_seg: 90.0348, loss: 0.2987
2023-11-27 15:15:03,116 - mmseg - INFO - Iter [115300/160000]	lr: 1.676e-05, eta: 9:52:56, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1929, decode.acc_seg: 91.8216, aux.loss_ce: 0.0939, aux.acc_seg: 90.4833, loss: 0.2868
2023-11-27 15:15:42,824 - mmseg - INFO - Iter [115350/160000]	lr: 1.674e-05, eta: 9:52:16, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2025, decode.acc_seg: 91.3736, aux.loss_ce: 0.0959, aux.acc_seg: 90.1470, loss: 0.2984
2023-11-27 15:16:22,939 - mmseg - INFO - Iter [115400/160000]	lr: 1.673e-05, eta: 9:51:36, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1950, decode.acc_seg: 91.8033, aux.loss_ce: 0.0936, aux.acc_seg: 90.5830, loss: 0.2886
2023-11-27 15:17:02,567 - mmseg - INFO - Iter [115450/160000]	lr: 1.671e-05, eta: 9:50:56, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2069, decode.acc_seg: 91.3544, aux.loss_ce: 0.0991, aux.acc_seg: 90.0766, loss: 0.3059
2023-11-27 15:17:40,433 - mmseg - INFO - Iter [115500/160000]	lr: 1.669e-05, eta: 9:50:16, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1891, decode.acc_seg: 91.8449, aux.loss_ce: 0.0907, aux.acc_seg: 90.3984, loss: 0.2798
2023-11-27 15:18:17,277 - mmseg - INFO - Iter [115550/160000]	lr: 1.667e-05, eta: 9:49:35, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1913, decode.acc_seg: 91.7135, aux.loss_ce: 0.0922, aux.acc_seg: 90.5254, loss: 0.2835
2023-11-27 15:18:56,380 - mmseg - INFO - Iter [115600/160000]	lr: 1.665e-05, eta: 9:48:55, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1975, decode.acc_seg: 91.6071, aux.loss_ce: 0.0947, aux.acc_seg: 90.3859, loss: 0.2922
2023-11-27 15:19:37,092 - mmseg - INFO - Iter [115650/160000]	lr: 1.663e-05, eta: 9:48:15, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1854, decode.acc_seg: 92.0017, aux.loss_ce: 0.0917, aux.acc_seg: 90.5372, loss: 0.2770
2023-11-27 15:20:14,781 - mmseg - INFO - Iter [115700/160000]	lr: 1.661e-05, eta: 9:47:35, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1865, decode.acc_seg: 92.1706, aux.loss_ce: 0.0896, aux.acc_seg: 90.8743, loss: 0.2761
2023-11-27 15:20:53,058 - mmseg - INFO - Iter [115750/160000]	lr: 1.659e-05, eta: 9:46:54, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1901, decode.acc_seg: 91.8322, aux.loss_ce: 0.0930, aux.acc_seg: 90.3749, loss: 0.2831
2023-11-27 15:21:31,777 - mmseg - INFO - Iter [115800/160000]	lr: 1.658e-05, eta: 9:46:14, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1977, decode.acc_seg: 91.6830, aux.loss_ce: 0.0945, aux.acc_seg: 90.4809, loss: 0.2922
2023-11-27 15:22:09,846 - mmseg - INFO - Iter [115850/160000]	lr: 1.656e-05, eta: 9:45:34, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1893, decode.acc_seg: 92.1521, aux.loss_ce: 0.0926, aux.acc_seg: 90.7578, loss: 0.2819
2023-11-27 15:22:48,680 - mmseg - INFO - Iter [115900/160000]	lr: 1.654e-05, eta: 9:44:53, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1823, decode.acc_seg: 92.1755, aux.loss_ce: 0.0886, aux.acc_seg: 90.7350, loss: 0.2710
2023-11-27 15:23:28,815 - mmseg - INFO - Iter [115950/160000]	lr: 1.652e-05, eta: 9:44:14, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1945, decode.acc_seg: 91.9237, aux.loss_ce: 0.0945, aux.acc_seg: 90.4554, loss: 0.2889
2023-11-27 15:24:07,812 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 15:24:07,812 - mmseg - INFO - Iter [116000/160000]	lr: 1.650e-05, eta: 9:43:34, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1788, decode.acc_seg: 92.4132, aux.loss_ce: 0.0873, aux.acc_seg: 91.0830, loss: 0.2661
2023-11-27 15:24:48,178 - mmseg - INFO - Iter [116050/160000]	lr: 1.648e-05, eta: 9:42:54, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1891, decode.acc_seg: 92.0919, aux.loss_ce: 0.0918, aux.acc_seg: 90.8486, loss: 0.2810
2023-11-27 15:25:29,393 - mmseg - INFO - Iter [116100/160000]	lr: 1.646e-05, eta: 9:42:15, time: 0.824, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1942, decode.acc_seg: 91.6895, aux.loss_ce: 0.0931, aux.acc_seg: 90.4495, loss: 0.2873
2023-11-27 15:26:08,681 - mmseg - INFO - Iter [116150/160000]	lr: 1.644e-05, eta: 9:41:35, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1872, decode.acc_seg: 92.0453, aux.loss_ce: 0.0908, aux.acc_seg: 90.7196, loss: 0.2781
2023-11-27 15:26:50,555 - mmseg - INFO - Iter [116200/160000]	lr: 1.643e-05, eta: 9:40:56, time: 0.838, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1913, decode.acc_seg: 91.9924, aux.loss_ce: 0.0927, aux.acc_seg: 90.7507, loss: 0.2840
2023-11-27 15:27:27,242 - mmseg - INFO - Iter [116250/160000]	lr: 1.641e-05, eta: 9:40:15, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1880, decode.acc_seg: 92.0800, aux.loss_ce: 0.0909, aux.acc_seg: 90.7832, loss: 0.2789
2023-11-27 15:28:06,765 - mmseg - INFO - Iter [116300/160000]	lr: 1.639e-05, eta: 9:39:35, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1722, decode.acc_seg: 92.7120, aux.loss_ce: 0.0840, aux.acc_seg: 91.3624, loss: 0.2562
2023-11-27 15:28:47,224 - mmseg - INFO - Iter [116350/160000]	lr: 1.637e-05, eta: 9:38:56, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1968, decode.acc_seg: 91.6146, aux.loss_ce: 0.0962, aux.acc_seg: 90.2669, loss: 0.2931
2023-11-27 15:29:28,141 - mmseg - INFO - Iter [116400/160000]	lr: 1.635e-05, eta: 9:38:16, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1892, decode.acc_seg: 92.0264, aux.loss_ce: 0.0921, aux.acc_seg: 90.7804, loss: 0.2813
2023-11-27 15:30:04,927 - mmseg - INFO - Iter [116450/160000]	lr: 1.633e-05, eta: 9:37:35, time: 0.736, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1852, decode.acc_seg: 92.2231, aux.loss_ce: 0.0913, aux.acc_seg: 90.7580, loss: 0.2765
2023-11-27 15:30:44,919 - mmseg - INFO - Iter [116500/160000]	lr: 1.631e-05, eta: 9:36:56, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 92.0166, aux.loss_ce: 0.0907, aux.acc_seg: 90.6472, loss: 0.2737
2023-11-27 15:31:25,165 - mmseg - INFO - Iter [116550/160000]	lr: 1.629e-05, eta: 9:36:16, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1864, decode.acc_seg: 92.0236, aux.loss_ce: 0.0899, aux.acc_seg: 90.7133, loss: 0.2763
2023-11-27 15:32:05,540 - mmseg - INFO - Iter [116600/160000]	lr: 1.628e-05, eta: 9:35:36, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1925, decode.acc_seg: 91.8395, aux.loss_ce: 0.0945, aux.acc_seg: 90.4768, loss: 0.2870
2023-11-27 15:32:45,597 - mmseg - INFO - Iter [116650/160000]	lr: 1.626e-05, eta: 9:34:57, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1823, decode.acc_seg: 92.2310, aux.loss_ce: 0.0894, aux.acc_seg: 91.0217, loss: 0.2717
2023-11-27 15:33:25,227 - mmseg - INFO - Iter [116700/160000]	lr: 1.624e-05, eta: 9:34:17, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 91.7198, aux.loss_ce: 0.0932, aux.acc_seg: 90.4102, loss: 0.2855
2023-11-27 15:34:05,244 - mmseg - INFO - Iter [116750/160000]	lr: 1.622e-05, eta: 9:33:37, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1890, decode.acc_seg: 92.0804, aux.loss_ce: 0.0929, aux.acc_seg: 90.6970, loss: 0.2819
2023-11-27 15:34:45,749 - mmseg - INFO - Iter [116800/160000]	lr: 1.620e-05, eta: 9:32:58, time: 0.811, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1934, decode.acc_seg: 91.7331, aux.loss_ce: 0.0935, aux.acc_seg: 90.5169, loss: 0.2869
2023-11-27 15:35:26,194 - mmseg - INFO - Iter [116850/160000]	lr: 1.618e-05, eta: 9:32:18, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1893, decode.acc_seg: 91.7833, aux.loss_ce: 0.0933, aux.acc_seg: 90.2792, loss: 0.2826
2023-11-27 15:36:05,295 - mmseg - INFO - Iter [116900/160000]	lr: 1.616e-05, eta: 9:31:38, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1940, decode.acc_seg: 91.8588, aux.loss_ce: 0.0944, aux.acc_seg: 90.4365, loss: 0.2884
2023-11-27 15:36:44,771 - mmseg - INFO - Iter [116950/160000]	lr: 1.614e-05, eta: 9:30:58, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1928, decode.acc_seg: 92.0817, aux.loss_ce: 0.0928, aux.acc_seg: 90.8249, loss: 0.2856
2023-11-27 15:37:24,354 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 15:37:24,355 - mmseg - INFO - Iter [117000/160000]	lr: 1.613e-05, eta: 9:30:18, time: 0.793, data_time: 0.012, memory: 21695, decode.loss_ce: 0.2016, decode.acc_seg: 91.2833, aux.loss_ce: 0.0990, aux.acc_seg: 89.8360, loss: 0.3005
2023-11-27 15:38:01,016 - mmseg - INFO - Iter [117050/160000]	lr: 1.611e-05, eta: 9:29:37, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1822, decode.acc_seg: 92.2643, aux.loss_ce: 0.0895, aux.acc_seg: 90.9084, loss: 0.2717
2023-11-27 15:38:38,988 - mmseg - INFO - Iter [117100/160000]	lr: 1.609e-05, eta: 9:28:57, time: 0.758, data_time: 0.009, memory: 21695, decode.loss_ce: 0.1901, decode.acc_seg: 91.9530, aux.loss_ce: 0.0924, aux.acc_seg: 90.5370, loss: 0.2825
2023-11-27 15:39:18,066 - mmseg - INFO - Iter [117150/160000]	lr: 1.607e-05, eta: 9:28:17, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.2001, decode.acc_seg: 91.5374, aux.loss_ce: 0.0965, aux.acc_seg: 90.1597, loss: 0.2966
2023-11-27 15:39:55,548 - mmseg - INFO - Iter [117200/160000]	lr: 1.605e-05, eta: 9:27:36, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1940, decode.acc_seg: 91.8242, aux.loss_ce: 0.0934, aux.acc_seg: 90.3704, loss: 0.2875
2023-11-27 15:40:34,019 - mmseg - INFO - Iter [117250/160000]	lr: 1.603e-05, eta: 9:26:56, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.3228, aux.loss_ce: 0.0869, aux.acc_seg: 91.0882, loss: 0.2653
2023-11-27 15:41:12,751 - mmseg - INFO - Iter [117300/160000]	lr: 1.601e-05, eta: 9:26:16, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1855, decode.acc_seg: 92.3562, aux.loss_ce: 0.0909, aux.acc_seg: 90.9329, loss: 0.2765
2023-11-27 15:41:51,839 - mmseg - INFO - Iter [117350/160000]	lr: 1.599e-05, eta: 9:25:36, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1857, decode.acc_seg: 91.9962, aux.loss_ce: 0.0884, aux.acc_seg: 90.8128, loss: 0.2741
2023-11-27 15:42:30,249 - mmseg - INFO - Iter [117400/160000]	lr: 1.598e-05, eta: 9:24:55, time: 0.770, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1921, decode.acc_seg: 91.5615, aux.loss_ce: 0.0957, aux.acc_seg: 90.0208, loss: 0.2878
2023-11-27 15:43:08,411 - mmseg - INFO - Iter [117450/160000]	lr: 1.596e-05, eta: 9:24:15, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1886, decode.acc_seg: 92.0864, aux.loss_ce: 0.0913, aux.acc_seg: 90.7516, loss: 0.2798
2023-11-27 15:43:49,090 - mmseg - INFO - Iter [117500/160000]	lr: 1.594e-05, eta: 9:23:36, time: 0.814, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1893, decode.acc_seg: 91.9223, aux.loss_ce: 0.0929, aux.acc_seg: 90.4934, loss: 0.2823
2023-11-27 15:44:29,752 - mmseg - INFO - Iter [117550/160000]	lr: 1.592e-05, eta: 9:22:56, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1931, decode.acc_seg: 91.7758, aux.loss_ce: 0.0940, aux.acc_seg: 90.3082, loss: 0.2871
2023-11-27 15:45:08,922 - mmseg - INFO - Iter [117600/160000]	lr: 1.590e-05, eta: 9:22:16, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1820, decode.acc_seg: 92.3670, aux.loss_ce: 0.0883, aux.acc_seg: 91.0094, loss: 0.2703
2023-11-27 15:45:48,833 - mmseg - INFO - Iter [117650/160000]	lr: 1.588e-05, eta: 9:21:36, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1770, decode.acc_seg: 92.3808, aux.loss_ce: 0.0855, aux.acc_seg: 91.2491, loss: 0.2626
2023-11-27 15:46:26,345 - mmseg - INFO - Iter [117700/160000]	lr: 1.586e-05, eta: 9:20:56, time: 0.751, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1827, decode.acc_seg: 92.3815, aux.loss_ce: 0.0897, aux.acc_seg: 91.0466, loss: 0.2724
2023-11-27 15:47:06,853 - mmseg - INFO - Iter [117750/160000]	lr: 1.584e-05, eta: 9:20:16, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1802, decode.acc_seg: 92.2191, aux.loss_ce: 0.0878, aux.acc_seg: 90.8869, loss: 0.2680
2023-11-27 15:47:46,862 - mmseg - INFO - Iter [117800/160000]	lr: 1.583e-05, eta: 9:19:37, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1771, decode.acc_seg: 92.5437, aux.loss_ce: 0.0855, aux.acc_seg: 91.2902, loss: 0.2625
2023-11-27 15:48:24,949 - mmseg - INFO - Iter [117850/160000]	lr: 1.581e-05, eta: 9:18:56, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1801, decode.acc_seg: 92.3229, aux.loss_ce: 0.0889, aux.acc_seg: 90.9759, loss: 0.2690
2023-11-27 15:49:02,295 - mmseg - INFO - Iter [117900/160000]	lr: 1.579e-05, eta: 9:18:15, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1815, decode.acc_seg: 92.4025, aux.loss_ce: 0.0866, aux.acc_seg: 91.1728, loss: 0.2681
2023-11-27 15:49:39,012 - mmseg - INFO - Iter [117950/160000]	lr: 1.577e-05, eta: 9:17:35, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1943, decode.acc_seg: 91.5841, aux.loss_ce: 0.0926, aux.acc_seg: 90.4142, loss: 0.2869
2023-11-27 15:50:16,493 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 15:50:16,493 - mmseg - INFO - Iter [118000/160000]	lr: 1.575e-05, eta: 9:16:54, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1842, decode.acc_seg: 91.9588, aux.loss_ce: 0.0888, aux.acc_seg: 90.6811, loss: 0.2731
2023-11-27 15:50:55,587 - mmseg - INFO - Iter [118050/160000]	lr: 1.573e-05, eta: 9:16:14, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1815, decode.acc_seg: 92.3739, aux.loss_ce: 0.0887, aux.acc_seg: 91.1590, loss: 0.2702
2023-11-27 15:51:32,495 - mmseg - INFO - Iter [118100/160000]	lr: 1.571e-05, eta: 9:15:33, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2011, decode.acc_seg: 91.5151, aux.loss_ce: 0.0976, aux.acc_seg: 90.1152, loss: 0.2986
2023-11-27 15:52:13,349 - mmseg - INFO - Iter [118150/160000]	lr: 1.569e-05, eta: 9:14:54, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1881, decode.acc_seg: 91.9997, aux.loss_ce: 0.0919, aux.acc_seg: 90.6309, loss: 0.2799
2023-11-27 15:52:52,648 - mmseg - INFO - Iter [118200/160000]	lr: 1.568e-05, eta: 9:14:14, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 92.1725, aux.loss_ce: 0.0887, aux.acc_seg: 90.8179, loss: 0.2718
2023-11-27 15:53:30,535 - mmseg - INFO - Iter [118250/160000]	lr: 1.566e-05, eta: 9:13:33, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1893, decode.acc_seg: 91.7969, aux.loss_ce: 0.0937, aux.acc_seg: 90.2877, loss: 0.2830
2023-11-27 15:54:10,935 - mmseg - INFO - Iter [118300/160000]	lr: 1.564e-05, eta: 9:12:54, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1892, decode.acc_seg: 92.1004, aux.loss_ce: 0.0917, aux.acc_seg: 90.9471, loss: 0.2809
2023-11-27 15:54:48,497 - mmseg - INFO - Iter [118350/160000]	lr: 1.562e-05, eta: 9:12:13, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1750, decode.acc_seg: 92.4328, aux.loss_ce: 0.0854, aux.acc_seg: 91.2008, loss: 0.2604
2023-11-27 15:55:27,641 - mmseg - INFO - Iter [118400/160000]	lr: 1.560e-05, eta: 9:11:33, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1744, decode.acc_seg: 92.4061, aux.loss_ce: 0.0841, aux.acc_seg: 91.1775, loss: 0.2586
2023-11-27 15:56:06,127 - mmseg - INFO - Iter [118450/160000]	lr: 1.558e-05, eta: 9:10:53, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1838, decode.acc_seg: 92.0460, aux.loss_ce: 0.0913, aux.acc_seg: 90.6160, loss: 0.2752
2023-11-27 15:56:45,536 - mmseg - INFO - Iter [118500/160000]	lr: 1.556e-05, eta: 9:10:13, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1966, decode.acc_seg: 91.6918, aux.loss_ce: 0.0958, aux.acc_seg: 90.3241, loss: 0.2924
2023-11-27 15:57:26,150 - mmseg - INFO - Iter [118550/160000]	lr: 1.554e-05, eta: 9:09:34, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1969, decode.acc_seg: 91.5649, aux.loss_ce: 0.0943, aux.acc_seg: 90.3763, loss: 0.2913
2023-11-27 15:58:02,982 - mmseg - INFO - Iter [118600/160000]	lr: 1.553e-05, eta: 9:08:53, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1718, decode.acc_seg: 92.7210, aux.loss_ce: 0.0841, aux.acc_seg: 91.4610, loss: 0.2559
2023-11-27 15:58:42,182 - mmseg - INFO - Iter [118650/160000]	lr: 1.551e-05, eta: 9:08:13, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1882, decode.acc_seg: 91.7531, aux.loss_ce: 0.0917, aux.acc_seg: 90.3593, loss: 0.2800
2023-11-27 15:59:19,869 - mmseg - INFO - Iter [118700/160000]	lr: 1.549e-05, eta: 9:07:32, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1827, decode.acc_seg: 92.3012, aux.loss_ce: 0.0880, aux.acc_seg: 91.0001, loss: 0.2707
2023-11-27 16:00:00,594 - mmseg - INFO - Iter [118750/160000]	lr: 1.547e-05, eta: 9:06:53, time: 0.813, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1876, decode.acc_seg: 92.3557, aux.loss_ce: 0.0899, aux.acc_seg: 91.1489, loss: 0.2775
2023-11-27 16:00:41,910 - mmseg - INFO - Iter [118800/160000]	lr: 1.545e-05, eta: 9:06:14, time: 0.826, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1868, decode.acc_seg: 91.8994, aux.loss_ce: 0.0901, aux.acc_seg: 90.6769, loss: 0.2768
2023-11-27 16:01:20,575 - mmseg - INFO - Iter [118850/160000]	lr: 1.543e-05, eta: 9:05:34, time: 0.775, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1881, decode.acc_seg: 92.0117, aux.loss_ce: 0.0905, aux.acc_seg: 90.7821, loss: 0.2786
2023-11-27 16:01:57,703 - mmseg - INFO - Iter [118900/160000]	lr: 1.541e-05, eta: 9:04:53, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1746, decode.acc_seg: 92.5670, aux.loss_ce: 0.0850, aux.acc_seg: 91.3107, loss: 0.2595
2023-11-27 16:02:36,962 - mmseg - INFO - Iter [118950/160000]	lr: 1.539e-05, eta: 9:04:13, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1889, decode.acc_seg: 92.0206, aux.loss_ce: 0.0920, aux.acc_seg: 90.6122, loss: 0.2809
2023-11-27 16:03:16,561 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 16:03:16,562 - mmseg - INFO - Iter [119000/160000]	lr: 1.538e-05, eta: 9:03:33, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1764, decode.acc_seg: 92.4506, aux.loss_ce: 0.0867, aux.acc_seg: 91.0955, loss: 0.2631
2023-11-27 16:03:55,329 - mmseg - INFO - Iter [119050/160000]	lr: 1.536e-05, eta: 9:02:53, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1778, decode.acc_seg: 92.5587, aux.loss_ce: 0.0872, aux.acc_seg: 91.1336, loss: 0.2650
2023-11-27 16:04:35,509 - mmseg - INFO - Iter [119100/160000]	lr: 1.534e-05, eta: 9:02:13, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1776, decode.acc_seg: 92.3914, aux.loss_ce: 0.0853, aux.acc_seg: 91.2574, loss: 0.2629
2023-11-27 16:05:13,891 - mmseg - INFO - Iter [119150/160000]	lr: 1.532e-05, eta: 9:01:33, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1956, decode.acc_seg: 91.9107, aux.loss_ce: 0.0949, aux.acc_seg: 90.4204, loss: 0.2904
2023-11-27 16:05:53,183 - mmseg - INFO - Iter [119200/160000]	lr: 1.530e-05, eta: 9:00:53, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1743, decode.acc_seg: 92.4377, aux.loss_ce: 0.0865, aux.acc_seg: 91.0160, loss: 0.2608
2023-11-27 16:06:33,663 - mmseg - INFO - Iter [119250/160000]	lr: 1.528e-05, eta: 9:00:14, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1818, decode.acc_seg: 92.2364, aux.loss_ce: 0.0894, aux.acc_seg: 90.9610, loss: 0.2712
2023-11-27 16:07:14,133 - mmseg - INFO - Iter [119300/160000]	lr: 1.526e-05, eta: 8:59:34, time: 0.810, data_time: 0.010, memory: 21695, decode.loss_ce: 0.2144, decode.acc_seg: 91.1734, aux.loss_ce: 0.1019, aux.acc_seg: 89.6935, loss: 0.3163
2023-11-27 16:07:51,097 - mmseg - INFO - Iter [119350/160000]	lr: 1.524e-05, eta: 8:58:53, time: 0.739, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1788, decode.acc_seg: 92.4706, aux.loss_ce: 0.0874, aux.acc_seg: 91.2547, loss: 0.2662
2023-11-27 16:08:28,319 - mmseg - INFO - Iter [119400/160000]	lr: 1.523e-05, eta: 8:58:13, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1932, decode.acc_seg: 91.8459, aux.loss_ce: 0.0943, aux.acc_seg: 90.4205, loss: 0.2875
2023-11-27 16:09:06,446 - mmseg - INFO - Iter [119450/160000]	lr: 1.521e-05, eta: 8:57:32, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1910, decode.acc_seg: 91.8912, aux.loss_ce: 0.0937, aux.acc_seg: 90.4834, loss: 0.2847
2023-11-27 16:09:45,524 - mmseg - INFO - Iter [119500/160000]	lr: 1.519e-05, eta: 8:56:52, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1926, decode.acc_seg: 91.8840, aux.loss_ce: 0.0939, aux.acc_seg: 90.4952, loss: 0.2865
2023-11-27 16:10:26,243 - mmseg - INFO - Iter [119550/160000]	lr: 1.517e-05, eta: 8:56:13, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1799, decode.acc_seg: 92.3260, aux.loss_ce: 0.0893, aux.acc_seg: 90.8703, loss: 0.2692
2023-11-27 16:11:06,521 - mmseg - INFO - Iter [119600/160000]	lr: 1.515e-05, eta: 8:55:33, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1753, decode.acc_seg: 92.2349, aux.loss_ce: 0.0872, aux.acc_seg: 90.8460, loss: 0.2625
2023-11-27 16:11:46,785 - mmseg - INFO - Iter [119650/160000]	lr: 1.513e-05, eta: 8:54:54, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.3090, aux.loss_ce: 0.0875, aux.acc_seg: 91.1395, loss: 0.2688
2023-11-27 16:12:26,856 - mmseg - INFO - Iter [119700/160000]	lr: 1.511e-05, eta: 8:54:14, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1918, decode.acc_seg: 92.0141, aux.loss_ce: 0.0947, aux.acc_seg: 90.5713, loss: 0.2865
2023-11-27 16:13:07,059 - mmseg - INFO - Iter [119750/160000]	lr: 1.509e-05, eta: 8:53:34, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1902, decode.acc_seg: 91.8253, aux.loss_ce: 0.0917, aux.acc_seg: 90.5332, loss: 0.2819
2023-11-27 16:13:46,873 - mmseg - INFO - Iter [119800/160000]	lr: 1.508e-05, eta: 8:52:55, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1786, decode.acc_seg: 92.2460, aux.loss_ce: 0.0867, aux.acc_seg: 90.9489, loss: 0.2654
2023-11-27 16:14:27,196 - mmseg - INFO - Iter [119850/160000]	lr: 1.506e-05, eta: 8:52:15, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1881, decode.acc_seg: 92.0591, aux.loss_ce: 0.0898, aux.acc_seg: 90.8327, loss: 0.2779
2023-11-27 16:15:07,712 - mmseg - INFO - Iter [119900/160000]	lr: 1.504e-05, eta: 8:51:36, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1967, decode.acc_seg: 91.6234, aux.loss_ce: 0.0952, aux.acc_seg: 90.3193, loss: 0.2919
2023-11-27 16:15:47,892 - mmseg - INFO - Iter [119950/160000]	lr: 1.502e-05, eta: 8:50:56, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1926, decode.acc_seg: 91.9263, aux.loss_ce: 0.0904, aux.acc_seg: 90.6734, loss: 0.2831
2023-11-27 16:16:28,871 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 16:16:28,871 - mmseg - INFO - Iter [120000/160000]	lr: 1.500e-05, eta: 8:50:17, time: 0.819, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1892, decode.acc_seg: 92.0065, aux.loss_ce: 0.0919, aux.acc_seg: 90.6278, loss: 0.2811
2023-11-27 16:17:08,367 - mmseg - INFO - Iter [120050/160000]	lr: 1.498e-05, eta: 8:49:37, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1909, decode.acc_seg: 91.9644, aux.loss_ce: 0.0919, aux.acc_seg: 90.7425, loss: 0.2828
2023-11-27 16:17:47,899 - mmseg - INFO - Iter [120100/160000]	lr: 1.496e-05, eta: 8:48:57, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1829, decode.acc_seg: 92.3065, aux.loss_ce: 0.0881, aux.acc_seg: 91.0692, loss: 0.2710
2023-11-27 16:18:27,544 - mmseg - INFO - Iter [120150/160000]	lr: 1.494e-05, eta: 8:48:17, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1837, decode.acc_seg: 92.1638, aux.loss_ce: 0.0893, aux.acc_seg: 90.7383, loss: 0.2730
2023-11-27 16:19:07,838 - mmseg - INFO - Iter [120200/160000]	lr: 1.493e-05, eta: 8:47:37, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1724, decode.acc_seg: 92.5886, aux.loss_ce: 0.0847, aux.acc_seg: 91.2587, loss: 0.2571
2023-11-27 16:19:49,256 - mmseg - INFO - Iter [120250/160000]	lr: 1.491e-05, eta: 8:46:58, time: 0.828, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1817, decode.acc_seg: 92.2079, aux.loss_ce: 0.0887, aux.acc_seg: 90.9144, loss: 0.2704
2023-11-27 16:20:29,197 - mmseg - INFO - Iter [120300/160000]	lr: 1.489e-05, eta: 8:46:19, time: 0.799, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1700, decode.acc_seg: 92.6191, aux.loss_ce: 0.0845, aux.acc_seg: 91.1516, loss: 0.2546
2023-11-27 16:21:08,893 - mmseg - INFO - Iter [120350/160000]	lr: 1.487e-05, eta: 8:45:39, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1792, decode.acc_seg: 92.4453, aux.loss_ce: 0.0882, aux.acc_seg: 91.1026, loss: 0.2673
2023-11-27 16:21:49,241 - mmseg - INFO - Iter [120400/160000]	lr: 1.485e-05, eta: 8:44:59, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1900, decode.acc_seg: 91.8662, aux.loss_ce: 0.0948, aux.acc_seg: 90.3289, loss: 0.2848
2023-11-27 16:22:27,221 - mmseg - INFO - Iter [120450/160000]	lr: 1.483e-05, eta: 8:44:19, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1872, decode.acc_seg: 91.9639, aux.loss_ce: 0.0924, aux.acc_seg: 90.5761, loss: 0.2796
2023-11-27 16:23:05,655 - mmseg - INFO - Iter [120500/160000]	lr: 1.481e-05, eta: 8:43:39, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1909, decode.acc_seg: 91.8988, aux.loss_ce: 0.0928, aux.acc_seg: 90.6192, loss: 0.2837
2023-11-27 16:23:46,125 - mmseg - INFO - Iter [120550/160000]	lr: 1.479e-05, eta: 8:42:59, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1852, decode.acc_seg: 92.0759, aux.loss_ce: 0.0917, aux.acc_seg: 90.6253, loss: 0.2769
2023-11-27 16:24:25,570 - mmseg - INFO - Iter [120600/160000]	lr: 1.478e-05, eta: 8:42:19, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1773, decode.acc_seg: 92.5804, aux.loss_ce: 0.0864, aux.acc_seg: 91.2238, loss: 0.2637
2023-11-27 16:25:04,606 - mmseg - INFO - Iter [120650/160000]	lr: 1.476e-05, eta: 8:41:39, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1782, decode.acc_seg: 92.3164, aux.loss_ce: 0.0882, aux.acc_seg: 90.9797, loss: 0.2664
2023-11-27 16:25:45,272 - mmseg - INFO - Iter [120700/160000]	lr: 1.474e-05, eta: 8:41:00, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1786, decode.acc_seg: 92.4256, aux.loss_ce: 0.0885, aux.acc_seg: 91.0711, loss: 0.2671
2023-11-27 16:26:25,468 - mmseg - INFO - Iter [120750/160000]	lr: 1.472e-05, eta: 8:40:20, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.2637, aux.loss_ce: 0.0850, aux.acc_seg: 91.1457, loss: 0.2616
2023-11-27 16:27:04,297 - mmseg - INFO - Iter [120800/160000]	lr: 1.470e-05, eta: 8:39:40, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1782, decode.acc_seg: 92.4453, aux.loss_ce: 0.0868, aux.acc_seg: 91.1499, loss: 0.2650
2023-11-27 16:27:42,866 - mmseg - INFO - Iter [120850/160000]	lr: 1.468e-05, eta: 8:39:00, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1822, decode.acc_seg: 92.0881, aux.loss_ce: 0.0906, aux.acc_seg: 90.6906, loss: 0.2728
2023-11-27 16:28:21,662 - mmseg - INFO - Iter [120900/160000]	lr: 1.466e-05, eta: 8:38:20, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1904, decode.acc_seg: 91.7941, aux.loss_ce: 0.0938, aux.acc_seg: 90.4527, loss: 0.2842
2023-11-27 16:29:01,603 - mmseg - INFO - Iter [120950/160000]	lr: 1.464e-05, eta: 8:37:40, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1844, decode.acc_seg: 92.1105, aux.loss_ce: 0.0906, aux.acc_seg: 90.7057, loss: 0.2750
2023-11-27 16:29:41,740 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 16:29:41,740 - mmseg - INFO - Iter [121000/160000]	lr: 1.463e-05, eta: 8:37:00, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1953, decode.acc_seg: 91.7079, aux.loss_ce: 0.0940, aux.acc_seg: 90.4633, loss: 0.2894
2023-11-27 16:30:21,906 - mmseg - INFO - Iter [121050/160000]	lr: 1.461e-05, eta: 8:36:21, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1912, decode.acc_seg: 91.9197, aux.loss_ce: 0.0933, aux.acc_seg: 90.5771, loss: 0.2845
2023-11-27 16:30:59,033 - mmseg - INFO - Iter [121100/160000]	lr: 1.459e-05, eta: 8:35:40, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1798, decode.acc_seg: 92.1164, aux.loss_ce: 0.0888, aux.acc_seg: 90.8247, loss: 0.2686
2023-11-27 16:31:38,235 - mmseg - INFO - Iter [121150/160000]	lr: 1.457e-05, eta: 8:35:00, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1863, decode.acc_seg: 92.2300, aux.loss_ce: 0.0900, aux.acc_seg: 90.9211, loss: 0.2763
2023-11-27 16:32:17,341 - mmseg - INFO - Iter [121200/160000]	lr: 1.455e-05, eta: 8:34:20, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1827, decode.acc_seg: 92.1988, aux.loss_ce: 0.0876, aux.acc_seg: 90.9971, loss: 0.2703
2023-11-27 16:32:59,579 - mmseg - INFO - Iter [121250/160000]	lr: 1.453e-05, eta: 8:33:41, time: 0.845, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1876, decode.acc_seg: 92.1194, aux.loss_ce: 0.0920, aux.acc_seg: 90.6034, loss: 0.2795
2023-11-27 16:33:39,846 - mmseg - INFO - Iter [121300/160000]	lr: 1.451e-05, eta: 8:33:02, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1736, decode.acc_seg: 92.5198, aux.loss_ce: 0.0859, aux.acc_seg: 91.2269, loss: 0.2596
2023-11-27 16:34:19,974 - mmseg - INFO - Iter [121350/160000]	lr: 1.449e-05, eta: 8:32:22, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1909, decode.acc_seg: 91.9564, aux.loss_ce: 0.0944, aux.acc_seg: 90.5766, loss: 0.2853
2023-11-27 16:34:57,287 - mmseg - INFO - Iter [121400/160000]	lr: 1.448e-05, eta: 8:31:41, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1885, decode.acc_seg: 91.8736, aux.loss_ce: 0.0902, aux.acc_seg: 90.7621, loss: 0.2787
2023-11-27 16:35:37,653 - mmseg - INFO - Iter [121450/160000]	lr: 1.446e-05, eta: 8:31:02, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.3552, aux.loss_ce: 0.0851, aux.acc_seg: 91.0937, loss: 0.2611
2023-11-27 16:36:18,182 - mmseg - INFO - Iter [121500/160000]	lr: 1.444e-05, eta: 8:30:22, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1861, decode.acc_seg: 91.8057, aux.loss_ce: 0.0921, aux.acc_seg: 90.3579, loss: 0.2781
2023-11-27 16:36:58,052 - mmseg - INFO - Iter [121550/160000]	lr: 1.442e-05, eta: 8:29:42, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1817, decode.acc_seg: 92.3866, aux.loss_ce: 0.0872, aux.acc_seg: 91.2409, loss: 0.2689
2023-11-27 16:37:35,954 - mmseg - INFO - Iter [121600/160000]	lr: 1.440e-05, eta: 8:29:02, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1768, decode.acc_seg: 92.5066, aux.loss_ce: 0.0867, aux.acc_seg: 91.1538, loss: 0.2635
2023-11-27 16:38:15,430 - mmseg - INFO - Iter [121650/160000]	lr: 1.438e-05, eta: 8:28:22, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1796, decode.acc_seg: 92.1809, aux.loss_ce: 0.0883, aux.acc_seg: 90.8515, loss: 0.2679
2023-11-27 16:38:55,374 - mmseg - INFO - Iter [121700/160000]	lr: 1.436e-05, eta: 8:27:43, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1769, decode.acc_seg: 92.4216, aux.loss_ce: 0.0864, aux.acc_seg: 91.2289, loss: 0.2632
2023-11-27 16:39:32,609 - mmseg - INFO - Iter [121750/160000]	lr: 1.434e-05, eta: 8:27:02, time: 0.746, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1820, decode.acc_seg: 92.1609, aux.loss_ce: 0.0887, aux.acc_seg: 90.8754, loss: 0.2707
2023-11-27 16:40:11,653 - mmseg - INFO - Iter [121800/160000]	lr: 1.433e-05, eta: 8:26:22, time: 0.780, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1897, decode.acc_seg: 92.0816, aux.loss_ce: 0.0935, aux.acc_seg: 90.5678, loss: 0.2832
2023-11-27 16:40:52,062 - mmseg - INFO - Iter [121850/160000]	lr: 1.431e-05, eta: 8:25:42, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1849, decode.acc_seg: 92.2461, aux.loss_ce: 0.0889, aux.acc_seg: 91.0030, loss: 0.2737
2023-11-27 16:41:32,466 - mmseg - INFO - Iter [121900/160000]	lr: 1.429e-05, eta: 8:25:03, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1879, decode.acc_seg: 91.9147, aux.loss_ce: 0.0929, aux.acc_seg: 90.5089, loss: 0.2807
2023-11-27 16:42:11,535 - mmseg - INFO - Iter [121950/160000]	lr: 1.427e-05, eta: 8:24:23, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1894, decode.acc_seg: 92.0395, aux.loss_ce: 0.0923, aux.acc_seg: 90.7531, loss: 0.2816
2023-11-27 16:42:50,615 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 16:42:50,615 - mmseg - INFO - Iter [122000/160000]	lr: 1.425e-05, eta: 8:23:43, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1902, decode.acc_seg: 91.8234, aux.loss_ce: 0.0919, aux.acc_seg: 90.5004, loss: 0.2821
2023-11-27 16:43:27,994 - mmseg - INFO - Iter [122050/160000]	lr: 1.423e-05, eta: 8:23:02, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1836, decode.acc_seg: 92.1551, aux.loss_ce: 0.0904, aux.acc_seg: 90.6895, loss: 0.2740
2023-11-27 16:44:06,948 - mmseg - INFO - Iter [122100/160000]	lr: 1.421e-05, eta: 8:22:22, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.3480, aux.loss_ce: 0.0856, aux.acc_seg: 91.1443, loss: 0.2622
2023-11-27 16:44:48,023 - mmseg - INFO - Iter [122150/160000]	lr: 1.419e-05, eta: 8:21:43, time: 0.822, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.0883, aux.loss_ce: 0.0885, aux.acc_seg: 90.7286, loss: 0.2698
2023-11-27 16:45:27,316 - mmseg - INFO - Iter [122200/160000]	lr: 1.418e-05, eta: 8:21:03, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1834, decode.acc_seg: 92.2209, aux.loss_ce: 0.0897, aux.acc_seg: 90.8809, loss: 0.2732
2023-11-27 16:46:06,937 - mmseg - INFO - Iter [122250/160000]	lr: 1.416e-05, eta: 8:20:23, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1846, decode.acc_seg: 91.8087, aux.loss_ce: 0.0916, aux.acc_seg: 90.3810, loss: 0.2762
2023-11-27 16:46:47,385 - mmseg - INFO - Iter [122300/160000]	lr: 1.414e-05, eta: 8:19:44, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1846, decode.acc_seg: 92.1415, aux.loss_ce: 0.0905, aux.acc_seg: 90.7261, loss: 0.2751
2023-11-27 16:47:27,616 - mmseg - INFO - Iter [122350/160000]	lr: 1.412e-05, eta: 8:19:04, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1822, decode.acc_seg: 92.4236, aux.loss_ce: 0.0893, aux.acc_seg: 91.1230, loss: 0.2715
2023-11-27 16:48:06,384 - mmseg - INFO - Iter [122400/160000]	lr: 1.410e-05, eta: 8:18:24, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1964, decode.acc_seg: 91.7965, aux.loss_ce: 0.0945, aux.acc_seg: 90.4559, loss: 0.2909
2023-11-27 16:48:45,091 - mmseg - INFO - Iter [122450/160000]	lr: 1.408e-05, eta: 8:17:44, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1801, decode.acc_seg: 92.4577, aux.loss_ce: 0.0885, aux.acc_seg: 91.0560, loss: 0.2685
2023-11-27 16:49:24,731 - mmseg - INFO - Iter [122500/160000]	lr: 1.406e-05, eta: 8:17:04, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1913, decode.acc_seg: 91.8700, aux.loss_ce: 0.0915, aux.acc_seg: 90.6969, loss: 0.2827
2023-11-27 16:50:06,812 - mmseg - INFO - Iter [122550/160000]	lr: 1.404e-05, eta: 8:16:25, time: 0.841, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 92.1227, aux.loss_ce: 0.0887, aux.acc_seg: 90.9192, loss: 0.2718
2023-11-27 16:50:45,249 - mmseg - INFO - Iter [122600/160000]	lr: 1.403e-05, eta: 8:15:45, time: 0.770, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1910, decode.acc_seg: 91.9703, aux.loss_ce: 0.0934, aux.acc_seg: 90.5849, loss: 0.2843
2023-11-27 16:51:22,867 - mmseg - INFO - Iter [122650/160000]	lr: 1.401e-05, eta: 8:15:04, time: 0.752, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1786, decode.acc_seg: 92.4616, aux.loss_ce: 0.0874, aux.acc_seg: 91.1522, loss: 0.2661
2023-11-27 16:51:59,677 - mmseg - INFO - Iter [122700/160000]	lr: 1.399e-05, eta: 8:14:24, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1803, decode.acc_seg: 92.3898, aux.loss_ce: 0.0870, aux.acc_seg: 91.0324, loss: 0.2672
2023-11-27 16:52:38,969 - mmseg - INFO - Iter [122750/160000]	lr: 1.397e-05, eta: 8:13:44, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1868, decode.acc_seg: 92.1328, aux.loss_ce: 0.0916, aux.acc_seg: 90.7681, loss: 0.2784
2023-11-27 16:53:18,552 - mmseg - INFO - Iter [122800/160000]	lr: 1.395e-05, eta: 8:13:04, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.6075, aux.loss_ce: 0.0862, aux.acc_seg: 91.2663, loss: 0.2601
2023-11-27 16:53:56,355 - mmseg - INFO - Iter [122850/160000]	lr: 1.393e-05, eta: 8:12:24, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1868, decode.acc_seg: 92.2502, aux.loss_ce: 0.0915, aux.acc_seg: 90.9265, loss: 0.2783
2023-11-27 16:54:35,294 - mmseg - INFO - Iter [122900/160000]	lr: 1.391e-05, eta: 8:11:44, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1805, decode.acc_seg: 92.4043, aux.loss_ce: 0.0889, aux.acc_seg: 90.9865, loss: 0.2694
2023-11-27 16:55:12,300 - mmseg - INFO - Iter [122950/160000]	lr: 1.389e-05, eta: 8:11:03, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1785, decode.acc_seg: 92.4696, aux.loss_ce: 0.0870, aux.acc_seg: 91.1487, loss: 0.2655
2023-11-27 16:55:51,923 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 16:55:51,924 - mmseg - INFO - Iter [123000/160000]	lr: 1.388e-05, eta: 8:10:23, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1851, decode.acc_seg: 91.9793, aux.loss_ce: 0.0897, aux.acc_seg: 90.6393, loss: 0.2748
2023-11-27 16:56:31,362 - mmseg - INFO - Iter [123050/160000]	lr: 1.386e-05, eta: 8:09:43, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1845, decode.acc_seg: 92.1925, aux.loss_ce: 0.0916, aux.acc_seg: 90.7304, loss: 0.2760
2023-11-27 16:57:12,272 - mmseg - INFO - Iter [123100/160000]	lr: 1.384e-05, eta: 8:09:04, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1723, decode.acc_seg: 92.7078, aux.loss_ce: 0.0829, aux.acc_seg: 91.4601, loss: 0.2552
2023-11-27 16:57:53,297 - mmseg - INFO - Iter [123150/160000]	lr: 1.382e-05, eta: 8:08:25, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1844, decode.acc_seg: 92.0999, aux.loss_ce: 0.0912, aux.acc_seg: 90.6988, loss: 0.2756
2023-11-27 16:58:32,600 - mmseg - INFO - Iter [123200/160000]	lr: 1.380e-05, eta: 8:07:45, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1828, decode.acc_seg: 91.9652, aux.loss_ce: 0.0886, aux.acc_seg: 90.6584, loss: 0.2714
2023-11-27 16:59:11,342 - mmseg - INFO - Iter [123250/160000]	lr: 1.378e-05, eta: 8:07:05, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1864, decode.acc_seg: 92.0644, aux.loss_ce: 0.0921, aux.acc_seg: 90.7237, loss: 0.2785
2023-11-27 16:59:51,909 - mmseg - INFO - Iter [123300/160000]	lr: 1.376e-05, eta: 8:06:25, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1937, decode.acc_seg: 91.7249, aux.loss_ce: 0.0940, aux.acc_seg: 90.3891, loss: 0.2877
2023-11-27 17:00:31,764 - mmseg - INFO - Iter [123350/160000]	lr: 1.374e-05, eta: 8:05:45, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1769, decode.acc_seg: 92.5033, aux.loss_ce: 0.0868, aux.acc_seg: 91.1196, loss: 0.2637
2023-11-27 17:01:10,516 - mmseg - INFO - Iter [123400/160000]	lr: 1.373e-05, eta: 8:05:05, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 92.0452, aux.loss_ce: 0.0944, aux.acc_seg: 90.7683, loss: 0.2867
2023-11-27 17:01:50,536 - mmseg - INFO - Iter [123450/160000]	lr: 1.371e-05, eta: 8:04:26, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.5449, aux.loss_ce: 0.0839, aux.acc_seg: 91.2520, loss: 0.2533
2023-11-27 17:02:30,149 - mmseg - INFO - Iter [123500/160000]	lr: 1.369e-05, eta: 8:03:46, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1770, decode.acc_seg: 92.5019, aux.loss_ce: 0.0876, aux.acc_seg: 91.1330, loss: 0.2646
2023-11-27 17:03:08,550 - mmseg - INFO - Iter [123550/160000]	lr: 1.367e-05, eta: 8:03:06, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1730, decode.acc_seg: 92.5518, aux.loss_ce: 0.0857, aux.acc_seg: 91.1453, loss: 0.2587
2023-11-27 17:03:46,152 - mmseg - INFO - Iter [123600/160000]	lr: 1.365e-05, eta: 8:02:25, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1883, decode.acc_seg: 92.1453, aux.loss_ce: 0.0930, aux.acc_seg: 90.7087, loss: 0.2813
2023-11-27 17:04:25,626 - mmseg - INFO - Iter [123650/160000]	lr: 1.363e-05, eta: 8:01:45, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1829, decode.acc_seg: 92.1426, aux.loss_ce: 0.0895, aux.acc_seg: 90.7364, loss: 0.2724
2023-11-27 17:05:05,792 - mmseg - INFO - Iter [123700/160000]	lr: 1.361e-05, eta: 8:01:06, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1826, decode.acc_seg: 92.3071, aux.loss_ce: 0.0888, aux.acc_seg: 91.0683, loss: 0.2714
2023-11-27 17:05:44,288 - mmseg - INFO - Iter [123750/160000]	lr: 1.359e-05, eta: 8:00:26, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1916, decode.acc_seg: 91.8853, aux.loss_ce: 0.0929, aux.acc_seg: 90.6173, loss: 0.2845
2023-11-27 17:06:25,075 - mmseg - INFO - Iter [123800/160000]	lr: 1.358e-05, eta: 7:59:46, time: 0.815, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1785, decode.acc_seg: 92.2253, aux.loss_ce: 0.0884, aux.acc_seg: 90.8250, loss: 0.2669
2023-11-27 17:07:05,983 - mmseg - INFO - Iter [123850/160000]	lr: 1.356e-05, eta: 7:59:07, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.8103, aux.loss_ce: 0.0828, aux.acc_seg: 91.5103, loss: 0.2529
2023-11-27 17:07:44,899 - mmseg - INFO - Iter [123900/160000]	lr: 1.354e-05, eta: 7:58:27, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1847, decode.acc_seg: 92.1010, aux.loss_ce: 0.0896, aux.acc_seg: 90.8359, loss: 0.2743
2023-11-27 17:08:25,032 - mmseg - INFO - Iter [123950/160000]	lr: 1.352e-05, eta: 7:57:47, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1751, decode.acc_seg: 92.3546, aux.loss_ce: 0.0855, aux.acc_seg: 91.0509, loss: 0.2606
2023-11-27 17:09:04,157 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 17:09:04,158 - mmseg - INFO - Iter [124000/160000]	lr: 1.350e-05, eta: 7:57:07, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1892, decode.acc_seg: 91.8939, aux.loss_ce: 0.0913, aux.acc_seg: 90.6511, loss: 0.2805
2023-11-27 17:09:43,264 - mmseg - INFO - Iter [124050/160000]	lr: 1.348e-05, eta: 7:56:27, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1835, decode.acc_seg: 91.9156, aux.loss_ce: 0.0879, aux.acc_seg: 90.7076, loss: 0.2714
2023-11-27 17:10:23,269 - mmseg - INFO - Iter [124100/160000]	lr: 1.346e-05, eta: 7:55:48, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1852, decode.acc_seg: 92.2734, aux.loss_ce: 0.0916, aux.acc_seg: 90.9288, loss: 0.2767
2023-11-27 17:11:01,075 - mmseg - INFO - Iter [124150/160000]	lr: 1.344e-05, eta: 7:55:07, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1861, decode.acc_seg: 92.1315, aux.loss_ce: 0.0906, aux.acc_seg: 90.8220, loss: 0.2768
2023-11-27 17:11:40,098 - mmseg - INFO - Iter [124200/160000]	lr: 1.343e-05, eta: 7:54:27, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1799, decode.acc_seg: 92.2541, aux.loss_ce: 0.0879, aux.acc_seg: 91.0044, loss: 0.2678
2023-11-27 17:12:20,350 - mmseg - INFO - Iter [124250/160000]	lr: 1.341e-05, eta: 7:53:48, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1923, decode.acc_seg: 92.1014, aux.loss_ce: 0.0920, aux.acc_seg: 91.0128, loss: 0.2843
2023-11-27 17:12:58,351 - mmseg - INFO - Iter [124300/160000]	lr: 1.339e-05, eta: 7:53:07, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.4892, aux.loss_ce: 0.0881, aux.acc_seg: 91.3184, loss: 0.2693
2023-11-27 17:13:37,156 - mmseg - INFO - Iter [124350/160000]	lr: 1.337e-05, eta: 7:52:27, time: 0.775, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1826, decode.acc_seg: 92.2408, aux.loss_ce: 0.0899, aux.acc_seg: 90.8459, loss: 0.2725
2023-11-27 17:14:16,338 - mmseg - INFO - Iter [124400/160000]	lr: 1.335e-05, eta: 7:51:47, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1816, decode.acc_seg: 92.2930, aux.loss_ce: 0.0893, aux.acc_seg: 90.9320, loss: 0.2709
2023-11-27 17:14:57,603 - mmseg - INFO - Iter [124450/160000]	lr: 1.333e-05, eta: 7:51:08, time: 0.825, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.7842, aux.loss_ce: 0.0838, aux.acc_seg: 91.4527, loss: 0.2545
2023-11-27 17:15:38,185 - mmseg - INFO - Iter [124500/160000]	lr: 1.331e-05, eta: 7:50:29, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1801, decode.acc_seg: 92.1147, aux.loss_ce: 0.0878, aux.acc_seg: 90.7478, loss: 0.2679
2023-11-27 17:16:18,865 - mmseg - INFO - Iter [124550/160000]	lr: 1.329e-05, eta: 7:49:49, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1837, decode.acc_seg: 92.2717, aux.loss_ce: 0.0902, aux.acc_seg: 91.0017, loss: 0.2739
2023-11-27 17:16:59,491 - mmseg - INFO - Iter [124600/160000]	lr: 1.328e-05, eta: 7:49:10, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1873, decode.acc_seg: 92.1394, aux.loss_ce: 0.0913, aux.acc_seg: 90.7416, loss: 0.2786
2023-11-27 17:17:36,929 - mmseg - INFO - Iter [124650/160000]	lr: 1.326e-05, eta: 7:48:29, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1809, decode.acc_seg: 92.3644, aux.loss_ce: 0.0881, aux.acc_seg: 91.0416, loss: 0.2689
2023-11-27 17:18:14,692 - mmseg - INFO - Iter [124700/160000]	lr: 1.324e-05, eta: 7:47:49, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1805, decode.acc_seg: 92.3113, aux.loss_ce: 0.0888, aux.acc_seg: 90.9429, loss: 0.2693
2023-11-27 17:18:55,191 - mmseg - INFO - Iter [124750/160000]	lr: 1.322e-05, eta: 7:47:09, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.6870, aux.loss_ce: 0.0817, aux.acc_seg: 91.5317, loss: 0.2512
2023-11-27 17:19:35,852 - mmseg - INFO - Iter [124800/160000]	lr: 1.320e-05, eta: 7:46:30, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1790, decode.acc_seg: 92.2547, aux.loss_ce: 0.0868, aux.acc_seg: 91.0443, loss: 0.2658
2023-11-27 17:20:13,314 - mmseg - INFO - Iter [124850/160000]	lr: 1.318e-05, eta: 7:45:49, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1689, decode.acc_seg: 92.7951, aux.loss_ce: 0.0821, aux.acc_seg: 91.6073, loss: 0.2510
2023-11-27 17:20:53,539 - mmseg - INFO - Iter [124900/160000]	lr: 1.316e-05, eta: 7:45:10, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1770, decode.acc_seg: 92.3698, aux.loss_ce: 0.0861, aux.acc_seg: 91.1295, loss: 0.2631
2023-11-27 17:21:32,808 - mmseg - INFO - Iter [124950/160000]	lr: 1.314e-05, eta: 7:44:30, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1726, decode.acc_seg: 92.4634, aux.loss_ce: 0.0848, aux.acc_seg: 91.1486, loss: 0.2574
2023-11-27 17:22:09,711 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 17:22:09,711 - mmseg - INFO - Iter [125000/160000]	lr: 1.313e-05, eta: 7:43:49, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1900, decode.acc_seg: 91.8877, aux.loss_ce: 0.0920, aux.acc_seg: 90.5375, loss: 0.2820
2023-11-27 17:22:49,692 - mmseg - INFO - Iter [125050/160000]	lr: 1.311e-05, eta: 7:43:10, time: 0.800, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1866, decode.acc_seg: 92.0479, aux.loss_ce: 0.0911, aux.acc_seg: 90.6267, loss: 0.2778
2023-11-27 17:23:29,894 - mmseg - INFO - Iter [125100/160000]	lr: 1.309e-05, eta: 7:42:30, time: 0.803, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1818, decode.acc_seg: 91.9747, aux.loss_ce: 0.0889, aux.acc_seg: 90.5908, loss: 0.2707
2023-11-27 17:24:09,093 - mmseg - INFO - Iter [125150/160000]	lr: 1.307e-05, eta: 7:41:50, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1784, decode.acc_seg: 92.3720, aux.loss_ce: 0.0883, aux.acc_seg: 90.9019, loss: 0.2667
2023-11-27 17:24:48,718 - mmseg - INFO - Iter [125200/160000]	lr: 1.305e-05, eta: 7:41:10, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1747, decode.acc_seg: 92.6539, aux.loss_ce: 0.0853, aux.acc_seg: 91.2828, loss: 0.2600
2023-11-27 17:25:29,134 - mmseg - INFO - Iter [125250/160000]	lr: 1.303e-05, eta: 7:40:31, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1820, decode.acc_seg: 92.2507, aux.loss_ce: 0.0905, aux.acc_seg: 90.8683, loss: 0.2726
2023-11-27 17:26:09,100 - mmseg - INFO - Iter [125300/160000]	lr: 1.301e-05, eta: 7:39:51, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1709, decode.acc_seg: 92.5912, aux.loss_ce: 0.0836, aux.acc_seg: 91.3644, loss: 0.2545
2023-11-27 17:26:49,111 - mmseg - INFO - Iter [125350/160000]	lr: 1.299e-05, eta: 7:39:11, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1918, decode.acc_seg: 91.8225, aux.loss_ce: 0.0929, aux.acc_seg: 90.5483, loss: 0.2846
2023-11-27 17:27:28,554 - mmseg - INFO - Iter [125400/160000]	lr: 1.298e-05, eta: 7:38:31, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1807, decode.acc_seg: 92.4770, aux.loss_ce: 0.0885, aux.acc_seg: 91.1647, loss: 0.2693
2023-11-27 17:28:08,683 - mmseg - INFO - Iter [125450/160000]	lr: 1.296e-05, eta: 7:37:52, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.3783, aux.loss_ce: 0.0881, aux.acc_seg: 91.1306, loss: 0.2693
2023-11-27 17:28:48,719 - mmseg - INFO - Iter [125500/160000]	lr: 1.294e-05, eta: 7:37:12, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1731, decode.acc_seg: 92.6339, aux.loss_ce: 0.0842, aux.acc_seg: 91.3750, loss: 0.2573
2023-11-27 17:29:28,008 - mmseg - INFO - Iter [125550/160000]	lr: 1.292e-05, eta: 7:36:32, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1763, decode.acc_seg: 92.4860, aux.loss_ce: 0.0875, aux.acc_seg: 91.0309, loss: 0.2637
2023-11-27 17:30:06,769 - mmseg - INFO - Iter [125600/160000]	lr: 1.290e-05, eta: 7:35:52, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1815, decode.acc_seg: 92.4198, aux.loss_ce: 0.0895, aux.acc_seg: 90.9738, loss: 0.2710
2023-11-27 17:30:46,773 - mmseg - INFO - Iter [125650/160000]	lr: 1.288e-05, eta: 7:35:12, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1726, decode.acc_seg: 92.4717, aux.loss_ce: 0.0837, aux.acc_seg: 91.2580, loss: 0.2563
2023-11-27 17:31:26,612 - mmseg - INFO - Iter [125700/160000]	lr: 1.286e-05, eta: 7:34:33, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1780, decode.acc_seg: 92.4036, aux.loss_ce: 0.0876, aux.acc_seg: 91.0074, loss: 0.2655
2023-11-27 17:32:05,059 - mmseg - INFO - Iter [125750/160000]	lr: 1.284e-05, eta: 7:33:53, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.2941, aux.loss_ce: 0.0880, aux.acc_seg: 90.9574, loss: 0.2663
2023-11-27 17:32:43,907 - mmseg - INFO - Iter [125800/160000]	lr: 1.283e-05, eta: 7:33:13, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1813, decode.acc_seg: 92.2748, aux.loss_ce: 0.0875, aux.acc_seg: 90.9633, loss: 0.2687
2023-11-27 17:33:24,347 - mmseg - INFO - Iter [125850/160000]	lr: 1.281e-05, eta: 7:32:33, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1790, decode.acc_seg: 92.4159, aux.loss_ce: 0.0881, aux.acc_seg: 91.1235, loss: 0.2670
2023-11-27 17:34:02,291 - mmseg - INFO - Iter [125900/160000]	lr: 1.279e-05, eta: 7:31:53, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.4792, aux.loss_ce: 0.0845, aux.acc_seg: 91.3159, loss: 0.2584
2023-11-27 17:34:42,679 - mmseg - INFO - Iter [125950/160000]	lr: 1.277e-05, eta: 7:31:13, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1807, decode.acc_seg: 92.1217, aux.loss_ce: 0.0882, aux.acc_seg: 90.8755, loss: 0.2689
2023-11-27 17:35:23,178 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 17:35:23,178 - mmseg - INFO - Iter [126000/160000]	lr: 1.275e-05, eta: 7:30:34, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1764, decode.acc_seg: 92.4392, aux.loss_ce: 0.0869, aux.acc_seg: 91.0756, loss: 0.2633
2023-11-27 17:36:03,127 - mmseg - INFO - Iter [126050/160000]	lr: 1.273e-05, eta: 7:29:54, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1863, decode.acc_seg: 92.2541, aux.loss_ce: 0.0926, aux.acc_seg: 90.8014, loss: 0.2789
2023-11-27 17:36:43,608 - mmseg - INFO - Iter [126100/160000]	lr: 1.271e-05, eta: 7:29:14, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1748, decode.acc_seg: 92.2509, aux.loss_ce: 0.0866, aux.acc_seg: 90.8684, loss: 0.2614
2023-11-27 17:37:24,291 - mmseg - INFO - Iter [126150/160000]	lr: 1.269e-05, eta: 7:28:35, time: 0.814, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1730, decode.acc_seg: 92.4221, aux.loss_ce: 0.0851, aux.acc_seg: 91.0280, loss: 0.2580
2023-11-27 17:38:03,133 - mmseg - INFO - Iter [126200/160000]	lr: 1.268e-05, eta: 7:27:55, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1899, decode.acc_seg: 92.0125, aux.loss_ce: 0.0937, aux.acc_seg: 90.6503, loss: 0.2836
2023-11-27 17:38:42,593 - mmseg - INFO - Iter [126250/160000]	lr: 1.266e-05, eta: 7:27:15, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1736, decode.acc_seg: 92.5045, aux.loss_ce: 0.0845, aux.acc_seg: 91.2160, loss: 0.2581
2023-11-27 17:39:22,112 - mmseg - INFO - Iter [126300/160000]	lr: 1.264e-05, eta: 7:26:35, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.5421, aux.loss_ce: 0.0849, aux.acc_seg: 91.3012, loss: 0.2609
2023-11-27 17:40:02,390 - mmseg - INFO - Iter [126350/160000]	lr: 1.262e-05, eta: 7:25:56, time: 0.804, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1741, decode.acc_seg: 92.5470, aux.loss_ce: 0.0877, aux.acc_seg: 91.1105, loss: 0.2618
2023-11-27 17:40:43,044 - mmseg - INFO - Iter [126400/160000]	lr: 1.260e-05, eta: 7:25:16, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1860, decode.acc_seg: 92.1441, aux.loss_ce: 0.0906, aux.acc_seg: 90.7438, loss: 0.2765
2023-11-27 17:41:21,687 - mmseg - INFO - Iter [126450/160000]	lr: 1.258e-05, eta: 7:24:36, time: 0.772, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1845, decode.acc_seg: 92.1261, aux.loss_ce: 0.0907, aux.acc_seg: 90.6983, loss: 0.2751
2023-11-27 17:42:01,695 - mmseg - INFO - Iter [126500/160000]	lr: 1.256e-05, eta: 7:23:56, time: 0.800, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1818, decode.acc_seg: 92.2427, aux.loss_ce: 0.0883, aux.acc_seg: 90.9375, loss: 0.2701
2023-11-27 17:42:41,922 - mmseg - INFO - Iter [126550/160000]	lr: 1.254e-05, eta: 7:23:17, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1725, decode.acc_seg: 92.6485, aux.loss_ce: 0.0849, aux.acc_seg: 91.3512, loss: 0.2575
2023-11-27 17:43:21,409 - mmseg - INFO - Iter [126600/160000]	lr: 1.253e-05, eta: 7:22:37, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1887, decode.acc_seg: 92.1526, aux.loss_ce: 0.0913, aux.acc_seg: 90.8957, loss: 0.2800
2023-11-27 17:43:59,471 - mmseg - INFO - Iter [126650/160000]	lr: 1.251e-05, eta: 7:21:57, time: 0.760, data_time: 0.009, memory: 21695, decode.loss_ce: 0.1860, decode.acc_seg: 92.2505, aux.loss_ce: 0.0895, aux.acc_seg: 91.0083, loss: 0.2755
2023-11-27 17:44:40,366 - mmseg - INFO - Iter [126700/160000]	lr: 1.249e-05, eta: 7:21:17, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1782, decode.acc_seg: 92.3963, aux.loss_ce: 0.0869, aux.acc_seg: 91.1099, loss: 0.2651
2023-11-27 17:45:21,162 - mmseg - INFO - Iter [126750/160000]	lr: 1.247e-05, eta: 7:20:38, time: 0.816, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1823, decode.acc_seg: 92.3350, aux.loss_ce: 0.0895, aux.acc_seg: 90.8236, loss: 0.2718
2023-11-27 17:46:01,143 - mmseg - INFO - Iter [126800/160000]	lr: 1.245e-05, eta: 7:19:58, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1808, decode.acc_seg: 92.2852, aux.loss_ce: 0.0894, aux.acc_seg: 90.8684, loss: 0.2702
2023-11-27 17:46:38,115 - mmseg - INFO - Iter [126850/160000]	lr: 1.243e-05, eta: 7:19:18, time: 0.739, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1916, decode.acc_seg: 91.7377, aux.loss_ce: 0.0931, aux.acc_seg: 90.3518, loss: 0.2847
2023-11-27 17:47:16,613 - mmseg - INFO - Iter [126900/160000]	lr: 1.241e-05, eta: 7:18:37, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1756, decode.acc_seg: 92.5691, aux.loss_ce: 0.0893, aux.acc_seg: 91.1365, loss: 0.2649
2023-11-27 17:47:56,760 - mmseg - INFO - Iter [126950/160000]	lr: 1.239e-05, eta: 7:17:58, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1765, decode.acc_seg: 92.3181, aux.loss_ce: 0.0869, aux.acc_seg: 90.9358, loss: 0.2634
2023-11-27 17:48:36,657 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 17:48:36,657 - mmseg - INFO - Iter [127000/160000]	lr: 1.238e-05, eta: 7:17:18, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.8021, aux.loss_ce: 0.0829, aux.acc_seg: 91.5033, loss: 0.2536
2023-11-27 17:49:15,367 - mmseg - INFO - Iter [127050/160000]	lr: 1.236e-05, eta: 7:16:38, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1904, decode.acc_seg: 91.7859, aux.loss_ce: 0.0915, aux.acc_seg: 90.4869, loss: 0.2819
2023-11-27 17:49:55,206 - mmseg - INFO - Iter [127100/160000]	lr: 1.234e-05, eta: 7:15:58, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1735, decode.acc_seg: 92.5973, aux.loss_ce: 0.0844, aux.acc_seg: 91.3834, loss: 0.2580
2023-11-27 17:50:32,254 - mmseg - INFO - Iter [127150/160000]	lr: 1.232e-05, eta: 7:15:18, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1837, decode.acc_seg: 92.3994, aux.loss_ce: 0.0903, aux.acc_seg: 90.9853, loss: 0.2740
2023-11-27 17:51:10,663 - mmseg - INFO - Iter [127200/160000]	lr: 1.230e-05, eta: 7:14:38, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1772, decode.acc_seg: 92.3450, aux.loss_ce: 0.0854, aux.acc_seg: 91.1765, loss: 0.2626
2023-11-27 17:51:47,299 - mmseg - INFO - Iter [127250/160000]	lr: 1.228e-05, eta: 7:13:57, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1754, decode.acc_seg: 92.5040, aux.loss_ce: 0.0856, aux.acc_seg: 91.2290, loss: 0.2611
2023-11-27 17:52:25,670 - mmseg - INFO - Iter [127300/160000]	lr: 1.226e-05, eta: 7:13:17, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1740, decode.acc_seg: 92.4047, aux.loss_ce: 0.0851, aux.acc_seg: 91.1010, loss: 0.2591
2023-11-27 17:53:04,217 - mmseg - INFO - Iter [127350/160000]	lr: 1.224e-05, eta: 7:12:37, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1884, decode.acc_seg: 92.0248, aux.loss_ce: 0.0906, aux.acc_seg: 90.6277, loss: 0.2791
2023-11-27 17:53:44,382 - mmseg - INFO - Iter [127400/160000]	lr: 1.223e-05, eta: 7:11:57, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1810, decode.acc_seg: 92.3297, aux.loss_ce: 0.0880, aux.acc_seg: 90.9138, loss: 0.2690
2023-11-27 17:54:24,407 - mmseg - INFO - Iter [127450/160000]	lr: 1.221e-05, eta: 7:11:18, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1806, decode.acc_seg: 92.3768, aux.loss_ce: 0.0885, aux.acc_seg: 91.0050, loss: 0.2692
2023-11-27 17:55:04,621 - mmseg - INFO - Iter [127500/160000]	lr: 1.219e-05, eta: 7:10:38, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1685, decode.acc_seg: 92.6096, aux.loss_ce: 0.0838, aux.acc_seg: 91.2809, loss: 0.2523
2023-11-27 17:55:45,460 - mmseg - INFO - Iter [127550/160000]	lr: 1.217e-05, eta: 7:09:59, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1678, decode.acc_seg: 92.8541, aux.loss_ce: 0.0814, aux.acc_seg: 91.6364, loss: 0.2492
2023-11-27 17:56:26,345 - mmseg - INFO - Iter [127600/160000]	lr: 1.215e-05, eta: 7:09:19, time: 0.818, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1882, decode.acc_seg: 92.0508, aux.loss_ce: 0.0918, aux.acc_seg: 90.7271, loss: 0.2800
2023-11-27 17:57:06,221 - mmseg - INFO - Iter [127650/160000]	lr: 1.213e-05, eta: 7:08:39, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1837, decode.acc_seg: 92.2132, aux.loss_ce: 0.0901, aux.acc_seg: 90.9707, loss: 0.2738
2023-11-27 17:57:44,313 - mmseg - INFO - Iter [127700/160000]	lr: 1.211e-05, eta: 7:07:59, time: 0.762, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1750, decode.acc_seg: 92.5910, aux.loss_ce: 0.0852, aux.acc_seg: 91.3630, loss: 0.2602
2023-11-27 17:58:23,788 - mmseg - INFO - Iter [127750/160000]	lr: 1.209e-05, eta: 7:07:19, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1733, decode.acc_seg: 92.5548, aux.loss_ce: 0.0869, aux.acc_seg: 91.1785, loss: 0.2602
2023-11-27 17:59:03,141 - mmseg - INFO - Iter [127800/160000]	lr: 1.208e-05, eta: 7:06:40, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.4884, aux.loss_ce: 0.0865, aux.acc_seg: 91.1215, loss: 0.2605
2023-11-27 17:59:42,893 - mmseg - INFO - Iter [127850/160000]	lr: 1.206e-05, eta: 7:06:00, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1807, decode.acc_seg: 92.1850, aux.loss_ce: 0.0884, aux.acc_seg: 90.7955, loss: 0.2691
2023-11-27 18:00:19,765 - mmseg - INFO - Iter [127900/160000]	lr: 1.204e-05, eta: 7:05:19, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1685, decode.acc_seg: 92.8344, aux.loss_ce: 0.0839, aux.acc_seg: 91.4437, loss: 0.2525
2023-11-27 18:00:59,718 - mmseg - INFO - Iter [127950/160000]	lr: 1.202e-05, eta: 7:04:40, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1865, decode.acc_seg: 92.0314, aux.loss_ce: 0.0913, aux.acc_seg: 90.6819, loss: 0.2778
2023-11-27 18:01:38,710 - mmseg - INFO - Saving checkpoint at 128000 iterations
2023-11-27 18:01:44,228 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:01:44,228 - mmseg - INFO - Iter [128000/160000]	lr: 1.200e-05, eta: 7:04:01, time: 0.891, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1810, decode.acc_seg: 92.2383, aux.loss_ce: 0.0889, aux.acc_seg: 90.9186, loss: 0.2699
2023-11-27 18:03:23,474 - mmseg - INFO - per class results:
2023-11-27 18:03:23,489 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 77.83 | 88.66 |
|       building      | 80.21 | 89.49 |
|         sky         | 94.48 | 97.44 |
|        floor        | 82.33 | 90.54 |
|         tree        | 75.19 | 89.09 |
|       ceiling       | 84.71 | 92.92 |
|         road        | 84.54 | 89.83 |
|         bed         | 89.42 | 96.25 |
|      windowpane     | 62.83 | 79.77 |
|        grass        | 65.53 | 83.19 |
|       cabinet       | 63.91 | 76.53 |
|       sidewalk      | 68.52 | 84.56 |
|        person       |  82.5 | 93.05 |
|        earth        |  35.5 | 47.83 |
|         door        | 53.14 | 68.57 |
|        table        |  61.0 | 77.64 |
|       mountain      | 54.17 | 65.02 |
|        plant        |  53.0 | 64.14 |
|       curtain       | 74.71 | 86.45 |
|        chair        | 57.78 | 68.67 |
|         car         | 85.56 | 92.75 |
|        water        | 61.73 | 78.37 |
|       painting      |  73.6 | 90.57 |
|         sofa        | 64.53 | 77.83 |
|        shelf        | 45.29 | 64.07 |
|        house        | 32.61 | 48.41 |
|         sea         | 56.76 | 71.49 |
|        mirror       | 68.93 | 76.81 |
|         rug         | 65.71 | 79.75 |
|        field        | 30.69 | 52.62 |
|       armchair      | 45.63 |  72.2 |
|         seat        | 60.83 | 82.98 |
|        fence        | 47.23 |  59.4 |
|         desk        | 51.22 | 69.96 |
|         rock        | 50.23 | 69.82 |
|       wardrobe      | 50.45 | 66.53 |
|         lamp        | 66.21 | 77.43 |
|       bathtub       | 80.39 | 86.85 |
|       railing       | 37.17 |  53.5 |
|       cushion       | 60.59 | 74.18 |
|         base        | 32.06 | 37.79 |
|         box         | 29.45 | 39.86 |
|        column       | 44.67 |  54.7 |
|      signboard      | 40.28 | 54.66 |
|   chest of drawers  | 47.05 | 59.96 |
|       counter       | 32.34 | 39.15 |
|         sand        | 49.36 | 72.28 |
|         sink        | 73.07 | 80.86 |
|      skyscraper     | 46.49 | 54.75 |
|      fireplace      |  74.8 | 92.53 |
|     refrigerator    | 75.39 | 87.47 |
|      grandstand     |  48.1 | 73.42 |
|         path        | 23.75 | 35.01 |
|        stairs       | 31.78 | 44.49 |
|        runway       |  68.4 | 91.43 |
|         case        |  62.3 | 75.06 |
|      pool table     | 93.16 | 95.96 |
|        pillow       | 59.93 | 68.62 |
|     screen door     | 70.37 | 84.29 |
|       stairway      | 29.46 | 34.76 |
|        river        | 12.69 | 25.81 |
|        bridge       | 72.11 |  81.5 |
|       bookcase      | 41.48 | 62.36 |
|        blind        | 41.04 | 46.43 |
|     coffee table    | 56.46 | 79.94 |
|        toilet       | 80.53 | 91.34 |
|        flower       | 40.02 | 62.17 |
|         book        | 46.16 | 65.41 |
|         hill        |  7.1  | 12.06 |
|        bench        | 46.03 | 52.18 |
|      countertop     | 56.41 | 76.69 |
|        stove        | 74.45 | 83.01 |
|         palm        | 54.26 | 75.71 |
|    kitchen island   | 48.61 | 87.17 |
|       computer      | 67.49 | 78.33 |
|     swivel chair    | 45.45 | 71.28 |
|         boat        | 46.96 | 54.53 |
|         bar         | 45.22 | 64.97 |
|    arcade machine   | 52.26 | 55.18 |
|        hovel        | 46.12 | 71.11 |
|         bus         | 83.09 | 96.69 |
|        towel        |  67.6 | 80.26 |
|        light        | 58.67 | 68.35 |
|        truck        | 41.53 | 51.93 |
|        tower        | 16.78 | 29.17 |
|      chandelier     | 67.07 | 80.95 |
|        awning       | 28.06 | 34.39 |
|     streetlight     | 27.99 | 35.49 |
|        booth        | 48.99 | 51.92 |
| television receiver | 69.47 | 80.22 |
|       airplane      | 54.15 | 66.33 |
|      dirt track     | 13.39 | 27.02 |
|       apparel       |  49.9 | 64.07 |
|         pole        | 27.28 | 39.81 |
|         land        |  3.65 |  5.62 |
|      bannister      | 16.24 | 22.92 |
|      escalator      | 29.97 | 43.11 |
|       ottoman       | 43.17 | 53.66 |
|        bottle       | 35.15 |  55.7 |
|        buffet       | 51.08 | 62.01 |
|        poster       | 32.77 | 43.39 |
|        stage        | 17.99 | 26.26 |
|         van         | 45.64 | 65.11 |
|         ship        | 11.05 | 16.34 |
|       fountain      | 21.33 | 21.71 |
|    conveyer belt    | 72.46 | 91.37 |
|        canopy       | 15.74 | 21.96 |
|        washer       | 72.01 | 77.55 |
|      plaything      | 33.87 | 42.66 |
|    swimming pool    | 66.73 | 91.64 |
|        stool        | 44.19 | 59.91 |
|        barrel       | 47.01 | 68.97 |
|        basket       | 38.76 | 50.02 |
|      waterfall      | 64.09 | 87.09 |
|         tent        | 93.01 | 98.62 |
|         bag         | 14.02 | 16.89 |
|       minibike      | 71.43 | 86.29 |
|        cradle       | 72.49 | 84.02 |
|         oven        | 52.16 | 65.44 |
|         ball        | 41.98 | 52.24 |
|         food        | 52.58 | 57.13 |
|         step        | 20.67 | 24.81 |
|         tank        | 45.38 | 51.94 |
|      trade name     | 25.22 | 28.82 |
|      microwave      | 81.35 | 91.01 |
|         pot         | 44.81 | 50.83 |
|        animal       | 63.06 |  67.4 |
|       bicycle       | 57.69 | 81.03 |
|         lake        | 65.07 | 67.35 |
|      dishwasher     | 65.12 | 75.47 |
|        screen       |  66.3 | 89.26 |
|       blanket       | 12.64 | 14.95 |
|      sculpture      | 60.23 | 75.86 |
|         hood        |  67.2 | 72.99 |
|        sconce       | 48.19 | 58.29 |
|         vase        | 42.17 | 57.13 |
|    traffic light    | 36.37 | 55.61 |
|         tray        | 10.84 | 17.08 |
|        ashcan       | 39.69 | 55.49 |
|         fan         | 63.49 | 75.59 |
|         pier        |  62.7 | 71.98 |
|      crt screen     |  7.34 | 19.34 |
|        plate        | 54.79 | 67.29 |
|       monitor       |  8.79 | 12.69 |
|    bulletin board   |  46.0 | 59.69 |
|        shower       |  8.49 |  8.67 |
|       radiator      | 65.93 | 69.21 |
|        glass        | 14.14 |  14.8 |
|        clock        |  36.4 | 48.22 |
|         flag        | 40.08 | 43.65 |
+---------------------+-------+-------+
2023-11-27 18:03:23,489 - mmseg - INFO - Summary:
2023-11-27 18:03:23,490 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 83.36 | 50.83 | 63.0 |
+-------+-------+------+
2023-11-27 18:03:23,492 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:03:23,493 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8336, mIoU: 0.5083, mAcc: 0.6300, IoU.wall: 0.7783, IoU.building: 0.8021, IoU.sky: 0.9448, IoU.floor: 0.8233, IoU.tree: 0.7519, IoU.ceiling: 0.8471, IoU.road: 0.8454, IoU.bed : 0.8942, IoU.windowpane: 0.6283, IoU.grass: 0.6553, IoU.cabinet: 0.6391, IoU.sidewalk: 0.6852, IoU.person: 0.8250, IoU.earth: 0.3550, IoU.door: 0.5314, IoU.table: 0.6100, IoU.mountain: 0.5417, IoU.plant: 0.5300, IoU.curtain: 0.7471, IoU.chair: 0.5778, IoU.car: 0.8556, IoU.water: 0.6173, IoU.painting: 0.7360, IoU.sofa: 0.6453, IoU.shelf: 0.4529, IoU.house: 0.3261, IoU.sea: 0.5676, IoU.mirror: 0.6893, IoU.rug: 0.6571, IoU.field: 0.3069, IoU.armchair: 0.4563, IoU.seat: 0.6083, IoU.fence: 0.4723, IoU.desk: 0.5122, IoU.rock: 0.5023, IoU.wardrobe: 0.5045, IoU.lamp: 0.6621, IoU.bathtub: 0.8039, IoU.railing: 0.3717, IoU.cushion: 0.6059, IoU.base: 0.3206, IoU.box: 0.2945, IoU.column: 0.4467, IoU.signboard: 0.4028, IoU.chest of drawers: 0.4705, IoU.counter: 0.3234, IoU.sand: 0.4936, IoU.sink: 0.7307, IoU.skyscraper: 0.4649, IoU.fireplace: 0.7480, IoU.refrigerator: 0.7539, IoU.grandstand: 0.4810, IoU.path: 0.2375, IoU.stairs: 0.3178, IoU.runway: 0.6840, IoU.case: 0.6230, IoU.pool table: 0.9316, IoU.pillow: 0.5993, IoU.screen door: 0.7037, IoU.stairway: 0.2946, IoU.river: 0.1269, IoU.bridge: 0.7211, IoU.bookcase: 0.4148, IoU.blind: 0.4104, IoU.coffee table: 0.5646, IoU.toilet: 0.8053, IoU.flower: 0.4002, IoU.book: 0.4616, IoU.hill: 0.0710, IoU.bench: 0.4603, IoU.countertop: 0.5641, IoU.stove: 0.7445, IoU.palm: 0.5426, IoU.kitchen island: 0.4861, IoU.computer: 0.6749, IoU.swivel chair: 0.4545, IoU.boat: 0.4696, IoU.bar: 0.4522, IoU.arcade machine: 0.5226, IoU.hovel: 0.4612, IoU.bus: 0.8309, IoU.towel: 0.6760, IoU.light: 0.5867, IoU.truck: 0.4153, IoU.tower: 0.1678, IoU.chandelier: 0.6707, IoU.awning: 0.2806, IoU.streetlight: 0.2799, IoU.booth: 0.4899, IoU.television receiver: 0.6947, IoU.airplane: 0.5415, IoU.dirt track: 0.1339, IoU.apparel: 0.4990, IoU.pole: 0.2728, IoU.land: 0.0365, IoU.bannister: 0.1624, IoU.escalator: 0.2997, IoU.ottoman: 0.4317, IoU.bottle: 0.3515, IoU.buffet: 0.5108, IoU.poster: 0.3277, IoU.stage: 0.1799, IoU.van: 0.4564, IoU.ship: 0.1105, IoU.fountain: 0.2133, IoU.conveyer belt: 0.7246, IoU.canopy: 0.1574, IoU.washer: 0.7201, IoU.plaything: 0.3387, IoU.swimming pool: 0.6673, IoU.stool: 0.4419, IoU.barrel: 0.4701, IoU.basket: 0.3876, IoU.waterfall: 0.6409, IoU.tent: 0.9301, IoU.bag: 0.1402, IoU.minibike: 0.7143, IoU.cradle: 0.7249, IoU.oven: 0.5216, IoU.ball: 0.4198, IoU.food: 0.5258, IoU.step: 0.2067, IoU.tank: 0.4538, IoU.trade name: 0.2522, IoU.microwave: 0.8135, IoU.pot: 0.4481, IoU.animal: 0.6306, IoU.bicycle: 0.5769, IoU.lake: 0.6507, IoU.dishwasher: 0.6512, IoU.screen: 0.6630, IoU.blanket: 0.1264, IoU.sculpture: 0.6023, IoU.hood: 0.6720, IoU.sconce: 0.4819, IoU.vase: 0.4217, IoU.traffic light: 0.3637, IoU.tray: 0.1084, IoU.ashcan: 0.3969, IoU.fan: 0.6349, IoU.pier: 0.6270, IoU.crt screen: 0.0734, IoU.plate: 0.5479, IoU.monitor: 0.0879, IoU.bulletin board: 0.4600, IoU.shower: 0.0849, IoU.radiator: 0.6593, IoU.glass: 0.1414, IoU.clock: 0.3640, IoU.flag: 0.4008, Acc.wall: 0.8866, Acc.building: 0.8949, Acc.sky: 0.9744, Acc.floor: 0.9054, Acc.tree: 0.8909, Acc.ceiling: 0.9292, Acc.road: 0.8983, Acc.bed : 0.9625, Acc.windowpane: 0.7977, Acc.grass: 0.8319, Acc.cabinet: 0.7653, Acc.sidewalk: 0.8456, Acc.person: 0.9305, Acc.earth: 0.4783, Acc.door: 0.6857, Acc.table: 0.7764, Acc.mountain: 0.6502, Acc.plant: 0.6414, Acc.curtain: 0.8645, Acc.chair: 0.6867, Acc.car: 0.9275, Acc.water: 0.7837, Acc.painting: 0.9057, Acc.sofa: 0.7783, Acc.shelf: 0.6407, Acc.house: 0.4841, Acc.sea: 0.7149, Acc.mirror: 0.7681, Acc.rug: 0.7975, Acc.field: 0.5262, Acc.armchair: 0.7220, Acc.seat: 0.8298, Acc.fence: 0.5940, Acc.desk: 0.6996, Acc.rock: 0.6982, Acc.wardrobe: 0.6653, Acc.lamp: 0.7743, Acc.bathtub: 0.8685, Acc.railing: 0.5350, Acc.cushion: 0.7418, Acc.base: 0.3779, Acc.box: 0.3986, Acc.column: 0.5470, Acc.signboard: 0.5466, Acc.chest of drawers: 0.5996, Acc.counter: 0.3915, Acc.sand: 0.7228, Acc.sink: 0.8086, Acc.skyscraper: 0.5475, Acc.fireplace: 0.9253, Acc.refrigerator: 0.8747, Acc.grandstand: 0.7342, Acc.path: 0.3501, Acc.stairs: 0.4449, Acc.runway: 0.9143, Acc.case: 0.7506, Acc.pool table: 0.9596, Acc.pillow: 0.6862, Acc.screen door: 0.8429, Acc.stairway: 0.3476, Acc.river: 0.2581, Acc.bridge: 0.8150, Acc.bookcase: 0.6236, Acc.blind: 0.4643, Acc.coffee table: 0.7994, Acc.toilet: 0.9134, Acc.flower: 0.6217, Acc.book: 0.6541, Acc.hill: 0.1206, Acc.bench: 0.5218, Acc.countertop: 0.7669, Acc.stove: 0.8301, Acc.palm: 0.7571, Acc.kitchen island: 0.8717, Acc.computer: 0.7833, Acc.swivel chair: 0.7128, Acc.boat: 0.5453, Acc.bar: 0.6497, Acc.arcade machine: 0.5518, Acc.hovel: 0.7111, Acc.bus: 0.9669, Acc.towel: 0.8026, Acc.light: 0.6835, Acc.truck: 0.5193, Acc.tower: 0.2917, Acc.chandelier: 0.8095, Acc.awning: 0.3439, Acc.streetlight: 0.3549, Acc.booth: 0.5192, Acc.television receiver: 0.8022, Acc.airplane: 0.6633, Acc.dirt track: 0.2702, Acc.apparel: 0.6407, Acc.pole: 0.3981, Acc.land: 0.0562, Acc.bannister: 0.2292, Acc.escalator: 0.4311, Acc.ottoman: 0.5366, Acc.bottle: 0.5570, Acc.buffet: 0.6201, Acc.poster: 0.4339, Acc.stage: 0.2626, Acc.van: 0.6511, Acc.ship: 0.1634, Acc.fountain: 0.2171, Acc.conveyer belt: 0.9137, Acc.canopy: 0.2196, Acc.washer: 0.7755, Acc.plaything: 0.4266, Acc.swimming pool: 0.9164, Acc.stool: 0.5991, Acc.barrel: 0.6897, Acc.basket: 0.5002, Acc.waterfall: 0.8709, Acc.tent: 0.9862, Acc.bag: 0.1689, Acc.minibike: 0.8629, Acc.cradle: 0.8402, Acc.oven: 0.6544, Acc.ball: 0.5224, Acc.food: 0.5713, Acc.step: 0.2481, Acc.tank: 0.5194, Acc.trade name: 0.2882, Acc.microwave: 0.9101, Acc.pot: 0.5083, Acc.animal: 0.6740, Acc.bicycle: 0.8103, Acc.lake: 0.6735, Acc.dishwasher: 0.7547, Acc.screen: 0.8926, Acc.blanket: 0.1495, Acc.sculpture: 0.7586, Acc.hood: 0.7299, Acc.sconce: 0.5829, Acc.vase: 0.5713, Acc.traffic light: 0.5561, Acc.tray: 0.1708, Acc.ashcan: 0.5549, Acc.fan: 0.7559, Acc.pier: 0.7198, Acc.crt screen: 0.1934, Acc.plate: 0.6729, Acc.monitor: 0.1269, Acc.bulletin board: 0.5969, Acc.shower: 0.0867, Acc.radiator: 0.6921, Acc.glass: 0.1480, Acc.clock: 0.4822, Acc.flag: 0.4365
2023-11-27 18:04:00,233 - mmseg - INFO - Iter [128050/160000]	lr: 1.198e-05, eta: 7:03:45, time: 2.720, data_time: 1.995, memory: 21695, decode.loss_ce: 0.1844, decode.acc_seg: 92.1330, aux.loss_ce: 0.0910, aux.acc_seg: 90.6231, loss: 0.2753
2023-11-27 18:04:40,535 - mmseg - INFO - Iter [128100/160000]	lr: 1.196e-05, eta: 7:03:06, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1723, decode.acc_seg: 92.4485, aux.loss_ce: 0.0844, aux.acc_seg: 91.0933, loss: 0.2568
2023-11-27 18:05:22,114 - mmseg - INFO - Iter [128150/160000]	lr: 1.194e-05, eta: 7:02:26, time: 0.832, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1787, decode.acc_seg: 92.3544, aux.loss_ce: 0.0893, aux.acc_seg: 90.8902, loss: 0.2680
2023-11-27 18:06:03,389 - mmseg - INFO - Iter [128200/160000]	lr: 1.193e-05, eta: 7:01:47, time: 0.825, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1714, decode.acc_seg: 92.5737, aux.loss_ce: 0.0846, aux.acc_seg: 91.2564, loss: 0.2560
2023-11-27 18:06:43,350 - mmseg - INFO - Iter [128250/160000]	lr: 1.191e-05, eta: 7:01:07, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1665, decode.acc_seg: 92.8984, aux.loss_ce: 0.0813, aux.acc_seg: 91.6276, loss: 0.2478
2023-11-27 18:07:20,284 - mmseg - INFO - Iter [128300/160000]	lr: 1.189e-05, eta: 7:00:27, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.4906, aux.loss_ce: 0.0870, aux.acc_seg: 91.1864, loss: 0.2637
2023-11-27 18:07:59,565 - mmseg - INFO - Iter [128350/160000]	lr: 1.187e-05, eta: 6:59:47, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1724, decode.acc_seg: 92.6272, aux.loss_ce: 0.0847, aux.acc_seg: 91.3434, loss: 0.2571
2023-11-27 18:08:38,770 - mmseg - INFO - Iter [128400/160000]	lr: 1.185e-05, eta: 6:59:07, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1746, decode.acc_seg: 92.6016, aux.loss_ce: 0.0839, aux.acc_seg: 91.3802, loss: 0.2584
2023-11-27 18:09:16,629 - mmseg - INFO - Iter [128450/160000]	lr: 1.183e-05, eta: 6:58:27, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 92.8601, aux.loss_ce: 0.0819, aux.acc_seg: 91.3641, loss: 0.2469
2023-11-27 18:09:56,096 - mmseg - INFO - Iter [128500/160000]	lr: 1.181e-05, eta: 6:57:47, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1762, decode.acc_seg: 92.4212, aux.loss_ce: 0.0845, aux.acc_seg: 91.2105, loss: 0.2607
2023-11-27 18:10:36,582 - mmseg - INFO - Iter [128550/160000]	lr: 1.179e-05, eta: 6:57:07, time: 0.809, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1763, decode.acc_seg: 92.5058, aux.loss_ce: 0.0874, aux.acc_seg: 91.1347, loss: 0.2637
2023-11-27 18:11:15,215 - mmseg - INFO - Iter [128600/160000]	lr: 1.178e-05, eta: 6:56:27, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1844, decode.acc_seg: 92.0904, aux.loss_ce: 0.0906, aux.acc_seg: 90.6966, loss: 0.2750
2023-11-27 18:11:53,471 - mmseg - INFO - Iter [128650/160000]	lr: 1.176e-05, eta: 6:55:47, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.3810, aux.loss_ce: 0.0878, aux.acc_seg: 90.9970, loss: 0.2660
2023-11-27 18:12:33,665 - mmseg - INFO - Iter [128700/160000]	lr: 1.174e-05, eta: 6:55:07, time: 0.804, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 93.0405, aux.loss_ce: 0.0808, aux.acc_seg: 91.7559, loss: 0.2453
2023-11-27 18:13:11,179 - mmseg - INFO - Iter [128750/160000]	lr: 1.172e-05, eta: 6:54:27, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1791, decode.acc_seg: 92.3623, aux.loss_ce: 0.0866, aux.acc_seg: 91.0902, loss: 0.2657
2023-11-27 18:13:48,535 - mmseg - INFO - Iter [128800/160000]	lr: 1.170e-05, eta: 6:53:46, time: 0.748, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1799, decode.acc_seg: 92.4616, aux.loss_ce: 0.0887, aux.acc_seg: 91.1910, loss: 0.2686
2023-11-27 18:14:29,360 - mmseg - INFO - Iter [128850/160000]	lr: 1.168e-05, eta: 6:53:07, time: 0.816, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1795, decode.acc_seg: 92.3568, aux.loss_ce: 0.0898, aux.acc_seg: 90.7898, loss: 0.2693
2023-11-27 18:15:09,037 - mmseg - INFO - Iter [128900/160000]	lr: 1.166e-05, eta: 6:52:27, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1775, decode.acc_seg: 92.4919, aux.loss_ce: 0.0863, aux.acc_seg: 91.1326, loss: 0.2638
2023-11-27 18:15:49,528 - mmseg - INFO - Iter [128950/160000]	lr: 1.164e-05, eta: 6:51:47, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1821, decode.acc_seg: 92.1932, aux.loss_ce: 0.0895, aux.acc_seg: 90.8443, loss: 0.2717
2023-11-27 18:16:29,864 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:16:29,864 - mmseg - INFO - Iter [129000/160000]	lr: 1.163e-05, eta: 6:51:08, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1779, decode.acc_seg: 92.2831, aux.loss_ce: 0.0871, aux.acc_seg: 91.0199, loss: 0.2650
2023-11-27 18:17:09,711 - mmseg - INFO - Iter [129050/160000]	lr: 1.161e-05, eta: 6:50:28, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1734, decode.acc_seg: 92.6380, aux.loss_ce: 0.0853, aux.acc_seg: 91.3346, loss: 0.2587
2023-11-27 18:17:47,893 - mmseg - INFO - Iter [129100/160000]	lr: 1.159e-05, eta: 6:49:48, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1838, decode.acc_seg: 92.2917, aux.loss_ce: 0.0900, aux.acc_seg: 90.8248, loss: 0.2738
2023-11-27 18:18:26,093 - mmseg - INFO - Iter [129150/160000]	lr: 1.157e-05, eta: 6:49:08, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1876, decode.acc_seg: 91.8855, aux.loss_ce: 0.0919, aux.acc_seg: 90.5317, loss: 0.2795
2023-11-27 18:19:05,908 - mmseg - INFO - Iter [129200/160000]	lr: 1.155e-05, eta: 6:48:28, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1782, decode.acc_seg: 92.5492, aux.loss_ce: 0.0876, aux.acc_seg: 91.1598, loss: 0.2659
2023-11-27 18:19:46,512 - mmseg - INFO - Iter [129250/160000]	lr: 1.153e-05, eta: 6:47:48, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1745, decode.acc_seg: 92.7574, aux.loss_ce: 0.0874, aux.acc_seg: 91.2161, loss: 0.2619
2023-11-27 18:20:25,530 - mmseg - INFO - Iter [129300/160000]	lr: 1.151e-05, eta: 6:47:08, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1790, decode.acc_seg: 92.1753, aux.loss_ce: 0.0879, aux.acc_seg: 90.7643, loss: 0.2669
2023-11-27 18:21:03,817 - mmseg - INFO - Iter [129350/160000]	lr: 1.149e-05, eta: 6:46:28, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1666, decode.acc_seg: 92.7556, aux.loss_ce: 0.0824, aux.acc_seg: 91.4503, loss: 0.2490
2023-11-27 18:21:44,242 - mmseg - INFO - Iter [129400/160000]	lr: 1.148e-05, eta: 6:45:49, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1888, decode.acc_seg: 91.8454, aux.loss_ce: 0.0908, aux.acc_seg: 90.5636, loss: 0.2796
2023-11-27 18:22:22,712 - mmseg - INFO - Iter [129450/160000]	lr: 1.146e-05, eta: 6:45:09, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1637, decode.acc_seg: 92.7537, aux.loss_ce: 0.0812, aux.acc_seg: 91.3231, loss: 0.2449
2023-11-27 18:23:01,784 - mmseg - INFO - Iter [129500/160000]	lr: 1.144e-05, eta: 6:44:29, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1809, decode.acc_seg: 92.1538, aux.loss_ce: 0.0891, aux.acc_seg: 90.7106, loss: 0.2701
2023-11-27 18:23:39,157 - mmseg - INFO - Iter [129550/160000]	lr: 1.142e-05, eta: 6:43:48, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1870, decode.acc_seg: 92.1938, aux.loss_ce: 0.0904, aux.acc_seg: 90.9305, loss: 0.2774
2023-11-27 18:24:17,749 - mmseg - INFO - Iter [129600/160000]	lr: 1.140e-05, eta: 6:43:08, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.3079, aux.loss_ce: 0.0874, aux.acc_seg: 91.1145, loss: 0.2657
2023-11-27 18:24:58,914 - mmseg - INFO - Iter [129650/160000]	lr: 1.138e-05, eta: 6:42:29, time: 0.824, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1873, decode.acc_seg: 91.9289, aux.loss_ce: 0.0900, aux.acc_seg: 90.5364, loss: 0.2773
2023-11-27 18:25:37,848 - mmseg - INFO - Iter [129700/160000]	lr: 1.136e-05, eta: 6:41:49, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1804, decode.acc_seg: 92.4346, aux.loss_ce: 0.0880, aux.acc_seg: 91.0986, loss: 0.2684
2023-11-27 18:26:18,420 - mmseg - INFO - Iter [129750/160000]	lr: 1.134e-05, eta: 6:41:09, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1822, decode.acc_seg: 92.2791, aux.loss_ce: 0.0877, aux.acc_seg: 91.1897, loss: 0.2699
2023-11-27 18:26:57,100 - mmseg - INFO - Iter [129800/160000]	lr: 1.133e-05, eta: 6:40:29, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1747, decode.acc_seg: 92.3387, aux.loss_ce: 0.0863, aux.acc_seg: 90.8683, loss: 0.2610
2023-11-27 18:27:35,673 - mmseg - INFO - Iter [129850/160000]	lr: 1.131e-05, eta: 6:39:49, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1776, decode.acc_seg: 92.4626, aux.loss_ce: 0.0854, aux.acc_seg: 91.2510, loss: 0.2629
2023-11-27 18:28:13,914 - mmseg - INFO - Iter [129900/160000]	lr: 1.129e-05, eta: 6:39:09, time: 0.764, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1747, decode.acc_seg: 92.4620, aux.loss_ce: 0.0868, aux.acc_seg: 90.9315, loss: 0.2614
2023-11-27 18:28:54,209 - mmseg - INFO - Iter [129950/160000]	lr: 1.127e-05, eta: 6:38:29, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1778, decode.acc_seg: 92.1824, aux.loss_ce: 0.0876, aux.acc_seg: 90.8523, loss: 0.2654
2023-11-27 18:29:33,680 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:29:33,681 - mmseg - INFO - Iter [130000/160000]	lr: 1.125e-05, eta: 6:37:49, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1755, decode.acc_seg: 92.5421, aux.loss_ce: 0.0860, aux.acc_seg: 91.2800, loss: 0.2616
2023-11-27 18:30:13,955 - mmseg - INFO - Iter [130050/160000]	lr: 1.123e-05, eta: 6:37:10, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1796, decode.acc_seg: 92.2742, aux.loss_ce: 0.0894, aux.acc_seg: 90.8482, loss: 0.2690
2023-11-27 18:30:55,860 - mmseg - INFO - Iter [130100/160000]	lr: 1.121e-05, eta: 6:36:30, time: 0.838, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1798, decode.acc_seg: 92.2195, aux.loss_ce: 0.0880, aux.acc_seg: 90.9397, loss: 0.2678
2023-11-27 18:31:35,226 - mmseg - INFO - Iter [130150/160000]	lr: 1.119e-05, eta: 6:35:50, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1858, decode.acc_seg: 92.0779, aux.loss_ce: 0.0901, aux.acc_seg: 90.8299, loss: 0.2759
2023-11-27 18:32:15,579 - mmseg - INFO - Iter [130200/160000]	lr: 1.118e-05, eta: 6:35:11, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1762, decode.acc_seg: 92.3478, aux.loss_ce: 0.0873, aux.acc_seg: 90.9411, loss: 0.2634
2023-11-27 18:32:55,708 - mmseg - INFO - Iter [130250/160000]	lr: 1.116e-05, eta: 6:34:31, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1785, decode.acc_seg: 92.2400, aux.loss_ce: 0.0881, aux.acc_seg: 90.9163, loss: 0.2666
2023-11-27 18:33:34,621 - mmseg - INFO - Iter [130300/160000]	lr: 1.114e-05, eta: 6:33:51, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1776, decode.acc_seg: 92.3901, aux.loss_ce: 0.0869, aux.acc_seg: 91.0461, loss: 0.2645
2023-11-27 18:34:11,531 - mmseg - INFO - Iter [130350/160000]	lr: 1.112e-05, eta: 6:33:11, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1724, decode.acc_seg: 92.6287, aux.loss_ce: 0.0855, aux.acc_seg: 91.2790, loss: 0.2579
2023-11-27 18:34:48,677 - mmseg - INFO - Iter [130400/160000]	lr: 1.110e-05, eta: 6:32:30, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1859, decode.acc_seg: 92.3437, aux.loss_ce: 0.0884, aux.acc_seg: 91.1255, loss: 0.2743
2023-11-27 18:35:28,032 - mmseg - INFO - Iter [130450/160000]	lr: 1.108e-05, eta: 6:31:50, time: 0.787, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.7437, aux.loss_ce: 0.0845, aux.acc_seg: 91.3293, loss: 0.2533
2023-11-27 18:36:08,380 - mmseg - INFO - Iter [130500/160000]	lr: 1.106e-05, eta: 6:31:11, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1818, decode.acc_seg: 92.3921, aux.loss_ce: 0.0891, aux.acc_seg: 91.0970, loss: 0.2709
2023-11-27 18:36:48,156 - mmseg - INFO - Iter [130550/160000]	lr: 1.104e-05, eta: 6:30:31, time: 0.796, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1761, decode.acc_seg: 92.5754, aux.loss_ce: 0.0854, aux.acc_seg: 91.3426, loss: 0.2615
2023-11-27 18:37:25,125 - mmseg - INFO - Iter [130600/160000]	lr: 1.103e-05, eta: 6:29:51, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1789, decode.acc_seg: 92.1957, aux.loss_ce: 0.0866, aux.acc_seg: 91.0082, loss: 0.2655
2023-11-27 18:38:01,764 - mmseg - INFO - Iter [130650/160000]	lr: 1.101e-05, eta: 6:29:10, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1937, decode.acc_seg: 91.7626, aux.loss_ce: 0.0942, aux.acc_seg: 90.4053, loss: 0.2878
2023-11-27 18:38:40,253 - mmseg - INFO - Iter [130700/160000]	lr: 1.099e-05, eta: 6:28:30, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1737, decode.acc_seg: 92.5371, aux.loss_ce: 0.0852, aux.acc_seg: 91.2268, loss: 0.2589
2023-11-27 18:39:17,845 - mmseg - INFO - Iter [130750/160000]	lr: 1.097e-05, eta: 6:27:50, time: 0.751, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1711, decode.acc_seg: 92.6464, aux.loss_ce: 0.0850, aux.acc_seg: 91.3359, loss: 0.2561
2023-11-27 18:39:56,722 - mmseg - INFO - Iter [130800/160000]	lr: 1.095e-05, eta: 6:27:10, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1835, decode.acc_seg: 92.2745, aux.loss_ce: 0.0907, aux.acc_seg: 90.9337, loss: 0.2742
2023-11-27 18:40:34,424 - mmseg - INFO - Iter [130850/160000]	lr: 1.093e-05, eta: 6:26:30, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1768, decode.acc_seg: 92.3728, aux.loss_ce: 0.0888, aux.acc_seg: 90.9266, loss: 0.2656
2023-11-27 18:41:11,874 - mmseg - INFO - Iter [130900/160000]	lr: 1.091e-05, eta: 6:25:49, time: 0.748, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1861, decode.acc_seg: 92.0352, aux.loss_ce: 0.0903, aux.acc_seg: 90.8395, loss: 0.2764
2023-11-27 18:41:52,082 - mmseg - INFO - Iter [130950/160000]	lr: 1.089e-05, eta: 6:25:10, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.6641, aux.loss_ce: 0.0845, aux.acc_seg: 91.4326, loss: 0.2584
2023-11-27 18:42:32,565 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:42:32,565 - mmseg - INFO - Iter [131000/160000]	lr: 1.088e-05, eta: 6:24:30, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.7534, aux.loss_ce: 0.0839, aux.acc_seg: 91.3882, loss: 0.2546
2023-11-27 18:43:12,588 - mmseg - INFO - Iter [131050/160000]	lr: 1.086e-05, eta: 6:23:50, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1758, decode.acc_seg: 92.6013, aux.loss_ce: 0.0843, aux.acc_seg: 91.4158, loss: 0.2601
2023-11-27 18:43:52,461 - mmseg - INFO - Iter [131100/160000]	lr: 1.084e-05, eta: 6:23:10, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1737, decode.acc_seg: 92.6139, aux.loss_ce: 0.0859, aux.acc_seg: 91.2528, loss: 0.2597
2023-11-27 18:44:31,694 - mmseg - INFO - Iter [131150/160000]	lr: 1.082e-05, eta: 6:22:31, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1755, decode.acc_seg: 92.5735, aux.loss_ce: 0.0872, aux.acc_seg: 91.1309, loss: 0.2627
2023-11-27 18:45:11,271 - mmseg - INFO - Iter [131200/160000]	lr: 1.080e-05, eta: 6:21:51, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1765, decode.acc_seg: 92.6071, aux.loss_ce: 0.0848, aux.acc_seg: 91.4481, loss: 0.2613
2023-11-27 18:45:50,063 - mmseg - INFO - Iter [131250/160000]	lr: 1.078e-05, eta: 6:21:11, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1763, decode.acc_seg: 91.9649, aux.loss_ce: 0.0878, aux.acc_seg: 90.4264, loss: 0.2641
2023-11-27 18:46:31,047 - mmseg - INFO - Iter [131300/160000]	lr: 1.076e-05, eta: 6:20:31, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1821, decode.acc_seg: 92.2814, aux.loss_ce: 0.0895, aux.acc_seg: 90.9530, loss: 0.2716
2023-11-27 18:47:10,602 - mmseg - INFO - Iter [131350/160000]	lr: 1.074e-05, eta: 6:19:51, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.3706, aux.loss_ce: 0.0874, aux.acc_seg: 90.9233, loss: 0.2634
2023-11-27 18:47:51,735 - mmseg - INFO - Iter [131400/160000]	lr: 1.073e-05, eta: 6:19:12, time: 0.823, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1806, decode.acc_seg: 92.4341, aux.loss_ce: 0.0894, aux.acc_seg: 90.9305, loss: 0.2700
2023-11-27 18:48:30,720 - mmseg - INFO - Iter [131450/160000]	lr: 1.071e-05, eta: 6:18:32, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1665, decode.acc_seg: 92.7507, aux.loss_ce: 0.0808, aux.acc_seg: 91.5126, loss: 0.2473
2023-11-27 18:49:10,946 - mmseg - INFO - Iter [131500/160000]	lr: 1.069e-05, eta: 6:17:52, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1744, decode.acc_seg: 92.5291, aux.loss_ce: 0.0856, aux.acc_seg: 91.2572, loss: 0.2600
2023-11-27 18:49:50,338 - mmseg - INFO - Iter [131550/160000]	lr: 1.067e-05, eta: 6:17:12, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1747, decode.acc_seg: 92.8773, aux.loss_ce: 0.0858, aux.acc_seg: 91.5445, loss: 0.2604
2023-11-27 18:50:30,274 - mmseg - INFO - Iter [131600/160000]	lr: 1.065e-05, eta: 6:16:33, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1803, decode.acc_seg: 92.4274, aux.loss_ce: 0.0897, aux.acc_seg: 91.0144, loss: 0.2699
2023-11-27 18:51:09,352 - mmseg - INFO - Iter [131650/160000]	lr: 1.063e-05, eta: 6:15:53, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1806, decode.acc_seg: 92.4334, aux.loss_ce: 0.0883, aux.acc_seg: 91.0573, loss: 0.2689
2023-11-27 18:51:49,586 - mmseg - INFO - Iter [131700/160000]	lr: 1.061e-05, eta: 6:15:13, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1750, decode.acc_seg: 92.3742, aux.loss_ce: 0.0858, aux.acc_seg: 90.9906, loss: 0.2609
2023-11-27 18:52:26,380 - mmseg - INFO - Iter [131750/160000]	lr: 1.059e-05, eta: 6:14:33, time: 0.735, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1794, decode.acc_seg: 92.3615, aux.loss_ce: 0.0883, aux.acc_seg: 90.8971, loss: 0.2678
2023-11-27 18:53:07,371 - mmseg - INFO - Iter [131800/160000]	lr: 1.058e-05, eta: 6:13:53, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1819, decode.acc_seg: 92.1598, aux.loss_ce: 0.0879, aux.acc_seg: 90.8355, loss: 0.2697
2023-11-27 18:53:48,215 - mmseg - INFO - Iter [131850/160000]	lr: 1.056e-05, eta: 6:13:14, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1742, decode.acc_seg: 92.7272, aux.loss_ce: 0.0866, aux.acc_seg: 91.3337, loss: 0.2608
2023-11-27 18:54:27,435 - mmseg - INFO - Iter [131900/160000]	lr: 1.054e-05, eta: 6:12:34, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1764, decode.acc_seg: 92.5113, aux.loss_ce: 0.0856, aux.acc_seg: 91.1418, loss: 0.2620
2023-11-27 18:55:06,894 - mmseg - INFO - Iter [131950/160000]	lr: 1.052e-05, eta: 6:11:54, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1712, decode.acc_seg: 92.5990, aux.loss_ce: 0.0835, aux.acc_seg: 91.3193, loss: 0.2547
2023-11-27 18:55:46,767 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 18:55:46,767 - mmseg - INFO - Iter [132000/160000]	lr: 1.050e-05, eta: 6:11:14, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1717, decode.acc_seg: 92.5881, aux.loss_ce: 0.0850, aux.acc_seg: 91.1455, loss: 0.2567
2023-11-27 18:56:25,682 - mmseg - INFO - Iter [132050/160000]	lr: 1.048e-05, eta: 6:10:34, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1784, decode.acc_seg: 92.5621, aux.loss_ce: 0.0864, aux.acc_seg: 91.3230, loss: 0.2648
2023-11-27 18:57:05,680 - mmseg - INFO - Iter [132100/160000]	lr: 1.046e-05, eta: 6:09:54, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1824, decode.acc_seg: 92.0908, aux.loss_ce: 0.0888, aux.acc_seg: 90.7479, loss: 0.2712
2023-11-27 18:57:45,896 - mmseg - INFO - Iter [132150/160000]	lr: 1.044e-05, eta: 6:09:15, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1841, decode.acc_seg: 92.2244, aux.loss_ce: 0.0896, aux.acc_seg: 90.9166, loss: 0.2737
2023-11-27 18:58:23,734 - mmseg - INFO - Iter [132200/160000]	lr: 1.043e-05, eta: 6:08:35, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1675, decode.acc_seg: 92.8247, aux.loss_ce: 0.0825, aux.acc_seg: 91.4901, loss: 0.2500
2023-11-27 18:59:03,750 - mmseg - INFO - Iter [132250/160000]	lr: 1.041e-05, eta: 6:07:55, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1710, decode.acc_seg: 92.6585, aux.loss_ce: 0.0845, aux.acc_seg: 91.3928, loss: 0.2556
2023-11-27 18:59:41,754 - mmseg - INFO - Iter [132300/160000]	lr: 1.039e-05, eta: 6:07:15, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1682, decode.acc_seg: 92.8742, aux.loss_ce: 0.0812, aux.acc_seg: 91.7190, loss: 0.2494
2023-11-27 19:00:21,507 - mmseg - INFO - Iter [132350/160000]	lr: 1.037e-05, eta: 6:06:35, time: 0.795, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1659, decode.acc_seg: 92.6444, aux.loss_ce: 0.0819, aux.acc_seg: 91.3739, loss: 0.2478
2023-11-27 19:01:01,850 - mmseg - INFO - Iter [132400/160000]	lr: 1.035e-05, eta: 6:05:55, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1812, decode.acc_seg: 92.2527, aux.loss_ce: 0.0894, aux.acc_seg: 90.8257, loss: 0.2706
2023-11-27 19:01:42,020 - mmseg - INFO - Iter [132450/160000]	lr: 1.033e-05, eta: 6:05:16, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1763, decode.acc_seg: 92.3032, aux.loss_ce: 0.0869, aux.acc_seg: 91.0035, loss: 0.2632
2023-11-27 19:02:22,118 - mmseg - INFO - Iter [132500/160000]	lr: 1.031e-05, eta: 6:04:36, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1827, decode.acc_seg: 92.3764, aux.loss_ce: 0.0905, aux.acc_seg: 90.9848, loss: 0.2732
2023-11-27 19:02:59,280 - mmseg - INFO - Iter [132550/160000]	lr: 1.029e-05, eta: 6:03:56, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1788, decode.acc_seg: 92.2741, aux.loss_ce: 0.0880, aux.acc_seg: 90.7783, loss: 0.2668
2023-11-27 19:03:38,659 - mmseg - INFO - Iter [132600/160000]	lr: 1.028e-05, eta: 6:03:16, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1816, decode.acc_seg: 92.1892, aux.loss_ce: 0.0884, aux.acc_seg: 90.9438, loss: 0.2700
2023-11-27 19:04:18,993 - mmseg - INFO - Iter [132650/160000]	lr: 1.026e-05, eta: 6:02:36, time: 0.808, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 93.0770, aux.loss_ce: 0.0808, aux.acc_seg: 91.8456, loss: 0.2458
2023-11-27 19:04:58,579 - mmseg - INFO - Iter [132700/160000]	lr: 1.024e-05, eta: 6:01:56, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1751, decode.acc_seg: 92.4139, aux.loss_ce: 0.0866, aux.acc_seg: 91.0573, loss: 0.2617
2023-11-27 19:05:39,134 - mmseg - INFO - Iter [132750/160000]	lr: 1.022e-05, eta: 6:01:17, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8915, aux.loss_ce: 0.0827, aux.acc_seg: 91.4614, loss: 0.2474
2023-11-27 19:06:17,062 - mmseg - INFO - Iter [132800/160000]	lr: 1.020e-05, eta: 6:00:36, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1743, decode.acc_seg: 92.6457, aux.loss_ce: 0.0868, aux.acc_seg: 91.0800, loss: 0.2611
2023-11-27 19:06:54,369 - mmseg - INFO - Iter [132850/160000]	lr: 1.018e-05, eta: 5:59:56, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.7565, aux.loss_ce: 0.0834, aux.acc_seg: 91.4134, loss: 0.2540
2023-11-27 19:07:33,666 - mmseg - INFO - Iter [132900/160000]	lr: 1.016e-05, eta: 5:59:16, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 93.0168, aux.loss_ce: 0.0805, aux.acc_seg: 91.8761, loss: 0.2460
2023-11-27 19:08:13,628 - mmseg - INFO - Iter [132950/160000]	lr: 1.014e-05, eta: 5:58:37, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1831, decode.acc_seg: 92.2670, aux.loss_ce: 0.0889, aux.acc_seg: 91.0125, loss: 0.2720
2023-11-27 19:08:54,021 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 19:08:54,022 - mmseg - INFO - Iter [133000/160000]	lr: 1.013e-05, eta: 5:57:57, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.6273, aux.loss_ce: 0.0831, aux.acc_seg: 91.2461, loss: 0.2531
2023-11-27 19:09:32,898 - mmseg - INFO - Iter [133050/160000]	lr: 1.011e-05, eta: 5:57:17, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1745, decode.acc_seg: 92.4147, aux.loss_ce: 0.0844, aux.acc_seg: 91.2276, loss: 0.2589
2023-11-27 19:10:11,993 - mmseg - INFO - Iter [133100/160000]	lr: 1.009e-05, eta: 5:56:37, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.4529, aux.loss_ce: 0.0863, aux.acc_seg: 91.0844, loss: 0.2629
2023-11-27 19:10:52,555 - mmseg - INFO - Iter [133150/160000]	lr: 1.007e-05, eta: 5:55:57, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.7747, aux.loss_ce: 0.0840, aux.acc_seg: 91.4115, loss: 0.2540
2023-11-27 19:11:33,107 - mmseg - INFO - Iter [133200/160000]	lr: 1.005e-05, eta: 5:55:18, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.7575, aux.loss_ce: 0.0858, aux.acc_seg: 91.3733, loss: 0.2566
2023-11-27 19:12:13,617 - mmseg - INFO - Iter [133250/160000]	lr: 1.003e-05, eta: 5:54:38, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.5501, aux.loss_ce: 0.0847, aux.acc_seg: 91.1696, loss: 0.2567
2023-11-27 19:12:50,506 - mmseg - INFO - Iter [133300/160000]	lr: 1.001e-05, eta: 5:53:58, time: 0.739, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1737, decode.acc_seg: 92.4764, aux.loss_ce: 0.0858, aux.acc_seg: 90.9890, loss: 0.2595
2023-11-27 19:13:28,148 - mmseg - INFO - Iter [133350/160000]	lr: 9.994e-06, eta: 5:53:18, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1683, decode.acc_seg: 92.8113, aux.loss_ce: 0.0840, aux.acc_seg: 91.4411, loss: 0.2523
2023-11-27 19:14:05,856 - mmseg - INFO - Iter [133400/160000]	lr: 9.975e-06, eta: 5:52:37, time: 0.754, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1687, decode.acc_seg: 92.7109, aux.loss_ce: 0.0833, aux.acc_seg: 91.3860, loss: 0.2520
2023-11-27 19:14:46,274 - mmseg - INFO - Iter [133450/160000]	lr: 9.957e-06, eta: 5:51:58, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1700, decode.acc_seg: 92.4926, aux.loss_ce: 0.0829, aux.acc_seg: 91.2010, loss: 0.2529
2023-11-27 19:15:26,764 - mmseg - INFO - Iter [133500/160000]	lr: 9.938e-06, eta: 5:51:18, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1767, decode.acc_seg: 92.4962, aux.loss_ce: 0.0872, aux.acc_seg: 91.1516, loss: 0.2638
2023-11-27 19:16:07,198 - mmseg - INFO - Iter [133550/160000]	lr: 9.919e-06, eta: 5:50:39, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1811, decode.acc_seg: 92.3090, aux.loss_ce: 0.0889, aux.acc_seg: 91.0353, loss: 0.2700
2023-11-27 19:16:47,381 - mmseg - INFO - Iter [133600/160000]	lr: 9.900e-06, eta: 5:49:59, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1711, decode.acc_seg: 92.6950, aux.loss_ce: 0.0842, aux.acc_seg: 91.3437, loss: 0.2553
2023-11-27 19:17:28,426 - mmseg - INFO - Iter [133650/160000]	lr: 9.882e-06, eta: 5:49:19, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1781, decode.acc_seg: 92.4890, aux.loss_ce: 0.0871, aux.acc_seg: 91.1603, loss: 0.2652
2023-11-27 19:18:08,429 - mmseg - INFO - Iter [133700/160000]	lr: 9.863e-06, eta: 5:48:40, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1794, decode.acc_seg: 92.3553, aux.loss_ce: 0.0870, aux.acc_seg: 91.0254, loss: 0.2664
2023-11-27 19:18:48,317 - mmseg - INFO - Iter [133750/160000]	lr: 9.844e-06, eta: 5:48:00, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.6974, aux.loss_ce: 0.0839, aux.acc_seg: 91.3547, loss: 0.2516
2023-11-27 19:19:27,272 - mmseg - INFO - Iter [133800/160000]	lr: 9.825e-06, eta: 5:47:20, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1703, decode.acc_seg: 92.6407, aux.loss_ce: 0.0845, aux.acc_seg: 91.3171, loss: 0.2548
2023-11-27 19:20:07,967 - mmseg - INFO - Iter [133850/160000]	lr: 9.807e-06, eta: 5:46:40, time: 0.813, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1753, decode.acc_seg: 92.6223, aux.loss_ce: 0.0854, aux.acc_seg: 91.3225, loss: 0.2607
2023-11-27 19:20:48,968 - mmseg - INFO - Iter [133900/160000]	lr: 9.788e-06, eta: 5:46:01, time: 0.820, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1707, decode.acc_seg: 92.5535, aux.loss_ce: 0.0847, aux.acc_seg: 91.0974, loss: 0.2555
2023-11-27 19:21:29,595 - mmseg - INFO - Iter [133950/160000]	lr: 9.769e-06, eta: 5:45:21, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1776, decode.acc_seg: 92.2645, aux.loss_ce: 0.0872, aux.acc_seg: 90.8584, loss: 0.2648
2023-11-27 19:22:10,208 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 19:22:10,208 - mmseg - INFO - Iter [134000/160000]	lr: 9.750e-06, eta: 5:44:42, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1771, decode.acc_seg: 92.4166, aux.loss_ce: 0.0883, aux.acc_seg: 90.9231, loss: 0.2655
2023-11-27 19:22:50,594 - mmseg - INFO - Iter [134050/160000]	lr: 9.732e-06, eta: 5:44:02, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1781, decode.acc_seg: 92.4368, aux.loss_ce: 0.0901, aux.acc_seg: 90.9006, loss: 0.2682
2023-11-27 19:23:30,671 - mmseg - INFO - Iter [134100/160000]	lr: 9.713e-06, eta: 5:43:22, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1811, decode.acc_seg: 92.2594, aux.loss_ce: 0.0891, aux.acc_seg: 90.9337, loss: 0.2702
2023-11-27 19:24:09,169 - mmseg - INFO - Iter [134150/160000]	lr: 9.694e-06, eta: 5:42:42, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1628, decode.acc_seg: 92.9826, aux.loss_ce: 0.0808, aux.acc_seg: 91.7004, loss: 0.2437
2023-11-27 19:24:47,893 - mmseg - INFO - Iter [134200/160000]	lr: 9.675e-06, eta: 5:42:02, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1784, decode.acc_seg: 92.3485, aux.loss_ce: 0.0878, aux.acc_seg: 90.9773, loss: 0.2662
2023-11-27 19:25:27,714 - mmseg - INFO - Iter [134250/160000]	lr: 9.657e-06, eta: 5:41:22, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.5322, aux.loss_ce: 0.0868, aux.acc_seg: 91.2238, loss: 0.2607
2023-11-27 19:26:08,334 - mmseg - INFO - Iter [134300/160000]	lr: 9.638e-06, eta: 5:40:43, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1690, decode.acc_seg: 92.5445, aux.loss_ce: 0.0840, aux.acc_seg: 91.0554, loss: 0.2531
2023-11-27 19:26:48,226 - mmseg - INFO - Iter [134350/160000]	lr: 9.619e-06, eta: 5:40:03, time: 0.798, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1746, decode.acc_seg: 92.7215, aux.loss_ce: 0.0871, aux.acc_seg: 91.3317, loss: 0.2617
2023-11-27 19:27:26,178 - mmseg - INFO - Iter [134400/160000]	lr: 9.600e-06, eta: 5:39:23, time: 0.760, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1666, decode.acc_seg: 92.9385, aux.loss_ce: 0.0826, aux.acc_seg: 91.5605, loss: 0.2492
2023-11-27 19:28:05,683 - mmseg - INFO - Iter [134450/160000]	lr: 9.582e-06, eta: 5:38:43, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1691, decode.acc_seg: 92.7495, aux.loss_ce: 0.0829, aux.acc_seg: 91.5213, loss: 0.2520
2023-11-27 19:28:45,734 - mmseg - INFO - Iter [134500/160000]	lr: 9.563e-06, eta: 5:38:03, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1694, decode.acc_seg: 92.7542, aux.loss_ce: 0.0837, aux.acc_seg: 91.3897, loss: 0.2532
2023-11-27 19:29:25,387 - mmseg - INFO - Iter [134550/160000]	lr: 9.544e-06, eta: 5:37:24, time: 0.793, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1713, decode.acc_seg: 92.6180, aux.loss_ce: 0.0849, aux.acc_seg: 91.1252, loss: 0.2561
2023-11-27 19:30:03,296 - mmseg - INFO - Iter [134600/160000]	lr: 9.525e-06, eta: 5:36:44, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.3970, aux.loss_ce: 0.0853, aux.acc_seg: 91.2281, loss: 0.2620
2023-11-27 19:30:40,459 - mmseg - INFO - Iter [134650/160000]	lr: 9.507e-06, eta: 5:36:03, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1761, decode.acc_seg: 92.3328, aux.loss_ce: 0.0867, aux.acc_seg: 90.9224, loss: 0.2628
2023-11-27 19:31:19,688 - mmseg - INFO - Iter [134700/160000]	lr: 9.488e-06, eta: 5:35:23, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1798, decode.acc_seg: 92.3356, aux.loss_ce: 0.0885, aux.acc_seg: 91.0418, loss: 0.2683
2023-11-27 19:31:58,899 - mmseg - INFO - Iter [134750/160000]	lr: 9.469e-06, eta: 5:34:44, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1764, decode.acc_seg: 92.4330, aux.loss_ce: 0.0858, aux.acc_seg: 91.0985, loss: 0.2622
2023-11-27 19:32:38,999 - mmseg - INFO - Iter [134800/160000]	lr: 9.450e-06, eta: 5:34:04, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.4842, aux.loss_ce: 0.0846, aux.acc_seg: 91.1511, loss: 0.2565
2023-11-27 19:33:18,241 - mmseg - INFO - Iter [134850/160000]	lr: 9.432e-06, eta: 5:33:24, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.3694, aux.loss_ce: 0.0879, aux.acc_seg: 91.0927, loss: 0.2662
2023-11-27 19:33:58,795 - mmseg - INFO - Iter [134900/160000]	lr: 9.413e-06, eta: 5:32:44, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1634, decode.acc_seg: 92.8012, aux.loss_ce: 0.0806, aux.acc_seg: 91.4599, loss: 0.2440
2023-11-27 19:34:36,275 - mmseg - INFO - Iter [134950/160000]	lr: 9.394e-06, eta: 5:32:04, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1725, decode.acc_seg: 92.4993, aux.loss_ce: 0.0841, aux.acc_seg: 91.0903, loss: 0.2566
2023-11-27 19:35:13,555 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 19:35:13,555 - mmseg - INFO - Iter [135000/160000]	lr: 9.375e-06, eta: 5:31:24, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1706, decode.acc_seg: 92.7380, aux.loss_ce: 0.0837, aux.acc_seg: 91.4253, loss: 0.2543
2023-11-27 19:35:50,768 - mmseg - INFO - Iter [135050/160000]	lr: 9.357e-06, eta: 5:30:44, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1741, decode.acc_seg: 92.5498, aux.loss_ce: 0.0862, aux.acc_seg: 91.1768, loss: 0.2602
2023-11-27 19:36:31,119 - mmseg - INFO - Iter [135100/160000]	lr: 9.338e-06, eta: 5:30:04, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1795, decode.acc_seg: 92.3564, aux.loss_ce: 0.0882, aux.acc_seg: 90.9516, loss: 0.2677
2023-11-27 19:37:12,500 - mmseg - INFO - Iter [135150/160000]	lr: 9.319e-06, eta: 5:29:25, time: 0.829, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1613, decode.acc_seg: 92.9159, aux.loss_ce: 0.0809, aux.acc_seg: 91.5088, loss: 0.2422
2023-11-27 19:37:50,692 - mmseg - INFO - Iter [135200/160000]	lr: 9.300e-06, eta: 5:28:44, time: 0.763, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1690, decode.acc_seg: 92.6028, aux.loss_ce: 0.0820, aux.acc_seg: 91.3665, loss: 0.2510
2023-11-27 19:38:30,746 - mmseg - INFO - Iter [135250/160000]	lr: 9.282e-06, eta: 5:28:05, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1728, decode.acc_seg: 92.5721, aux.loss_ce: 0.0858, aux.acc_seg: 91.0210, loss: 0.2586
2023-11-27 19:39:11,178 - mmseg - INFO - Iter [135300/160000]	lr: 9.263e-06, eta: 5:27:25, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1694, decode.acc_seg: 92.7218, aux.loss_ce: 0.0847, aux.acc_seg: 91.3970, loss: 0.2541
2023-11-27 19:39:50,859 - mmseg - INFO - Iter [135350/160000]	lr: 9.244e-06, eta: 5:26:45, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1746, decode.acc_seg: 92.1727, aux.loss_ce: 0.0858, aux.acc_seg: 90.8096, loss: 0.2603
2023-11-27 19:40:32,243 - mmseg - INFO - Iter [135400/160000]	lr: 9.225e-06, eta: 5:26:06, time: 0.827, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1738, decode.acc_seg: 92.5471, aux.loss_ce: 0.0852, aux.acc_seg: 91.1719, loss: 0.2589
2023-11-27 19:41:12,351 - mmseg - INFO - Iter [135450/160000]	lr: 9.207e-06, eta: 5:25:26, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1785, decode.acc_seg: 92.3222, aux.loss_ce: 0.0896, aux.acc_seg: 90.7021, loss: 0.2681
2023-11-27 19:41:50,050 - mmseg - INFO - Iter [135500/160000]	lr: 9.188e-06, eta: 5:24:46, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1712, decode.acc_seg: 92.6207, aux.loss_ce: 0.0846, aux.acc_seg: 91.1668, loss: 0.2558
2023-11-27 19:42:29,014 - mmseg - INFO - Iter [135550/160000]	lr: 9.169e-06, eta: 5:24:06, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.9149, aux.loss_ce: 0.0839, aux.acc_seg: 91.4230, loss: 0.2520
2023-11-27 19:43:06,634 - mmseg - INFO - Iter [135600/160000]	lr: 9.150e-06, eta: 5:23:26, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1690, decode.acc_seg: 92.8005, aux.loss_ce: 0.0833, aux.acc_seg: 91.5969, loss: 0.2522
2023-11-27 19:43:44,246 - mmseg - INFO - Iter [135650/160000]	lr: 9.132e-06, eta: 5:22:46, time: 0.751, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1741, decode.acc_seg: 92.5087, aux.loss_ce: 0.0860, aux.acc_seg: 91.2596, loss: 0.2601
2023-11-27 19:44:24,189 - mmseg - INFO - Iter [135700/160000]	lr: 9.113e-06, eta: 5:22:06, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1703, decode.acc_seg: 92.7731, aux.loss_ce: 0.0834, aux.acc_seg: 91.5450, loss: 0.2537
2023-11-27 19:45:05,253 - mmseg - INFO - Iter [135750/160000]	lr: 9.094e-06, eta: 5:21:27, time: 0.823, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1828, decode.acc_seg: 92.1765, aux.loss_ce: 0.0904, aux.acc_seg: 90.7513, loss: 0.2732
2023-11-27 19:45:43,371 - mmseg - INFO - Iter [135800/160000]	lr: 9.075e-06, eta: 5:20:46, time: 0.761, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.9782, aux.loss_ce: 0.0808, aux.acc_seg: 91.7797, loss: 0.2485
2023-11-27 19:46:23,148 - mmseg - INFO - Iter [135850/160000]	lr: 9.057e-06, eta: 5:20:07, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1682, decode.acc_seg: 92.7298, aux.loss_ce: 0.0824, aux.acc_seg: 91.3861, loss: 0.2506
2023-11-27 19:46:59,889 - mmseg - INFO - Iter [135900/160000]	lr: 9.038e-06, eta: 5:19:26, time: 0.735, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.7311, aux.loss_ce: 0.0833, aux.acc_seg: 91.5281, loss: 0.2529
2023-11-27 19:47:36,462 - mmseg - INFO - Iter [135950/160000]	lr: 9.019e-06, eta: 5:18:46, time: 0.732, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1722, decode.acc_seg: 92.5846, aux.loss_ce: 0.0854, aux.acc_seg: 91.3098, loss: 0.2575
2023-11-27 19:48:12,986 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 19:48:12,986 - mmseg - INFO - Iter [136000/160000]	lr: 9.000e-06, eta: 5:18:06, time: 0.730, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1749, decode.acc_seg: 92.5023, aux.loss_ce: 0.0874, aux.acc_seg: 90.9569, loss: 0.2623
2023-11-27 19:48:51,714 - mmseg - INFO - Iter [136050/160000]	lr: 8.982e-06, eta: 5:17:26, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1797, decode.acc_seg: 92.4240, aux.loss_ce: 0.0869, aux.acc_seg: 91.1435, loss: 0.2667
2023-11-27 19:49:33,176 - mmseg - INFO - Iter [136100/160000]	lr: 8.963e-06, eta: 5:16:46, time: 0.829, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1774, decode.acc_seg: 92.4342, aux.loss_ce: 0.0869, aux.acc_seg: 91.1347, loss: 0.2643
2023-11-27 19:50:14,170 - mmseg - INFO - Iter [136150/160000]	lr: 8.944e-06, eta: 5:16:07, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1749, decode.acc_seg: 92.5960, aux.loss_ce: 0.0854, aux.acc_seg: 91.3182, loss: 0.2603
2023-11-27 19:50:55,117 - mmseg - INFO - Iter [136200/160000]	lr: 8.925e-06, eta: 5:15:27, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.5325, aux.loss_ce: 0.0850, aux.acc_seg: 91.1614, loss: 0.2551
2023-11-27 19:51:35,531 - mmseg - INFO - Iter [136250/160000]	lr: 8.907e-06, eta: 5:14:48, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.7775, aux.loss_ce: 0.0818, aux.acc_seg: 91.4198, loss: 0.2464
2023-11-27 19:52:16,422 - mmseg - INFO - Iter [136300/160000]	lr: 8.888e-06, eta: 5:14:08, time: 0.818, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1746, decode.acc_seg: 92.4609, aux.loss_ce: 0.0862, aux.acc_seg: 91.1545, loss: 0.2608
2023-11-27 19:52:55,318 - mmseg - INFO - Iter [136350/160000]	lr: 8.869e-06, eta: 5:13:28, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.7302, aux.loss_ce: 0.0831, aux.acc_seg: 91.5572, loss: 0.2532
2023-11-27 19:53:33,317 - mmseg - INFO - Iter [136400/160000]	lr: 8.850e-06, eta: 5:12:48, time: 0.761, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1771, decode.acc_seg: 92.4253, aux.loss_ce: 0.0865, aux.acc_seg: 91.0617, loss: 0.2636
2023-11-27 19:54:12,235 - mmseg - INFO - Iter [136450/160000]	lr: 8.832e-06, eta: 5:12:08, time: 0.778, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1730, decode.acc_seg: 92.5700, aux.loss_ce: 0.0845, aux.acc_seg: 91.3507, loss: 0.2576
2023-11-27 19:54:50,432 - mmseg - INFO - Iter [136500/160000]	lr: 8.813e-06, eta: 5:11:28, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1781, decode.acc_seg: 92.4378, aux.loss_ce: 0.0888, aux.acc_seg: 91.0231, loss: 0.2669
2023-11-27 19:55:30,543 - mmseg - INFO - Iter [136550/160000]	lr: 8.794e-06, eta: 5:10:48, time: 0.802, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.7365, aux.loss_ce: 0.0822, aux.acc_seg: 91.4954, loss: 0.2483
2023-11-27 19:56:10,720 - mmseg - INFO - Iter [136600/160000]	lr: 8.775e-06, eta: 5:10:09, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1758, decode.acc_seg: 92.3901, aux.loss_ce: 0.0858, aux.acc_seg: 91.0761, loss: 0.2617
2023-11-27 19:56:49,957 - mmseg - INFO - Iter [136650/160000]	lr: 8.757e-06, eta: 5:09:29, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1869, decode.acc_seg: 92.0212, aux.loss_ce: 0.0925, aux.acc_seg: 90.6029, loss: 0.2793
2023-11-27 19:57:29,939 - mmseg - INFO - Iter [136700/160000]	lr: 8.738e-06, eta: 5:08:49, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1780, decode.acc_seg: 92.3319, aux.loss_ce: 0.0874, aux.acc_seg: 90.9879, loss: 0.2654
2023-11-27 19:58:09,068 - mmseg - INFO - Iter [136750/160000]	lr: 8.719e-06, eta: 5:08:09, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1705, decode.acc_seg: 92.8193, aux.loss_ce: 0.0836, aux.acc_seg: 91.5692, loss: 0.2541
2023-11-27 19:58:49,385 - mmseg - INFO - Iter [136800/160000]	lr: 8.700e-06, eta: 5:07:30, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1710, decode.acc_seg: 92.6311, aux.loss_ce: 0.0832, aux.acc_seg: 91.4897, loss: 0.2542
2023-11-27 19:59:30,106 - mmseg - INFO - Iter [136850/160000]	lr: 8.682e-06, eta: 5:06:50, time: 0.814, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1722, decode.acc_seg: 92.6467, aux.loss_ce: 0.0852, aux.acc_seg: 91.3008, loss: 0.2574
2023-11-27 20:00:10,662 - mmseg - INFO - Iter [136900/160000]	lr: 8.663e-06, eta: 5:06:10, time: 0.811, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1752, decode.acc_seg: 92.5588, aux.loss_ce: 0.0861, aux.acc_seg: 91.2398, loss: 0.2613
2023-11-27 20:00:49,998 - mmseg - INFO - Iter [136950/160000]	lr: 8.644e-06, eta: 5:05:30, time: 0.787, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1787, decode.acc_seg: 92.3449, aux.loss_ce: 0.0891, aux.acc_seg: 90.8735, loss: 0.2678
2023-11-27 20:01:30,444 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 20:01:30,445 - mmseg - INFO - Iter [137000/160000]	lr: 8.625e-06, eta: 5:04:51, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1705, decode.acc_seg: 92.7162, aux.loss_ce: 0.0849, aux.acc_seg: 91.1989, loss: 0.2554
2023-11-27 20:02:10,500 - mmseg - INFO - Iter [137050/160000]	lr: 8.607e-06, eta: 5:04:11, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1699, decode.acc_seg: 92.7704, aux.loss_ce: 0.0836, aux.acc_seg: 91.4983, loss: 0.2535
2023-11-27 20:02:50,654 - mmseg - INFO - Iter [137100/160000]	lr: 8.588e-06, eta: 5:03:31, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.4955, aux.loss_ce: 0.0845, aux.acc_seg: 91.2988, loss: 0.2585
2023-11-27 20:03:30,775 - mmseg - INFO - Iter [137150/160000]	lr: 8.569e-06, eta: 5:02:52, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1696, decode.acc_seg: 92.6511, aux.loss_ce: 0.0822, aux.acc_seg: 91.4137, loss: 0.2518
2023-11-27 20:04:10,788 - mmseg - INFO - Iter [137200/160000]	lr: 8.550e-06, eta: 5:02:12, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1621, decode.acc_seg: 92.8543, aux.loss_ce: 0.0796, aux.acc_seg: 91.6005, loss: 0.2418
2023-11-27 20:04:50,567 - mmseg - INFO - Iter [137250/160000]	lr: 8.532e-06, eta: 5:01:32, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.2727, aux.loss_ce: 0.0875, aux.acc_seg: 90.8162, loss: 0.2636
2023-11-27 20:05:29,974 - mmseg - INFO - Iter [137300/160000]	lr: 8.513e-06, eta: 5:00:52, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1715, decode.acc_seg: 92.6620, aux.loss_ce: 0.0830, aux.acc_seg: 91.4867, loss: 0.2545
2023-11-27 20:06:07,268 - mmseg - INFO - Iter [137350/160000]	lr: 8.494e-06, eta: 5:00:12, time: 0.746, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1682, decode.acc_seg: 92.8106, aux.loss_ce: 0.0818, aux.acc_seg: 91.6319, loss: 0.2500
2023-11-27 20:06:47,287 - mmseg - INFO - Iter [137400/160000]	lr: 8.475e-06, eta: 4:59:32, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1743, decode.acc_seg: 92.4206, aux.loss_ce: 0.0857, aux.acc_seg: 91.0477, loss: 0.2600
2023-11-27 20:07:26,558 - mmseg - INFO - Iter [137450/160000]	lr: 8.457e-06, eta: 4:58:53, time: 0.786, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1881, decode.acc_seg: 92.2282, aux.loss_ce: 0.0913, aux.acc_seg: 90.8900, loss: 0.2794
2023-11-27 20:08:06,706 - mmseg - INFO - Iter [137500/160000]	lr: 8.438e-06, eta: 4:58:13, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1735, decode.acc_seg: 92.5806, aux.loss_ce: 0.0856, aux.acc_seg: 91.3255, loss: 0.2591
2023-11-27 20:08:43,650 - mmseg - INFO - Iter [137550/160000]	lr: 8.419e-06, eta: 4:57:33, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1717, decode.acc_seg: 92.4592, aux.loss_ce: 0.0856, aux.acc_seg: 90.9771, loss: 0.2573
2023-11-27 20:09:20,321 - mmseg - INFO - Iter [137600/160000]	lr: 8.400e-06, eta: 4:56:52, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.6998, aux.loss_ce: 0.0836, aux.acc_seg: 91.3350, loss: 0.2529
2023-11-27 20:09:57,317 - mmseg - INFO - Iter [137650/160000]	lr: 8.382e-06, eta: 4:56:12, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1797, decode.acc_seg: 92.2522, aux.loss_ce: 0.0887, aux.acc_seg: 90.8366, loss: 0.2684
2023-11-27 20:10:39,110 - mmseg - INFO - Iter [137700/160000]	lr: 8.363e-06, eta: 4:55:33, time: 0.837, data_time: 0.054, memory: 21695, decode.loss_ce: 0.1663, decode.acc_seg: 92.5500, aux.loss_ce: 0.0813, aux.acc_seg: 91.2404, loss: 0.2476
2023-11-27 20:11:19,275 - mmseg - INFO - Iter [137750/160000]	lr: 8.344e-06, eta: 4:54:53, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1691, decode.acc_seg: 92.6178, aux.loss_ce: 0.0841, aux.acc_seg: 91.2576, loss: 0.2533
2023-11-27 20:11:59,285 - mmseg - INFO - Iter [137800/160000]	lr: 8.325e-06, eta: 4:54:13, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1730, decode.acc_seg: 92.7511, aux.loss_ce: 0.0867, aux.acc_seg: 91.3716, loss: 0.2597
2023-11-27 20:12:39,645 - mmseg - INFO - Iter [137850/160000]	lr: 8.307e-06, eta: 4:53:34, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1640, decode.acc_seg: 92.9011, aux.loss_ce: 0.0802, aux.acc_seg: 91.7060, loss: 0.2442
2023-11-27 20:13:19,696 - mmseg - INFO - Iter [137900/160000]	lr: 8.288e-06, eta: 4:52:54, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1834, decode.acc_seg: 92.3792, aux.loss_ce: 0.0907, aux.acc_seg: 90.8067, loss: 0.2740
2023-11-27 20:13:57,241 - mmseg - INFO - Iter [137950/160000]	lr: 8.269e-06, eta: 4:52:14, time: 0.752, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1667, decode.acc_seg: 92.7815, aux.loss_ce: 0.0826, aux.acc_seg: 91.5087, loss: 0.2492
2023-11-27 20:14:34,112 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 20:14:34,112 - mmseg - INFO - Iter [138000/160000]	lr: 8.250e-06, eta: 4:51:34, time: 0.737, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 92.8728, aux.loss_ce: 0.0805, aux.acc_seg: 91.6645, loss: 0.2434
2023-11-27 20:15:12,646 - mmseg - INFO - Iter [138050/160000]	lr: 8.232e-06, eta: 4:50:54, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1687, decode.acc_seg: 92.5110, aux.loss_ce: 0.0836, aux.acc_seg: 91.1359, loss: 0.2522
2023-11-27 20:15:52,951 - mmseg - INFO - Iter [138100/160000]	lr: 8.213e-06, eta: 4:50:14, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.7366, aux.loss_ce: 0.0824, aux.acc_seg: 91.6096, loss: 0.2517
2023-11-27 20:16:32,115 - mmseg - INFO - Iter [138150/160000]	lr: 8.194e-06, eta: 4:49:34, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1678, decode.acc_seg: 92.6547, aux.loss_ce: 0.0833, aux.acc_seg: 91.2311, loss: 0.2511
2023-11-27 20:17:09,180 - mmseg - INFO - Iter [138200/160000]	lr: 8.175e-06, eta: 4:48:54, time: 0.742, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1730, decode.acc_seg: 92.3747, aux.loss_ce: 0.0840, aux.acc_seg: 91.1438, loss: 0.2570
2023-11-27 20:17:47,385 - mmseg - INFO - Iter [138250/160000]	lr: 8.157e-06, eta: 4:48:14, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1829, decode.acc_seg: 92.0120, aux.loss_ce: 0.0899, aux.acc_seg: 90.6143, loss: 0.2728
2023-11-27 20:18:24,827 - mmseg - INFO - Iter [138300/160000]	lr: 8.138e-06, eta: 4:47:34, time: 0.749, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1752, decode.acc_seg: 92.5822, aux.loss_ce: 0.0866, aux.acc_seg: 91.2684, loss: 0.2618
2023-11-27 20:19:03,297 - mmseg - INFO - Iter [138350/160000]	lr: 8.119e-06, eta: 4:46:54, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1770, decode.acc_seg: 92.3097, aux.loss_ce: 0.0881, aux.acc_seg: 90.9150, loss: 0.2651
2023-11-27 20:19:43,641 - mmseg - INFO - Iter [138400/160000]	lr: 8.100e-06, eta: 4:46:14, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.7467, aux.loss_ce: 0.0823, aux.acc_seg: 91.2648, loss: 0.2484
2023-11-27 20:20:23,841 - mmseg - INFO - Iter [138450/160000]	lr: 8.082e-06, eta: 4:45:35, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1634, decode.acc_seg: 92.7957, aux.loss_ce: 0.0809, aux.acc_seg: 91.4603, loss: 0.2443
2023-11-27 20:21:04,125 - mmseg - INFO - Iter [138500/160000]	lr: 8.063e-06, eta: 4:44:55, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1736, decode.acc_seg: 92.5710, aux.loss_ce: 0.0838, aux.acc_seg: 91.3484, loss: 0.2574
2023-11-27 20:21:44,358 - mmseg - INFO - Iter [138550/160000]	lr: 8.044e-06, eta: 4:44:15, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.5695, aux.loss_ce: 0.0872, aux.acc_seg: 91.2515, loss: 0.2639
2023-11-27 20:22:24,876 - mmseg - INFO - Iter [138600/160000]	lr: 8.025e-06, eta: 4:43:36, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.5586, aux.loss_ce: 0.0830, aux.acc_seg: 91.3069, loss: 0.2518
2023-11-27 20:23:05,158 - mmseg - INFO - Iter [138650/160000]	lr: 8.007e-06, eta: 4:42:56, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.7058, aux.loss_ce: 0.0846, aux.acc_seg: 91.4058, loss: 0.2541
2023-11-27 20:23:43,681 - mmseg - INFO - Iter [138700/160000]	lr: 7.988e-06, eta: 4:42:16, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.8747, aux.loss_ce: 0.0833, aux.acc_seg: 91.6243, loss: 0.2515
2023-11-27 20:24:23,737 - mmseg - INFO - Iter [138750/160000]	lr: 7.969e-06, eta: 4:41:36, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1664, decode.acc_seg: 92.8099, aux.loss_ce: 0.0821, aux.acc_seg: 91.4153, loss: 0.2485
2023-11-27 20:25:02,443 - mmseg - INFO - Iter [138800/160000]	lr: 7.950e-06, eta: 4:40:56, time: 0.775, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.6583, aux.loss_ce: 0.0843, aux.acc_seg: 91.3131, loss: 0.2562
2023-11-27 20:25:39,687 - mmseg - INFO - Iter [138850/160000]	lr: 7.932e-06, eta: 4:40:16, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.6209, aux.loss_ce: 0.0871, aux.acc_seg: 91.1195, loss: 0.2631
2023-11-27 20:26:18,345 - mmseg - INFO - Iter [138900/160000]	lr: 7.913e-06, eta: 4:39:36, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.3983, aux.loss_ce: 0.0863, aux.acc_seg: 91.0214, loss: 0.2623
2023-11-27 20:26:58,598 - mmseg - INFO - Iter [138950/160000]	lr: 7.894e-06, eta: 4:38:57, time: 0.804, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1703, decode.acc_seg: 92.7341, aux.loss_ce: 0.0849, aux.acc_seg: 91.2642, loss: 0.2552
2023-11-27 20:27:37,524 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 20:27:37,525 - mmseg - INFO - Iter [139000/160000]	lr: 7.875e-06, eta: 4:38:17, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1668, decode.acc_seg: 92.7315, aux.loss_ce: 0.0819, aux.acc_seg: 91.5124, loss: 0.2487
2023-11-27 20:28:17,751 - mmseg - INFO - Iter [139050/160000]	lr: 7.857e-06, eta: 4:37:37, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1719, decode.acc_seg: 92.5730, aux.loss_ce: 0.0850, aux.acc_seg: 91.3414, loss: 0.2569
2023-11-27 20:28:57,185 - mmseg - INFO - Iter [139100/160000]	lr: 7.838e-06, eta: 4:36:57, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1760, decode.acc_seg: 92.5654, aux.loss_ce: 0.0865, aux.acc_seg: 91.2103, loss: 0.2625
2023-11-27 20:29:34,266 - mmseg - INFO - Iter [139150/160000]	lr: 7.819e-06, eta: 4:36:17, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1672, decode.acc_seg: 92.8956, aux.loss_ce: 0.0843, aux.acc_seg: 91.3154, loss: 0.2515
2023-11-27 20:30:12,291 - mmseg - INFO - Iter [139200/160000]	lr: 7.800e-06, eta: 4:35:37, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1735, decode.acc_seg: 92.5540, aux.loss_ce: 0.0858, aux.acc_seg: 91.1496, loss: 0.2593
2023-11-27 20:30:50,057 - mmseg - INFO - Iter [139250/160000]	lr: 7.782e-06, eta: 4:34:57, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1663, decode.acc_seg: 92.8172, aux.loss_ce: 0.0816, aux.acc_seg: 91.5484, loss: 0.2478
2023-11-27 20:31:31,113 - mmseg - INFO - Iter [139300/160000]	lr: 7.763e-06, eta: 4:34:17, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.9395, aux.loss_ce: 0.0822, aux.acc_seg: 91.6979, loss: 0.2517
2023-11-27 20:32:11,246 - mmseg - INFO - Iter [139350/160000]	lr: 7.744e-06, eta: 4:33:38, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.6908, aux.loss_ce: 0.0835, aux.acc_seg: 91.3161, loss: 0.2530
2023-11-27 20:32:51,420 - mmseg - INFO - Iter [139400/160000]	lr: 7.725e-06, eta: 4:32:58, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.5841, aux.loss_ce: 0.0842, aux.acc_seg: 91.1763, loss: 0.2535
2023-11-27 20:33:29,995 - mmseg - INFO - Iter [139450/160000]	lr: 7.707e-06, eta: 4:32:18, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1642, decode.acc_seg: 93.0705, aux.loss_ce: 0.0822, aux.acc_seg: 91.6790, loss: 0.2464
2023-11-27 20:34:07,494 - mmseg - INFO - Iter [139500/160000]	lr: 7.688e-06, eta: 4:31:38, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.6352, aux.loss_ce: 0.0839, aux.acc_seg: 91.3908, loss: 0.2527
2023-11-27 20:34:45,906 - mmseg - INFO - Iter [139550/160000]	lr: 7.669e-06, eta: 4:30:58, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1685, decode.acc_seg: 92.7737, aux.loss_ce: 0.0830, aux.acc_seg: 91.4526, loss: 0.2515
2023-11-27 20:35:23,918 - mmseg - INFO - Iter [139600/160000]	lr: 7.650e-06, eta: 4:30:18, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1642, decode.acc_seg: 92.8231, aux.loss_ce: 0.0815, aux.acc_seg: 91.5535, loss: 0.2458
2023-11-27 20:36:01,432 - mmseg - INFO - Iter [139650/160000]	lr: 7.632e-06, eta: 4:29:38, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1758, decode.acc_seg: 92.4980, aux.loss_ce: 0.0892, aux.acc_seg: 90.9240, loss: 0.2649
2023-11-27 20:36:39,219 - mmseg - INFO - Iter [139700/160000]	lr: 7.613e-06, eta: 4:28:58, time: 0.756, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1683, decode.acc_seg: 92.6022, aux.loss_ce: 0.0829, aux.acc_seg: 91.3394, loss: 0.2511
2023-11-27 20:37:16,139 - mmseg - INFO - Iter [139750/160000]	lr: 7.594e-06, eta: 4:28:18, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1715, decode.acc_seg: 92.6954, aux.loss_ce: 0.0839, aux.acc_seg: 91.4748, loss: 0.2554
2023-11-27 20:37:53,183 - mmseg - INFO - Iter [139800/160000]	lr: 7.575e-06, eta: 4:27:38, time: 0.741, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1708, decode.acc_seg: 92.8207, aux.loss_ce: 0.0831, aux.acc_seg: 91.5731, loss: 0.2539
2023-11-27 20:38:33,543 - mmseg - INFO - Iter [139850/160000]	lr: 7.557e-06, eta: 4:26:58, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1771, decode.acc_seg: 92.5624, aux.loss_ce: 0.0864, aux.acc_seg: 91.3108, loss: 0.2635
2023-11-27 20:39:13,110 - mmseg - INFO - Iter [139900/160000]	lr: 7.538e-06, eta: 4:26:18, time: 0.792, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1700, decode.acc_seg: 92.4983, aux.loss_ce: 0.0846, aux.acc_seg: 91.1131, loss: 0.2546
2023-11-27 20:39:52,232 - mmseg - INFO - Iter [139950/160000]	lr: 7.519e-06, eta: 4:25:38, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1687, decode.acc_seg: 92.8384, aux.loss_ce: 0.0832, aux.acc_seg: 91.5216, loss: 0.2519
2023-11-27 20:40:31,660 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 20:40:31,660 - mmseg - INFO - Iter [140000/160000]	lr: 7.500e-06, eta: 4:24:59, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1678, decode.acc_seg: 92.8386, aux.loss_ce: 0.0832, aux.acc_seg: 91.4039, loss: 0.2511
2023-11-27 20:41:12,031 - mmseg - INFO - Iter [140050/160000]	lr: 7.482e-06, eta: 4:24:19, time: 0.806, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1641, decode.acc_seg: 92.7367, aux.loss_ce: 0.0824, aux.acc_seg: 91.2114, loss: 0.2465
2023-11-27 20:41:52,091 - mmseg - INFO - Iter [140100/160000]	lr: 7.463e-06, eta: 4:23:39, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1715, decode.acc_seg: 92.4582, aux.loss_ce: 0.0849, aux.acc_seg: 91.1795, loss: 0.2564
2023-11-27 20:42:30,782 - mmseg - INFO - Iter [140150/160000]	lr: 7.444e-06, eta: 4:22:59, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1719, decode.acc_seg: 92.6974, aux.loss_ce: 0.0854, aux.acc_seg: 91.3510, loss: 0.2574
2023-11-27 20:43:10,693 - mmseg - INFO - Iter [140200/160000]	lr: 7.425e-06, eta: 4:22:20, time: 0.798, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 92.9191, aux.loss_ce: 0.0811, aux.acc_seg: 91.7397, loss: 0.2466
2023-11-27 20:43:48,991 - mmseg - INFO - Iter [140250/160000]	lr: 7.407e-06, eta: 4:21:40, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1790, decode.acc_seg: 92.5526, aux.loss_ce: 0.0895, aux.acc_seg: 91.0317, loss: 0.2684
2023-11-27 20:44:27,862 - mmseg - INFO - Iter [140300/160000]	lr: 7.388e-06, eta: 4:21:00, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1638, decode.acc_seg: 92.9486, aux.loss_ce: 0.0809, aux.acc_seg: 91.6850, loss: 0.2447
2023-11-27 20:45:06,285 - mmseg - INFO - Iter [140350/160000]	lr: 7.369e-06, eta: 4:20:20, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1622, decode.acc_seg: 93.0096, aux.loss_ce: 0.0806, aux.acc_seg: 91.5970, loss: 0.2428
2023-11-27 20:45:43,999 - mmseg - INFO - Iter [140400/160000]	lr: 7.350e-06, eta: 4:19:40, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 93.1080, aux.loss_ce: 0.0793, aux.acc_seg: 91.8978, loss: 0.2418
2023-11-27 20:46:25,282 - mmseg - INFO - Iter [140450/160000]	lr: 7.332e-06, eta: 4:19:00, time: 0.826, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1649, decode.acc_seg: 92.9733, aux.loss_ce: 0.0812, aux.acc_seg: 91.7347, loss: 0.2460
2023-11-27 20:47:05,771 - mmseg - INFO - Iter [140500/160000]	lr: 7.313e-06, eta: 4:18:21, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1721, decode.acc_seg: 92.4080, aux.loss_ce: 0.0850, aux.acc_seg: 91.0195, loss: 0.2571
2023-11-27 20:47:46,035 - mmseg - INFO - Iter [140550/160000]	lr: 7.294e-06, eta: 4:17:41, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1772, decode.acc_seg: 92.1754, aux.loss_ce: 0.0884, aux.acc_seg: 90.7824, loss: 0.2656
2023-11-27 20:48:26,176 - mmseg - INFO - Iter [140600/160000]	lr: 7.275e-06, eta: 4:17:01, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1584, decode.acc_seg: 93.0338, aux.loss_ce: 0.0765, aux.acc_seg: 91.8045, loss: 0.2349
2023-11-27 20:49:04,872 - mmseg - INFO - Iter [140650/160000]	lr: 7.257e-06, eta: 4:16:21, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1713, decode.acc_seg: 92.7325, aux.loss_ce: 0.0845, aux.acc_seg: 91.3484, loss: 0.2558
2023-11-27 20:49:43,089 - mmseg - INFO - Iter [140700/160000]	lr: 7.238e-06, eta: 4:15:41, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1587, decode.acc_seg: 93.1578, aux.loss_ce: 0.0788, aux.acc_seg: 91.7044, loss: 0.2375
2023-11-27 20:50:22,908 - mmseg - INFO - Iter [140750/160000]	lr: 7.219e-06, eta: 4:15:02, time: 0.795, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1685, decode.acc_seg: 92.8249, aux.loss_ce: 0.0830, aux.acc_seg: 91.6893, loss: 0.2515
2023-11-27 20:51:01,439 - mmseg - INFO - Iter [140800/160000]	lr: 7.200e-06, eta: 4:14:22, time: 0.772, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1781, decode.acc_seg: 92.3389, aux.loss_ce: 0.0880, aux.acc_seg: 91.0394, loss: 0.2661
2023-11-27 20:51:38,540 - mmseg - INFO - Iter [140850/160000]	lr: 7.182e-06, eta: 4:13:42, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1672, decode.acc_seg: 92.5822, aux.loss_ce: 0.0823, aux.acc_seg: 91.3303, loss: 0.2495
2023-11-27 20:52:15,357 - mmseg - INFO - Iter [140900/160000]	lr: 7.163e-06, eta: 4:13:02, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1713, decode.acc_seg: 92.8333, aux.loss_ce: 0.0839, aux.acc_seg: 91.5619, loss: 0.2552
2023-11-27 20:52:54,289 - mmseg - INFO - Iter [140950/160000]	lr: 7.144e-06, eta: 4:12:22, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1668, decode.acc_seg: 93.0525, aux.loss_ce: 0.0836, aux.acc_seg: 91.6598, loss: 0.2505
2023-11-27 20:53:33,712 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 20:53:33,713 - mmseg - INFO - Iter [141000/160000]	lr: 7.125e-06, eta: 4:11:42, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.7045, aux.loss_ce: 0.0830, aux.acc_seg: 91.4499, loss: 0.2511
2023-11-27 20:54:13,587 - mmseg - INFO - Iter [141050/160000]	lr: 7.107e-06, eta: 4:11:02, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.5921, aux.loss_ce: 0.0860, aux.acc_seg: 91.1823, loss: 0.2599
2023-11-27 20:54:51,851 - mmseg - INFO - Iter [141100/160000]	lr: 7.088e-06, eta: 4:10:22, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1705, decode.acc_seg: 92.6332, aux.loss_ce: 0.0844, aux.acc_seg: 91.1414, loss: 0.2550
2023-11-27 20:55:31,434 - mmseg - INFO - Iter [141150/160000]	lr: 7.069e-06, eta: 4:09:42, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1803, decode.acc_seg: 92.1246, aux.loss_ce: 0.0881, aux.acc_seg: 90.7147, loss: 0.2684
2023-11-27 20:56:09,330 - mmseg - INFO - Iter [141200/160000]	lr: 7.050e-06, eta: 4:09:03, time: 0.757, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1655, decode.acc_seg: 92.7145, aux.loss_ce: 0.0820, aux.acc_seg: 91.4308, loss: 0.2475
2023-11-27 20:56:49,727 - mmseg - INFO - Iter [141250/160000]	lr: 7.032e-06, eta: 4:08:23, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1607, decode.acc_seg: 93.2249, aux.loss_ce: 0.0782, aux.acc_seg: 92.0423, loss: 0.2390
2023-11-27 20:57:27,545 - mmseg - INFO - Iter [141300/160000]	lr: 7.013e-06, eta: 4:07:43, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1727, decode.acc_seg: 92.5641, aux.loss_ce: 0.0847, aux.acc_seg: 91.2464, loss: 0.2574
2023-11-27 20:58:05,241 - mmseg - INFO - Iter [141350/160000]	lr: 6.994e-06, eta: 4:07:03, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1691, decode.acc_seg: 92.7947, aux.loss_ce: 0.0835, aux.acc_seg: 91.4464, loss: 0.2526
2023-11-27 20:58:45,199 - mmseg - INFO - Iter [141400/160000]	lr: 6.975e-06, eta: 4:06:23, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1694, decode.acc_seg: 92.6061, aux.loss_ce: 0.0841, aux.acc_seg: 91.2926, loss: 0.2535
2023-11-27 20:59:23,973 - mmseg - INFO - Iter [141450/160000]	lr: 6.957e-06, eta: 4:05:43, time: 0.776, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.7504, aux.loss_ce: 0.0837, aux.acc_seg: 91.4202, loss: 0.2532
2023-11-27 21:00:03,548 - mmseg - INFO - Iter [141500/160000]	lr: 6.938e-06, eta: 4:05:04, time: 0.792, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1621, decode.acc_seg: 92.9438, aux.loss_ce: 0.0815, aux.acc_seg: 91.4639, loss: 0.2436
2023-11-27 21:00:40,549 - mmseg - INFO - Iter [141550/160000]	lr: 6.919e-06, eta: 4:04:23, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1721, decode.acc_seg: 92.5365, aux.loss_ce: 0.0842, aux.acc_seg: 91.2658, loss: 0.2564
2023-11-27 21:01:18,843 - mmseg - INFO - Iter [141600/160000]	lr: 6.900e-06, eta: 4:03:43, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1770, decode.acc_seg: 92.4194, aux.loss_ce: 0.0870, aux.acc_seg: 91.0598, loss: 0.2640
2023-11-27 21:01:58,989 - mmseg - INFO - Iter [141650/160000]	lr: 6.882e-06, eta: 4:03:04, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.8905, aux.loss_ce: 0.0826, aux.acc_seg: 91.6244, loss: 0.2507
2023-11-27 21:02:39,146 - mmseg - INFO - Iter [141700/160000]	lr: 6.863e-06, eta: 4:02:24, time: 0.803, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1636, decode.acc_seg: 92.8585, aux.loss_ce: 0.0817, aux.acc_seg: 91.4090, loss: 0.2453
2023-11-27 21:03:19,189 - mmseg - INFO - Iter [141750/160000]	lr: 6.844e-06, eta: 4:01:44, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1758, decode.acc_seg: 92.4106, aux.loss_ce: 0.0869, aux.acc_seg: 91.0018, loss: 0.2628
2023-11-27 21:03:58,023 - mmseg - INFO - Iter [141800/160000]	lr: 6.825e-06, eta: 4:01:05, time: 0.778, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1598, decode.acc_seg: 93.0639, aux.loss_ce: 0.0799, aux.acc_seg: 91.6591, loss: 0.2397
2023-11-27 21:04:38,043 - mmseg - INFO - Iter [141850/160000]	lr: 6.807e-06, eta: 4:00:25, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.4509, aux.loss_ce: 0.0851, aux.acc_seg: 91.1520, loss: 0.2571
2023-11-27 21:05:16,821 - mmseg - INFO - Iter [141900/160000]	lr: 6.788e-06, eta: 3:59:45, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 92.8088, aux.loss_ce: 0.0824, aux.acc_seg: 91.4316, loss: 0.2474
2023-11-27 21:05:56,592 - mmseg - INFO - Iter [141950/160000]	lr: 6.769e-06, eta: 3:59:05, time: 0.797, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1666, decode.acc_seg: 92.7599, aux.loss_ce: 0.0827, aux.acc_seg: 91.3378, loss: 0.2493
2023-11-27 21:06:35,049 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 21:06:35,049 - mmseg - INFO - Iter [142000/160000]	lr: 6.750e-06, eta: 3:58:25, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.6723, aux.loss_ce: 0.0857, aux.acc_seg: 91.3348, loss: 0.2577
2023-11-27 21:07:13,690 - mmseg - INFO - Iter [142050/160000]	lr: 6.732e-06, eta: 3:57:45, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1659, decode.acc_seg: 92.9344, aux.loss_ce: 0.0813, aux.acc_seg: 91.6719, loss: 0.2472
2023-11-27 21:07:54,106 - mmseg - INFO - Iter [142100/160000]	lr: 6.713e-06, eta: 3:57:06, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1612, decode.acc_seg: 92.9266, aux.loss_ce: 0.0802, aux.acc_seg: 91.6215, loss: 0.2414
2023-11-27 21:08:34,199 - mmseg - INFO - Iter [142150/160000]	lr: 6.694e-06, eta: 3:56:26, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1716, decode.acc_seg: 92.6674, aux.loss_ce: 0.0825, aux.acc_seg: 91.3623, loss: 0.2542
2023-11-27 21:09:13,703 - mmseg - INFO - Iter [142200/160000]	lr: 6.675e-06, eta: 3:55:46, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.7849, aux.loss_ce: 0.0823, aux.acc_seg: 91.2393, loss: 0.2468
2023-11-27 21:09:52,747 - mmseg - INFO - Iter [142250/160000]	lr: 6.657e-06, eta: 3:55:07, time: 0.782, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1622, decode.acc_seg: 92.8926, aux.loss_ce: 0.0821, aux.acc_seg: 91.4145, loss: 0.2443
2023-11-27 21:10:31,243 - mmseg - INFO - Iter [142300/160000]	lr: 6.638e-06, eta: 3:54:27, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1644, decode.acc_seg: 93.0370, aux.loss_ce: 0.0811, aux.acc_seg: 91.7580, loss: 0.2455
2023-11-27 21:11:10,493 - mmseg - INFO - Iter [142350/160000]	lr: 6.619e-06, eta: 3:53:47, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1728, decode.acc_seg: 92.6762, aux.loss_ce: 0.0856, aux.acc_seg: 91.3257, loss: 0.2584
2023-11-27 21:11:49,021 - mmseg - INFO - Iter [142400/160000]	lr: 6.600e-06, eta: 3:53:07, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1610, decode.acc_seg: 92.9822, aux.loss_ce: 0.0808, aux.acc_seg: 91.6280, loss: 0.2418
2023-11-27 21:12:27,243 - mmseg - INFO - Iter [142450/160000]	lr: 6.582e-06, eta: 3:52:27, time: 0.765, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1708, decode.acc_seg: 92.6474, aux.loss_ce: 0.0851, aux.acc_seg: 91.2596, loss: 0.2559
2023-11-27 21:13:07,183 - mmseg - INFO - Iter [142500/160000]	lr: 6.563e-06, eta: 3:51:47, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.7591, aux.loss_ce: 0.0848, aux.acc_seg: 91.3425, loss: 0.2529
2023-11-27 21:13:43,963 - mmseg - INFO - Iter [142550/160000]	lr: 6.544e-06, eta: 3:51:07, time: 0.736, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.2706, aux.loss_ce: 0.0787, aux.acc_seg: 91.9829, loss: 0.2363
2023-11-27 21:14:24,096 - mmseg - INFO - Iter [142600/160000]	lr: 6.525e-06, eta: 3:50:28, time: 0.802, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 92.8233, aux.loss_ce: 0.0802, aux.acc_seg: 91.5148, loss: 0.2426
2023-11-27 21:15:03,555 - mmseg - INFO - Iter [142650/160000]	lr: 6.507e-06, eta: 3:49:48, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1601, decode.acc_seg: 92.8836, aux.loss_ce: 0.0788, aux.acc_seg: 91.6814, loss: 0.2389
2023-11-27 21:15:41,977 - mmseg - INFO - Iter [142700/160000]	lr: 6.488e-06, eta: 3:49:08, time: 0.769, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1735, decode.acc_seg: 92.4212, aux.loss_ce: 0.0874, aux.acc_seg: 90.9518, loss: 0.2608
2023-11-27 21:16:22,041 - mmseg - INFO - Iter [142750/160000]	lr: 6.469e-06, eta: 3:48:28, time: 0.801, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1615, decode.acc_seg: 93.0470, aux.loss_ce: 0.0798, aux.acc_seg: 91.7693, loss: 0.2414
2023-11-27 21:17:02,606 - mmseg - INFO - Iter [142800/160000]	lr: 6.450e-06, eta: 3:47:49, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1579, decode.acc_seg: 93.0887, aux.loss_ce: 0.0801, aux.acc_seg: 91.6380, loss: 0.2380
2023-11-27 21:17:41,865 - mmseg - INFO - Iter [142850/160000]	lr: 6.432e-06, eta: 3:47:09, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1644, decode.acc_seg: 92.9716, aux.loss_ce: 0.0820, aux.acc_seg: 91.6301, loss: 0.2464
2023-11-27 21:18:21,918 - mmseg - INFO - Iter [142900/160000]	lr: 6.413e-06, eta: 3:46:29, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1700, decode.acc_seg: 92.4650, aux.loss_ce: 0.0839, aux.acc_seg: 91.1272, loss: 0.2540
2023-11-27 21:19:02,506 - mmseg - INFO - Iter [142950/160000]	lr: 6.394e-06, eta: 3:45:49, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.7362, aux.loss_ce: 0.0849, aux.acc_seg: 91.3087, loss: 0.2544
2023-11-27 21:19:41,541 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 21:19:41,541 - mmseg - INFO - Iter [143000/160000]	lr: 6.375e-06, eta: 3:45:10, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1772, decode.acc_seg: 92.5399, aux.loss_ce: 0.0874, aux.acc_seg: 91.2048, loss: 0.2646
2023-11-27 21:20:21,908 - mmseg - INFO - Iter [143050/160000]	lr: 6.357e-06, eta: 3:44:30, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1630, decode.acc_seg: 92.8874, aux.loss_ce: 0.0810, aux.acc_seg: 91.4883, loss: 0.2439
2023-11-27 21:21:02,423 - mmseg - INFO - Iter [143100/160000]	lr: 6.338e-06, eta: 3:43:50, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1732, decode.acc_seg: 92.4375, aux.loss_ce: 0.0862, aux.acc_seg: 90.9560, loss: 0.2594
2023-11-27 21:21:42,445 - mmseg - INFO - Iter [143150/160000]	lr: 6.319e-06, eta: 3:43:11, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1704, decode.acc_seg: 92.6881, aux.loss_ce: 0.0852, aux.acc_seg: 91.3160, loss: 0.2556
2023-11-27 21:22:20,974 - mmseg - INFO - Iter [143200/160000]	lr: 6.300e-06, eta: 3:42:31, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.1607, aux.loss_ce: 0.0782, aux.acc_seg: 91.9678, loss: 0.2357
2023-11-27 21:22:58,114 - mmseg - INFO - Iter [143250/160000]	lr: 6.282e-06, eta: 3:41:51, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1563, decode.acc_seg: 93.4568, aux.loss_ce: 0.0779, aux.acc_seg: 92.0990, loss: 0.2342
2023-11-27 21:23:36,819 - mmseg - INFO - Iter [143300/160000]	lr: 6.263e-06, eta: 3:41:11, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.9439, aux.loss_ce: 0.0825, aux.acc_seg: 91.6664, loss: 0.2485
2023-11-27 21:24:14,074 - mmseg - INFO - Iter [143350/160000]	lr: 6.244e-06, eta: 3:40:31, time: 0.745, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1642, decode.acc_seg: 92.8590, aux.loss_ce: 0.0816, aux.acc_seg: 91.5609, loss: 0.2457
2023-11-27 21:24:51,748 - mmseg - INFO - Iter [143400/160000]	lr: 6.225e-06, eta: 3:39:51, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 92.7939, aux.loss_ce: 0.0799, aux.acc_seg: 91.5073, loss: 0.2428
2023-11-27 21:25:31,943 - mmseg - INFO - Iter [143450/160000]	lr: 6.207e-06, eta: 3:39:11, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1743, decode.acc_seg: 92.3578, aux.loss_ce: 0.0856, aux.acc_seg: 90.9648, loss: 0.2598
2023-11-27 21:26:13,317 - mmseg - INFO - Iter [143500/160000]	lr: 6.188e-06, eta: 3:38:32, time: 0.827, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 93.0157, aux.loss_ce: 0.0799, aux.acc_seg: 91.6510, loss: 0.2415
2023-11-27 21:26:53,586 - mmseg - INFO - Iter [143550/160000]	lr: 6.169e-06, eta: 3:37:52, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1725, decode.acc_seg: 92.5144, aux.loss_ce: 0.0850, aux.acc_seg: 91.2915, loss: 0.2575
2023-11-27 21:27:33,926 - mmseg - INFO - Iter [143600/160000]	lr: 6.150e-06, eta: 3:37:12, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1706, decode.acc_seg: 92.7613, aux.loss_ce: 0.0830, aux.acc_seg: 91.5762, loss: 0.2536
2023-11-27 21:28:14,130 - mmseg - INFO - Iter [143650/160000]	lr: 6.132e-06, eta: 3:36:33, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1675, decode.acc_seg: 93.0202, aux.loss_ce: 0.0825, aux.acc_seg: 91.7679, loss: 0.2500
2023-11-27 21:28:53,995 - mmseg - INFO - Iter [143700/160000]	lr: 6.113e-06, eta: 3:35:53, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1689, decode.acc_seg: 92.7080, aux.loss_ce: 0.0837, aux.acc_seg: 91.3534, loss: 0.2526
2023-11-27 21:29:33,091 - mmseg - INFO - Iter [143750/160000]	lr: 6.094e-06, eta: 3:35:13, time: 0.783, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1808, decode.acc_seg: 92.2517, aux.loss_ce: 0.0879, aux.acc_seg: 90.9202, loss: 0.2688
2023-11-27 21:30:09,729 - mmseg - INFO - Iter [143800/160000]	lr: 6.075e-06, eta: 3:34:33, time: 0.733, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.8892, aux.loss_ce: 0.0812, aux.acc_seg: 91.5884, loss: 0.2457
2023-11-27 21:30:49,019 - mmseg - INFO - Iter [143850/160000]	lr: 6.057e-06, eta: 3:33:53, time: 0.784, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1561, decode.acc_seg: 93.0982, aux.loss_ce: 0.0775, aux.acc_seg: 91.7354, loss: 0.2335
2023-11-27 21:31:26,660 - mmseg - INFO - Iter [143900/160000]	lr: 6.038e-06, eta: 3:33:13, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.7532, aux.loss_ce: 0.0823, aux.acc_seg: 91.5109, loss: 0.2500
2023-11-27 21:32:05,568 - mmseg - INFO - Iter [143950/160000]	lr: 6.019e-06, eta: 3:32:33, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1643, decode.acc_seg: 92.8768, aux.loss_ce: 0.0844, aux.acc_seg: 91.3015, loss: 0.2486
2023-11-27 21:32:47,269 - mmseg - INFO - Saving checkpoint at 144000 iterations
2023-11-27 21:32:51,972 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 21:32:51,972 - mmseg - INFO - Iter [144000/160000]	lr: 6.000e-06, eta: 3:31:54, time: 0.929, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1742, decode.acc_seg: 92.5286, aux.loss_ce: 0.0866, aux.acc_seg: 91.1595, loss: 0.2608
2023-11-27 21:34:25,715 - mmseg - INFO - per class results:
2023-11-27 21:34:25,729 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 78.35 | 88.83 |
|       building      | 80.77 | 90.12 |
|         sky         | 94.61 | 97.65 |
|        floor        | 82.42 | 90.31 |
|         tree        | 75.36 | 87.57 |
|       ceiling       | 85.11 | 92.45 |
|         road        | 84.56 |  89.9 |
|         bed         | 89.32 |  96.1 |
|      windowpane     |  63.0 | 80.35 |
|        grass        | 63.99 | 83.25 |
|       cabinet       | 64.79 | 75.52 |
|       sidewalk      | 68.33 | 84.16 |
|        person       |  82.0 | 93.69 |
|        earth        | 36.19 | 48.66 |
|         door        | 53.26 | 67.68 |
|        table        | 62.21 | 76.69 |
|       mountain      | 59.14 | 74.28 |
|        plant        | 52.61 | 65.85 |
|       curtain       | 76.39 | 88.06 |
|        chair        | 57.72 | 69.74 |
|         car         | 85.43 | 92.84 |
|        water        |  61.2 | 79.55 |
|       painting      | 72.72 | 90.14 |
|         sofa        | 65.81 | 82.29 |
|        shelf        | 45.59 | 62.27 |
|        house        | 38.57 | 59.12 |
|         sea         |  57.0 | 71.48 |
|        mirror       |  69.0 |  76.4 |
|         rug         | 64.65 | 78.67 |
|        field        | 25.34 |  38.7 |
|       armchair      | 42.85 | 64.08 |
|         seat        | 61.74 | 82.55 |
|        fence        | 47.68 | 61.31 |
|         desk        |  51.0 | 72.01 |
|         rock        | 48.45 | 71.81 |
|       wardrobe      | 50.57 | 65.89 |
|         lamp        | 66.19 | 77.55 |
|       bathtub       | 80.58 | 86.62 |
|       railing       | 36.47 |  50.7 |
|       cushion       | 60.62 | 74.51 |
|         base        | 32.75 | 38.31 |
|         box         |  29.2 | 37.74 |
|        column       | 45.56 |  55.6 |
|      signboard      | 41.03 | 55.53 |
|   chest of drawers  | 51.76 | 70.97 |
|       counter       | 36.46 | 43.55 |
|         sand        | 47.98 | 69.11 |
|         sink        | 72.68 | 79.71 |
|      skyscraper     | 47.13 | 58.07 |
|      fireplace      | 72.17 | 89.71 |
|     refrigerator    | 77.25 | 89.09 |
|      grandstand     | 44.78 | 71.24 |
|         path        | 25.83 | 37.75 |
|        stairs       | 31.56 | 41.44 |
|        runway       | 69.11 | 90.93 |
|         case        |  61.2 | 73.34 |
|      pool table     | 93.43 | 96.87 |
|        pillow       | 61.31 | 72.97 |
|     screen door     | 65.75 | 77.31 |
|       stairway      | 30.06 | 39.61 |
|        river        | 12.93 | 24.87 |
|        bridge       | 76.59 | 85.75 |
|       bookcase      | 43.07 | 64.47 |
|        blind        | 41.76 | 45.91 |
|     coffee table    | 57.55 | 79.37 |
|        toilet       | 79.49 | 91.07 |
|        flower       | 44.74 | 59.56 |
|         book        | 45.15 | 66.17 |
|         hill        |  9.41 | 12.57 |
|        bench        | 48.01 | 53.88 |
|      countertop     |  55.2 | 78.72 |
|        stove        | 73.51 | 80.67 |
|         palm        | 53.71 | 78.07 |
|    kitchen island   |  48.1 | 87.46 |
|       computer      | 65.53 | 77.34 |
|     swivel chair    | 45.46 | 66.97 |
|         boat        |  46.6 | 54.55 |
|         bar         |  46.1 | 65.38 |
|    arcade machine   | 53.86 | 57.59 |
|        hovel        |  44.3 | 63.94 |
|         bus         | 85.66 | 96.67 |
|        towel        | 68.86 |  80.4 |
|        light        | 57.43 | 64.61 |
|        truck        | 40.58 | 49.95 |
|        tower        | 21.53 | 38.09 |
|      chandelier     | 67.13 |  84.5 |
|        awning       | 29.15 | 38.86 |
|     streetlight     | 29.16 | 39.02 |
|        booth        | 51.86 | 54.04 |
| television receiver | 68.29 | 79.96 |
|       airplane      | 56.97 | 69.45 |
|      dirt track     |  4.84 |  8.85 |
|       apparel       | 46.14 | 62.36 |
|         pole        | 27.67 | 40.25 |
|         land        |  4.75 |  7.03 |
|      bannister      | 16.34 |  21.6 |
|      escalator      | 37.89 | 54.52 |
|       ottoman       | 47.72 | 58.65 |
|        bottle       | 35.77 | 60.58 |
|        buffet       |  45.4 |  56.0 |
|        poster       | 33.67 | 41.36 |
|        stage        | 20.03 | 29.32 |
|         van         | 43.45 | 62.98 |
|         ship        | 35.71 | 56.63 |
|       fountain      | 21.54 | 21.79 |
|    conveyer belt    | 73.73 | 88.24 |
|        canopy       |  14.8 | 21.42 |
|        washer       | 70.89 | 76.96 |
|      plaything      | 32.07 | 43.29 |
|    swimming pool    | 65.19 | 90.65 |
|        stool        |  43.0 | 55.16 |
|        barrel       | 48.65 | 69.58 |
|        basket       | 38.11 |  52.1 |
|      waterfall      | 64.16 | 88.47 |
|         tent        | 94.07 | 98.88 |
|         bag         | 14.79 | 18.09 |
|       minibike      | 72.54 | 85.58 |
|        cradle       | 74.47 | 85.96 |
|         oven        | 50.94 | 58.27 |
|         ball        | 47.96 |  60.1 |
|         food        | 54.62 | 65.15 |
|         step        | 18.95 | 22.06 |
|         tank        | 44.94 | 51.87 |
|      trade name     | 27.45 | 32.16 |
|      microwave      | 84.15 | 94.16 |
|         pot         | 45.28 | 52.87 |
|        animal       | 61.01 | 64.08 |
|       bicycle       | 57.88 | 78.76 |
|         lake        | 60.28 | 65.69 |
|      dishwasher     | 69.14 | 77.03 |
|        screen       | 68.12 | 87.94 |
|       blanket       | 13.58 | 16.85 |
|      sculpture      | 59.08 |  78.8 |
|         hood        | 66.98 | 74.12 |
|        sconce       | 48.68 | 58.02 |
|         vase        | 41.64 |  56.5 |
|    traffic light    | 35.66 | 53.91 |
|         tray        | 12.18 | 17.21 |
|        ashcan       | 37.06 | 50.99 |
|         fan         | 64.03 |  77.1 |
|         pier        | 43.31 | 56.08 |
|      crt screen     |  4.55 | 11.98 |
|        plate        | 56.18 | 72.89 |
|       monitor       |  7.07 | 10.16 |
|    bulletin board   | 49.49 | 64.27 |
|        shower       |  6.56 |  7.79 |
|       radiator      | 68.85 | 73.16 |
|        glass        | 16.55 | 17.44 |
|        clock        | 35.15 | 50.17 |
|         flag        | 54.39 | 61.06 |
+---------------------+-------+-------+
2023-11-27 21:34:25,729 - mmseg - INFO - Summary:
2023-11-27 21:34:25,730 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.61 | 51.24 | 63.55 |
+-------+-------+-------+
2023-11-27 21:34:25,758 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 21:34:25,759 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8361, mIoU: 0.5124, mAcc: 0.6355, IoU.wall: 0.7835, IoU.building: 0.8077, IoU.sky: 0.9461, IoU.floor: 0.8242, IoU.tree: 0.7536, IoU.ceiling: 0.8511, IoU.road: 0.8456, IoU.bed : 0.8932, IoU.windowpane: 0.6300, IoU.grass: 0.6399, IoU.cabinet: 0.6479, IoU.sidewalk: 0.6833, IoU.person: 0.8200, IoU.earth: 0.3619, IoU.door: 0.5326, IoU.table: 0.6221, IoU.mountain: 0.5914, IoU.plant: 0.5261, IoU.curtain: 0.7639, IoU.chair: 0.5772, IoU.car: 0.8543, IoU.water: 0.6120, IoU.painting: 0.7272, IoU.sofa: 0.6581, IoU.shelf: 0.4559, IoU.house: 0.3857, IoU.sea: 0.5700, IoU.mirror: 0.6900, IoU.rug: 0.6465, IoU.field: 0.2534, IoU.armchair: 0.4285, IoU.seat: 0.6174, IoU.fence: 0.4768, IoU.desk: 0.5100, IoU.rock: 0.4845, IoU.wardrobe: 0.5057, IoU.lamp: 0.6619, IoU.bathtub: 0.8058, IoU.railing: 0.3647, IoU.cushion: 0.6062, IoU.base: 0.3275, IoU.box: 0.2920, IoU.column: 0.4556, IoU.signboard: 0.4103, IoU.chest of drawers: 0.5176, IoU.counter: 0.3646, IoU.sand: 0.4798, IoU.sink: 0.7268, IoU.skyscraper: 0.4713, IoU.fireplace: 0.7217, IoU.refrigerator: 0.7725, IoU.grandstand: 0.4478, IoU.path: 0.2583, IoU.stairs: 0.3156, IoU.runway: 0.6911, IoU.case: 0.6120, IoU.pool table: 0.9343, IoU.pillow: 0.6131, IoU.screen door: 0.6575, IoU.stairway: 0.3006, IoU.river: 0.1293, IoU.bridge: 0.7659, IoU.bookcase: 0.4307, IoU.blind: 0.4176, IoU.coffee table: 0.5755, IoU.toilet: 0.7949, IoU.flower: 0.4474, IoU.book: 0.4515, IoU.hill: 0.0941, IoU.bench: 0.4801, IoU.countertop: 0.5520, IoU.stove: 0.7351, IoU.palm: 0.5371, IoU.kitchen island: 0.4810, IoU.computer: 0.6553, IoU.swivel chair: 0.4546, IoU.boat: 0.4660, IoU.bar: 0.4610, IoU.arcade machine: 0.5386, IoU.hovel: 0.4430, IoU.bus: 0.8566, IoU.towel: 0.6886, IoU.light: 0.5743, IoU.truck: 0.4058, IoU.tower: 0.2153, IoU.chandelier: 0.6713, IoU.awning: 0.2915, IoU.streetlight: 0.2916, IoU.booth: 0.5186, IoU.television receiver: 0.6829, IoU.airplane: 0.5697, IoU.dirt track: 0.0484, IoU.apparel: 0.4614, IoU.pole: 0.2767, IoU.land: 0.0475, IoU.bannister: 0.1634, IoU.escalator: 0.3789, IoU.ottoman: 0.4772, IoU.bottle: 0.3577, IoU.buffet: 0.4540, IoU.poster: 0.3367, IoU.stage: 0.2003, IoU.van: 0.4345, IoU.ship: 0.3571, IoU.fountain: 0.2154, IoU.conveyer belt: 0.7373, IoU.canopy: 0.1480, IoU.washer: 0.7089, IoU.plaything: 0.3207, IoU.swimming pool: 0.6519, IoU.stool: 0.4300, IoU.barrel: 0.4865, IoU.basket: 0.3811, IoU.waterfall: 0.6416, IoU.tent: 0.9407, IoU.bag: 0.1479, IoU.minibike: 0.7254, IoU.cradle: 0.7447, IoU.oven: 0.5094, IoU.ball: 0.4796, IoU.food: 0.5462, IoU.step: 0.1895, IoU.tank: 0.4494, IoU.trade name: 0.2745, IoU.microwave: 0.8415, IoU.pot: 0.4528, IoU.animal: 0.6101, IoU.bicycle: 0.5788, IoU.lake: 0.6028, IoU.dishwasher: 0.6914, IoU.screen: 0.6812, IoU.blanket: 0.1358, IoU.sculpture: 0.5908, IoU.hood: 0.6698, IoU.sconce: 0.4868, IoU.vase: 0.4164, IoU.traffic light: 0.3566, IoU.tray: 0.1218, IoU.ashcan: 0.3706, IoU.fan: 0.6403, IoU.pier: 0.4331, IoU.crt screen: 0.0455, IoU.plate: 0.5618, IoU.monitor: 0.0707, IoU.bulletin board: 0.4949, IoU.shower: 0.0656, IoU.radiator: 0.6885, IoU.glass: 0.1655, IoU.clock: 0.3515, IoU.flag: 0.5439, Acc.wall: 0.8883, Acc.building: 0.9012, Acc.sky: 0.9765, Acc.floor: 0.9031, Acc.tree: 0.8757, Acc.ceiling: 0.9245, Acc.road: 0.8990, Acc.bed : 0.9610, Acc.windowpane: 0.8035, Acc.grass: 0.8325, Acc.cabinet: 0.7552, Acc.sidewalk: 0.8416, Acc.person: 0.9369, Acc.earth: 0.4866, Acc.door: 0.6768, Acc.table: 0.7669, Acc.mountain: 0.7428, Acc.plant: 0.6585, Acc.curtain: 0.8806, Acc.chair: 0.6974, Acc.car: 0.9284, Acc.water: 0.7955, Acc.painting: 0.9014, Acc.sofa: 0.8229, Acc.shelf: 0.6227, Acc.house: 0.5912, Acc.sea: 0.7148, Acc.mirror: 0.7640, Acc.rug: 0.7867, Acc.field: 0.3870, Acc.armchair: 0.6408, Acc.seat: 0.8255, Acc.fence: 0.6131, Acc.desk: 0.7201, Acc.rock: 0.7181, Acc.wardrobe: 0.6589, Acc.lamp: 0.7755, Acc.bathtub: 0.8662, Acc.railing: 0.5070, Acc.cushion: 0.7451, Acc.base: 0.3831, Acc.box: 0.3774, Acc.column: 0.5560, Acc.signboard: 0.5553, Acc.chest of drawers: 0.7097, Acc.counter: 0.4355, Acc.sand: 0.6911, Acc.sink: 0.7971, Acc.skyscraper: 0.5807, Acc.fireplace: 0.8971, Acc.refrigerator: 0.8909, Acc.grandstand: 0.7124, Acc.path: 0.3775, Acc.stairs: 0.4144, Acc.runway: 0.9093, Acc.case: 0.7334, Acc.pool table: 0.9687, Acc.pillow: 0.7297, Acc.screen door: 0.7731, Acc.stairway: 0.3961, Acc.river: 0.2487, Acc.bridge: 0.8575, Acc.bookcase: 0.6447, Acc.blind: 0.4591, Acc.coffee table: 0.7937, Acc.toilet: 0.9107, Acc.flower: 0.5956, Acc.book: 0.6617, Acc.hill: 0.1257, Acc.bench: 0.5388, Acc.countertop: 0.7872, Acc.stove: 0.8067, Acc.palm: 0.7807, Acc.kitchen island: 0.8746, Acc.computer: 0.7734, Acc.swivel chair: 0.6697, Acc.boat: 0.5455, Acc.bar: 0.6538, Acc.arcade machine: 0.5759, Acc.hovel: 0.6394, Acc.bus: 0.9667, Acc.towel: 0.8040, Acc.light: 0.6461, Acc.truck: 0.4995, Acc.tower: 0.3809, Acc.chandelier: 0.8450, Acc.awning: 0.3886, Acc.streetlight: 0.3902, Acc.booth: 0.5404, Acc.television receiver: 0.7996, Acc.airplane: 0.6945, Acc.dirt track: 0.0885, Acc.apparel: 0.6236, Acc.pole: 0.4025, Acc.land: 0.0703, Acc.bannister: 0.2160, Acc.escalator: 0.5452, Acc.ottoman: 0.5865, Acc.bottle: 0.6058, Acc.buffet: 0.5600, Acc.poster: 0.4136, Acc.stage: 0.2932, Acc.van: 0.6298, Acc.ship: 0.5663, Acc.fountain: 0.2179, Acc.conveyer belt: 0.8824, Acc.canopy: 0.2142, Acc.washer: 0.7696, Acc.plaything: 0.4329, Acc.swimming pool: 0.9065, Acc.stool: 0.5516, Acc.barrel: 0.6958, Acc.basket: 0.5210, Acc.waterfall: 0.8847, Acc.tent: 0.9888, Acc.bag: 0.1809, Acc.minibike: 0.8558, Acc.cradle: 0.8596, Acc.oven: 0.5827, Acc.ball: 0.6010, Acc.food: 0.6515, Acc.step: 0.2206, Acc.tank: 0.5187, Acc.trade name: 0.3216, Acc.microwave: 0.9416, Acc.pot: 0.5287, Acc.animal: 0.6408, Acc.bicycle: 0.7876, Acc.lake: 0.6569, Acc.dishwasher: 0.7703, Acc.screen: 0.8794, Acc.blanket: 0.1685, Acc.sculpture: 0.7880, Acc.hood: 0.7412, Acc.sconce: 0.5802, Acc.vase: 0.5650, Acc.traffic light: 0.5391, Acc.tray: 0.1721, Acc.ashcan: 0.5099, Acc.fan: 0.7710, Acc.pier: 0.5608, Acc.crt screen: 0.1198, Acc.plate: 0.7289, Acc.monitor: 0.1016, Acc.bulletin board: 0.6427, Acc.shower: 0.0779, Acc.radiator: 0.7316, Acc.glass: 0.1744, Acc.clock: 0.5017, Acc.flag: 0.6106
2023-11-27 21:35:05,067 - mmseg - INFO - Iter [144050/160000]	lr: 5.982e-06, eta: 3:31:25, time: 2.662, data_time: 1.886, memory: 21695, decode.loss_ce: 0.1710, decode.acc_seg: 92.7947, aux.loss_ce: 0.0828, aux.acc_seg: 91.6395, loss: 0.2538
2023-11-27 21:35:45,203 - mmseg - INFO - Iter [144100/160000]	lr: 5.963e-06, eta: 3:30:45, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1738, decode.acc_seg: 92.4828, aux.loss_ce: 0.0863, aux.acc_seg: 90.9712, loss: 0.2601
2023-11-27 21:36:22,171 - mmseg - INFO - Iter [144150/160000]	lr: 5.944e-06, eta: 3:30:05, time: 0.739, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1658, decode.acc_seg: 92.9760, aux.loss_ce: 0.0821, aux.acc_seg: 91.6578, loss: 0.2479
2023-11-27 21:37:00,968 - mmseg - INFO - Iter [144200/160000]	lr: 5.925e-06, eta: 3:29:25, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1601, decode.acc_seg: 92.9883, aux.loss_ce: 0.0798, aux.acc_seg: 91.5752, loss: 0.2398
2023-11-27 21:37:40,795 - mmseg - INFO - Iter [144250/160000]	lr: 5.907e-06, eta: 3:28:46, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1640, decode.acc_seg: 92.9351, aux.loss_ce: 0.0839, aux.acc_seg: 91.3224, loss: 0.2479
2023-11-27 21:38:19,281 - mmseg - INFO - Iter [144300/160000]	lr: 5.888e-06, eta: 3:28:06, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1686, decode.acc_seg: 92.5378, aux.loss_ce: 0.0826, aux.acc_seg: 91.2714, loss: 0.2513
2023-11-27 21:38:59,989 - mmseg - INFO - Iter [144350/160000]	lr: 5.869e-06, eta: 3:27:26, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1745, decode.acc_seg: 92.4687, aux.loss_ce: 0.0875, aux.acc_seg: 90.9931, loss: 0.2620
2023-11-27 21:39:40,105 - mmseg - INFO - Iter [144400/160000]	lr: 5.850e-06, eta: 3:26:46, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1725, decode.acc_seg: 92.4977, aux.loss_ce: 0.0845, aux.acc_seg: 91.1558, loss: 0.2570
2023-11-27 21:40:19,933 - mmseg - INFO - Iter [144450/160000]	lr: 5.832e-06, eta: 3:26:07, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.8179, aux.loss_ce: 0.0826, aux.acc_seg: 91.5211, loss: 0.2507
2023-11-27 21:41:00,129 - mmseg - INFO - Iter [144500/160000]	lr: 5.813e-06, eta: 3:25:27, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.4147, aux.loss_ce: 0.0843, aux.acc_seg: 91.0042, loss: 0.2531
2023-11-27 21:41:38,276 - mmseg - INFO - Iter [144550/160000]	lr: 5.794e-06, eta: 3:24:47, time: 0.762, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1608, decode.acc_seg: 93.1465, aux.loss_ce: 0.0813, aux.acc_seg: 91.7490, loss: 0.2422
2023-11-27 21:42:18,417 - mmseg - INFO - Iter [144600/160000]	lr: 5.775e-06, eta: 3:24:07, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1672, decode.acc_seg: 92.6780, aux.loss_ce: 0.0828, aux.acc_seg: 91.2796, loss: 0.2500
2023-11-27 21:42:58,654 - mmseg - INFO - Iter [144650/160000]	lr: 5.757e-06, eta: 3:23:27, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1662, decode.acc_seg: 92.7298, aux.loss_ce: 0.0829, aux.acc_seg: 91.3318, loss: 0.2491
2023-11-27 21:43:38,903 - mmseg - INFO - Iter [144700/160000]	lr: 5.738e-06, eta: 3:22:48, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1675, decode.acc_seg: 92.8590, aux.loss_ce: 0.0828, aux.acc_seg: 91.5088, loss: 0.2503
2023-11-27 21:44:15,922 - mmseg - INFO - Iter [144750/160000]	lr: 5.719e-06, eta: 3:22:08, time: 0.741, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1578, decode.acc_seg: 93.0340, aux.loss_ce: 0.0786, aux.acc_seg: 91.7385, loss: 0.2364
2023-11-27 21:44:52,923 - mmseg - INFO - Iter [144800/160000]	lr: 5.700e-06, eta: 3:21:28, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1667, decode.acc_seg: 92.8699, aux.loss_ce: 0.0829, aux.acc_seg: 91.5288, loss: 0.2495
2023-11-27 21:45:32,039 - mmseg - INFO - Iter [144850/160000]	lr: 5.682e-06, eta: 3:20:48, time: 0.781, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1678, decode.acc_seg: 92.7550, aux.loss_ce: 0.0826, aux.acc_seg: 91.5048, loss: 0.2504
2023-11-27 21:46:12,101 - mmseg - INFO - Iter [144900/160000]	lr: 5.663e-06, eta: 3:20:08, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1649, decode.acc_seg: 92.7378, aux.loss_ce: 0.0816, aux.acc_seg: 91.3502, loss: 0.2465
2023-11-27 21:46:50,451 - mmseg - INFO - Iter [144950/160000]	lr: 5.644e-06, eta: 3:19:28, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1681, decode.acc_seg: 92.6340, aux.loss_ce: 0.0829, aux.acc_seg: 91.2277, loss: 0.2511
2023-11-27 21:47:30,378 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 21:47:30,378 - mmseg - INFO - Iter [145000/160000]	lr: 5.625e-06, eta: 3:18:48, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 93.0839, aux.loss_ce: 0.0798, aux.acc_seg: 91.7244, loss: 0.2426
2023-11-27 21:48:10,263 - mmseg - INFO - Iter [145050/160000]	lr: 5.607e-06, eta: 3:18:09, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1529, decode.acc_seg: 93.2078, aux.loss_ce: 0.0764, aux.acc_seg: 91.7421, loss: 0.2293
2023-11-27 21:48:47,656 - mmseg - INFO - Iter [145100/160000]	lr: 5.588e-06, eta: 3:17:29, time: 0.748, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1657, decode.acc_seg: 92.7254, aux.loss_ce: 0.0811, aux.acc_seg: 91.4753, loss: 0.2468
2023-11-27 21:49:26,021 - mmseg - INFO - Iter [145150/160000]	lr: 5.569e-06, eta: 3:16:49, time: 0.768, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1656, decode.acc_seg: 92.8321, aux.loss_ce: 0.0818, aux.acc_seg: 91.4623, loss: 0.2474
2023-11-27 21:50:04,770 - mmseg - INFO - Iter [145200/160000]	lr: 5.550e-06, eta: 3:16:09, time: 0.774, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1687, decode.acc_seg: 92.7704, aux.loss_ce: 0.0841, aux.acc_seg: 91.3894, loss: 0.2528
2023-11-27 21:50:46,476 - mmseg - INFO - Iter [145250/160000]	lr: 5.532e-06, eta: 3:15:29, time: 0.835, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1615, decode.acc_seg: 92.8202, aux.loss_ce: 0.0810, aux.acc_seg: 91.3440, loss: 0.2425
2023-11-27 21:51:23,674 - mmseg - INFO - Iter [145300/160000]	lr: 5.513e-06, eta: 3:14:49, time: 0.744, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1588, decode.acc_seg: 93.2570, aux.loss_ce: 0.0790, aux.acc_seg: 91.9686, loss: 0.2378
2023-11-27 21:52:02,500 - mmseg - INFO - Iter [145350/160000]	lr: 5.494e-06, eta: 3:14:09, time: 0.777, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1610, decode.acc_seg: 93.0584, aux.loss_ce: 0.0804, aux.acc_seg: 91.7729, loss: 0.2414
2023-11-27 21:52:42,046 - mmseg - INFO - Iter [145400/160000]	lr: 5.475e-06, eta: 3:13:30, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1765, decode.acc_seg: 92.4041, aux.loss_ce: 0.0871, aux.acc_seg: 90.9707, loss: 0.2636
2023-11-27 21:53:20,263 - mmseg - INFO - Iter [145450/160000]	lr: 5.457e-06, eta: 3:12:50, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.7317, aux.loss_ce: 0.0810, aux.acc_seg: 91.5456, loss: 0.2455
2023-11-27 21:53:58,818 - mmseg - INFO - Iter [145500/160000]	lr: 5.438e-06, eta: 3:12:10, time: 0.771, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1672, decode.acc_seg: 92.6063, aux.loss_ce: 0.0829, aux.acc_seg: 91.2127, loss: 0.2501
2023-11-27 21:54:37,724 - mmseg - INFO - Iter [145550/160000]	lr: 5.419e-06, eta: 3:11:30, time: 0.778, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1691, decode.acc_seg: 93.0150, aux.loss_ce: 0.0843, aux.acc_seg: 91.5420, loss: 0.2533
2023-11-27 21:55:18,270 - mmseg - INFO - Iter [145600/160000]	lr: 5.400e-06, eta: 3:10:50, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1642, decode.acc_seg: 93.1159, aux.loss_ce: 0.0819, aux.acc_seg: 91.7224, loss: 0.2461
2023-11-27 21:55:58,093 - mmseg - INFO - Iter [145650/160000]	lr: 5.382e-06, eta: 3:10:11, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 92.9940, aux.loss_ce: 0.0813, aux.acc_seg: 91.7595, loss: 0.2464
2023-11-27 21:56:35,222 - mmseg - INFO - Iter [145700/160000]	lr: 5.363e-06, eta: 3:09:31, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1748, decode.acc_seg: 92.7131, aux.loss_ce: 0.0862, aux.acc_seg: 91.3434, loss: 0.2610
2023-11-27 21:57:12,151 - mmseg - INFO - Iter [145750/160000]	lr: 5.344e-06, eta: 3:08:51, time: 0.738, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.8338, aux.loss_ce: 0.0824, aux.acc_seg: 91.5958, loss: 0.2517
2023-11-27 21:57:49,379 - mmseg - INFO - Iter [145800/160000]	lr: 5.325e-06, eta: 3:08:11, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1667, decode.acc_seg: 92.9013, aux.loss_ce: 0.0824, aux.acc_seg: 91.5557, loss: 0.2490
2023-11-27 21:58:29,250 - mmseg - INFO - Iter [145850/160000]	lr: 5.307e-06, eta: 3:07:31, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.8062, aux.loss_ce: 0.0822, aux.acc_seg: 91.4599, loss: 0.2483
2023-11-27 21:59:09,219 - mmseg - INFO - Iter [145900/160000]	lr: 5.288e-06, eta: 3:06:51, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1773, decode.acc_seg: 92.5133, aux.loss_ce: 0.0880, aux.acc_seg: 91.0408, loss: 0.2653
2023-11-27 21:59:49,268 - mmseg - INFO - Iter [145950/160000]	lr: 5.269e-06, eta: 3:06:11, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1605, decode.acc_seg: 93.1431, aux.loss_ce: 0.0793, aux.acc_seg: 91.8854, loss: 0.2398
2023-11-27 22:00:28,788 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 22:00:28,788 - mmseg - INFO - Iter [146000/160000]	lr: 5.250e-06, eta: 3:05:32, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 92.9363, aux.loss_ce: 0.0819, aux.acc_seg: 91.3703, loss: 0.2443
2023-11-27 22:01:06,701 - mmseg - INFO - Iter [146050/160000]	lr: 5.232e-06, eta: 3:04:52, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1734, decode.acc_seg: 92.6957, aux.loss_ce: 0.0863, aux.acc_seg: 91.3184, loss: 0.2597
2023-11-27 22:01:47,357 - mmseg - INFO - Iter [146100/160000]	lr: 5.213e-06, eta: 3:04:12, time: 0.812, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1687, decode.acc_seg: 92.6803, aux.loss_ce: 0.0829, aux.acc_seg: 91.4728, loss: 0.2516
2023-11-27 22:02:27,337 - mmseg - INFO - Iter [146150/160000]	lr: 5.194e-06, eta: 3:03:32, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1655, decode.acc_seg: 92.7807, aux.loss_ce: 0.0814, aux.acc_seg: 91.5248, loss: 0.2469
2023-11-27 22:03:08,048 - mmseg - INFO - Iter [146200/160000]	lr: 5.175e-06, eta: 3:02:52, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1655, decode.acc_seg: 92.7749, aux.loss_ce: 0.0824, aux.acc_seg: 91.3782, loss: 0.2479
2023-11-27 22:03:48,393 - mmseg - INFO - Iter [146250/160000]	lr: 5.157e-06, eta: 3:02:13, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1703, decode.acc_seg: 92.7300, aux.loss_ce: 0.0840, aux.acc_seg: 91.3990, loss: 0.2543
2023-11-27 22:04:28,123 - mmseg - INFO - Iter [146300/160000]	lr: 5.138e-06, eta: 3:01:33, time: 0.795, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1674, decode.acc_seg: 92.9265, aux.loss_ce: 0.0832, aux.acc_seg: 91.4752, loss: 0.2506
2023-11-27 22:05:06,868 - mmseg - INFO - Iter [146350/160000]	lr: 5.119e-06, eta: 3:00:53, time: 0.776, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1598, decode.acc_seg: 93.0262, aux.loss_ce: 0.0790, aux.acc_seg: 91.7943, loss: 0.2388
2023-11-27 22:05:44,280 - mmseg - INFO - Iter [146400/160000]	lr: 5.100e-06, eta: 3:00:13, time: 0.747, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1701, decode.acc_seg: 92.7812, aux.loss_ce: 0.0852, aux.acc_seg: 91.2394, loss: 0.2553
2023-11-27 22:06:24,763 - mmseg - INFO - Iter [146450/160000]	lr: 5.082e-06, eta: 2:59:34, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1619, decode.acc_seg: 92.9388, aux.loss_ce: 0.0812, aux.acc_seg: 91.5286, loss: 0.2431
2023-11-27 22:07:02,798 - mmseg - INFO - Iter [146500/160000]	lr: 5.063e-06, eta: 2:58:54, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1668, decode.acc_seg: 92.7064, aux.loss_ce: 0.0833, aux.acc_seg: 91.2930, loss: 0.2501
2023-11-27 22:07:44,739 - mmseg - INFO - Iter [146550/160000]	lr: 5.044e-06, eta: 2:58:14, time: 0.839, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1743, decode.acc_seg: 92.6596, aux.loss_ce: 0.0852, aux.acc_seg: 91.4557, loss: 0.2595
2023-11-27 22:08:24,647 - mmseg - INFO - Iter [146600/160000]	lr: 5.025e-06, eta: 2:57:34, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1762, decode.acc_seg: 92.4250, aux.loss_ce: 0.0890, aux.acc_seg: 90.9671, loss: 0.2652
2023-11-27 22:09:01,828 - mmseg - INFO - Iter [146650/160000]	lr: 5.007e-06, eta: 2:56:54, time: 0.745, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1622, decode.acc_seg: 92.9586, aux.loss_ce: 0.0814, aux.acc_seg: 91.5300, loss: 0.2436
2023-11-27 22:09:41,032 - mmseg - INFO - Iter [146700/160000]	lr: 4.988e-06, eta: 2:56:15, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1754, decode.acc_seg: 92.6146, aux.loss_ce: 0.0877, aux.acc_seg: 91.1260, loss: 0.2631
2023-11-27 22:10:20,942 - mmseg - INFO - Iter [146750/160000]	lr: 4.969e-06, eta: 2:55:35, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.5851, aux.loss_ce: 0.0816, aux.acc_seg: 91.3660, loss: 0.2469
2023-11-27 22:10:59,873 - mmseg - INFO - Iter [146800/160000]	lr: 4.950e-06, eta: 2:54:55, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1637, decode.acc_seg: 92.8699, aux.loss_ce: 0.0804, aux.acc_seg: 91.6136, loss: 0.2441
2023-11-27 22:11:40,884 - mmseg - INFO - Iter [146850/160000]	lr: 4.932e-06, eta: 2:54:15, time: 0.820, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1671, decode.acc_seg: 92.6929, aux.loss_ce: 0.0836, aux.acc_seg: 91.2545, loss: 0.2506
2023-11-27 22:12:21,458 - mmseg - INFO - Iter [146900/160000]	lr: 4.913e-06, eta: 2:53:36, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1578, decode.acc_seg: 93.2635, aux.loss_ce: 0.0787, aux.acc_seg: 91.9520, loss: 0.2364
2023-11-27 22:13:02,425 - mmseg - INFO - Iter [146950/160000]	lr: 4.894e-06, eta: 2:52:56, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 93.0248, aux.loss_ce: 0.0792, aux.acc_seg: 91.8404, loss: 0.2408
2023-11-27 22:13:43,461 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 22:13:43,461 - mmseg - INFO - Iter [147000/160000]	lr: 4.875e-06, eta: 2:52:16, time: 0.821, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1587, decode.acc_seg: 93.0690, aux.loss_ce: 0.0791, aux.acc_seg: 91.6866, loss: 0.2378
2023-11-27 22:14:24,244 - mmseg - INFO - Iter [147050/160000]	lr: 4.857e-06, eta: 2:51:37, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1771, decode.acc_seg: 92.4261, aux.loss_ce: 0.0872, aux.acc_seg: 91.0693, loss: 0.2643
2023-11-27 22:15:05,113 - mmseg - INFO - Iter [147100/160000]	lr: 4.838e-06, eta: 2:50:57, time: 0.817, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.8481, aux.loss_ce: 0.0820, aux.acc_seg: 91.4257, loss: 0.2481
2023-11-27 22:15:43,403 - mmseg - INFO - Iter [147150/160000]	lr: 4.819e-06, eta: 2:50:17, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1623, decode.acc_seg: 93.0548, aux.loss_ce: 0.0802, aux.acc_seg: 91.8111, loss: 0.2425
2023-11-27 22:16:21,845 - mmseg - INFO - Iter [147200/160000]	lr: 4.800e-06, eta: 2:49:37, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1741, decode.acc_seg: 92.6953, aux.loss_ce: 0.0852, aux.acc_seg: 91.3917, loss: 0.2593
2023-11-27 22:17:00,823 - mmseg - INFO - Iter [147250/160000]	lr: 4.782e-06, eta: 2:48:57, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1651, decode.acc_seg: 93.0016, aux.loss_ce: 0.0811, aux.acc_seg: 91.6750, loss: 0.2461
2023-11-27 22:17:40,907 - mmseg - INFO - Iter [147300/160000]	lr: 4.763e-06, eta: 2:48:18, time: 0.802, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.7179, aux.loss_ce: 0.0838, aux.acc_seg: 91.2930, loss: 0.2526
2023-11-27 22:18:20,951 - mmseg - INFO - Iter [147350/160000]	lr: 4.744e-06, eta: 2:47:38, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.7437, aux.loss_ce: 0.0834, aux.acc_seg: 91.3201, loss: 0.2510
2023-11-27 22:19:00,872 - mmseg - INFO - Iter [147400/160000]	lr: 4.725e-06, eta: 2:46:58, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1587, decode.acc_seg: 93.1697, aux.loss_ce: 0.0786, aux.acc_seg: 91.9310, loss: 0.2373
2023-11-27 22:19:41,235 - mmseg - INFO - Iter [147450/160000]	lr: 4.707e-06, eta: 2:46:19, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.7449, aux.loss_ce: 0.0845, aux.acc_seg: 91.2769, loss: 0.2538
2023-11-27 22:20:18,128 - mmseg - INFO - Iter [147500/160000]	lr: 4.688e-06, eta: 2:45:39, time: 0.739, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1742, decode.acc_seg: 92.3973, aux.loss_ce: 0.0857, aux.acc_seg: 91.1682, loss: 0.2599
2023-11-27 22:20:58,400 - mmseg - INFO - Iter [147550/160000]	lr: 4.669e-06, eta: 2:44:59, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1780, decode.acc_seg: 92.3666, aux.loss_ce: 0.0887, aux.acc_seg: 90.9433, loss: 0.2668
2023-11-27 22:21:38,206 - mmseg - INFO - Iter [147600/160000]	lr: 4.650e-06, eta: 2:44:19, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1635, decode.acc_seg: 93.0408, aux.loss_ce: 0.0801, aux.acc_seg: 91.7625, loss: 0.2437
2023-11-27 22:22:17,906 - mmseg - INFO - Iter [147650/160000]	lr: 4.632e-06, eta: 2:43:39, time: 0.793, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1537, decode.acc_seg: 93.1733, aux.loss_ce: 0.0773, aux.acc_seg: 91.7975, loss: 0.2310
2023-11-27 22:22:58,775 - mmseg - INFO - Iter [147700/160000]	lr: 4.613e-06, eta: 2:43:00, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1676, decode.acc_seg: 92.7689, aux.loss_ce: 0.0830, aux.acc_seg: 91.5011, loss: 0.2506
2023-11-27 22:23:38,832 - mmseg - INFO - Iter [147750/160000]	lr: 4.594e-06, eta: 2:42:20, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 93.0365, aux.loss_ce: 0.0813, aux.acc_seg: 91.7913, loss: 0.2437
2023-11-27 22:24:19,947 - mmseg - INFO - Iter [147800/160000]	lr: 4.575e-06, eta: 2:41:40, time: 0.822, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 92.8121, aux.loss_ce: 0.0810, aux.acc_seg: 91.4227, loss: 0.2434
2023-11-27 22:25:00,199 - mmseg - INFO - Iter [147850/160000]	lr: 4.557e-06, eta: 2:41:01, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.2787, aux.loss_ce: 0.0790, aux.acc_seg: 91.9139, loss: 0.2366
2023-11-27 22:25:39,916 - mmseg - INFO - Iter [147900/160000]	lr: 4.538e-06, eta: 2:40:21, time: 0.794, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1686, decode.acc_seg: 92.6466, aux.loss_ce: 0.0827, aux.acc_seg: 91.4455, loss: 0.2513
2023-11-27 22:26:20,146 - mmseg - INFO - Iter [147950/160000]	lr: 4.519e-06, eta: 2:39:41, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1554, decode.acc_seg: 93.1533, aux.loss_ce: 0.0778, aux.acc_seg: 91.8998, loss: 0.2332
2023-11-27 22:26:59,710 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 22:26:59,710 - mmseg - INFO - Iter [148000/160000]	lr: 4.500e-06, eta: 2:39:01, time: 0.791, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1755, decode.acc_seg: 92.5440, aux.loss_ce: 0.0854, aux.acc_seg: 91.2285, loss: 0.2609
2023-11-27 22:27:39,664 - mmseg - INFO - Iter [148050/160000]	lr: 4.482e-06, eta: 2:38:22, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.0978, aux.loss_ce: 0.0805, aux.acc_seg: 91.5887, loss: 0.2380
2023-11-27 22:28:19,854 - mmseg - INFO - Iter [148100/160000]	lr: 4.463e-06, eta: 2:37:42, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1626, decode.acc_seg: 93.0356, aux.loss_ce: 0.0813, aux.acc_seg: 91.6270, loss: 0.2438
2023-11-27 22:28:59,964 - mmseg - INFO - Iter [148150/160000]	lr: 4.444e-06, eta: 2:37:02, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1536, decode.acc_seg: 93.2887, aux.loss_ce: 0.0761, aux.acc_seg: 92.0282, loss: 0.2297
2023-11-27 22:29:37,964 - mmseg - INFO - Iter [148200/160000]	lr: 4.425e-06, eta: 2:36:22, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1706, decode.acc_seg: 92.5437, aux.loss_ce: 0.0842, aux.acc_seg: 91.3238, loss: 0.2548
2023-11-27 22:30:18,268 - mmseg - INFO - Iter [148250/160000]	lr: 4.407e-06, eta: 2:35:42, time: 0.805, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1705, decode.acc_seg: 92.5106, aux.loss_ce: 0.0837, aux.acc_seg: 91.2575, loss: 0.2543
2023-11-27 22:30:56,665 - mmseg - INFO - Iter [148300/160000]	lr: 4.388e-06, eta: 2:35:03, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.6764, aux.loss_ce: 0.0828, aux.acc_seg: 91.4700, loss: 0.2505
2023-11-27 22:31:36,165 - mmseg - INFO - Iter [148350/160000]	lr: 4.369e-06, eta: 2:34:23, time: 0.789, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1602, decode.acc_seg: 93.0934, aux.loss_ce: 0.0817, aux.acc_seg: 91.6142, loss: 0.2419
2023-11-27 22:32:15,656 - mmseg - INFO - Iter [148400/160000]	lr: 4.350e-06, eta: 2:33:43, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1553, decode.acc_seg: 93.2276, aux.loss_ce: 0.0775, aux.acc_seg: 91.9339, loss: 0.2328
2023-11-27 22:32:52,884 - mmseg - INFO - Iter [148450/160000]	lr: 4.332e-06, eta: 2:33:03, time: 0.744, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1741, decode.acc_seg: 92.5667, aux.loss_ce: 0.0863, aux.acc_seg: 91.0455, loss: 0.2604
2023-11-27 22:33:31,978 - mmseg - INFO - Iter [148500/160000]	lr: 4.313e-06, eta: 2:32:23, time: 0.781, data_time: 0.009, memory: 21695, decode.loss_ce: 0.1610, decode.acc_seg: 93.0031, aux.loss_ce: 0.0792, aux.acc_seg: 91.7496, loss: 0.2402
2023-11-27 22:34:11,654 - mmseg - INFO - Iter [148550/160000]	lr: 4.294e-06, eta: 2:31:44, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1757, decode.acc_seg: 92.3808, aux.loss_ce: 0.0862, aux.acc_seg: 90.9962, loss: 0.2618
2023-11-27 22:34:50,735 - mmseg - INFO - Iter [148600/160000]	lr: 4.275e-06, eta: 2:31:04, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1784, decode.acc_seg: 92.4676, aux.loss_ce: 0.0881, aux.acc_seg: 91.0226, loss: 0.2665
2023-11-27 22:35:30,658 - mmseg - INFO - Iter [148650/160000]	lr: 4.257e-06, eta: 2:30:24, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1635, decode.acc_seg: 92.9449, aux.loss_ce: 0.0827, aux.acc_seg: 91.6871, loss: 0.2462
2023-11-27 22:36:10,849 - mmseg - INFO - Iter [148700/160000]	lr: 4.238e-06, eta: 2:29:44, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1659, decode.acc_seg: 92.8679, aux.loss_ce: 0.0831, aux.acc_seg: 91.3954, loss: 0.2490
2023-11-27 22:36:50,991 - mmseg - INFO - Iter [148750/160000]	lr: 4.219e-06, eta: 2:29:05, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1637, decode.acc_seg: 93.0110, aux.loss_ce: 0.0806, aux.acc_seg: 91.7667, loss: 0.2443
2023-11-27 22:37:31,057 - mmseg - INFO - Iter [148800/160000]	lr: 4.200e-06, eta: 2:28:25, time: 0.801, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1584, decode.acc_seg: 93.3031, aux.loss_ce: 0.0771, aux.acc_seg: 92.1314, loss: 0.2355
2023-11-27 22:38:11,554 - mmseg - INFO - Iter [148850/160000]	lr: 4.182e-06, eta: 2:27:45, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1666, decode.acc_seg: 92.9172, aux.loss_ce: 0.0817, aux.acc_seg: 91.5731, loss: 0.2483
2023-11-27 22:38:52,210 - mmseg - INFO - Iter [148900/160000]	lr: 4.163e-06, eta: 2:27:05, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1657, decode.acc_seg: 92.7475, aux.loss_ce: 0.0826, aux.acc_seg: 91.3097, loss: 0.2483
2023-11-27 22:39:30,043 - mmseg - INFO - Iter [148950/160000]	lr: 4.144e-06, eta: 2:26:26, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1561, decode.acc_seg: 93.3510, aux.loss_ce: 0.0769, aux.acc_seg: 92.1073, loss: 0.2330
2023-11-27 22:40:09,899 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 22:40:09,899 - mmseg - INFO - Iter [149000/160000]	lr: 4.125e-06, eta: 2:25:46, time: 0.797, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.8735, aux.loss_ce: 0.0821, aux.acc_seg: 91.4339, loss: 0.2466
2023-11-27 22:40:51,096 - mmseg - INFO - Iter [149050/160000]	lr: 4.107e-06, eta: 2:25:06, time: 0.825, data_time: 0.055, memory: 21695, decode.loss_ce: 0.1631, decode.acc_seg: 93.0616, aux.loss_ce: 0.0806, aux.acc_seg: 91.8947, loss: 0.2437
2023-11-27 22:41:31,762 - mmseg - INFO - Iter [149100/160000]	lr: 4.088e-06, eta: 2:24:26, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8224, aux.loss_ce: 0.0813, aux.acc_seg: 91.4953, loss: 0.2459
2023-11-27 22:42:10,902 - mmseg - INFO - Iter [149150/160000]	lr: 4.069e-06, eta: 2:23:47, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1571, decode.acc_seg: 93.1321, aux.loss_ce: 0.0792, aux.acc_seg: 91.7096, loss: 0.2362
2023-11-27 22:42:51,323 - mmseg - INFO - Iter [149200/160000]	lr: 4.050e-06, eta: 2:23:07, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1626, decode.acc_seg: 92.9265, aux.loss_ce: 0.0809, aux.acc_seg: 91.7067, loss: 0.2435
2023-11-27 22:43:30,116 - mmseg - INFO - Iter [149250/160000]	lr: 4.032e-06, eta: 2:22:27, time: 0.776, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1675, decode.acc_seg: 92.7127, aux.loss_ce: 0.0839, aux.acc_seg: 91.2764, loss: 0.2514
2023-11-27 22:44:09,974 - mmseg - INFO - Iter [149300/160000]	lr: 4.013e-06, eta: 2:21:47, time: 0.796, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1745, decode.acc_seg: 92.6655, aux.loss_ce: 0.0860, aux.acc_seg: 91.3599, loss: 0.2606
2023-11-27 22:44:48,245 - mmseg - INFO - Iter [149350/160000]	lr: 3.994e-06, eta: 2:21:07, time: 0.766, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1644, decode.acc_seg: 92.8750, aux.loss_ce: 0.0816, aux.acc_seg: 91.5765, loss: 0.2460
2023-11-27 22:45:28,992 - mmseg - INFO - Iter [149400/160000]	lr: 3.975e-06, eta: 2:20:28, time: 0.814, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1532, decode.acc_seg: 93.4337, aux.loss_ce: 0.0779, aux.acc_seg: 92.0109, loss: 0.2311
2023-11-27 22:46:07,868 - mmseg - INFO - Iter [149450/160000]	lr: 3.957e-06, eta: 2:19:48, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1699, decode.acc_seg: 92.8412, aux.loss_ce: 0.0843, aux.acc_seg: 91.5273, loss: 0.2542
2023-11-27 22:46:44,575 - mmseg - INFO - Iter [149500/160000]	lr: 3.938e-06, eta: 2:19:08, time: 0.734, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1709, decode.acc_seg: 92.5996, aux.loss_ce: 0.0845, aux.acc_seg: 91.2659, loss: 0.2554
2023-11-27 22:47:21,570 - mmseg - INFO - Iter [149550/160000]	lr: 3.919e-06, eta: 2:18:28, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1621, decode.acc_seg: 93.0015, aux.loss_ce: 0.0812, aux.acc_seg: 91.6491, loss: 0.2433
2023-11-27 22:48:00,106 - mmseg - INFO - Iter [149600/160000]	lr: 3.900e-06, eta: 2:17:48, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1610, decode.acc_seg: 93.1353, aux.loss_ce: 0.0809, aux.acc_seg: 91.8198, loss: 0.2419
2023-11-27 22:48:40,060 - mmseg - INFO - Iter [149650/160000]	lr: 3.882e-06, eta: 2:17:08, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 93.1620, aux.loss_ce: 0.0803, aux.acc_seg: 91.8510, loss: 0.2419
2023-11-27 22:49:20,532 - mmseg - INFO - Iter [149700/160000]	lr: 3.863e-06, eta: 2:16:29, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 93.0039, aux.loss_ce: 0.0825, aux.acc_seg: 91.5925, loss: 0.2449
2023-11-27 22:50:00,449 - mmseg - INFO - Iter [149750/160000]	lr: 3.844e-06, eta: 2:15:49, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1607, decode.acc_seg: 93.0199, aux.loss_ce: 0.0807, aux.acc_seg: 91.6706, loss: 0.2415
2023-11-27 22:50:39,200 - mmseg - INFO - Iter [149800/160000]	lr: 3.825e-06, eta: 2:15:09, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1618, decode.acc_seg: 92.9500, aux.loss_ce: 0.0810, aux.acc_seg: 91.5454, loss: 0.2428
2023-11-27 22:51:19,234 - mmseg - INFO - Iter [149850/160000]	lr: 3.807e-06, eta: 2:14:29, time: 0.800, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1587, decode.acc_seg: 92.9679, aux.loss_ce: 0.0781, aux.acc_seg: 91.6961, loss: 0.2368
2023-11-27 22:51:59,923 - mmseg - INFO - Iter [149900/160000]	lr: 3.788e-06, eta: 2:13:50, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1671, decode.acc_seg: 92.9418, aux.loss_ce: 0.0818, aux.acc_seg: 91.6439, loss: 0.2489
2023-11-27 22:52:39,720 - mmseg - INFO - Iter [149950/160000]	lr: 3.769e-06, eta: 2:13:10, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1601, decode.acc_seg: 93.0433, aux.loss_ce: 0.0795, aux.acc_seg: 91.8406, loss: 0.2396
2023-11-27 22:53:20,001 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 22:53:20,002 - mmseg - INFO - Iter [150000/160000]	lr: 3.750e-06, eta: 2:12:30, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 92.9439, aux.loss_ce: 0.0797, aux.acc_seg: 91.4965, loss: 0.2413
2023-11-27 22:54:00,407 - mmseg - INFO - Iter [150050/160000]	lr: 3.732e-06, eta: 2:11:51, time: 0.808, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1633, decode.acc_seg: 92.7527, aux.loss_ce: 0.0821, aux.acc_seg: 91.2929, loss: 0.2454
2023-11-27 22:54:41,242 - mmseg - INFO - Iter [150100/160000]	lr: 3.713e-06, eta: 2:11:11, time: 0.816, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8958, aux.loss_ce: 0.0812, aux.acc_seg: 91.6140, loss: 0.2458
2023-11-27 22:55:21,863 - mmseg - INFO - Iter [150150/160000]	lr: 3.694e-06, eta: 2:10:31, time: 0.812, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1724, decode.acc_seg: 92.5441, aux.loss_ce: 0.0836, aux.acc_seg: 91.3743, loss: 0.2560
2023-11-27 22:56:02,382 - mmseg - INFO - Iter [150200/160000]	lr: 3.675e-06, eta: 2:09:52, time: 0.811, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1702, decode.acc_seg: 92.6970, aux.loss_ce: 0.0833, aux.acc_seg: 91.5278, loss: 0.2535
2023-11-27 22:56:42,841 - mmseg - INFO - Iter [150250/160000]	lr: 3.657e-06, eta: 2:09:12, time: 0.808, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1651, decode.acc_seg: 92.9566, aux.loss_ce: 0.0828, aux.acc_seg: 91.5923, loss: 0.2479
2023-11-27 22:57:23,134 - mmseg - INFO - Iter [150300/160000]	lr: 3.638e-06, eta: 2:08:32, time: 0.806, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1676, decode.acc_seg: 92.7575, aux.loss_ce: 0.0829, aux.acc_seg: 91.4275, loss: 0.2505
2023-11-27 22:58:01,300 - mmseg - INFO - Iter [150350/160000]	lr: 3.619e-06, eta: 2:07:52, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1625, decode.acc_seg: 93.0378, aux.loss_ce: 0.0809, aux.acc_seg: 91.7045, loss: 0.2433
2023-11-27 22:58:41,368 - mmseg - INFO - Iter [150400/160000]	lr: 3.600e-06, eta: 2:07:12, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1643, decode.acc_seg: 92.8493, aux.loss_ce: 0.0824, aux.acc_seg: 91.5136, loss: 0.2467
2023-11-27 22:59:19,587 - mmseg - INFO - Iter [150450/160000]	lr: 3.582e-06, eta: 2:06:33, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.6443, aux.loss_ce: 0.0849, aux.acc_seg: 91.2286, loss: 0.2544
2023-11-27 22:59:57,060 - mmseg - INFO - Iter [150500/160000]	lr: 3.563e-06, eta: 2:05:53, time: 0.749, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1720, decode.acc_seg: 92.7243, aux.loss_ce: 0.0852, aux.acc_seg: 91.2942, loss: 0.2572
2023-11-27 23:00:35,474 - mmseg - INFO - Iter [150550/160000]	lr: 3.544e-06, eta: 2:05:13, time: 0.768, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1640, decode.acc_seg: 92.9048, aux.loss_ce: 0.0814, aux.acc_seg: 91.5765, loss: 0.2454
2023-11-27 23:01:15,531 - mmseg - INFO - Iter [150600/160000]	lr: 3.525e-06, eta: 2:04:33, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1637, decode.acc_seg: 92.7697, aux.loss_ce: 0.0818, aux.acc_seg: 91.2562, loss: 0.2455
2023-11-27 23:01:56,461 - mmseg - INFO - Iter [150650/160000]	lr: 3.507e-06, eta: 2:03:53, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1518, decode.acc_seg: 93.4137, aux.loss_ce: 0.0775, aux.acc_seg: 92.0211, loss: 0.2293
2023-11-27 23:02:37,423 - mmseg - INFO - Iter [150700/160000]	lr: 3.488e-06, eta: 2:03:14, time: 0.819, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.7687, aux.loss_ce: 0.0829, aux.acc_seg: 91.3024, loss: 0.2483
2023-11-27 23:03:18,393 - mmseg - INFO - Iter [150750/160000]	lr: 3.469e-06, eta: 2:02:34, time: 0.819, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1569, decode.acc_seg: 93.1890, aux.loss_ce: 0.0775, aux.acc_seg: 91.9483, loss: 0.2344
2023-11-27 23:03:59,098 - mmseg - INFO - Iter [150800/160000]	lr: 3.450e-06, eta: 2:01:54, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1581, decode.acc_seg: 93.0851, aux.loss_ce: 0.0797, aux.acc_seg: 91.7346, loss: 0.2378
2023-11-27 23:04:39,394 - mmseg - INFO - Iter [150850/160000]	lr: 3.432e-06, eta: 2:01:15, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1569, decode.acc_seg: 93.1212, aux.loss_ce: 0.0785, aux.acc_seg: 91.6953, loss: 0.2354
2023-11-27 23:05:17,744 - mmseg - INFO - Iter [150900/160000]	lr: 3.413e-06, eta: 2:00:35, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1590, decode.acc_seg: 93.2724, aux.loss_ce: 0.0781, aux.acc_seg: 91.9535, loss: 0.2370
2023-11-27 23:05:56,933 - mmseg - INFO - Iter [150950/160000]	lr: 3.394e-06, eta: 1:59:55, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1632, decode.acc_seg: 92.9443, aux.loss_ce: 0.0827, aux.acc_seg: 91.4054, loss: 0.2459
2023-11-27 23:06:35,162 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 23:06:35,162 - mmseg - INFO - Iter [151000/160000]	lr: 3.375e-06, eta: 1:59:15, time: 0.765, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1728, decode.acc_seg: 92.4974, aux.loss_ce: 0.0861, aux.acc_seg: 91.0667, loss: 0.2589
2023-11-27 23:07:14,035 - mmseg - INFO - Iter [151050/160000]	lr: 3.357e-06, eta: 1:58:35, time: 0.777, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1643, decode.acc_seg: 92.8352, aux.loss_ce: 0.0821, aux.acc_seg: 91.4957, loss: 0.2464
2023-11-27 23:07:51,134 - mmseg - INFO - Iter [151100/160000]	lr: 3.338e-06, eta: 1:57:56, time: 0.742, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1669, decode.acc_seg: 92.6425, aux.loss_ce: 0.0841, aux.acc_seg: 91.2656, loss: 0.2510
2023-11-27 23:08:29,081 - mmseg - INFO - Iter [151150/160000]	lr: 3.319e-06, eta: 1:57:16, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1690, decode.acc_seg: 92.7036, aux.loss_ce: 0.0840, aux.acc_seg: 91.4328, loss: 0.2530
2023-11-27 23:09:08,994 - mmseg - INFO - Iter [151200/160000]	lr: 3.300e-06, eta: 1:56:36, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1635, decode.acc_seg: 93.0188, aux.loss_ce: 0.0818, aux.acc_seg: 91.6600, loss: 0.2453
2023-11-27 23:09:49,054 - mmseg - INFO - Iter [151250/160000]	lr: 3.282e-06, eta: 1:55:56, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1568, decode.acc_seg: 93.1796, aux.loss_ce: 0.0762, aux.acc_seg: 92.0398, loss: 0.2330
2023-11-27 23:10:29,447 - mmseg - INFO - Iter [151300/160000]	lr: 3.263e-06, eta: 1:55:16, time: 0.807, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1641, decode.acc_seg: 92.8524, aux.loss_ce: 0.0813, aux.acc_seg: 91.5185, loss: 0.2454
2023-11-27 23:11:08,232 - mmseg - INFO - Iter [151350/160000]	lr: 3.244e-06, eta: 1:54:37, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1696, decode.acc_seg: 92.6115, aux.loss_ce: 0.0837, aux.acc_seg: 91.2071, loss: 0.2533
2023-11-27 23:11:45,960 - mmseg - INFO - Iter [151400/160000]	lr: 3.225e-06, eta: 1:53:57, time: 0.756, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1608, decode.acc_seg: 92.8465, aux.loss_ce: 0.0794, aux.acc_seg: 91.4912, loss: 0.2402
2023-11-27 23:12:22,954 - mmseg - INFO - Iter [151450/160000]	lr: 3.207e-06, eta: 1:53:17, time: 0.740, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1588, decode.acc_seg: 93.0512, aux.loss_ce: 0.0797, aux.acc_seg: 91.5711, loss: 0.2385
2023-11-27 23:13:01,959 - mmseg - INFO - Iter [151500/160000]	lr: 3.188e-06, eta: 1:52:37, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1597, decode.acc_seg: 93.1229, aux.loss_ce: 0.0791, aux.acc_seg: 91.8506, loss: 0.2388
2023-11-27 23:13:41,024 - mmseg - INFO - Iter [151550/160000]	lr: 3.169e-06, eta: 1:51:57, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1518, decode.acc_seg: 93.4327, aux.loss_ce: 0.0752, aux.acc_seg: 92.1921, loss: 0.2271
2023-11-27 23:14:23,173 - mmseg - INFO - Iter [151600/160000]	lr: 3.150e-06, eta: 1:51:18, time: 0.843, data_time: 0.054, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 92.9421, aux.loss_ce: 0.0812, aux.acc_seg: 91.7183, loss: 0.2462
2023-11-27 23:15:03,602 - mmseg - INFO - Iter [151650/160000]	lr: 3.132e-06, eta: 1:50:38, time: 0.809, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1583, decode.acc_seg: 93.2650, aux.loss_ce: 0.0779, aux.acc_seg: 92.1020, loss: 0.2363
2023-11-27 23:15:41,500 - mmseg - INFO - Iter [151700/160000]	lr: 3.113e-06, eta: 1:49:58, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1669, decode.acc_seg: 92.9531, aux.loss_ce: 0.0831, aux.acc_seg: 91.5324, loss: 0.2501
2023-11-27 23:16:19,384 - mmseg - INFO - Iter [151750/160000]	lr: 3.094e-06, eta: 1:49:18, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1537, decode.acc_seg: 93.2925, aux.loss_ce: 0.0757, aux.acc_seg: 92.0546, loss: 0.2294
2023-11-27 23:16:58,955 - mmseg - INFO - Iter [151800/160000]	lr: 3.075e-06, eta: 1:48:39, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 92.9462, aux.loss_ce: 0.0812, aux.acc_seg: 91.6004, loss: 0.2436
2023-11-27 23:17:36,924 - mmseg - INFO - Iter [151850/160000]	lr: 3.057e-06, eta: 1:47:59, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1552, decode.acc_seg: 93.1985, aux.loss_ce: 0.0767, aux.acc_seg: 91.9604, loss: 0.2318
2023-11-27 23:18:15,498 - mmseg - INFO - Iter [151900/160000]	lr: 3.038e-06, eta: 1:47:19, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1627, decode.acc_seg: 92.8897, aux.loss_ce: 0.0823, aux.acc_seg: 91.3821, loss: 0.2450
2023-11-27 23:18:55,069 - mmseg - INFO - Iter [151950/160000]	lr: 3.019e-06, eta: 1:46:39, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.9798, aux.loss_ce: 0.0838, aux.acc_seg: 91.5739, loss: 0.2491
2023-11-27 23:19:33,839 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 23:19:33,840 - mmseg - INFO - Iter [152000/160000]	lr: 3.000e-06, eta: 1:45:59, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1699, decode.acc_seg: 92.8141, aux.loss_ce: 0.0852, aux.acc_seg: 91.5318, loss: 0.2551
2023-11-27 23:20:14,134 - mmseg - INFO - Iter [152050/160000]	lr: 2.982e-06, eta: 1:45:20, time: 0.807, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1530, decode.acc_seg: 93.1301, aux.loss_ce: 0.0764, aux.acc_seg: 91.7573, loss: 0.2293
2023-11-27 23:20:52,198 - mmseg - INFO - Iter [152100/160000]	lr: 2.963e-06, eta: 1:44:40, time: 0.761, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 93.0342, aux.loss_ce: 0.0813, aux.acc_seg: 91.7222, loss: 0.2467
2023-11-27 23:21:30,477 - mmseg - INFO - Iter [152150/160000]	lr: 2.944e-06, eta: 1:44:00, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1683, decode.acc_seg: 92.7942, aux.loss_ce: 0.0840, aux.acc_seg: 91.4512, loss: 0.2522
2023-11-27 23:22:10,146 - mmseg - INFO - Iter [152200/160000]	lr: 2.925e-06, eta: 1:43:20, time: 0.794, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1683, decode.acc_seg: 92.7695, aux.loss_ce: 0.0810, aux.acc_seg: 91.6382, loss: 0.2492
2023-11-27 23:22:48,163 - mmseg - INFO - Iter [152250/160000]	lr: 2.907e-06, eta: 1:42:40, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1659, decode.acc_seg: 93.0271, aux.loss_ce: 0.0828, aux.acc_seg: 91.6630, loss: 0.2487
2023-11-27 23:23:25,935 - mmseg - INFO - Iter [152300/160000]	lr: 2.888e-06, eta: 1:42:00, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1714, decode.acc_seg: 92.5039, aux.loss_ce: 0.0851, aux.acc_seg: 91.1062, loss: 0.2566
2023-11-27 23:24:02,795 - mmseg - INFO - Iter [152350/160000]	lr: 2.869e-06, eta: 1:41:21, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 93.0523, aux.loss_ce: 0.0809, aux.acc_seg: 91.7196, loss: 0.2454
2023-11-27 23:24:43,455 - mmseg - INFO - Iter [152400/160000]	lr: 2.850e-06, eta: 1:40:41, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1679, decode.acc_seg: 92.8233, aux.loss_ce: 0.0841, aux.acc_seg: 91.5106, loss: 0.2521
2023-11-27 23:25:22,066 - mmseg - INFO - Iter [152450/160000]	lr: 2.832e-06, eta: 1:40:01, time: 0.773, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1725, decode.acc_seg: 92.6193, aux.loss_ce: 0.0853, aux.acc_seg: 91.2640, loss: 0.2578
2023-11-27 23:25:59,803 - mmseg - INFO - Iter [152500/160000]	lr: 2.813e-06, eta: 1:39:21, time: 0.754, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1615, decode.acc_seg: 92.9223, aux.loss_ce: 0.0807, aux.acc_seg: 91.6952, loss: 0.2421
2023-11-27 23:26:39,818 - mmseg - INFO - Iter [152550/160000]	lr: 2.794e-06, eta: 1:38:42, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1668, decode.acc_seg: 92.9439, aux.loss_ce: 0.0828, aux.acc_seg: 91.6135, loss: 0.2496
2023-11-27 23:27:19,705 - mmseg - INFO - Iter [152600/160000]	lr: 2.775e-06, eta: 1:38:02, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 93.0169, aux.loss_ce: 0.0807, aux.acc_seg: 91.5988, loss: 0.2423
2023-11-27 23:27:56,645 - mmseg - INFO - Iter [152650/160000]	lr: 2.757e-06, eta: 1:37:22, time: 0.739, data_time: 0.009, memory: 21695, decode.loss_ce: 0.1614, decode.acc_seg: 92.8505, aux.loss_ce: 0.0791, aux.acc_seg: 91.5969, loss: 0.2406
2023-11-27 23:28:35,933 - mmseg - INFO - Iter [152700/160000]	lr: 2.738e-06, eta: 1:36:42, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1554, decode.acc_seg: 93.3800, aux.loss_ce: 0.0776, aux.acc_seg: 91.9871, loss: 0.2331
2023-11-27 23:29:14,136 - mmseg - INFO - Iter [152750/160000]	lr: 2.719e-06, eta: 1:36:02, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1673, decode.acc_seg: 92.8572, aux.loss_ce: 0.0829, aux.acc_seg: 91.4887, loss: 0.2502
2023-11-27 23:29:53,153 - mmseg - INFO - Iter [152800/160000]	lr: 2.700e-06, eta: 1:35:23, time: 0.781, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.6030, aux.loss_ce: 0.0836, aux.acc_seg: 91.2587, loss: 0.2529
2023-11-27 23:30:33,431 - mmseg - INFO - Iter [152850/160000]	lr: 2.682e-06, eta: 1:34:43, time: 0.806, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1572, decode.acc_seg: 93.1193, aux.loss_ce: 0.0779, aux.acc_seg: 91.8019, loss: 0.2351
2023-11-27 23:31:10,626 - mmseg - INFO - Iter [152900/160000]	lr: 2.663e-06, eta: 1:34:03, time: 0.743, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1709, decode.acc_seg: 92.7909, aux.loss_ce: 0.0843, aux.acc_seg: 91.3062, loss: 0.2552
2023-11-27 23:31:50,808 - mmseg - INFO - Iter [152950/160000]	lr: 2.644e-06, eta: 1:33:23, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1591, decode.acc_seg: 93.2656, aux.loss_ce: 0.0783, aux.acc_seg: 92.0948, loss: 0.2375
2023-11-27 23:32:28,788 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 23:32:28,789 - mmseg - INFO - Iter [153000/160000]	lr: 2.625e-06, eta: 1:32:43, time: 0.760, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1693, decode.acc_seg: 92.7129, aux.loss_ce: 0.0827, aux.acc_seg: 91.5134, loss: 0.2521
2023-11-27 23:33:06,868 - mmseg - INFO - Iter [153050/160000]	lr: 2.607e-06, eta: 1:32:04, time: 0.761, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1714, decode.acc_seg: 92.4931, aux.loss_ce: 0.0862, aux.acc_seg: 91.0854, loss: 0.2576
2023-11-27 23:33:46,314 - mmseg - INFO - Iter [153100/160000]	lr: 2.588e-06, eta: 1:31:24, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1645, decode.acc_seg: 92.8679, aux.loss_ce: 0.0813, aux.acc_seg: 91.5597, loss: 0.2458
2023-11-27 23:34:23,468 - mmseg - INFO - Iter [153150/160000]	lr: 2.569e-06, eta: 1:30:44, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1630, decode.acc_seg: 93.1036, aux.loss_ce: 0.0824, aux.acc_seg: 91.7011, loss: 0.2454
2023-11-27 23:35:03,761 - mmseg - INFO - Iter [153200/160000]	lr: 2.550e-06, eta: 1:30:04, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1619, decode.acc_seg: 93.0336, aux.loss_ce: 0.0789, aux.acc_seg: 91.8202, loss: 0.2408
2023-11-27 23:35:42,242 - mmseg - INFO - Iter [153250/160000]	lr: 2.532e-06, eta: 1:29:24, time: 0.770, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1636, decode.acc_seg: 92.8810, aux.loss_ce: 0.0812, aux.acc_seg: 91.5539, loss: 0.2449
2023-11-27 23:36:20,833 - mmseg - INFO - Iter [153300/160000]	lr: 2.513e-06, eta: 1:28:45, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1572, decode.acc_seg: 93.0761, aux.loss_ce: 0.0782, aux.acc_seg: 91.7504, loss: 0.2354
2023-11-27 23:37:01,313 - mmseg - INFO - Iter [153350/160000]	lr: 2.494e-06, eta: 1:28:05, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1599, decode.acc_seg: 93.3074, aux.loss_ce: 0.0780, aux.acc_seg: 92.1069, loss: 0.2379
2023-11-27 23:37:39,774 - mmseg - INFO - Iter [153400/160000]	lr: 2.475e-06, eta: 1:27:25, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1565, decode.acc_seg: 93.1900, aux.loss_ce: 0.0791, aux.acc_seg: 91.7436, loss: 0.2357
2023-11-27 23:38:19,685 - mmseg - INFO - Iter [153450/160000]	lr: 2.457e-06, eta: 1:26:45, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1676, decode.acc_seg: 92.8473, aux.loss_ce: 0.0813, aux.acc_seg: 91.5313, loss: 0.2489
2023-11-27 23:38:59,976 - mmseg - INFO - Iter [153500/160000]	lr: 2.438e-06, eta: 1:26:06, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1688, decode.acc_seg: 92.7923, aux.loss_ce: 0.0829, aux.acc_seg: 91.4575, loss: 0.2517
2023-11-27 23:39:40,106 - mmseg - INFO - Iter [153550/160000]	lr: 2.419e-06, eta: 1:25:26, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1602, decode.acc_seg: 93.0559, aux.loss_ce: 0.0805, aux.acc_seg: 91.7570, loss: 0.2407
2023-11-27 23:40:20,856 - mmseg - INFO - Iter [153600/160000]	lr: 2.400e-06, eta: 1:24:46, time: 0.815, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1619, decode.acc_seg: 92.9662, aux.loss_ce: 0.0814, aux.acc_seg: 91.6452, loss: 0.2433
2023-11-27 23:40:58,584 - mmseg - INFO - Iter [153650/160000]	lr: 2.382e-06, eta: 1:24:06, time: 0.755, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 92.9661, aux.loss_ce: 0.0818, aux.acc_seg: 91.7333, loss: 0.2471
2023-11-27 23:41:37,513 - mmseg - INFO - Iter [153700/160000]	lr: 2.363e-06, eta: 1:23:27, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1573, decode.acc_seg: 93.0303, aux.loss_ce: 0.0789, aux.acc_seg: 91.5967, loss: 0.2362
2023-11-27 23:42:15,122 - mmseg - INFO - Iter [153750/160000]	lr: 2.344e-06, eta: 1:22:47, time: 0.752, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1624, decode.acc_seg: 92.9870, aux.loss_ce: 0.0821, aux.acc_seg: 91.5153, loss: 0.2445
2023-11-27 23:42:55,152 - mmseg - INFO - Iter [153800/160000]	lr: 2.325e-06, eta: 1:22:07, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1796, decode.acc_seg: 92.4493, aux.loss_ce: 0.0883, aux.acc_seg: 90.9658, loss: 0.2679
2023-11-27 23:43:35,199 - mmseg - INFO - Iter [153850/160000]	lr: 2.307e-06, eta: 1:21:27, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 92.7328, aux.loss_ce: 0.0798, aux.acc_seg: 91.4640, loss: 0.2428
2023-11-27 23:44:13,679 - mmseg - INFO - Iter [153900/160000]	lr: 2.288e-06, eta: 1:20:48, time: 0.770, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1739, decode.acc_seg: 92.4968, aux.loss_ce: 0.0870, aux.acc_seg: 91.0415, loss: 0.2608
2023-11-27 23:44:52,253 - mmseg - INFO - Iter [153950/160000]	lr: 2.269e-06, eta: 1:20:08, time: 0.771, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1619, decode.acc_seg: 92.9200, aux.loss_ce: 0.0806, aux.acc_seg: 91.5603, loss: 0.2426
2023-11-27 23:45:30,746 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 23:45:30,746 - mmseg - INFO - Iter [154000/160000]	lr: 2.250e-06, eta: 1:19:28, time: 0.771, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.2890, aux.loss_ce: 0.0772, aux.acc_seg: 92.1337, loss: 0.2347
2023-11-27 23:46:07,918 - mmseg - INFO - Iter [154050/160000]	lr: 2.232e-06, eta: 1:18:48, time: 0.743, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1643, decode.acc_seg: 93.0144, aux.loss_ce: 0.0824, aux.acc_seg: 91.6195, loss: 0.2467
2023-11-27 23:46:48,767 - mmseg - INFO - Iter [154100/160000]	lr: 2.213e-06, eta: 1:18:09, time: 0.817, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8751, aux.loss_ce: 0.0819, aux.acc_seg: 91.4265, loss: 0.2465
2023-11-27 23:47:26,681 - mmseg - INFO - Iter [154150/160000]	lr: 2.194e-06, eta: 1:17:29, time: 0.757, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1549, decode.acc_seg: 93.2747, aux.loss_ce: 0.0759, aux.acc_seg: 92.0301, loss: 0.2308
2023-11-27 23:48:04,173 - mmseg - INFO - Iter [154200/160000]	lr: 2.175e-06, eta: 1:16:49, time: 0.750, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1674, decode.acc_seg: 92.5106, aux.loss_ce: 0.0841, aux.acc_seg: 91.0156, loss: 0.2515
2023-11-27 23:48:44,119 - mmseg - INFO - Iter [154250/160000]	lr: 2.157e-06, eta: 1:16:09, time: 0.799, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1591, decode.acc_seg: 93.1181, aux.loss_ce: 0.0783, aux.acc_seg: 91.9465, loss: 0.2374
2023-11-27 23:49:22,038 - mmseg - INFO - Iter [154300/160000]	lr: 2.138e-06, eta: 1:15:29, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1627, decode.acc_seg: 92.9649, aux.loss_ce: 0.0809, aux.acc_seg: 91.5954, loss: 0.2436
2023-11-27 23:50:02,002 - mmseg - INFO - Iter [154350/160000]	lr: 2.119e-06, eta: 1:14:50, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1599, decode.acc_seg: 93.0711, aux.loss_ce: 0.0796, aux.acc_seg: 91.7439, loss: 0.2395
2023-11-27 23:50:40,706 - mmseg - INFO - Iter [154400/160000]	lr: 2.100e-06, eta: 1:14:10, time: 0.774, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1520, decode.acc_seg: 93.4338, aux.loss_ce: 0.0749, aux.acc_seg: 92.2422, loss: 0.2270
2023-11-27 23:51:19,319 - mmseg - INFO - Iter [154450/160000]	lr: 2.082e-06, eta: 1:13:30, time: 0.772, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1552, decode.acc_seg: 93.2054, aux.loss_ce: 0.0780, aux.acc_seg: 91.7893, loss: 0.2332
2023-11-27 23:51:59,367 - mmseg - INFO - Iter [154500/160000]	lr: 2.063e-06, eta: 1:12:50, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1628, decode.acc_seg: 92.7846, aux.loss_ce: 0.0817, aux.acc_seg: 91.3044, loss: 0.2444
2023-11-27 23:52:39,245 - mmseg - INFO - Iter [154550/160000]	lr: 2.044e-06, eta: 1:12:11, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1647, decode.acc_seg: 92.9598, aux.loss_ce: 0.0823, aux.acc_seg: 91.5498, loss: 0.2470
2023-11-27 23:53:17,144 - mmseg - INFO - Iter [154600/160000]	lr: 2.025e-06, eta: 1:11:31, time: 0.758, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1620, decode.acc_seg: 92.8750, aux.loss_ce: 0.0818, aux.acc_seg: 91.4144, loss: 0.2438
2023-11-27 23:53:57,768 - mmseg - INFO - Iter [154650/160000]	lr: 2.007e-06, eta: 1:10:51, time: 0.812, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1634, decode.acc_seg: 93.0073, aux.loss_ce: 0.0809, aux.acc_seg: 91.6993, loss: 0.2443
2023-11-27 23:54:39,291 - mmseg - INFO - Iter [154700/160000]	lr: 1.988e-06, eta: 1:10:11, time: 0.831, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1623, decode.acc_seg: 92.9679, aux.loss_ce: 0.0811, aux.acc_seg: 91.6712, loss: 0.2434
2023-11-27 23:55:18,175 - mmseg - INFO - Iter [154750/160000]	lr: 1.969e-06, eta: 1:09:32, time: 0.777, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8900, aux.loss_ce: 0.0835, aux.acc_seg: 91.4452, loss: 0.2481
2023-11-27 23:55:59,845 - mmseg - INFO - Iter [154800/160000]	lr: 1.950e-06, eta: 1:08:52, time: 0.834, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1595, decode.acc_seg: 92.9644, aux.loss_ce: 0.0796, aux.acc_seg: 91.5832, loss: 0.2391
2023-11-27 23:56:40,096 - mmseg - INFO - Iter [154850/160000]	lr: 1.932e-06, eta: 1:08:12, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1594, decode.acc_seg: 93.1186, aux.loss_ce: 0.0795, aux.acc_seg: 91.8039, loss: 0.2390
2023-11-27 23:57:20,883 - mmseg - INFO - Iter [154900/160000]	lr: 1.913e-06, eta: 1:07:33, time: 0.816, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1783, decode.acc_seg: 92.4248, aux.loss_ce: 0.0883, aux.acc_seg: 90.9822, loss: 0.2666
2023-11-27 23:58:01,096 - mmseg - INFO - Iter [154950/160000]	lr: 1.894e-06, eta: 1:06:53, time: 0.804, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1602, decode.acc_seg: 92.9950, aux.loss_ce: 0.0808, aux.acc_seg: 91.5113, loss: 0.2410
2023-11-27 23:58:41,131 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-27 23:58:41,131 - mmseg - INFO - Iter [155000/160000]	lr: 1.875e-06, eta: 1:06:13, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1550, decode.acc_seg: 93.1668, aux.loss_ce: 0.0764, aux.acc_seg: 91.9295, loss: 0.2314
2023-11-27 23:59:19,829 - mmseg - INFO - Iter [155050/160000]	lr: 1.857e-06, eta: 1:05:33, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.9105, aux.loss_ce: 0.0827, aux.acc_seg: 91.4409, loss: 0.2480
2023-11-27 23:59:56,839 - mmseg - INFO - Iter [155100/160000]	lr: 1.838e-06, eta: 1:04:54, time: 0.740, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1633, decode.acc_seg: 92.8347, aux.loss_ce: 0.0810, aux.acc_seg: 91.5360, loss: 0.2443
2023-11-28 00:00:35,874 - mmseg - INFO - Iter [155150/160000]	lr: 1.819e-06, eta: 1:04:14, time: 0.780, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1539, decode.acc_seg: 93.3060, aux.loss_ce: 0.0760, aux.acc_seg: 92.0750, loss: 0.2299
2023-11-28 00:01:15,945 - mmseg - INFO - Iter [155200/160000]	lr: 1.800e-06, eta: 1:03:34, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1647, decode.acc_seg: 92.8772, aux.loss_ce: 0.0805, aux.acc_seg: 91.6437, loss: 0.2452
2023-11-28 00:01:56,066 - mmseg - INFO - Iter [155250/160000]	lr: 1.782e-06, eta: 1:02:54, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1666, decode.acc_seg: 92.8751, aux.loss_ce: 0.0834, aux.acc_seg: 91.5526, loss: 0.2500
2023-11-28 00:02:34,834 - mmseg - INFO - Iter [155300/160000]	lr: 1.763e-06, eta: 1:02:15, time: 0.775, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.9634, aux.loss_ce: 0.0826, aux.acc_seg: 91.6451, loss: 0.2487
2023-11-28 00:03:15,134 - mmseg - INFO - Iter [155350/160000]	lr: 1.744e-06, eta: 1:01:35, time: 0.806, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 92.8594, aux.loss_ce: 0.0826, aux.acc_seg: 91.4892, loss: 0.2480
2023-11-28 00:03:54,697 - mmseg - INFO - Iter [155400/160000]	lr: 1.725e-06, eta: 1:00:55, time: 0.790, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1581, decode.acc_seg: 93.2666, aux.loss_ce: 0.0804, aux.acc_seg: 91.8128, loss: 0.2385
2023-11-28 00:04:34,047 - mmseg - INFO - Iter [155450/160000]	lr: 1.707e-06, eta: 1:00:15, time: 0.788, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1677, decode.acc_seg: 92.9125, aux.loss_ce: 0.0839, aux.acc_seg: 91.5015, loss: 0.2516
2023-11-28 00:05:13,953 - mmseg - INFO - Iter [155500/160000]	lr: 1.688e-06, eta: 0:59:36, time: 0.797, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1580, decode.acc_seg: 93.1313, aux.loss_ce: 0.0772, aux.acc_seg: 91.9649, loss: 0.2352
2023-11-28 00:05:54,068 - mmseg - INFO - Iter [155550/160000]	lr: 1.669e-06, eta: 0:58:56, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1708, decode.acc_seg: 92.5093, aux.loss_ce: 0.0831, aux.acc_seg: 91.2603, loss: 0.2539
2023-11-28 00:06:32,598 - mmseg - INFO - Iter [155600/160000]	lr: 1.650e-06, eta: 0:58:16, time: 0.770, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1615, decode.acc_seg: 92.9796, aux.loss_ce: 0.0798, aux.acc_seg: 91.6725, loss: 0.2412
2023-11-28 00:07:09,358 - mmseg - INFO - Iter [155650/160000]	lr: 1.632e-06, eta: 0:57:36, time: 0.736, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1692, decode.acc_seg: 92.6582, aux.loss_ce: 0.0848, aux.acc_seg: 91.2240, loss: 0.2541
2023-11-28 00:07:47,113 - mmseg - INFO - Iter [155700/160000]	lr: 1.613e-06, eta: 0:56:57, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1642, decode.acc_seg: 92.8335, aux.loss_ce: 0.0822, aux.acc_seg: 91.4326, loss: 0.2464
2023-11-28 00:08:27,093 - mmseg - INFO - Iter [155750/160000]	lr: 1.594e-06, eta: 0:56:17, time: 0.801, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1731, decode.acc_seg: 92.4703, aux.loss_ce: 0.0853, aux.acc_seg: 91.1501, loss: 0.2584
2023-11-28 00:09:07,024 - mmseg - INFO - Iter [155800/160000]	lr: 1.575e-06, eta: 0:55:37, time: 0.798, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1662, decode.acc_seg: 92.7305, aux.loss_ce: 0.0826, aux.acc_seg: 91.2429, loss: 0.2488
2023-11-28 00:09:46,478 - mmseg - INFO - Iter [155850/160000]	lr: 1.557e-06, eta: 0:54:57, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1556, decode.acc_seg: 93.2663, aux.loss_ce: 0.0783, aux.acc_seg: 91.9011, loss: 0.2339
2023-11-28 00:10:24,157 - mmseg - INFO - Iter [155900/160000]	lr: 1.538e-06, eta: 0:54:18, time: 0.753, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1572, decode.acc_seg: 93.2644, aux.loss_ce: 0.0790, aux.acc_seg: 91.9196, loss: 0.2361
2023-11-28 00:11:02,466 - mmseg - INFO - Iter [155950/160000]	lr: 1.519e-06, eta: 0:53:38, time: 0.767, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1627, decode.acc_seg: 93.1029, aux.loss_ce: 0.0811, aux.acc_seg: 91.7597, loss: 0.2439
2023-11-28 00:11:40,430 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 00:11:40,430 - mmseg - INFO - Iter [156000/160000]	lr: 1.500e-06, eta: 0:52:58, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1658, decode.acc_seg: 92.8910, aux.loss_ce: 0.0829, aux.acc_seg: 91.5551, loss: 0.2487
2023-11-28 00:12:20,398 - mmseg - INFO - Iter [156050/160000]	lr: 1.482e-06, eta: 0:52:18, time: 0.799, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1545, decode.acc_seg: 93.1565, aux.loss_ce: 0.0776, aux.acc_seg: 91.7515, loss: 0.2320
2023-11-28 00:13:00,487 - mmseg - INFO - Iter [156100/160000]	lr: 1.463e-06, eta: 0:51:39, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1656, decode.acc_seg: 92.9676, aux.loss_ce: 0.0819, aux.acc_seg: 91.5780, loss: 0.2474
2023-11-28 00:13:39,265 - mmseg - INFO - Iter [156150/160000]	lr: 1.444e-06, eta: 0:50:59, time: 0.776, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1578, decode.acc_seg: 93.1485, aux.loss_ce: 0.0793, aux.acc_seg: 91.7682, loss: 0.2371
2023-11-28 00:14:19,977 - mmseg - INFO - Iter [156200/160000]	lr: 1.425e-06, eta: 0:50:19, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.6293, aux.loss_ce: 0.0825, aux.acc_seg: 91.3005, loss: 0.2486
2023-11-28 00:15:00,604 - mmseg - INFO - Iter [156250/160000]	lr: 1.407e-06, eta: 0:49:39, time: 0.813, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1563, decode.acc_seg: 93.1775, aux.loss_ce: 0.0784, aux.acc_seg: 91.9005, loss: 0.2347
2023-11-28 00:15:41,125 - mmseg - INFO - Iter [156300/160000]	lr: 1.388e-06, eta: 0:49:00, time: 0.810, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1549, decode.acc_seg: 93.0484, aux.loss_ce: 0.0771, aux.acc_seg: 91.7448, loss: 0.2321
2023-11-28 00:16:21,847 - mmseg - INFO - Iter [156350/160000]	lr: 1.369e-06, eta: 0:48:20, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1633, decode.acc_seg: 93.0911, aux.loss_ce: 0.0807, aux.acc_seg: 91.8393, loss: 0.2439
2023-11-28 00:17:02,088 - mmseg - INFO - Iter [156400/160000]	lr: 1.350e-06, eta: 0:47:40, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1709, decode.acc_seg: 92.7530, aux.loss_ce: 0.0862, aux.acc_seg: 91.2479, loss: 0.2572
2023-11-28 00:17:40,995 - mmseg - INFO - Iter [156450/160000]	lr: 1.332e-06, eta: 0:47:01, time: 0.779, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1617, decode.acc_seg: 92.9611, aux.loss_ce: 0.0807, aux.acc_seg: 91.6857, loss: 0.2425
2023-11-28 00:18:20,632 - mmseg - INFO - Iter [156500/160000]	lr: 1.313e-06, eta: 0:46:21, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1518, decode.acc_seg: 93.2457, aux.loss_ce: 0.0769, aux.acc_seg: 91.8306, loss: 0.2287
2023-11-28 00:19:00,464 - mmseg - INFO - Iter [156550/160000]	lr: 1.294e-06, eta: 0:45:41, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1455, decode.acc_seg: 93.5944, aux.loss_ce: 0.0726, aux.acc_seg: 92.4206, loss: 0.2181
2023-11-28 00:19:39,906 - mmseg - INFO - Iter [156600/160000]	lr: 1.275e-06, eta: 0:45:01, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1587, decode.acc_seg: 93.0836, aux.loss_ce: 0.0800, aux.acc_seg: 91.6293, loss: 0.2387
2023-11-28 00:20:22,587 - mmseg - INFO - Iter [156650/160000]	lr: 1.257e-06, eta: 0:44:22, time: 0.853, data_time: 0.053, memory: 21695, decode.loss_ce: 0.1670, decode.acc_seg: 92.6650, aux.loss_ce: 0.0835, aux.acc_seg: 91.1992, loss: 0.2505
2023-11-28 00:21:02,426 - mmseg - INFO - Iter [156700/160000]	lr: 1.238e-06, eta: 0:43:42, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1612, decode.acc_seg: 93.1470, aux.loss_ce: 0.0796, aux.acc_seg: 91.9865, loss: 0.2408
2023-11-28 00:21:42,767 - mmseg - INFO - Iter [156750/160000]	lr: 1.219e-06, eta: 0:43:02, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1679, decode.acc_seg: 92.9716, aux.loss_ce: 0.0835, aux.acc_seg: 91.7414, loss: 0.2514
2023-11-28 00:22:20,974 - mmseg - INFO - Iter [156800/160000]	lr: 1.200e-06, eta: 0:42:22, time: 0.764, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1623, decode.acc_seg: 92.9721, aux.loss_ce: 0.0808, aux.acc_seg: 91.5034, loss: 0.2432
2023-11-28 00:23:00,521 - mmseg - INFO - Iter [156850/160000]	lr: 1.182e-06, eta: 0:41:43, time: 0.790, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1570, decode.acc_seg: 93.0305, aux.loss_ce: 0.0789, aux.acc_seg: 91.6851, loss: 0.2358
2023-11-28 00:23:40,753 - mmseg - INFO - Iter [156900/160000]	lr: 1.163e-06, eta: 0:41:03, time: 0.806, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1560, decode.acc_seg: 93.4654, aux.loss_ce: 0.0775, aux.acc_seg: 92.2082, loss: 0.2335
2023-11-28 00:24:18,733 - mmseg - INFO - Iter [156950/160000]	lr: 1.144e-06, eta: 0:40:23, time: 0.759, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1556, decode.acc_seg: 93.2620, aux.loss_ce: 0.0782, aux.acc_seg: 91.9333, loss: 0.2338
2023-11-28 00:24:58,781 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 00:24:58,781 - mmseg - INFO - Iter [157000/160000]	lr: 1.125e-06, eta: 0:39:43, time: 0.802, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1558, decode.acc_seg: 93.2121, aux.loss_ce: 0.0777, aux.acc_seg: 91.8911, loss: 0.2335
2023-11-28 00:25:36,268 - mmseg - INFO - Iter [157050/160000]	lr: 1.107e-06, eta: 0:39:04, time: 0.750, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.9049, aux.loss_ce: 0.0819, aux.acc_seg: 91.5112, loss: 0.2472
2023-11-28 00:26:15,937 - mmseg - INFO - Iter [157100/160000]	lr: 1.088e-06, eta: 0:38:24, time: 0.792, data_time: 0.009, memory: 21695, decode.loss_ce: 0.1676, decode.acc_seg: 92.7596, aux.loss_ce: 0.0826, aux.acc_seg: 91.4036, loss: 0.2502
2023-11-28 00:26:53,782 - mmseg - INFO - Iter [157150/160000]	lr: 1.069e-06, eta: 0:37:44, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1582, decode.acc_seg: 93.2331, aux.loss_ce: 0.0792, aux.acc_seg: 91.9183, loss: 0.2375
2023-11-28 00:27:33,070 - mmseg - INFO - Iter [157200/160000]	lr: 1.050e-06, eta: 0:37:04, time: 0.785, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.7010, aux.loss_ce: 0.0832, aux.acc_seg: 91.3035, loss: 0.2528
2023-11-28 00:28:11,643 - mmseg - INFO - Iter [157250/160000]	lr: 1.032e-06, eta: 0:36:25, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1650, decode.acc_seg: 92.8103, aux.loss_ce: 0.0819, aux.acc_seg: 91.4764, loss: 0.2469
2023-11-28 00:28:50,805 - mmseg - INFO - Iter [157300/160000]	lr: 1.013e-06, eta: 0:35:45, time: 0.784, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1620, decode.acc_seg: 92.8736, aux.loss_ce: 0.0816, aux.acc_seg: 91.5807, loss: 0.2436
2023-11-28 00:29:29,376 - mmseg - INFO - Iter [157350/160000]	lr: 9.941e-07, eta: 0:35:05, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1612, decode.acc_seg: 92.9530, aux.loss_ce: 0.0811, aux.acc_seg: 91.5365, loss: 0.2423
2023-11-28 00:30:07,707 - mmseg - INFO - Iter [157400/160000]	lr: 9.754e-07, eta: 0:34:25, time: 0.766, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1489, decode.acc_seg: 93.4333, aux.loss_ce: 0.0741, aux.acc_seg: 92.2067, loss: 0.2231
2023-11-28 00:30:44,791 - mmseg - INFO - Iter [157450/160000]	lr: 9.566e-07, eta: 0:33:46, time: 0.742, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1510, decode.acc_seg: 93.4018, aux.loss_ce: 0.0759, aux.acc_seg: 92.0988, loss: 0.2269
2023-11-28 00:31:24,134 - mmseg - INFO - Iter [157500/160000]	lr: 9.379e-07, eta: 0:33:06, time: 0.786, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1532, decode.acc_seg: 93.2990, aux.loss_ce: 0.0764, aux.acc_seg: 92.0162, loss: 0.2296
2023-11-28 00:32:03,844 - mmseg - INFO - Iter [157550/160000]	lr: 9.191e-07, eta: 0:32:26, time: 0.796, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1597, decode.acc_seg: 93.0850, aux.loss_ce: 0.0811, aux.acc_seg: 91.5213, loss: 0.2408
2023-11-28 00:32:40,366 - mmseg - INFO - Iter [157600/160000]	lr: 9.004e-07, eta: 0:31:46, time: 0.730, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1689, decode.acc_seg: 92.6783, aux.loss_ce: 0.0856, aux.acc_seg: 91.0758, loss: 0.2545
2023-11-28 00:33:17,151 - mmseg - INFO - Iter [157650/160000]	lr: 8.816e-07, eta: 0:31:07, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1623, decode.acc_seg: 93.0383, aux.loss_ce: 0.0826, aux.acc_seg: 91.5489, loss: 0.2449
2023-11-28 00:33:55,744 - mmseg - INFO - Iter [157700/160000]	lr: 8.629e-07, eta: 0:30:27, time: 0.771, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1676, decode.acc_seg: 92.8266, aux.loss_ce: 0.0836, aux.acc_seg: 91.4978, loss: 0.2512
2023-11-28 00:34:36,001 - mmseg - INFO - Iter [157750/160000]	lr: 8.441e-07, eta: 0:29:47, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1656, decode.acc_seg: 92.8937, aux.loss_ce: 0.0820, aux.acc_seg: 91.5679, loss: 0.2475
2023-11-28 00:35:13,744 - mmseg - INFO - Iter [157800/160000]	lr: 8.254e-07, eta: 0:29:07, time: 0.755, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 92.9182, aux.loss_ce: 0.0810, aux.acc_seg: 91.6456, loss: 0.2439
2023-11-28 00:35:54,424 - mmseg - INFO - Iter [157850/160000]	lr: 8.066e-07, eta: 0:28:28, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1582, decode.acc_seg: 93.1712, aux.loss_ce: 0.0782, aux.acc_seg: 91.8747, loss: 0.2363
2023-11-28 00:36:36,106 - mmseg - INFO - Iter [157900/160000]	lr: 7.879e-07, eta: 0:27:48, time: 0.833, data_time: 0.054, memory: 21695, decode.loss_ce: 0.1621, decode.acc_seg: 92.9832, aux.loss_ce: 0.0806, aux.acc_seg: 91.5945, loss: 0.2426
2023-11-28 00:37:15,963 - mmseg - INFO - Iter [157950/160000]	lr: 7.691e-07, eta: 0:27:08, time: 0.798, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1629, decode.acc_seg: 93.2486, aux.loss_ce: 0.0799, aux.acc_seg: 92.0382, loss: 0.2428
2023-11-28 00:37:54,126 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 00:37:54,126 - mmseg - INFO - Iter [158000/160000]	lr: 7.504e-07, eta: 0:26:29, time: 0.763, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1652, decode.acc_seg: 92.9216, aux.loss_ce: 0.0810, aux.acc_seg: 91.5652, loss: 0.2462
2023-11-28 00:38:34,339 - mmseg - INFO - Iter [158050/160000]	lr: 7.316e-07, eta: 0:25:49, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1612, decode.acc_seg: 93.0952, aux.loss_ce: 0.0801, aux.acc_seg: 91.7596, loss: 0.2413
2023-11-28 00:39:13,960 - mmseg - INFO - Iter [158100/160000]	lr: 7.129e-07, eta: 0:25:09, time: 0.792, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1654, decode.acc_seg: 93.0542, aux.loss_ce: 0.0827, aux.acc_seg: 91.5840, loss: 0.2481
2023-11-28 00:39:51,594 - mmseg - INFO - Iter [158150/160000]	lr: 6.941e-07, eta: 0:24:29, time: 0.754, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1591, decode.acc_seg: 93.2970, aux.loss_ce: 0.0776, aux.acc_seg: 92.0242, loss: 0.2367
2023-11-28 00:40:30,944 - mmseg - INFO - Iter [158200/160000]	lr: 6.754e-07, eta: 0:23:50, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1766, decode.acc_seg: 92.4023, aux.loss_ce: 0.0876, aux.acc_seg: 90.9875, loss: 0.2642
2023-11-28 00:41:09,767 - mmseg - INFO - Iter [158250/160000]	lr: 6.566e-07, eta: 0:23:10, time: 0.776, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1544, decode.acc_seg: 93.2829, aux.loss_ce: 0.0771, aux.acc_seg: 91.9713, loss: 0.2315
2023-11-28 00:41:50,526 - mmseg - INFO - Iter [158300/160000]	lr: 6.379e-07, eta: 0:22:30, time: 0.815, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1614, decode.acc_seg: 92.9553, aux.loss_ce: 0.0809, aux.acc_seg: 91.6054, loss: 0.2423
2023-11-28 00:42:31,429 - mmseg - INFO - Iter [158350/160000]	lr: 6.191e-07, eta: 0:21:50, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1601, decode.acc_seg: 93.1847, aux.loss_ce: 0.0808, aux.acc_seg: 91.8233, loss: 0.2409
2023-11-28 00:43:12,120 - mmseg - INFO - Iter [158400/160000]	lr: 6.004e-07, eta: 0:21:11, time: 0.814, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1560, decode.acc_seg: 93.1762, aux.loss_ce: 0.0781, aux.acc_seg: 91.8356, loss: 0.2340
2023-11-28 00:43:52,132 - mmseg - INFO - Iter [158450/160000]	lr: 5.816e-07, eta: 0:20:31, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1592, decode.acc_seg: 92.9315, aux.loss_ce: 0.0798, aux.acc_seg: 91.4203, loss: 0.2390
2023-11-28 00:44:31,536 - mmseg - INFO - Iter [158500/160000]	lr: 5.629e-07, eta: 0:19:51, time: 0.789, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1643, decode.acc_seg: 92.9475, aux.loss_ce: 0.0806, aux.acc_seg: 91.5465, loss: 0.2449
2023-11-28 00:45:09,430 - mmseg - INFO - Iter [158550/160000]	lr: 5.441e-07, eta: 0:19:12, time: 0.758, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1596, decode.acc_seg: 93.1819, aux.loss_ce: 0.0794, aux.acc_seg: 91.8860, loss: 0.2389
2023-11-28 00:45:48,420 - mmseg - INFO - Iter [158600/160000]	lr: 5.254e-07, eta: 0:18:32, time: 0.779, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1583, decode.acc_seg: 93.0350, aux.loss_ce: 0.0788, aux.acc_seg: 91.7657, loss: 0.2371
2023-11-28 00:46:27,695 - mmseg - INFO - Iter [158650/160000]	lr: 5.066e-07, eta: 0:17:52, time: 0.786, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.5332, aux.loss_ce: 0.0861, aux.acc_seg: 91.0937, loss: 0.2555
2023-11-28 00:47:07,856 - mmseg - INFO - Iter [158700/160000]	lr: 4.879e-07, eta: 0:17:12, time: 0.803, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1674, decode.acc_seg: 92.6704, aux.loss_ce: 0.0819, aux.acc_seg: 91.4193, loss: 0.2493
2023-11-28 00:47:46,748 - mmseg - INFO - Iter [158750/160000]	lr: 4.691e-07, eta: 0:16:33, time: 0.778, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.9253, aux.loss_ce: 0.0822, aux.acc_seg: 91.6298, loss: 0.2468
2023-11-28 00:48:28,295 - mmseg - INFO - Iter [158800/160000]	lr: 4.504e-07, eta: 0:15:53, time: 0.831, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1633, decode.acc_seg: 92.9275, aux.loss_ce: 0.0814, aux.acc_seg: 91.5999, loss: 0.2446
2023-11-28 00:49:09,189 - mmseg - INFO - Iter [158850/160000]	lr: 4.316e-07, eta: 0:15:13, time: 0.818, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1661, decode.acc_seg: 92.9379, aux.loss_ce: 0.0822, aux.acc_seg: 91.5827, loss: 0.2483
2023-11-28 00:49:48,589 - mmseg - INFO - Iter [158900/160000]	lr: 4.129e-07, eta: 0:14:33, time: 0.788, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1659, decode.acc_seg: 92.7749, aux.loss_ce: 0.0830, aux.acc_seg: 91.3122, loss: 0.2489
2023-11-28 00:50:28,616 - mmseg - INFO - Iter [158950/160000]	lr: 3.941e-07, eta: 0:13:54, time: 0.801, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.6906, aux.loss_ce: 0.0810, aux.acc_seg: 91.3560, loss: 0.2456
2023-11-28 00:51:08,541 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 00:51:08,541 - mmseg - INFO - Iter [159000/160000]	lr: 3.754e-07, eta: 0:13:14, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1695, decode.acc_seg: 92.8725, aux.loss_ce: 0.0863, aux.acc_seg: 91.3794, loss: 0.2558
2023-11-28 00:51:47,807 - mmseg - INFO - Iter [159050/160000]	lr: 3.566e-07, eta: 0:12:34, time: 0.785, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1588, decode.acc_seg: 93.0743, aux.loss_ce: 0.0784, aux.acc_seg: 91.7476, loss: 0.2371
2023-11-28 00:52:25,839 - mmseg - INFO - Iter [159100/160000]	lr: 3.379e-07, eta: 0:11:55, time: 0.762, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1616, decode.acc_seg: 92.8612, aux.loss_ce: 0.0804, aux.acc_seg: 91.5795, loss: 0.2420
2023-11-28 00:53:06,735 - mmseg - INFO - Iter [159150/160000]	lr: 3.191e-07, eta: 0:11:15, time: 0.818, data_time: 0.052, memory: 21695, decode.loss_ce: 0.1631, decode.acc_seg: 93.0243, aux.loss_ce: 0.0814, aux.acc_seg: 91.7230, loss: 0.2445
2023-11-28 00:53:43,545 - mmseg - INFO - Iter [159200/160000]	lr: 3.004e-07, eta: 0:10:35, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1591, decode.acc_seg: 92.9686, aux.loss_ce: 0.0793, aux.acc_seg: 91.6770, loss: 0.2383
2023-11-28 00:54:20,465 - mmseg - INFO - Iter [159250/160000]	lr: 2.816e-07, eta: 0:09:55, time: 0.738, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1605, decode.acc_seg: 93.2048, aux.loss_ce: 0.0796, aux.acc_seg: 91.8203, loss: 0.2402
2023-11-28 00:55:00,564 - mmseg - INFO - Iter [159300/160000]	lr: 2.629e-07, eta: 0:09:16, time: 0.802, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1641, decode.acc_seg: 92.9590, aux.loss_ce: 0.0825, aux.acc_seg: 91.4257, loss: 0.2466
2023-11-28 00:55:40,200 - mmseg - INFO - Iter [159350/160000]	lr: 2.441e-07, eta: 0:08:36, time: 0.791, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1574, decode.acc_seg: 93.2715, aux.loss_ce: 0.0787, aux.acc_seg: 91.8787, loss: 0.2361
2023-11-28 00:56:19,501 - mmseg - INFO - Iter [159400/160000]	lr: 2.254e-07, eta: 0:07:56, time: 0.787, data_time: 0.012, memory: 21695, decode.loss_ce: 0.1623, decode.acc_seg: 92.8087, aux.loss_ce: 0.0810, aux.acc_seg: 91.3438, loss: 0.2433
2023-11-28 00:56:58,200 - mmseg - INFO - Iter [159450/160000]	lr: 2.066e-07, eta: 0:07:16, time: 0.773, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1674, decode.acc_seg: 92.9292, aux.loss_ce: 0.0815, aux.acc_seg: 91.7516, loss: 0.2489
2023-11-28 00:57:38,410 - mmseg - INFO - Iter [159500/160000]	lr: 1.879e-07, eta: 0:06:37, time: 0.804, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1575, decode.acc_seg: 93.2205, aux.loss_ce: 0.0799, aux.acc_seg: 91.7719, loss: 0.2374
2023-11-28 00:58:18,644 - mmseg - INFO - Iter [159550/160000]	lr: 1.691e-07, eta: 0:05:57, time: 0.805, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1571, decode.acc_seg: 93.1022, aux.loss_ce: 0.0785, aux.acc_seg: 91.7251, loss: 0.2356
2023-11-28 00:58:57,068 - mmseg - INFO - Iter [159600/160000]	lr: 1.504e-07, eta: 0:05:17, time: 0.769, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1646, decode.acc_seg: 92.8446, aux.loss_ce: 0.0828, aux.acc_seg: 91.3316, loss: 0.2473
2023-11-28 00:59:36,295 - mmseg - INFO - Iter [159650/160000]	lr: 1.316e-07, eta: 0:04:38, time: 0.783, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1606, decode.acc_seg: 93.1654, aux.loss_ce: 0.0806, aux.acc_seg: 91.6731, loss: 0.2412
2023-11-28 01:00:14,163 - mmseg - INFO - Iter [159700/160000]	lr: 1.129e-07, eta: 0:03:58, time: 0.759, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1593, decode.acc_seg: 92.8462, aux.loss_ce: 0.0799, aux.acc_seg: 91.4854, loss: 0.2392
2023-11-28 01:00:50,989 - mmseg - INFO - Iter [159750/160000]	lr: 9.413e-08, eta: 0:03:18, time: 0.736, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1653, decode.acc_seg: 92.8670, aux.loss_ce: 0.0831, aux.acc_seg: 91.3370, loss: 0.2485
2023-11-28 01:01:30,079 - mmseg - INFO - Iter [159800/160000]	lr: 7.537e-08, eta: 0:02:38, time: 0.782, data_time: 0.010, memory: 21695, decode.loss_ce: 0.1626, decode.acc_seg: 93.0394, aux.loss_ce: 0.0814, aux.acc_seg: 91.5478, loss: 0.2440
2023-11-28 01:02:10,149 - mmseg - INFO - Iter [159850/160000]	lr: 5.663e-08, eta: 0:01:59, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1558, decode.acc_seg: 93.2862, aux.loss_ce: 0.0773, aux.acc_seg: 92.0409, loss: 0.2332
2023-11-28 01:02:50,163 - mmseg - INFO - Iter [159900/160000]	lr: 3.787e-08, eta: 0:01:19, time: 0.800, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1586, decode.acc_seg: 93.0262, aux.loss_ce: 0.0800, aux.acc_seg: 91.6361, loss: 0.2386
2023-11-28 01:03:30,062 - mmseg - INFO - Iter [159950/160000]	lr: 1.913e-08, eta: 0:00:39, time: 0.798, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1675, decode.acc_seg: 92.9926, aux.loss_ce: 0.0826, aux.acc_seg: 91.6312, loss: 0.2500
2023-11-28 01:04:09,710 - mmseg - INFO - Saving checkpoint at 160000 iterations
2023-11-28 01:04:14,905 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 01:04:14,905 - mmseg - INFO - Iter [160000/160000]	lr: 3.750e-10, eta: 0:00:00, time: 0.898, data_time: 0.011, memory: 21695, decode.loss_ce: 0.1626, decode.acc_seg: 93.1396, aux.loss_ce: 0.0810, aux.acc_seg: 91.8514, loss: 0.2436
2023-11-28 01:05:44,570 - mmseg - INFO - per class results:
2023-11-28 01:05:44,583 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 78.26 | 89.24 |
|       building      | 80.91 |  90.5 |
|         sky         | 94.54 | 97.69 |
|        floor        | 82.22 | 91.38 |
|         tree        | 75.56 | 87.51 |
|       ceiling       | 85.19 | 92.54 |
|         road        | 85.08 | 89.97 |
|         bed         | 89.69 | 95.77 |
|      windowpane     | 62.43 | 79.75 |
|        grass        | 64.85 | 81.59 |
|       cabinet       | 64.69 | 76.35 |
|       sidewalk      | 69.59 | 84.18 |
|        person       | 82.44 | 93.32 |
|        earth        | 37.01 | 51.22 |
|         door        | 51.76 | 64.14 |
|        table        | 61.96 | 76.78 |
|       mountain      |  55.7 | 69.78 |
|        plant        |  53.9 | 66.35 |
|       curtain       |  76.0 |  87.9 |
|        chair        | 58.85 | 71.57 |
|         car         | 85.41 |  93.2 |
|        water        | 63.66 | 81.72 |
|       painting      | 74.02 | 90.55 |
|         sofa        | 65.35 | 82.14 |
|        shelf        | 44.13 | 61.32 |
|        house        | 38.06 | 57.33 |
|         sea         | 61.09 | 77.14 |
|        mirror       | 70.11 | 76.91 |
|         rug         | 55.63 | 66.23 |
|        field        | 26.76 | 41.07 |
|       armchair      | 42.65 | 63.62 |
|         seat        | 61.27 | 83.87 |
|        fence        | 47.71 |  60.9 |
|         desk        | 51.58 | 70.84 |
|         rock        | 49.28 | 70.99 |
|       wardrobe      |  51.4 | 65.93 |
|         lamp        | 66.35 | 77.39 |
|       bathtub       | 80.17 | 86.09 |
|       railing       | 37.92 | 51.88 |
|       cushion       | 60.59 | 74.15 |
|         base        | 32.53 | 39.21 |
|         box         | 30.99 | 40.33 |
|        column       | 44.26 | 53.25 |
|      signboard      | 40.18 | 54.04 |
|   chest of drawers  | 49.49 | 65.45 |
|       counter       | 35.65 | 41.72 |
|         sand        |  47.2 | 70.97 |
|         sink        | 72.34 |  80.9 |
|      skyscraper     | 41.84 |  49.8 |
|      fireplace      | 72.94 | 88.72 |
|     refrigerator    | 77.51 | 87.29 |
|      grandstand     | 46.51 | 73.33 |
|         path        |  27.9 | 41.77 |
|        stairs       | 31.65 | 44.82 |
|        runway       | 69.12 | 91.02 |
|         case        |  60.3 | 72.09 |
|      pool table     | 93.25 | 96.62 |
|        pillow       |  62.2 | 73.71 |
|     screen door     | 66.84 | 76.19 |
|       stairway      | 31.01 | 37.24 |
|        river        | 17.63 | 26.63 |
|        bridge       | 75.63 | 84.43 |
|       bookcase      |  40.8 | 61.78 |
|        blind        | 41.17 | 45.95 |
|     coffee table    | 56.91 | 81.59 |
|        toilet       |  81.7 | 90.92 |
|        flower       | 43.66 | 59.41 |
|         book        | 44.29 |  68.1 |
|         hill        |  6.55 |  9.16 |
|        bench        | 47.89 | 53.68 |
|      countertop     |  52.6 | 77.88 |
|        stove        | 72.88 | 81.17 |
|         palm        | 54.43 |  78.1 |
|    kitchen island   | 47.31 | 82.28 |
|       computer      | 66.83 | 77.75 |
|     swivel chair    | 48.49 | 67.62 |
|         boat        | 47.53 | 54.99 |
|         bar         | 46.62 | 65.08 |
|    arcade machine   | 61.28 | 64.84 |
|        hovel        | 46.89 | 66.94 |
|         bus         | 84.06 | 96.89 |
|        towel        | 68.13 | 79.83 |
|        light        |  56.5 | 63.68 |
|        truck        | 40.87 |  49.6 |
|        tower        |  19.6 | 34.27 |
|      chandelier     | 66.69 | 84.96 |
|        awning       | 28.32 | 36.92 |
|     streetlight     | 29.04 | 37.32 |
|        booth        |  49.7 | 51.37 |
| television receiver | 68.98 | 80.48 |
|       airplane      | 59.97 | 69.48 |
|      dirt track     |  5.93 | 10.74 |
|       apparel       | 46.42 | 62.39 |
|         pole        | 27.72 | 38.48 |
|         land        |  5.13 |  7.16 |
|      bannister      | 16.33 | 21.98 |
|      escalator      | 34.46 | 47.12 |
|       ottoman       | 48.23 | 58.64 |
|        bottle       | 36.37 | 62.22 |
|        buffet       |  46.1 | 55.73 |
|        poster       | 34.49 | 43.17 |
|        stage        | 17.94 | 27.13 |
|         van         | 42.72 | 59.88 |
|         ship        | 38.94 | 61.25 |
|       fountain      | 21.46 | 21.73 |
|    conveyer belt    | 72.71 | 89.28 |
|        canopy       | 14.18 | 20.52 |
|        washer       | 71.56 | 76.79 |
|      plaything      | 33.36 | 44.32 |
|    swimming pool    | 66.47 | 90.08 |
|        stool        | 44.42 | 55.79 |
|        barrel       | 55.75 | 69.87 |
|        basket       | 37.99 | 51.44 |
|      waterfall      | 63.03 | 88.67 |
|         tent        | 94.03 | 98.95 |
|         bag         | 14.51 | 17.97 |
|       minibike      | 72.14 |  85.1 |
|        cradle       | 79.56 | 90.82 |
|         oven        | 49.54 | 59.09 |
|         ball        | 47.74 | 56.92 |
|         food        | 42.54 |  48.9 |
|         step        | 22.03 | 24.84 |
|         tank        | 44.41 | 51.13 |
|      trade name     | 27.79 | 33.06 |
|      microwave      | 83.65 | 93.75 |
|         pot         | 43.73 | 50.85 |
|        animal       | 59.51 | 62.79 |
|       bicycle       | 57.84 | 81.23 |
|         lake        | 66.38 | 67.34 |
|      dishwasher     | 69.57 |  77.9 |
|        screen       | 66.97 | 87.35 |
|       blanket       | 14.75 | 18.28 |
|      sculpture      | 56.21 | 77.94 |
|         hood        | 67.31 | 73.16 |
|        sconce       | 48.84 | 58.31 |
|         vase        | 41.23 | 57.15 |
|    traffic light    | 35.93 | 54.72 |
|         tray        | 13.04 |  19.9 |
|        ashcan       | 37.22 | 50.11 |
|         fan         | 63.97 | 76.48 |
|         pier        | 59.78 | 78.44 |
|      crt screen     |  6.51 | 19.33 |
|        plate        | 53.52 | 71.77 |
|       monitor       |  8.96 | 11.67 |
|    bulletin board   | 49.71 | 63.11 |
|        shower       |  6.52 |  7.32 |
|       radiator      | 69.21 | 74.41 |
|        glass        | 16.41 | 17.35 |
|        clock        | 37.12 |  49.7 |
|         flag        | 52.03 | 57.88 |
+---------------------+-------+-------+
2023-11-28 01:05:44,583 - mmseg - INFO - Summary:
2023-11-28 01:05:44,583 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.65 | 51.42 | 63.48 |
+-------+-------+-------+
2023-11-28 01:05:44,704 - mmseg - INFO - Exp name: upernet_512_debi_base_160k.py
2023-11-28 01:05:44,705 - mmseg - INFO - Iter(val) [250]	aAcc: 0.8365, mIoU: 0.5142, mAcc: 0.6348, IoU.wall: 0.7826, IoU.building: 0.8091, IoU.sky: 0.9454, IoU.floor: 0.8222, IoU.tree: 0.7556, IoU.ceiling: 0.8519, IoU.road: 0.8508, IoU.bed : 0.8969, IoU.windowpane: 0.6243, IoU.grass: 0.6485, IoU.cabinet: 0.6469, IoU.sidewalk: 0.6959, IoU.person: 0.8244, IoU.earth: 0.3701, IoU.door: 0.5176, IoU.table: 0.6196, IoU.mountain: 0.5570, IoU.plant: 0.5390, IoU.curtain: 0.7600, IoU.chair: 0.5885, IoU.car: 0.8541, IoU.water: 0.6366, IoU.painting: 0.7402, IoU.sofa: 0.6535, IoU.shelf: 0.4413, IoU.house: 0.3806, IoU.sea: 0.6109, IoU.mirror: 0.7011, IoU.rug: 0.5563, IoU.field: 0.2676, IoU.armchair: 0.4265, IoU.seat: 0.6127, IoU.fence: 0.4771, IoU.desk: 0.5158, IoU.rock: 0.4928, IoU.wardrobe: 0.5140, IoU.lamp: 0.6635, IoU.bathtub: 0.8017, IoU.railing: 0.3792, IoU.cushion: 0.6059, IoU.base: 0.3253, IoU.box: 0.3099, IoU.column: 0.4426, IoU.signboard: 0.4018, IoU.chest of drawers: 0.4949, IoU.counter: 0.3565, IoU.sand: 0.4720, IoU.sink: 0.7234, IoU.skyscraper: 0.4184, IoU.fireplace: 0.7294, IoU.refrigerator: 0.7751, IoU.grandstand: 0.4651, IoU.path: 0.2790, IoU.stairs: 0.3165, IoU.runway: 0.6912, IoU.case: 0.6030, IoU.pool table: 0.9325, IoU.pillow: 0.6220, IoU.screen door: 0.6684, IoU.stairway: 0.3101, IoU.river: 0.1763, IoU.bridge: 0.7563, IoU.bookcase: 0.4080, IoU.blind: 0.4117, IoU.coffee table: 0.5691, IoU.toilet: 0.8170, IoU.flower: 0.4366, IoU.book: 0.4429, IoU.hill: 0.0655, IoU.bench: 0.4789, IoU.countertop: 0.5260, IoU.stove: 0.7288, IoU.palm: 0.5443, IoU.kitchen island: 0.4731, IoU.computer: 0.6683, IoU.swivel chair: 0.4849, IoU.boat: 0.4753, IoU.bar: 0.4662, IoU.arcade machine: 0.6128, IoU.hovel: 0.4689, IoU.bus: 0.8406, IoU.towel: 0.6813, IoU.light: 0.5650, IoU.truck: 0.4087, IoU.tower: 0.1960, IoU.chandelier: 0.6669, IoU.awning: 0.2832, IoU.streetlight: 0.2904, IoU.booth: 0.4970, IoU.television receiver: 0.6898, IoU.airplane: 0.5997, IoU.dirt track: 0.0593, IoU.apparel: 0.4642, IoU.pole: 0.2772, IoU.land: 0.0513, IoU.bannister: 0.1633, IoU.escalator: 0.3446, IoU.ottoman: 0.4823, IoU.bottle: 0.3637, IoU.buffet: 0.4610, IoU.poster: 0.3449, IoU.stage: 0.1794, IoU.van: 0.4272, IoU.ship: 0.3894, IoU.fountain: 0.2146, IoU.conveyer belt: 0.7271, IoU.canopy: 0.1418, IoU.washer: 0.7156, IoU.plaything: 0.3336, IoU.swimming pool: 0.6647, IoU.stool: 0.4442, IoU.barrel: 0.5575, IoU.basket: 0.3799, IoU.waterfall: 0.6303, IoU.tent: 0.9403, IoU.bag: 0.1451, IoU.minibike: 0.7214, IoU.cradle: 0.7956, IoU.oven: 0.4954, IoU.ball: 0.4774, IoU.food: 0.4254, IoU.step: 0.2203, IoU.tank: 0.4441, IoU.trade name: 0.2779, IoU.microwave: 0.8365, IoU.pot: 0.4373, IoU.animal: 0.5951, IoU.bicycle: 0.5784, IoU.lake: 0.6638, IoU.dishwasher: 0.6957, IoU.screen: 0.6697, IoU.blanket: 0.1475, IoU.sculpture: 0.5621, IoU.hood: 0.6731, IoU.sconce: 0.4884, IoU.vase: 0.4123, IoU.traffic light: 0.3593, IoU.tray: 0.1304, IoU.ashcan: 0.3722, IoU.fan: 0.6397, IoU.pier: 0.5978, IoU.crt screen: 0.0651, IoU.plate: 0.5352, IoU.monitor: 0.0896, IoU.bulletin board: 0.4971, IoU.shower: 0.0652, IoU.radiator: 0.6921, IoU.glass: 0.1641, IoU.clock: 0.3712, IoU.flag: 0.5203, Acc.wall: 0.8924, Acc.building: 0.9050, Acc.sky: 0.9769, Acc.floor: 0.9138, Acc.tree: 0.8751, Acc.ceiling: 0.9254, Acc.road: 0.8997, Acc.bed : 0.9577, Acc.windowpane: 0.7975, Acc.grass: 0.8159, Acc.cabinet: 0.7635, Acc.sidewalk: 0.8418, Acc.person: 0.9332, Acc.earth: 0.5122, Acc.door: 0.6414, Acc.table: 0.7678, Acc.mountain: 0.6978, Acc.plant: 0.6635, Acc.curtain: 0.8790, Acc.chair: 0.7157, Acc.car: 0.9320, Acc.water: 0.8172, Acc.painting: 0.9055, Acc.sofa: 0.8214, Acc.shelf: 0.6132, Acc.house: 0.5733, Acc.sea: 0.7714, Acc.mirror: 0.7691, Acc.rug: 0.6623, Acc.field: 0.4107, Acc.armchair: 0.6362, Acc.seat: 0.8387, Acc.fence: 0.6090, Acc.desk: 0.7084, Acc.rock: 0.7099, Acc.wardrobe: 0.6593, Acc.lamp: 0.7739, Acc.bathtub: 0.8609, Acc.railing: 0.5188, Acc.cushion: 0.7415, Acc.base: 0.3921, Acc.box: 0.4033, Acc.column: 0.5325, Acc.signboard: 0.5404, Acc.chest of drawers: 0.6545, Acc.counter: 0.4172, Acc.sand: 0.7097, Acc.sink: 0.8090, Acc.skyscraper: 0.4980, Acc.fireplace: 0.8872, Acc.refrigerator: 0.8729, Acc.grandstand: 0.7333, Acc.path: 0.4177, Acc.stairs: 0.4482, Acc.runway: 0.9102, Acc.case: 0.7209, Acc.pool table: 0.9662, Acc.pillow: 0.7371, Acc.screen door: 0.7619, Acc.stairway: 0.3724, Acc.river: 0.2663, Acc.bridge: 0.8443, Acc.bookcase: 0.6178, Acc.blind: 0.4595, Acc.coffee table: 0.8159, Acc.toilet: 0.9092, Acc.flower: 0.5941, Acc.book: 0.6810, Acc.hill: 0.0916, Acc.bench: 0.5368, Acc.countertop: 0.7788, Acc.stove: 0.8117, Acc.palm: 0.7810, Acc.kitchen island: 0.8228, Acc.computer: 0.7775, Acc.swivel chair: 0.6762, Acc.boat: 0.5499, Acc.bar: 0.6508, Acc.arcade machine: 0.6484, Acc.hovel: 0.6694, Acc.bus: 0.9689, Acc.towel: 0.7983, Acc.light: 0.6368, Acc.truck: 0.4960, Acc.tower: 0.3427, Acc.chandelier: 0.8496, Acc.awning: 0.3692, Acc.streetlight: 0.3732, Acc.booth: 0.5137, Acc.television receiver: 0.8048, Acc.airplane: 0.6948, Acc.dirt track: 0.1074, Acc.apparel: 0.6239, Acc.pole: 0.3848, Acc.land: 0.0716, Acc.bannister: 0.2198, Acc.escalator: 0.4712, Acc.ottoman: 0.5864, Acc.bottle: 0.6222, Acc.buffet: 0.5573, Acc.poster: 0.4317, Acc.stage: 0.2713, Acc.van: 0.5988, Acc.ship: 0.6125, Acc.fountain: 0.2173, Acc.conveyer belt: 0.8928, Acc.canopy: 0.2052, Acc.washer: 0.7679, Acc.plaything: 0.4432, Acc.swimming pool: 0.9008, Acc.stool: 0.5579, Acc.barrel: 0.6987, Acc.basket: 0.5144, Acc.waterfall: 0.8867, Acc.tent: 0.9895, Acc.bag: 0.1797, Acc.minibike: 0.8510, Acc.cradle: 0.9082, Acc.oven: 0.5909, Acc.ball: 0.5692, Acc.food: 0.4890, Acc.step: 0.2484, Acc.tank: 0.5113, Acc.trade name: 0.3306, Acc.microwave: 0.9375, Acc.pot: 0.5085, Acc.animal: 0.6279, Acc.bicycle: 0.8123, Acc.lake: 0.6734, Acc.dishwasher: 0.7790, Acc.screen: 0.8735, Acc.blanket: 0.1828, Acc.sculpture: 0.7794, Acc.hood: 0.7316, Acc.sconce: 0.5831, Acc.vase: 0.5715, Acc.traffic light: 0.5472, Acc.tray: 0.1990, Acc.ashcan: 0.5011, Acc.fan: 0.7648, Acc.pier: 0.7844, Acc.crt screen: 0.1933, Acc.plate: 0.7177, Acc.monitor: 0.1167, Acc.bulletin board: 0.6311, Acc.shower: 0.0732, Acc.radiator: 0.7441, Acc.glass: 0.1735, Acc.clock: 0.4970, Acc.flag: 0.5788
